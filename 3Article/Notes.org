bibliography:../Biblio/biblio.bib

Mes notes pour ce projet ! 

* Tasks
** DONE Test
   CLOSED: [2017-01-16 lun. 17:35]
  Test de capture
** DONE Learn Rnotebook
   CLOSED: [2017-01-17 mar. 09:50]
   Il y a quand même quelque bug... pour regler la taile des fig il faut le
   mettre dans le chunk de setup il semblerait !!
   On Ne peut pas view in github... on doit ddl avant ! 
   
   Custum =Rmarkdown= html output: http://rmarkdown.rstudio.com/html_document_format.html
   Custum example: 
#+BEGIN_SRC R
---
title: "LFMM with missing value"
author: "kevin caye"
date: "16 janvier 2017"
output: 
  html_notebook:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    theme: journal
    highlight: tango
---
#+END_SRC
** DONE Les questions qui restent en suspet le <2017-01-20 Ven> et a faire la semaine prochaine
   CLOSED: [2017-01-31 mar. 17:21]
   - [X] Pk mon calcule de B.sigma2 est mauvais ?
   - [X] Reussir a mettre lasso dans les graphes precision-recall
   - [X] Visualiser l'évolution de la precision en function du lambda dans le
     ridge !!
   - [X] Pk dans file:./LabNotebook/AlternatedVsAnaliticRidge.nb.html lfmm ridge
     et lfmm analytics ne donne pas le même resultat sur le premier exemple ! Je
     pense que c'est parce que je ne laisse pas l'algo aller a assez loin ! Pour
     le papier il faut que les deux donnent la même chose ! Sinon j'ai aucun
     espoir d'avoir des resultats de convergeance !
   - [X] C'est en dernier mais c'est le plus important. On va se trouver
     quelques jeux données réels. On en parlera avec OF a la réunion !!
** DONE Le choix du lambda dans ridge
   CLOSED: [2017-01-31 mar. 17:21]
   - [X] cross validation (on peut le faire mais ne pas l'evaluer)
   - [X] genre de empirical bayes (lm et on regarde la variance des B)
   - [X] pour des raisons numerique d'inverse de P
** DONE EWAS for the article
   CLOSED: [2017-02-03 ven. 11:31] DEADLINE: <2017-01-25 mer.>
  - [X] add Refactor au methods
  - [X] get data (see my mails)
  - [X] Comparison with the paper result !!
    Il va falloir que je refasse leur resultats si je veux ma comparer a des
    EWAS. Il faudra aussi que je me compare sur leur simultation. Je pense que
    leur méthode on pour but d'apprendre la repartition cellulaire alors que moi
    c'est une structure de fond quelconque... A méditer ! 

** DONE L'avantage du lasso par rapport au ridge ?
   CLOSED: [2017-01-31 mar. 17:21]
   - [X] verifier l'influence de =sparse.prop=. Je m'attends a ce que si il est
     trop bas on fasse comme PCA + lm.
   - [X] trouver des cas de figure ou lasso meilleur ! Pour le moment ca faire
     toujours la même chose !
** DONE GSE42861 experience
   CLOSED: [2017-01-27 ven. 15:33]
   GO !!!
*** DONE La vraie experience !
    CLOSED: [2017-02-16 jeu. 15:32]
    On va faire le même préprocessing que dans cite:Zou_2014 et verifier qu'on
    trouve bien la même chose que dans la méthode reference based ! C'est ce
    qu'il font dans cite:Zou_2014,Rahmani_2016. Idéalement il faudrait que
    j'arrive a reproduire la méthode dites reference-based.
    
    *ERATUM* : IL FAUT que j'arrive a faire la méthodes dite refecence-based si
    je veux me comparer !!! Je m'en fous des autres !!
**** Conclusion
     En fait non, je vais appliquer ma méthode et comparer à leur résultat et si
     ca ne marche pas je prendrais un autre EWAS ! 
    
** DONE HGDP experiment
   CLOSED: [2017-02-01 mer. 15:33]
  
   J'ai commencé ./Article3Package/R/HGDP_function.R et
   ./Article3Package/tests/testthat/test_HGDP.R !!
** DONE Checkpoint et tache a faire le <2017-01-31 mar.>
   CLOSED: [2017-02-16 jeu. 15:33]
   Je pense que je vais abandonner les algo alterné avec le lasso, ca ne donne
   pas de bon résultats. Je vais essayer un algo qui alterne du lfmm ridge, en
   plus je pourrais peut être le justifier avec les resultats du papier
   cite:mazumder10_spect_regul_algor_learn_large_incom_matric. L'utilité d'un
   algo pour les missing data n'est pas a remettre en cause je pense ! Enfin
   faudrais que j'y reflechisse mais lfmm alterné PCA + ridge ne donne pas les
   memes resultats que le lfmmRidge... De toute facon si j'alterne lfmmRidge ca
   regle le pb !!

   - [ ] lfmm ridge et laternance de lm ridge et PCA ne donne pas la même chose,
     pk ?
   - [X] on a montré que le choix du lambda a une importance dans lfmm ridge,
     mais comment le choisir ? trouver un critere !!!
*** Conclusion
    Je vais voir le point non fait plus tard, avec la théorie.

** TODO On scale les datas ou pas ? 
   Ca change quoi de scale les données ?
   Voir dans l'acp ce qui est recommandé. 
** TODO Simulations de data from true dataset
   Faire des simulation à la facon d'of ! C'est a dire on va simuler des locus

   $$ G_j = Bj X + E $$ 
   
   Où E est un bruit avec la même corrélation que dans les data observées. On
   peut mettre un lien logistic a voir. Le problème était que ca faisait sortir
   un groupe dans l'acp, je comprends pas pk ! A voir ! 
** TODO GWAS method
   - Il me faut des méthodes de GWAS (celle de cite:Zhou_2013 a l'aire bien !)
   - On va faire des simulations de phénotype aussi, a réfléchire ! 
** TODO Un critère de stabilité 
   Dans cite:article_Leek_Storey_2007 il dit que SVA permet de stabilisé le
   ranking des gênes. Donc un critère de reprudicibilité est a voir.
   
   Je parle de ce problem dans [[ref:lambda_model_choice][cette note.]]
   
* 2017
** 2017-01 janvier
*** 2017-01-16 lundi
**** Test de capture d'un truc
   Entered on [2017-01-16 lun. 17:35]
   Test
**** R notebook
   Entered on [2017-01-16 lun. 17:38]
   
   Je vais arreter d'utiliser Bookdown, ca rend mon workflow trop compliqué !!
   Par contre R notebook semble le plus pratique !!
**** Labnotebook
   Entered on [2017-01-16 lun. 17:47]
   
   Only Rnotebook and I git =.nb.html= to capture results !!
*** 2017-01-17 mardi
**** Data with missing value                                     :LaNotebook:
     Entered on [2017-01-17 mar. 09:50]
   Le but est de montrer qu'on est meilleur avec la technique alterné !!
   file:./LabNotebook/MissingValue.nb.html
   En gros ca montre bien ce que je veux. Après il y a des cas ou ca merde
   surtout avec les missing values pas uniformément réparti... Je sais pas
   pourquoi j'ai pensé que ca serait plus dure dans ce cas.
   Demain on continue le papier :D et on fait des simulations a partir de jeux
   de données réel. 
   On va aussi faire les plots des data : cf mon cahier le
   [2017-01-17 mar.].
   Et il reste un mistere ! Pk le lambda de la reg ridge ne change rien ?
   
**** On ecrit l'article ù*$ù
   Entered on [2017-01-17 mar. 14:20] Bon l'objectif de l'article c'est de
   proposé une méthode d'association à facteurs lattents basé sur de un problème
   d'optimisation.
   C'est un modèle récurent car présent partout ...
   Nous on propose une méthode efficace avec des solutions analytics et un
   algorithme alterné dans le cas de présence de missing values.
   On montre que c'est bien qualibré, c'est rapide et ca marche sur des
   GWAS/EWAS.
*** 2017-01-18 mercredi
**** Bilan du mercredi [2017-01-18 mer.] 
   Entered on [2017-01-18 mer. 17:34]
   J'ai pas percé le mystère du lambda qui sert a rien dans lfmm Ridge. Par
   contre j'ai un nouveau sample de données a partir de vrai dataset. J'ai
   essayé de faire en sorte que les données en sortir resemble le plus possible
   a celle en entré. LFMM ridge fonctionne bien sur celle-ci aussi. Surtout
   quand la part de variance expliqué par X pour les outlier est forte =rho=0.9=! Dans ce
   cas PCA+lm se plante complet.
***** DONE Pour demain
      CLOSED: [2017-01-19 jeu. 10:31]
      - gerer les cas ou la variance est null pour eviter les zscore null
      - verifier la structure de covariance des données simulé (des indiv et des
        locus)
      - Percer le mystere du lambda
      - faire des simulation a la facon de OF, voir mon cahier 
     A demain :D
*** 2017-01-19 jeudi
**** Comparison of analytic and alternated lfmm                  :LaNotebook:
   Entered on [2017-01-19 jeu. 10:54]
   file:./LabNotebook/AlternatedVsAnaliticRidge.nb.html
   Je veux voir si ont a bien les mêmes solutions !! 
   et percer le mystere du lambda :D
   J'ai plusieurs problèmes:
   - le calcul du sigma dans le cas ridge donne des résultats très petit
     parfois ! pk ?
   - J'ai mis lambda = 0 dans lfmm ridge et alternatedSVD et la recalibration
     GIF ne marche plus !!
   - il s'emblerais finalement que lambda est un effet !!
   On va le mêtre en évidence et essayer de trouver comment le choisir !
**** Choix du lambda dans lfmm ridge                             :LaNotebook:
   Entered on [2017-01-19 jeu. 15:39]
   file:./LabNotebook/Lambda.nb.html

   Ca doit pouvoir se cross valider !
   
   Plus ca va, plus je me dit que la méthode lasso est pas mal du tout, elle
   permet vraiment de trouver le support ! Les outliers ! Il me faut un moyen de
   la comparer au autres sur les plots de precision-recall. 
**** Bilan de la journée
   Entered on [2017-01-19 jeu. 17:35]
   - Finalement lfmm lasso n'est pas à mettre à la poubelle
   - dans lfmm ridge lambda a une importance, si il est trop grand on a un
     shrinkage dégueulasse (mais est-il mauvais ?)! et si il est trop petit on n'arrive à inverser P.
     Mais dans mes examples c'est quand d'aller chercher l'acp sur l'orthogonal
     de X qui m'interesse ! Il faudrait que j'évalue la perte de puissance en
     fonction du lambda !
*** 2017-01-20 Vendredi
**** Fin de semaine
     Entered on [2017-01-20 Ven 15:31] J'ai une vision claire de l'article et de
     comment je vais l'organiser. En particulier je pense que je vais vendre en
     disant que je fait une estimation de la structure lattente mais sans
     prendre la variance du à la co-variable X (l'un est global l'autre ne
     concerne que quelque locus, d'ou l'interet pour le lasso). Je pourrais bien
     illustrer ca avec les exemples numeriques simples (comparaison avec lm, PCA +
     lm). Cette partie est vraiment que optimisation based dans le formalisme.
     On ajoute des statq quand on fait le test d'hypothèse. Et pourquoi pas
     ajouter le test d'hypothèse avec le lasso. 
     A la semaine prochaine !!!
*** 2017-01-23 lundi
**** Sample from true data set                                   :LaNotebook:
   Entered on [2017-01-23 lun. 12:44]
   file:./LabNotebook/SampleFromTrueDataSet.nb.html

   On va voir comment les méthodes réagisses en fonction de rho (la proportion
   de variance expliquée par X) et la correlation avec la structure. Je vais en
   profiter pour avoir un vrai test d'hypothèse pour lfmm ridge et lasso.
**** DONE C'est parti
     CLOSED: [2017-01-24 mar. 10:52]
   Entered on [2017-01-23 lun. 16:13] Réunion avec nous a permis de def les
   résultats ! c'est parti La je vais push mais je suis en train de mettre en
   place le lm a l'arrache a la fin, après lfmm. Je suis dans les test. Je
   comprends pas pk il y a besoin d'un gif. Et il faudrait que je réflechisse un
   peut a théoriquement comment l'expliquer a peut près proprement !!
   - [X] Aussi je voulais implementer une option pour choisir la proportion d'outlier
   dans le lasso.
*** 2017-01-24 mardi
**** lfmm ridge et PCA+lm
   Entered on [2017-01-24 mar. 09:19]
   
   Dans file:./Article3Package/tests/testthat/test_lm_zscore.R quand on prend un
   lambda très grand lfmm ridge et PCA+lm font la même chose logique car c'est
   comme ci il n'y avait pas de projection sur X quand lambda est grand !!
**** lfmm lasso avec sparse.prop
   Entered on [2017-01-24 mar. 10:49]
   
   C'est implémenté. Mais les premiers resultats ne sont pas tops. 
   En gros ca fait la même chose que lfmm ridge... 
   see file:./Article3Package/tests/testthat/test_lm_zscore.R
   Il faudrait trouver un exemple ou c'est mieux :D
**** Comparaison des méthodes sur une simu de 1000 genome        :LaNotebook:
   Entered on [2017-01-24 mar. 11:17]
   
   C'est parti c'est un résultat de validation pour le papier !!
   file:./LabNotebook/Validation_1000Genome.nb.html . Ca marche bien :D On
   arrive bin a montrer que : 
   - c'est robuste au choix de K
   - c'est conservatif mais c'est mieux que liberal
   - quand il y a trop d'outlier PCA + lm fait n'imp
***** DONE reste a faire
      CLOSED: [2017-01-24 mar. 17:26]
      - [X] lancer avec LEA et lasso
***** Conclusion 
      - lasso et ridge font pareil sur ses exemples la
      - LEA fait n'imp
      - on voit bien la force de lfmm ridge sur des exemples avec beaucoups de
        correlation en X et U1 et et beaucoups d'outlier.
      - Le FDR est un peut trop conservatif.
**** Run on krakenator
   Entered on [2017-01-24 mar. 16:57] 

   On va essayer de lancer les notebook long sur krakenator avec la command
   =rmarkdown::render(file)=

   ^_^': j'ai pas pandoc sur krakenator...

   Si je veux me lancer sur krakenator je vais devoir faire des scripts !!!
**** Bilan de mardi !! 
   Entered on [2017-01-24 mar. 17:21]
   
   Il y a la validation sur les data simulées a partir du 10000 genome qui
   tournent. Ca donne des bon résultats a par pour LEA::lfmm :(. Mais pour le
   reste on montre bien ce qu'on veut. Les petits bemols: 
   - le lasso et le ridge ont l'aire de donner la même chose.
   - parfois le test est trop conservatif. Je trouve que c'est mieux dans ce
     sens que trop libéral, au moins on controle le fdr.
  Globalement on avance :D et mon env de travail déchire sa race !
  
  Demain le <2017-01-25 mer.> on fait des EWAS !!!!! Et on dechire tout !!
*** 2017-01-25 mercredi
**** Mise a disposition du code et des données
   Entered on [2017-01-25 mer. 16:49]
   Pour le code github et pour les données torents :D
**** Fin de journée
   Entered on [2017-01-25 mer. 17:11]
   J'ai la putin de journée cette article de ù*^$ù*ù : cite:Rahmani_2016. Bon
   j'ai quand même les données ewas qu'il a utilisé. 
**** DONE Avant la fin de la semain putin !!!
     CLOSED: [2017-01-30 lun. 14:23]
    - [X] recupere des données GWAS pour faire un asssociation avec var envir
    - [X] lancer le script ReFACTor des autres branques.
    - [X] refaire leur association logistique donc X ~ G et avec la correction X
      ~ G + U + les autres co variables (ils disent qu'il y a la correction pour
      les batch mais d'après OF non... ils ont surement recopié un truc sans le
      comprendre...)
*** 2017-01-26 jeudi
**** G/EWAS and adjustment
   Entered on [2017-01-26 jeu. 10:44]
   
   Je me suis bien pris la tête hier pour savoir comment il faisait leur G/EWAS
   et "ajustait" pour la structure... C'est bien ce que je pensais ils ajoute
   simplement les scores (de la l'acp, ou autre) dans glm(Y ~ G + U...). D'après
   florian il utilise plutot plink pour faire leur regression logistic. On va
   utiliser l'algo de florian : https://github.com/privefl/bigstatsr
   
   *ATTENTION ALERT*  En faite en GWAS il font plusieurs regression univarié !!
   Flo lui veut faire avec lasso pour trouver les snips causaux par exemple.
   Mais dans la litérature ce qui se faire c'est de seuiller sur les score des
   regressions univariées :D !! 

   En faite c'est finalement pas différent de mon lm a la fin !! sauf que c'est
   dans l'autre sens !!! 
**** ReFACTor demo                                               :LaNotebook:
   Entered on [2017-01-26 jeu. 15:25]
   
   file:./LabNotebook/refractor.nb.html j'ai juste récupéré le code du [[https://github.com/cozygene/refactor/tree/master/R][github]].
   
***** TODO Comment ce jeux de données demo a été simulé ?
      Il plot le qqplot mais ca montre juste qu'il n'y a pas d'outlier en faite
      ! Il est tout plat !
*** 2017-01-27 vendredi
**** Le dossier BenchmarkDump 
   Entered on [2017-01-27 ven. 09:44]
   
   Je l'ai créer sur krakenator ici
   /home/cayek/Projects/Article3/Article3Package/BenchmarkDump/

   Sur timc-bcm-15 je vais mettre un lien symbolique.

**** Install Article3Package sur krakenator
   Entered on [2017-01-27 ven. 10:05]
   
   Sur krakenator je sais pas pk mais il faut installer le pacakge avec 
   
   #+BEGIN_SRC R
   devtools::install(dependencies = FALSE)
   #+END_SRC
   Sinon il essaie d'installer des pacakge qui sont deja installé et echoue... Je
   sais pas si ca ne vient pas du package =git2r= ...A voir.

   En faite si maintenant ca marche... il y a le =git2r= qui echoue a la fin
   mais le package est bien installé ! 

**** Fin de semaine
   Entered on [2017-01-27 ven. 16:51]
   Putin de semaine de merde !!! 
   
   Il faut que j'arrive a reproduire le reference based si je veux me comparer
   honettement. D'arpès OF il n'y a pas de batch effect correction car sinon on
   l'aurais eu dans les co variable !! Le mystère a perser c'est comment il
   trouve la composition céllualaire 

   Pour les GWAS on va dans frichot, les data c'est celle du HGDP + on prend les
   coordonnées des pop et on creer des var env avec le package raster !!!
   OF: il y a 3 pressions: 
   - le climat
   - la diete
   - les patogènes 

   A Lundi !!
*** 2017-01-30 lundi
**** Lasso, ridge et lambda                                      :LaNotebook:
   Entered on [2017-01-30 lun. 14:24]
   
   Objectif: touver des simulations où
   - lasso est meilleur que ridge
   - le choix du lambda pour lasso n'est pas un choix extrème 
   Je veux aussi trouver un critère de choix du lambda !!
   
   J'ai trouver des simulation ou le choix de lambda influe vraiment !! Sur les
   jeux de données simulé depuis le 1000 génome ! Voir les résultats :
   file:./LabNotebook/LassoRidgeEtLambda.nb.html .
*** 2017-01-31 mardi
**** Données simulé from le 1000 genomes                         :LaNotebook:
   Entered on [2017-01-31 mar. 13:56]
***** Objectif:
    reponds: Quelles sont les spécificités des dataset simulé from le
    1000 genomes et qui fait que lfmm echoue pour certaines valeurs de lambda ?
***** Résultats:
      de l'acp sur le chrm 22 du 1000 genomes :
      file:./LabNotebook/Validation_1000Genome.nb.html
      
      Les résultats montre qu'il y a un choix de lambda optimal : 
      file:./LabNotebook/DataFrom1000Genome.nb.html
***** Conlusion 
      Il y a un lambda optimal qui controle bien la corrélation avec la
      structure de fond ! 
      
      Il nous faut un critère pour le choisir ! 
      
      Il faut que je teste la version avec nuclear norme !!! Il me semble me
      souvenir que je l'avais bien vite abandonné ! Mais !!! je n'avais fait que
      des tests sur mes simulations générative bien propre et avec lambda à 0.
****** Le [2017-02-02 jeu.] :
       En fait je pense surtout que ces exemples sont très atypiques et
       dificil. Je vais essayer de simuler des covariable orthogonal a plusieurs
       axes ! 
       
       Les simulations que viens de faire à la fin montre bien sur des
       situations plus réaliste on dechire tout ;) et il faut un lambda petit ! 
******* DONE Ne pas rejeter cette situation ! 
        CLOSED: [2017-02-02 jeu. 10:22]
        Le lambda optimal n'existe que dans des cas particulier. Mais il
        faudrait quand même que je me penche sur la question !!
        
        Je pense que sur ses simulations particuliere la projection tuait plus
        vite la structure de fond que la partie de correlation avec X. Du coups
        quand le lambda était trop petit la structure de fond apprenait la
        partie de corrélation avec X. C'est pour ca que je fait moins bien que
        lm dans ce cas. 
        
        On retrouve ce phénomène quand je prend un K trop grand sur les
        simulations gausiennes. Il faut que lmbda soit suffisament petit pour
        empecher que la corrélation expliqué par X ne soit aprise par l'ACP.
        Voir file:./Article3Package/tests/testthat/test_NormalSAmpler2.R.

**** Nuclear norm LFMM                                           :LaNotebook:
   Entered on [2017-01-31 mar. 15:54]
***** Objectif: 
      on va faire une vrai evualuation de cette méthode pas seulement sur des
      belle simulations toutes propres !!
***** Resultats:
      file:./LabNotebook/NuclearLfmm.nb.html
***** Conclusion
      Je ne sais pas pk mais c'est moins bon avec la nuclear norme ... J'ai même
      essayer de corrigé avec le U trouvé par lfmm nuclear norme en co variable
      d'un lm a la fin. De plus quand je fais un hard thresholding plutot qu'un
      soft ca deviens très lent. Enfin je ne retombe pas sur le resultat de
      lfmm + ridge dans le cas d'une alternance de pca normal et lm ridge.
** 2017-02 février
*** 2017-02-01 mercredi
**** HGDP experiment                                             :LaNotebook:
   Entered on [2017-02-01 mer. 15:34]
***** TODO Objectifs
      - [X] lancer l'acp
      - [X] lancer la crossvalidation
      - [ ] lancer lfmmRidge avec imputation par la moyen
      - [ ] lancer lfmmRidge alterné (=finalLfmmRdigeMethod=)
      - [ ] lancer lfmmRidge avec imputation par lotter
****** DONE Bug dans =HGDP_runs=
       CLOSED: [2017-03-01 mer. 10:57]
       #+BEGIN_SRC R
       > library(Article3Package)
       >
       > G.file <- "~/Projects/Data2016_2017/Hgdp_Li/Hgdp_Li.rds"
       > X.file <- "~/Projects/Data2016_2017/Hgdp_Li/X_tmp.rds"
       >
       > s <- TrueSampler(G.file = G.file,
       +                  X.file = X.file,
       +                  outlier.file = NULL,
       +                  n = NULL,
       +                  L = NULL)
       >
       >
       > lambdas <- c(1e-10, 1e0, 1e2, 1e3)
       > Ks <- c(5, 20)
       > HGDB_runs(s, Ks = Ks, lambdas = lambdas, save = TRUE)
       Error in tempfile(tmpdir = exp$benchmakdir, fileext = ".rds") :
       valeur 'tempdir' incorrecte
       De plus : Warning message:
       executing %dopar% sequentially: no parallel backend registered
       >
       #+END_SRC
       Ca vient surement de dumpExperiment !!! Du coup laner lfmmRidge alterné à
       planté !!
       
       C'est juste que je me suis pas lancé dans le bon dossier !!! ./Article3Package/
***** Resultats
      file:./LabNotebook/HGDP.nb.html
**** Bilan de cette journée
   Entered on [2017-02-01 mer. 16:55]

   J'ai pas de solutions pour trouver le lambda, mais au moins je suis en train
   de converger vers uniquement lfmmRidge. Mon critère de comme de la
   correlation entre U et X sur le HGDP donne le même paterne que sur mes
   simulations, voir: 
   - file:./LabNotebook/HGDP.nb.html
   - file:./LabNotebook/DataFrom1000Genome.nb.html
   C'est bizare !!! Il y a aurait pas un moyen automatique de choisir ce lambda.
   
   :( Ce qui est triste c'est que au final mes simulations sur les vrai jeux de
   données montre surtout que PCA+lm est pas si mal !!

***** Questions
      - Je pense pouvoir avoir des resultats avec lfmmRidge alterné, pourtant je
        le papier de cite:mazumder10_spect_regul_algor_learn_large_incom_matric
        il dit qu'il n'y a pas de resultats avec la hard thresholding ! 
      - Comment trouver lambda ? 
      - Comment valoriser la méthode par rapport à PCA+lm qui fait pas si mal !
        Mon idée de variance de bacground est a développer ! 
      - Est ce que sur les ewas je vais faire si bien que ca, surtout que les
        méthodes auquel je veux me comparer veulent apprendre un truc bien
        particulier (la composition cellulaire).
      - Je pense que la ou on gagnerais c'est avec un lfmm avec un lien
        logistique ! 
      - Il faudrait que je me compare au GWAS plygénique aussi a locasion ! Voir
        les papier de stephens !
*** 2017-02-02 jeudi
**** lfmmRidge cross validation                                  :LaNotebook:
   Entered on [2017-02-02 jeu. 09:17]
***** Objectifs
      Montrer les resultats de crossvalidation sur des simulations
***** Resultats
      :PROPERTIES:
      :CUSTOM_ID: cross_validation_exp
      :END:
      file:./LabNotebook/CrossValidation.nb.html
      On observe les mêmes paterns que avec les simultations from a true
      dataset : file:./LabNotebook/DataFrom1000Genome.nb.html. 
***** Conclusion
      C'est pas gagné pour trouver un critère pour choisir le lambda... Ce
      pattern est juste typique des données binaire...
      
      Au final il n'y qu'un seul exemple qui m'enmerde ! Et si cétait un cas
      très particulier ! Dans les vrais dataset les variables X est corrélé avec
      plusieurs axes ! C'est deja ce que je fais en sommant plusieurs X.
**** Calibration du test d'hypothèse                             :LaNotebook:
   Entered on [2017-02-02 jeu. 16:12]

   Bon on est en gros d'accord sur la méthode !! On va explorer la calibration.
   C'est un notebook interactif, cad que les experience sont pas longues du coup
   on peut jouer avec !!!

***** Objectifs
      Montrer que la méthode est bien calibré sur tous mon panel de test !! 
***** Resultats
      file:./LabNotebook/calibration.nb.html
      
      J'avais fait une erreur dans ma fonction calibration... 

      Il semblerait que quand il y a trop d'outlier le gif marche mal !!! Il
      rend le test beaucoup trop conservatif. C'est genant si je vends lfmm
      comme utile quand il y a beaucoup d'outlier.
***** Conclusion
      Il faut que je reflechisse au test d'hypothèse. Je sur estime l'erreur (la
      variance des estimateurs) surement a cause de l'auto-corrélation des
      intividus ! Je pense que c'est d'autant plus vrai que quand je fait G - C.
      Il faut que je trouve un moyen de corriger proprement pour ca ! (voir ma
      ccl a la fin du notebook). Le GIF semble ne pas marcher quand il y a trop
      d'outlier, c'est logique car c'est en faite juste une median donc si il a
      trop d'outlier ca la tire ! 

      On doit pouvoir mesurer cette autocorrelation !! 
      
      Je reviens ;D

****** DONE SSMPG 2015 
       CLOSED: [2017-02-16 jeu. 15:36]
       Les resultats sont vraiment pas terrible à par sur le case 2. Je pense que
       le modèle n'est pas adapté. Il faudrait un moyen de le detecter ! Un
       critere qui dise si ma modélisation est bonne ou pas.
******* Conclusion
        On ne peut pas le detecter, le modèle est pas adapté c'est tout ! En
        tout cas on ne dit pas de chose fausse, le FDR est controlé.

        Voir [[#model_choice][Sur le choix des modèles de test d'hypothèse]]

**** Bilan de cette journée ! 
   Entered on [2017-02-02 jeu. 18:08]

   Il faut bosser le test d'hypothèse ! Parfois tester B = 0 à pas l'aire bon du
   tout. Il faudrait définir clairement mon hypothèse, avec la variance de
   background et le B !

   Je veux un test parfaitement calibre demain bitch !!
*** 2017-02-03 vendredi
**** Partir en vacance serein... ou pas
   Entered on [2017-02-03 ven. 15:30]
***** Les mistère restant sur la méthode a ce jour
      - Comment calibrer le test, je suis sur qu'il y a coup a jouer ici. Voir
        mon cahier. Mais je ne veux pas faire appel a une méthode ad hoc à la
        fin.
      - L'algo d'alternance de lfmmRidge converge-t-il en théorie ? Je pense que
        oui mais il faudra faire un peut de biblio. Voir cite:josse2009gestion.
      - Cette algo est-il vraiment utile ? Je pense que oui aussi, les resultats
        de file:./LabNotebook/MissingValue.nb.html son bizare mais je pense
        qu'on va reussir trouver des simulations ou c'est mieux :D. Le top
        serais de montrer que on en viens a dire n'importe quoi quand
        l'imputation est faite a l'arrache. Mais si je recalibre mes tests pour
        le degre of freedom effectif ou un truc comme ca... Bon on verra.
      - On peut utiliser ca en EWAS ??
***** Bonne vacance
      On progresse !!!!!
*** 2017-02-14 mardi
**** Calibration des tests avec boostrap                         :LaNotebook:
   Entered on [2017-02-14 mar. 10:50]
***** Objectif
      On va ajouter une option boostrap au test en fin de chaine.
      
      On va faire un bootstrap du model de lfmm complet.
***** Resultats
      file:LabNotebook/bootstrapCalibration.nb.html
***** Conclusion
      Non c'est logique que sigma soit encore moins bien estimé ! Le bootstrap
      sous estime l'erreur car les datasets sont très corrélés ! 
**** Bilan de la journée
   Entered on [2017-02-14 mar. 18:21]
   
   Il faut que je trouve un moyen destimer le nombre de degré de liberté
   effectif ! Voir [[https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)][cette page wikipedia]].

   A demain !!
*** 2017-02-15 mercredi
**** Les deux gros problèmes à résoudre
   Entered on [2017-02-15 mer. 09:38]
***** Calibration des tests
      Je veux un test d'hypothèse calibré !!
      - bootstrap : donne comme lm théorique voir
        [[file:LabNotebook/bootstrapCalibration.nb.html]].
      - permutation : on va perdre en puissance. Mon intuition est que on test
        ne sachant pas X, or on connait X ! 
***** Choix du lambda (choix du model)
      :PROPERTIES:
      :CUSTOM_ID: lambda_choice
      :END:
      Comment choisir le lambda, c'est a dire un modèle ! 
      - cross validation ne marche pas car ce n'est pas la généralisation que
        l'on veut
      - on pourrait essayer la reproducibilité (cad est ce que on retrouve les
        même resultat quand on prend des sample d'indiv). Mais j'y crois pas !
***** Rmk
      Le plus important est peut être la calibration du test ! Car si on a un
      test bien calibré on ne dira pas de connerie à la fin ! On aura peut être
      moins de puissance ! Mais on dit la vérité ! 

      Go calibrarion ! 
**** Quelques experience pour la calibration des tests           :LaNotebook:
   Entered on [2017-02-15 mer. 11:47]

   On va essayer de calculer l'équivalent du gif mais sur le residue !
***** Objectif
      Trouver un moyen d'esimer une variance residuelle plus juste !
***** Resultats
      [[file:LabNotebook/gifExperiment.nb.html]]
***** Conclusion
      Je pense pas que la corrélation va se voir dans les resudus, ils sont
      construit pour etre indépendant ! C'est vraiment dans les beta que ca se
      voit ! 
      
      C'est la merde bradley ! Il faut que je reflechisse à un model stat ou je
      peux faire des tests !!!! Pour le moment j'ai pas la solution ! Mon lm à
      la fin marche pas car c'est pas iid ... Enfin je pense !
*** 2017-02-16 jeudi
**** Réu OF
     Entered on [2017-02-16 jeu. 11:59]
   
   - on arrête de se prendre la tête sur la calibration, je verrais plus tard.
     Surtout qu'il y a beaucoups de méthode de calibration des test (exemple:
     cite:stephens16_false_discov_rates ou les truc de lissage pour enlever le
     ld etc...)
   - <<ld>>: En parlant de LD, le V du modèle est censé le capter, a valider. Et c'est
     un problème pour les tests d'hypothèse.
   - On va partir des résultats et garder lfmm avec lm + gif ! On part des
     résultats et on remonte.
   - Méthode : on décrit le plus clairement ce qu'on fait ! Pas de mystique ;D
   - On verra à la fin pour se prendre la tête sur les stats à la fin :p 
**** Sur le choix du lambda (choix de model)
     :PROPERTIES:
     :CUSTOM_ID: lambda_model_choice
     :END:
     Entered on [2017-02-16 jeu. 14:29]
   
     J'en avait déja parlé ici : [[#lambda_choice][Choix du lambda (choix du model)]]. Je me répète
     c'est vraiment une affaire de choix de model ! Mes experiences sur case2 de
     ssmpg (voir [[*Calibration du test d'hypothèse][Calibration du test d'hypothèse]]) montre que case2 n'est pas
     adapté a ce model ! Et c'est tout ! De toute facon ce que je dit est bien
     qualibré à la fin ;)
   
     Si lfmm Lasso marchait bien on aurrait un critere simple : la proportion des
     non null. Mais je pense qu'il y a plus de boulot pour lfmm lasso ! On verra
     plus tard.

     Au final, le plus sage est d'appliquer le model au cas ou on sait que la
     structure est plus forte que le reste -> un lambda petit. On pourra le
     justifier avec mes petit raisonnement (voir cahier le 30/01/2017). C'est le
     cas le moins violant par rapport à lm. On pourra peut etre montrer un choix
     de lambda optimal.

***** Un critère pour lfmm ?    
      Dans mon cas la [[#cross_validation_exp][crossvalidation]] donne toujours le meilleur critère pour
      lambda grand. Mais ca permet de voir la gamme de lambda ou il se passe
      quelque chose. 

      On va proposer ce critère visuel! La méthode est rapide c'est l'occasion
      de tester plusieurs modèles.
      
***** Conclusion 
      Je m'adresse a des situation ou la structure est plus forte que XB (c'est
      l'hypothèse) => lambda doit être petit.


**** Sur le choix des modèles de test d'hypothèse
     :PROPERTIES:
     :CUSTOM_ID: model_choice
     :END:
     Entered on [2017-02-16 jeu. 15:37]
     
     Quand on construit un test d'hypothèse, c'est très dur de savoir si ce test
     est adapté à notre situation. Je veux dire q'uil n'y à pas de critère
     objectif pour ca, comme la crossvalidation ou autre...Car ce n'est pas le
     modèle qui explique le mieux les données qui correspond a mon test d'hypothèse.
*** 2017-02-17 Vendredi
**** Un plan d'attaque pour le seminaire BCM
     DEADLINE: <2017-03-03 Ven>
     Entered on [2017-02-17 Ven 09:59]
***** Les resultats
****** Validation sur simulation                                 :LaNotebook:
       [[file:LabNotebook/simuValidation.nb.html]]
******* TODO Simulations
        From le 1000 genomes. 2 cas : 
        - peu d'outlier
        - beaucoups d'oulier
          
        Voir avec olivier les simus qu'avait fait eric dans
        cite:frichot13_testin_assoc_between_loci_envir. 

        Voir les simu qu'on peut faire d'autre

******* DONE Les méthodes
        CLOSED: [2017-03-01 mer. 15:29]
        - [X] lfmm ridge
        - [X] FAMT
        - [X] SVA
        - [X] PCA+lm
        - [X] méthode oracle+lm
        - [X] lm
        - [X] Refactor
        - [X] LEA
******* Le message
        - les facteurs lattents posent problèmes
        - quand il y a beaucoup d'outlier lfmm gagne sur lm et lm+PCA
        - Toutes les méthodes qui prennent en compte les facteur lattents disent
          en gros la même choses.
******* DONE Implementation
        CLOSED: [2017-02-17 Ven 16:22]
        Comparaison sur simulated data set function.
        J'implemente ca cette aprem !
****** TODO Missing values                                       :LaNotebook:
       Même experience que [[*Validation sur simulation][Validation sur simulation]] mais avec une strategie
       d'imputation des missing values
       
       [[file:LabNotebook/missingValuesSimuValidation.nb.html]]
******* Le message
        - La méthode alternée est meilleur quand il y a des missing values
        - je pense que je vais mettre juste deux lfmm avec imputation par la
          mean et lfmm alterner. Pour avoir un message clair.
          
******* TODO Implementation
        - [X] LEA with missing value 
        - [X] FAMT with missing value 
        - [X] lfmmRidge with missing value
        - [X] lm with missing value (on met des zeros, et on divise par le vrai
          nombre de données :D)
        - [ ] le notebook
****** Critere de reproductibilité                               :LaNotebook:
       J'espere que ca va marcher...Ok
       cite:crossValidated_PCACrossValidation_2017 m'a fait changer d'avis. On
       va essayer des missing values. 

       Ca marche !!! [[file:LabNotebook/crossValidationCriteria.nb.html]]
       Pas sur toutes mes simulations...
       
******* TODO La suite 
        Les bars d'erreurs ne sont pas pertinente par ce que d'un lambda a
        l'autre je suis sur que les erreur sont corrélé. Faut que je regarde
        plus en détail comment proprement faire de la cross validation (c'est
        vrai que je me suis jamais vraiment documenté). Peut être que de faire
        un vrai kfold et la moyen est plus pertinent !! La on sample au
        hasard...
        
        Donc : 
        - [X] faire un kfold pour la cross validation (k leave out truc ...):
          
          En faite non je pense que c'est pas trop mal mon [[https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Repeated_random_sub-sampling_validation][montecarlo crossvalidation]].

        - [ ] lancer sur les données ssmpg/simulation qui posait probleme !
        - [ ] lancer sur HGDP et GSE42861
        - [ ] cross valider sur K
******* Conclusion
        - avec beaucoup  de missing values pour la cross validation, on a des
          pattern plus franch. J'ai mis 0.5
        - C'est un critère de cross validation qui dit ce qui est mieux si on
          veut fitter les données... C'est pas forcément ce que l'on veut faire.
****** TODO GWAS                                                 :LaNotebook:
       Le HGDP. Et on compare se qui sort par rapport aux autres papiers.
******* Résultats
        [[file:LabNotebook/HGDP.nb.html]]
******* Le message
        - On fait comme dans cite:frichot13_testin_assoc_between_loci_envir.   
        
****** EWAS                                                      :LaNotebook:
       On lance lfmm dessus et on compare se qui sort.
       
       [[file:LabNotebook/GSE42861.nb.html]]
******* DONE pas encore fait
        CLOSED: [2017-03-08 mer. 08:50]
        On retrouve bien les locus du papier cite:Rahmani_2016, mais les qqplot
        ne resemble pas trop a ceux du papier... Ce que je peux faire c'est : 
        - [X] Run de lfmm : 
          - correction de G pour les autres facteurs de confusion
          - G - C (de lfmm)
          - on glm(G_ ~ X)
        - [X] Run de Refactor
******** Ccl
         Avec GLM c'est pas tout a fait calibré mais avec un petit par dessus ca
         va ! On retrouve bien les locus du papier. 

         Par contre Refactor n'est pas bien calibré je sais si il recalibre dans
         le papier mais chez moi c'est pas au top ! Après il me manque les batch
         effect peut être que j'aurais du les trouvé finalement ...

         Bref, avec la recalibration ca marche ! 
****** TODO Robustesse au choix des parametres
       A voir comment on peut faire.
**** FAMT test                                                   :LaNotebook:
   Entered on [2017-02-17 Ven 13:10]
 
   Test of the [[http://famt.free.fr/][famt package]] [[file:LabNotebook/FAMT.nb.html]]
**** SVA test                                                    :LaNotebook:
   Entered on [2017-02-17 Ven 14:32]
   
   Test of [[http://www.bioconductor.org/packages/release/bioc/html/sva.html][SVA R package]] : [[file:LabNotebook/SVA.nb.html]]
**** Bilan de la semaine
   Entered on [2017-02-17 Ven 16:28]
   
   On avance bien !! La semaine prochaine on continue d'inmplementer les tests
   systématiques. On discute avec olivier pour s'assurer que ca va dans le bon
   sens ! 

   OUS !
*** 2017-02-20 Lundi
**** DONE Est ce que lfmm est sensé enlever le "problème" du ld dans les tests ?
     CLOSED: [2017-02-20 Lun 21:58]
   Entered on [2017-02-20 Lun 20:59]
   
   Pour réponde à [[ld]].

   Déja je veux revenir sur le fait que c'est un problème ? Est ce que c'est
   référencé comme etant un problème ? A voir dans la biblio.

   En tout cas lfmm ne va pas résoudre ce problème, car si les locus sont
   autocorélé, les $B_j$ le seront aussi ! Même d'un point de vu biologique
   c'est logique. Si un locus monte en fréquence quand il est nord alors les
   autre aussi, à cause de ce que l'on appel le déséquilibre de liaison en
   genetique des populations.

   Je pensais que l'on ne controlait pas le fdr parce que certain $B_j$ sont non
   null alors qu'il n'y a pas d'association ici. Mais la on confond l'hypothèse
   biologique et statistique. 
   
   Par contre, ce qui est vrai est que quand les tests sont corrélé ca biaise
   l'estimation du taux d'erreur. Comme expliqué sur [[https://en.wikipedia.org/wiki/Multiple_comparisons_problem#Assessing_whether_any_alternative_hypotheses_are_true][cet article wikipedia]].
*** 2017-02-21 mardi
**** Bilan de la journée
   Entered on [2017-02-21 mar. 16:39]
   
   Je pense que je vais articuler le papier et la présentation comme ca : 
   - présentation des modèles à facteur lattent et leurs applications
   - présentation des algos 
   - interêt pour notre domaine
   - nos algos
   - nos resultats

   On a les résultats, demain je fais la biblio final et j'identifie tous les LFMMLike.

   J'ai l'impression que tous se passe bien parce que je valide sur mon
   modèle... Il faut que j'ai une vision plus claire de la biblio pour avoir
   confiance en ma demarche. Comment les autres on valider ?
*** 2017-02-23 jeudi
**** Bilan de la journée et long week end
   Entered on [2017-02-23 jeu. 16:36]

   On a bien avancé aujourd'hui : 
   - plan de la résentation dans le cahier
   - critère de cross validation qui marche pas mal !
     
   A Mardi !! Mardi on commence a générer les figures final pour la présentation
   et on la fait en parallèle ! Voir mon cahier.
** 2017-03 mars
*** 2017-03-01 mercredi
**** Deploy on krakenator with git
   Entered on [2017-03-01 mer. 11:04]

   - I create a repo on krakenator /home/cayek/GitRepo/Article3.git
   - [[file:hooks/post-receive.sh][post-receive hook]]
   - add a remote krakenator_deploy
*** 2017-03-02 jeudi
**** Illustration avec Arabidopsis Athaliana                     :LaNotebook:
   Entered on [2017-03-02 jeu. 08:49]

   Je veux faire un exemple pour illustrer les facteur de confusion, en
   replacant ma super carte :D
***** Resultats
      [[file:LabNotebook/AthalianaIllustration.nb.html]]
****** Avant et après le gif
       Avant le gif, on observe que rien n'est significatif ! Mon
       interpretation : le modèle linéaire simple n'est pas adapté, du coup la
       distribution sous H0 est fausse ! Avec le gif ce qu'on fait c'est une
       recalibration des pvaleur en utilisant le fait que presque tout le monde
       est sous H0 et on a une loi normal en gros, c'est l'idée de "Learning from
       the Experience of Others" dans cite:Efron_2009. Donc j'appel ca un gif
       mais c'est plutot une recalibration ! 

       Dans le modèle linéaire : $$G_j = Xb + e$$, les hypothèses fausses sont :
       - e gaussien mais à la limite c'est pas si grave (l'estimateur de B est
         gaussien)
       - les indiv sont iids. Ca donne une mauvaise estimation de la variance de
         $\hat{B}$
       - les locus sont iids. Ca donne une mauvaise estimation du FDR (je crois
         que dans BH il utilise ca pour le controle du FDR)

         Bon tout ca c'est de idées en vrac mais ca fait du bien de les écrire
         !!

         Suite de mes réflexions sur le cahier ! (3/3/17)
****** DONE Pourquoi ca ne marche pas comme je veux !!!
       CLOSED: [2017-03-03 ven. 11:35]
       Je m'attends a ce que lm donne beaucoup trop de pic, la quand je fais dfr
       control personne ne sort pour lm ...

       - [X] lancer lfmm sur une grille
       - [X] on va recalibrer avec autre chose que le gif c'est surement ca le
         pb (enfin un des pb)

         J'ai trop faim j'y vais !!
******* Conclusion 
        Ca marche avec le package =localfdr=. On a bien beaucoup plus de
        significativement corrélé avec lm. 

        Il faut que je comprenne bien les méthodes de recalibration !! Et que je
        justifie pk ce n'est pas mal honette ! Voir mon cachier le 3/3/2017
******* Conclusion 2 [2017-03-06 lun.]
        Il faudra forcement corrigé pour le test d'hypothèse, car on ne va ma
        mettre suffisament de variable lattente pour enlever tout le LD. Sinon
        ca pose des problèmes pour l'estimation des variables lattentes.
**** Les scipts long ! 
   Entered on [2017-03-02 jeu. 09:44]

   Je vais les mettre dans des fonctions plutots ! Comme ca j'ai juste a push
   sur krakenator et lancer la fonction ;D. En plus ca permet de documenter les
   scripts !!! Tout est package !!!

   Le workflow c'est package-notebook-orgmode: 
   - pacakge : un max de code et des test
   - notebook : le codé visuelle, rendu, plot,
   - orgmode : timeline, comment avance le projet
*** 2017-03-07 mardi
**** Programmation défensive
   Entered on [2017-03-07 mar. 08:56]
   
   On va utilisé [[https://github.com/hadley/assertthat][assertthat]] pour faire de la programmation defensive a fond !!
   Ca me permettra de comprendre se qui marche pas quand je reviendrais sur mon
   code :D
**** RUSH !!!!
   Entered on [2017-03-07 mar. 18:32]

   On y est presque pour le presentation demain je fini !!!!! Il me reste juste
   les resultats a generer même si ils sont mauvais je les ajoutes ! 

   Faut que je fasse la recalibration de cite:wang2015confounder (avec la median
   et le mad !!) et on est bon je genere ! 
