* 2017
** 2017-03 mars
*** 2017-03-10 Vendredi
**** DONE Changement de git pour la Biblio
     CLOSED: [2017-03-13 lun. 13:38]
   Entered on [2017-03-10 Ven 16:30]

   - [X] je backup sur le server kimsufy
   - [X] rm sur mon pc de bureau et cp dans ici :D
   - [X] mettre biblio.bib a la racode de Thesis
   - [X] le reste est private on fait un Gits sur kimsuffy et ce qui faut dans le
     makefile !!

     #+BEGIN_SRC bash
     git remote add origin cayek@176.31.253.205:/home/cayek/Gits/2017/Biblio.git
     #+END_SRC

**** TODO Migration des git articles
   Entered on [2017-03-10 Ven 16:44]

   - [ ] rm sur mes poste
   - [ ] rm les gits et les liens vers ceux ci (mon site)
   - [X] les backup
     
     On va migrer tous ca au fure et à masure :D

*** 2017-03-13 lundi
**** DONE Data dir 
     CLOSED: [2017-03-13 lun. 16:11]
   Entered on [2017-03-13 lun. 13:49]

   For git annex see [[https://git-annex.branchable.com/direct_mode/][direct mode]]
   #+BEGIN_SRC bash
   git annex unannex
   #+END_SRC
**** GWAS RIZ                                                     :Rnotebook:
     Entered on [2017-03-13 lun. 16:08]

     [[file:Rnotebook/gwas_riz/gwas_riz.nb.html]]

***** TODO climate
      - K = 1 2 3
      - lambda différente values
      - avec X = tmaxPC2
      - on recalibre
      - lancer avec un genotype aléatoires 
        
***** TODO flowering
      - K  1 2 3 4
      - lambda plusieurs valeurs ...
      - gerer les missing values dans X
**** Fin de journee
   Entered on [2017-03-13 lun. 18:01]

   Petit a petit je met en place le repo et bosse en même temps. Je vais migrer
   3Article au fur et a mesure.
***** DONE Questions
      CLOSED: [2017-03-15 Mer 13:41]
      - Comment on gere les images (git annex ? NON, ca bouge trop souvent)
      - Comment on gere les notebook ? (git annex ?NON idem)

        Faudrait pas faire grossir pour rien le repo...

        Je m'en balek, je vais tous mettre dans le repo ! 
*** 2017-03-14 Mardi
**** DONE Cross-validation
     CLOSED: [2017-03-14 Mar 13:51]
   Entered on [2017-03-14 Mar 07:21]
   
   Je vais supprimer tout ce que j'avais fait sur la crossvalidation et qui ne
   marche pas ! 

   - [X] implementer predict_row
   - [X] implementer left.out func
   - [X] implementer CrossValidation_rowwise: 
***** DONE test avec tess3r 
      CLOSED: [2017-03-15 Mer 13:44]
      Il va falloir implementer mes samplers. Je vais recuperer tous le code de
      tess3r ! C'est le plus simple.

      Finalement, c'est pas la priorité. On vera la cross validation pour la
      these mais pour les reviews ils ne reclamaient pas ca.
***** TODO test avec lfmm
      Ca donne quoi sur les vrais dataset que je veux mettre dans le papier !
   
**** Writting tools
   Entered on [2017-03-14 Mar 08:03]

   - [[https://joelkuiper.eu/spellcheck_emacs][un blog sur les outils emacs]]
   - [[http://www.cs.umd.edu/~nspring/software/style-check-readme.html][un style checker]]
   - [[https://github.com/mhayashi1120/Emacs-langtool][language tools in emacs]]
   - [[http://www.techrepublic.com/blog/linux-and-open-source/automatically-analyze-text-with-these-simple-command-line-tools/][diction and style]]
   - [[http://www.afterthedeadline.com/][afterthedeadline]]
   - [[https://www.quora.com/What-is-the-best-free-spell-style-and-grammar-checker-for-English][quora: best style and grammar checker]]
**** Biblio
   Entered on [2017-03-14 Mar 11:10]

   #+BEGIN_SRC bash 
   git clone cayek@176.31.253.205:/home/cayek/Gits/2017/Biblio.git
   #+END_SRC
**** TODO Migration du code de l'article 2
   Entered on [2017-03-14 Mar 14:29]

   Pour le moment je ne fait pas de fork de tess3r, ca va trop compliquer mon
   package. Je vais récuperer tous le code et le mettre dans
   R/2Article/2Article_ et dans un environment !

   Reste toutes les images a migrer ...
**** TODO Reunir tous les notebook
   Entered on [2017-03-14 Mar 15:02]

   Tout est dans le titre faudrait que je puisse visualiser tous mes notes book
   :D
**** ms
   Entered on [2017-03-14 Mar 15:30]
   
   On peut le ddl [[http://home.uchicago.edu/rhudson1/source/mksamples.html][ici]]. C'est ouf que j'ai utilisé un soft aussi vieux...
*** 2017-03-15 Mercredi
**** Organisation des Notes                      :1Article:2Article:3Article:
   Entered on [2017-03-15 Mer 08:14]
   
   On va tous mettre dans ./Notes.org avec des tags pour les 3 articles.
**** tess3r                                                        :2Article:
   Entered on [2017-03-15 Mer 08:50]
   
   Je vais copy-paste un parti du code que j'utilise dans l'env tess3r.env
**** Point sur 3Article                                            :3Article:
   Entered on [2017-03-15 Mer 14:53]
***** Que falta ?
      - HGDP PCA+cv+run
      - GSE42861 PCA+cv+run
      - (interet de l'algo avec missing value (rmse(U,U_true)))
***** TODO Plan d'attaque 
      On va generer les figures pour l'article !!!
      CAD:
      - [ ] comp de méthode sur simul (pcesision-recall et fdr control)
      - [ ] rmse de l'algo with missing value
      - [ ] HGDP (pca cv et result)
      - [ ] Refactor (pca cv et result)
      Après on envoie à olovier et on ecrit l'article ! 
**** Fin de journée                                                :3Article:
   Entered on [2017-03-15 Mer 17:11]

   Bon j'ai impementé les trois functions utile pour l'analyse des true dataset.
   DEMAIN je lance pour faire l'analyse d'olivier, HGDP et refactor.
*** 2017-03-16 Jeudi
**** GSE42861 analyse                                             :Rnotebook:
   Entered on [2017-03-16 Jeu 10:04]

   Deuxieme tour :D cette fois on fait ca propre:
   [[file:Rnotebook/GSE42861/GSE42861.nb.html]]
**** HGDP analyse                                                 :Rnotebook:
   Entered on [2017-03-16 Jeu 10:07]
   
   [[file:Rnotebook/HGDP/HGDP.nb.html]]
* 1Article                                                         :1Article:
* 2Article                                                         :2Article:
** Revisions
   Recu le [2017-03-02 Jeu].
  
*** Mail

    Dear Olivier François,

    Thank you for submqitting your paper "Fast inference of individual admixture
    coefficients using geographic data" for possible publication in Annals of
    Applied Statistics. It has now been carefully reviewed and my decision is:
    Revision required.

**** My comments are the following:
     The reviewers all agree that this paper is an interesting methodological
     contribution to the field of inference of population structure. There were
     four main revisions that should be made to the work according to the
     reviewer comments.
***** First, 
      slightly more space should be devoted to connecting the new work with the
      related work -- the related work is very clearly written, but the exact
      methods proposed here and the inclusion of geographic data should be
      motivated a bit more carefully and put in the perspective of the related
      work.
****** TODO a faire
         Pk on fait ca par rapport au ancienne version de TESS3. Pk faire une new
         version de tess3
***** Second, 
      the selection of hyper parameters was not well discussed, and two of the
      reviewers would rather those details be included in the paper to have it
      self-contained.
****** TODO a faire
       discuter plus la validation croisée. Pas mettre en reference.
***** Third, 
      related, R1 asks about model misspecification and how to evaluate the
      impact of incorrect priors on the results --- I agree that this point
      should be addressed adequately.
****** TODO a faire
       Test pour l'ibd, on le voit dans le variogram si il n'y a pas de d'interet
       du spatial. Il y a une grosse litérature sur ces tests ! 

***** Fourth, 
      the results should be expanded to a larger data set. There were a handful
      of minor comments that should also be addressed.


      In addition to these comments you may also find review reports posted on EJMS.

****** TODO a faire
       Prendre le AT 1001 genome. Data set est propre. 
       *Rmk* : On peut pas le faire sur des humains, on a pas les coord
       geographique, ca serait pas anonime.
**** To submit your revision,
     please log in to EJMS and submit it as a revised file to original
     submission. Please also include a detailed description of how you addressed
     all the points raised by the reviewers.

**** IMPORTANT NOTICE CONCERNING FIGURES: 

     Printing figures in color adds significantly to the production cost of the
     journal. While color may be used in the online publication, we will use
     color in the printed version only when essential to the display. Please use
     dashed/dotted lines or symbols where possible and avoid referring to colors
     in the text and the figure caption.

**** other

     If you have been asked to modify the title of your submission, or if the
     order of author names has changed, please contact Geri Mattson at
     mattsonpublishingservices@comcast.net so that the submission’s metadata can
     be updated.

     Thank you for considering The Annals of Applied Statistics as a venue for your work.

     Sincerely,
     Edoardo M. Airoldi
     Editor, The Annals of Applied Statistics
    
    
     Submission URL: https://www.e-publications.org/ims/submission/AOAS/
    
     Title:
     Fast inference of individual admixture coefficients using geographic data
    
     Authors:
     Kevin Caye, Flora Jay, Olivier Michel, Olivier François
    
     Abstract: Accurately evaluating the distribution of genetic ancestry across
     geographic space is one of the main questions addressed by evolutionary
     biologists. This question has been commonly addressed through the
     application of Bayesian estimation programs allowing their users to estimate
     individual admixture proportions and allele frequencies among putative
     ancestral populations. Following the explosion of high-throughput sequencing
     technologies, several algorithms have been proposed to cope with
     computational burden generated by the massive data in those studies. In this
     context, incorporating geographic proximity in ancestry estimation
     algorithms is an open statistical and computational challenge. In this
     study, we introduce new algorithms that use geographic information to
     estimate ancestry proportions and ancestral genotype frequencies from
     population genetic data. Our algorithms combine matrix factorization methods
     and spatial statistics to provide estimates of ancestry matrices based on
     least-squares approximation. We demonstrate the benefit of using spatial
     algorithms through extensive computer simulations, and we provide an example
     of application of our new algorithms to a set of spatially referenced
     samples for the plant species Arabidopsis thaliana. Without loss of
     statistical accuracy, the new algorithms exhibit runtimes that are much
     shorter than those observed for previously developed spatial methods. Our
     algorithms are implemented in the R package, tess3r, which is available from
     https://github.com/BioShock38/TESS3_encho_sen.

*** [[file:Revisions/AOAS1610-012R1R1.txt][R1]]
**** Intro
     Inferring individual ancestry (IA) from geontype data is an important
     problem in population genetics that has received much attention from both
     statistics and genetics communities. Caye et al. focus on the IA estimation
     problem in the setting where geographic data is available. They cast this
     problem as a regularized matrix factorization problem. The goal is to find Q
     and G matrices that reside in a convex set and approximate the genotype
     matrix. The requirement that geographically proximal individuals have
     similar IA parameters enforces a regularization on the solution. The authors
     explore two algorithms to this convex optimization problem: one based on
     alternating quadratic programming (AQP) and the second based on alternating
     projected least squares (APLS). The latter is shown to provide statistically
     accurate estimates while being computationally efficient on simulated data.
    
    
     The paper proposes a novel formulation and approach to incorporate spatial
     information for estimating IA. This model could be useful in applications
     where geographic locations are available along with genetic data. I think
     the paper represents an interesting applied statistics work. However, I have
     some comments that I would like the authors to address -- specifically,
     related to their choice of regularizer, model misspecification and empirical
     comparisons.

**** Comments:
    
***** 1.  
      While it is clear that spatial information can naturally be incorporated as
      a regularizer, it is not clear what the motivation is for the specific
      choice of regularizer. For example, it is intuitively not clear why the
      regularizer is inversely proportional to K and lambda_max.

      Further, if I decide to choose the regularizer coefficient by
      cross-validation, does it matter if the regularizer is scaled by parameters
      such as K,lambda_max as long as I search over a large rage of values of the
      regularizer coefficient ?

      Given that this is the central aspect of the paper, I would like the
      authors to provide intuition for their model choice including the choice of
      regularizer.

****** TODO a faire
      Donner une intuition.  

***** 2. The empirical assessment can be improved. 

****** a) 
       One of the concerns is that the simulations appear to assume that the true
       locations are known. I would like to know how correlated the IA estimates are
       with location in the simulations. How does the performance improvement relative
       to a method that does not use spatial information change if the locations are
       noisy so that the correlation between IA estimates and location is lower.

******* TODO a faire
        Une simu : on va bruité les coordonnées géographique. On regarde comment
        le bruit sur les coordonnées influ sur l'esimation de Q. On peut faire
        varier la variance du bruit. 
****** b) 
       A second and more important concern is that it is unclear how the model
       performs in instances where genetics and geography do not correlate. For
       example, many of the instances of large-scale admxiture involve population
       migration that results in relatedness between populations that are
       separated by large genetic distances. Consider, African-Americans that are
       admixed between African and European populations. In terms of location,
       African-Americans are located in the US which is not proximal to ancestral
       Africans or Europeans. IT is unclear how the inferences would change in
       this setting.
******* TODO a faire 
        Se verifie avec les test d'autocorélation spatial, le variogram etc.
        C'est de la validation des hypothèses. 

        *MAIS* pour nous la VC ne marche pas

        *Une simu*: prendre du 1000 genomes (européen affricain et
        afro-americain) et leur donner des coords geographique et voir ce qui se
        passe (comment ca degrade par rapport à NMF). C'est un peu moins bien,
        mais faut faire des hypothèse a un moment !!
****** c) 
       An interesting question that would point to the utility of these spatial
       models is to ask how approximate or noisy does the location information
       need to be to obtain an advantage over models that do not use spatial
       information. This would be an interesting quantity that could strengthen
       the appeal of the current study.
******* TODO a faire
        Repondu, par le graphe de a)
****** d) 
       The authors should also compare to other spatially explicit methods for
       inferring IA. e.g. SpaceMix (Bradburd et al. 2015). These methods jointly
       estimate IA as well as geographic coordinates in a Bayesian framework.
******* TODO a faire
        SpaceMix est pop based ? On les citera.
*** [[file:Revisions/AOAS1610-012R1R2.pdf][R2]]
**** Intro
     The authors propose an extension to their tess3 software to allow spatial
     coordinates of samples to be used to smooth local estimates of ancestry
     proportions. They use a matrix factorization approximation to the STRUCTURE
     model, which they have previously shown to give comparable results at
     reduced computational cost. Spatial smoothness in the ancestry proportions
     is attained using a Gaussian kernel whose length scale is estimated offline.
     Two optimization approaches are proposed: the first using alternating
     quadratic programming which is guaranteed to obtain a local optimum
     (strictly critical point) of the objective, the second using a heuristic
     optimize-and-project scheme which gives very comparable empirical
     performance at significantly reduced computational cost. On simulated data
     with K=2 admixed ancestral populations leveraging the spatial information is
     shown to improve estimation of the original ancestral frequencies and
     ancestry proportions. On a N=1000 dataset of A. thaliana across Europe the
     method is applied to show a distribution of multiple populations across
     Europe, and to detect candidate SNPs under selective pressure.

**** The paper is generally clearly written with an appropriate level of detail. There are some important details which are deferred to references, in particular:
    - the cross-validation scheme/objective used for choosing K
    - the variogram approach for choosing sigma
    - how SNPs are tested as being outliers under selective pressure
    It's perhaps only a personal preference but since these are key, non-
    standard steps in the analysis it would be good if they were at least
    described in the supplement so that the paper is more self-contained.

***** TODO a faire
      Expliquer ce qu'on a mis en ref.
**** Some prior work which should probably be cited:
     - Fast spatial ancestry via flexible allele frequency surfaces. Rañola JM1,
       Novembre J1, Lange K. Bioinformatics 2014.
       https://www.ncbi.nlm.nih.gov/pubmed/25012181. This method smooths both
       latent allele frequencies and allocation proportions but using a grid/pixel
       based random field approach which I assume is more computationally
       expensive than tess3r. The setup is somewhat different but a quantitative
       comparison might still be possible? Code is available in the OriGen R
       package.
     - Novel probabilistic models of spatial genetic ancestry with applications to
       stratification correction in genome-wide association studies. Anand
       Bhaskar, Adel Javanmard, Thomas A. Courtade, David Tse
       https://arxiv.org/abs/1610.07306. The problem setup between this ("GAP")
       and the current paper is quite different: GAP estimates spatial coordinates
       of individuals given their genotype data, and so should be grouped with the
       citations on lines 79-80, page 3.
***** TODO a faire
      a voir ce c'est. 
**** An analysis of at least one human dataset,  
     the Simons diversity panel being one interesting recent possibility, would
     add significantly to the paper and given the impressive run-times of the
     method presumably wouldn't be difficult to do.
***** TODO a faire
      Le pb c'est les coord spatial pour les humains ! On met AT 1001 genome,
      comme ca on fait des simunaltions pour LFMM. 

      En fait si le dataset est pas mal : [[https://www.simonsfoundation.org/life-sciences/simons-genome-diversity-project-dataset/][Simons diversity dataset]]. On va filter
      la maf et faire une belle carte (si il y a pas de pop admixed le spatial va
      renforcer le clustering)
**** I've annotated minor corrections/suggestions on the manuscript itself, hopefully attached.
*** [[file:Revisions/AOAS1610-012R1R3.txt][R3]]
**** Intro
    In this paper, Caye et al. present the newest iteration of their tess
    algorithm, which constructs an STRUCTURE-like mixed membership model while
    taking the spatial origin of data into account. This is a highly relevant
    problem, as spatial awareness has the potential to increase power, and gives
    more sensible answers when sampling is highly uneven.

    The main purpose of this paper is the presentation of two new algorithms, AQP
    and APLS, that both ofter fast runtimes. The reason why a standard EM cannot
    be used for the present problem is that the spatial awareness enters the
    model in the from a penalty matrix, without explicitly constructing a model.

    As someone unfamiliar with the algorithms presented here, the details
    presented in the paper are enough to follow the basic ideas behind the two
    minimization procedures,
     

**** APLS
    The APLS aogorithm proceeds by first updating each locus individually
    (assuming knowledge of each individual (the Q matrix) unconstrained, and then
    the constraints are enforced by a projection onto the relevant subspaces. As
    someone interested in this approach without too much knowledge in the field,
    I found the description to be lacking, as I was neither informed on how the
    implementation works, nor how the approximation is justified. Spending some
    more space on on what is the major innovation of the project could greatly
    enhance this paper.
***** TODO a faire
      Description plus verbale d'APLS: idée clées.
   
**** Simulations
     The simulation study accompanying the paper is adequate, and convincing that
     the implementation is correct and appropriate. They empirically show that the
     approximations arrive at a solution without any substantial change in error,
     and show that, under the assumed model, that adding space as a covariate
     increases power and reduces error. The underlying problem that is not
     addressed, is what "homogeneity" assumptions are made regarding the spatial
     patterns. I would expect that for populations whose genetic make-up is only
     loosely associated with space, that there is some point where a non-spatial
     algorithm might perform better. This may also be the reason why tess is used
     a lot less than structure/admixture in empirical studies, since the apparent
     assumption of strong spatial structure is not always that easy to make. One
     set of simulations to address that may be to repeat the analysis of fig 1
     where individuals are assigned locations at random. However, since the paper
     is highly technical and empiricists are not likely to be the target audience,
     this may not be the appropriate place for this.
***** TODO a faire    
      Encore un fois c'est le variogramm les test d'autocorélation spatials. Et
      ca serais résolu par le CV. On va mettre les graphes qu'on a fait pour R1.

**** AT
     The application to Arabidopis lacks a comparison point, it would have been
     interesting to compare the result with sNMF or earlier versions of TESS. One
     interesting point, for example, is that the ancestry coefficients in Fig 6B
     appear to be less peaked than in e.g. the data from the Francois et al. 2008
     paper, is this a function of the larger data set or the new algorithm?
     Finally, figure 6A has some extrapolation artefacts that should be corrected.
     Regions in Anatolia and Scandinavia appear to not-have any samples, but are
     assigned clusters from different regions. I assume this is a weird
     tail-behaviour in the spatial smoothing algorithm.
***** TODO a faire
      - enlever l'artefact en turquie.

   Overall, I think this is a solid paper, but the presentation of the main
   algorithms could be a bit more detailed, if not in the main text, in a
   supplementary technical reference.
*** On résume à faire
**** TODO experiments
     - [ ] on reprend les simulations et on bruite les coords. graph RMSE(Q) x
       sigma(bruit) x regularization param 
     - [ ] CV si ca marche ! 
     - [ ] simu 1000 genome (European Africain et Afro americain). Que donne snmf et
       tess3r. Le fichier est énorme, on va faire un LD prunning et un filtrage
       par la maf ! Prendre données ecric ?
     - [ ] simons avec la maf 5%
**** TODO implémentation
     - [ ] un fonction prédict sur un indiv pas vu ! Qui pourrait servir pour la
       cross validation.

** Rnotebook
*** TODO Cross validation                                         :Rnotebook:
    On va voir si la cross validation marche
   
    j'en suis a implémenter tess3_wrapper.R
*** Tess3r avec des coordonnées bruitées                          :Rnotebook:
    [[file:2Article/Rnotebook/Revisions/tess3NoisyCoord.nb.html]]
    
    On voit bien la perte de précision avec la bruit sur les coordonnées. On
    voit aussi que le variogramme permet d'évaluer l'autocorélation spatiale des
    données génétiques.
    

* 3Article                                                         :3Article:
** 2017
*** 2017-01 janvier
**** 2017-01-16 lundi
***** Test de capture d'un truc
    Entered on [2017-01-16 lun. 17:35]
    Test
***** R notebook
    Entered on [2017-01-16 lun. 17:38]
   
    Je vais arreter d'utiliser Bookdown, ca rend mon workflow trop compliqué !!
    Par contre R notebook semble le plus pratique !!
***** Labnotebook
    Entered on [2017-01-16 lun. 17:47]
   
    Only Rnotebook and I git =.nb.html= to capture results !!
**** 2017-01-17 mardi
***** Data with missing value                                    :Rnotebook:
      Entered on [2017-01-17 mar. 09:50]
    Le but est de montrer qu'on est meilleur avec la technique alterné !!
    file:./3Article/LabNotebook/MissingValue.nb.html
    En gros ca montre bien ce que je veux. Après il y a des cas ou ca merde
    surtout avec les missing values pas uniformément réparti... Je sais pas
    pourquoi j'ai pensé que ca serait plus dure dans ce cas.
    Demain on continue le papier :D et on fait des simulations a partir de jeux
    de données réel. 
    On va aussi faire les plots des data : cf mon cahier le
    [2017-01-17 mar.].
    Et il reste un mistere ! Pk le lambda de la reg ridge ne change rien ?
   
***** On ecrit l'article ù*$ù
    Entered on [2017-01-17 mar. 14:20] Bon l'objectif de l'article c'est de
    proposé une méthode d'association à facteurs lattents basé sur de un problème
    d'optimisation.
    C'est un modèle récurent car présent partout ...
    Nous on propose une méthode efficace avec des solutions analytics et un
    algorithme alterné dans le cas de présence de missing values.
    On montre que c'est bien qualibré, c'est rapide et ca marche sur des
    GWAS/EWAS.
**** 2017-01-18 mercredi
***** Bilan du mercredi [2017-01-18 mer.] 
    Entered on [2017-01-18 mer. 17:34]
    J'ai pas percé le mystère du lambda qui sert a rien dans lfmm Ridge. Par
    contre j'ai un nouveau sample de données a partir de vrai dataset. J'ai
    essayé de faire en sorte que les données en sortir resemble le plus possible
    a celle en entré. LFMM ridge fonctionne bien sur celle-ci aussi. Surtout
    quand la part de variance expliqué par X pour les outlier est forte =rho=0.9=! Dans ce
    cas PCA+lm se plante complet.
****** DONE Pour demain
       CLOSED: [2017-01-19 jeu. 10:31]
       - gerer les cas ou la variance est null pour eviter les zscore null
       - verifier la structure de covariance des données simulé (des indiv et des
         locus)
       - Percer le mystere du lambda
       - faire des simulation a la facon de OF, voir mon cahier 
      A demain :D
**** 2017-01-19 jeudi
***** Comparison of analytic and alternated lfmm                 :Rnotebook:
    Entered on [2017-01-19 jeu. 10:54]
    file:./3Article/LabNotebook/AlternatedVsAnaliticRidge.nb.html
    Je veux voir si ont a bien les mêmes solutions !! 
    et percer le mystere du lambda :D
    J'ai plusieurs problèmes:
    - le calcul du sigma dans le cas ridge donne des résultats très petit
      parfois ! pk ?
    - J'ai mis lambda = 0 dans lfmm ridge et alternatedSVD et la recalibration
      GIF ne marche plus !!
    - il s'emblerais finalement que lambda est un effet !!
    On va le mêtre en évidence et essayer de trouver comment le choisir !
***** Choix du lambda dans lfmm ridge                            :Rnotebook:
    Entered on [2017-01-19 jeu. 15:39]
    file:./3Article/LabNotebook/Lambda.nb.html

    Ca doit pouvoir se cross valider !
   
    Plus ca va, plus je me dit que la méthode lasso est pas mal du tout, elle
    permet vraiment de trouver le support ! Les outliers ! Il me faut un moyen de
    la comparer au autres sur les plots de precision-recall. 
***** Bilan de la journée
    Entered on [2017-01-19 jeu. 17:35]
    - Finalement lfmm lasso n'est pas à mettre à la poubelle
    - dans lfmm ridge lambda a une importance, si il est trop grand on a un
      shrinkage dégueulasse (mais est-il mauvais ?)! et si il est trop petit on n'arrive à inverser P.
      Mais dans mes examples c'est quand d'aller chercher l'acp sur l'orthogonal
      de X qui m'interesse ! Il faudrait que j'évalue la perte de puissance en
      fonction du lambda !
**** 2017-01-20 Vendredi
***** Fin de semaine
      Entered on [2017-01-20 Ven 15:31] J'ai une vision claire de l'article et de
      comment je vais l'organiser. En particulier je pense que je vais vendre en
      disant que je fait une estimation de la structure lattente mais sans
      prendre la variance du à la co-variable X (l'un est global l'autre ne
      concerne que quelque locus, d'ou l'interet pour le lasso). Je pourrais bien
      illustrer ca avec les exemples numeriques simples (comparaison avec lm, PCA +
      lm). Cette partie est vraiment que optimisation based dans le formalisme.
      On ajoute des statq quand on fait le test d'hypothèse. Et pourquoi pas
      ajouter le test d'hypothèse avec le lasso. 
      A la semaine prochaine !!!
**** 2017-01-23 lundi
***** Sample from true data set                                  :Rnotebook:
    Entered on [2017-01-23 lun. 12:44]
    file:./3Article/LabNotebook/SampleFromTrueDataSet.nb.html

    On va voir comment les méthodes réagisses en fonction de rho (la proportion
    de variance expliquée par X) et la correlation avec la structure. Je vais en
    profiter pour avoir un vrai test d'hypothèse pour lfmm ridge et lasso.
***** DONE C'est parti
      CLOSED: [2017-01-24 mar. 10:52]
    Entered on [2017-01-23 lun. 16:13] Réunion avec nous a permis de def les
    résultats ! c'est parti La je vais push mais je suis en train de mettre en
    place le lm a l'arrache a la fin, après lfmm. Je suis dans les test. Je
    comprends pas pk il y a besoin d'un gif. Et il faudrait que je réflechisse un
    peut a théoriquement comment l'expliquer a peut près proprement !!
    - [X] Aussi je voulais implementer une option pour choisir la proportion d'outlier
    dans le lasso.
**** 2017-01-24 mardi
***** lfmm ridge et PCA+lm
    Entered on [2017-01-24 mar. 09:19]
   
    Dans file:./Article3Package/tests/testthat/test_lm_zscore.R quand on prend un
    lambda très grand lfmm ridge et PCA+lm font la même chose logique car c'est
    comme ci il n'y avait pas de projection sur X quand lambda est grand !!
***** lfmm lasso avec sparse.prop
    Entered on [2017-01-24 mar. 10:49]
   
    C'est implémenté. Mais les premiers resultats ne sont pas tops. 
    En gros ca fait la même chose que lfmm ridge... 
    see file:./Article3Package/tests/testthat/test_lm_zscore.R
    Il faudrait trouver un exemple ou c'est mieux :D
***** Comparaison des méthodes sur une simu de 1000 genome       :Rnotebook:
    Entered on [2017-01-24 mar. 11:17]
   
    C'est parti c'est un résultat de validation pour le papier !!
    file:./3Article/LabNotebook/Validation_1000Genome.nb.html . Ca marche bien :D On
    arrive bin a montrer que : 
    - c'est robuste au choix de K
    - c'est conservatif mais c'est mieux que liberal
    - quand il y a trop d'outlier PCA + lm fait n'imp
****** DONE reste a faire
       CLOSED: [2017-01-24 mar. 17:26]
       - [X] lancer avec LEA et lasso
****** Conclusion 
       - lasso et ridge font pareil sur ses exemples la
       - LEA fait n'imp
       - on voit bien la force de lfmm ridge sur des exemples avec beaucoups de
         correlation en X et U1 et et beaucoups d'outlier.
       - Le FDR est un peut trop conservatif.
***** Run on krakenator
    Entered on [2017-01-24 mar. 16:57] 

    On va essayer de lancer les notebook long sur krakenator avec la command
    =rmarkdown::render(file)=

    ^_^': j'ai pas pandoc sur krakenator...

    Si je veux me lancer sur krakenator je vais devoir faire des scripts !!!
***** Bilan de mardi !! 
    Entered on [2017-01-24 mar. 17:21]
   
    Il y a la validation sur les data simulées a partir du 10000 genome qui
    tournent. Ca donne des bon résultats a par pour LEA::lfmm :(. Mais pour le
    reste on montre bien ce qu'on veut. Les petits bemols: 
    - le lasso et le ridge ont l'aire de donner la même chose.
    - parfois le test est trop conservatif. Je trouve que c'est mieux dans ce
      sens que trop libéral, au moins on controle le fdr.
   Globalement on avance :D et mon env de travail déchire sa race !
  
   Demain le <2017-01-25 mer.> on fait des EWAS !!!!! Et on dechire tout !!
**** 2017-01-25 mercredi
***** Mise a disposition du code et des données
    Entered on [2017-01-25 mer. 16:49]
    Pour le code github et pour les données torents :D
***** Fin de journée
    Entered on [2017-01-25 mer. 17:11]
    J'ai la putin de journée cette article de ù*^$ù*ù : cite:Rahmani_2016. Bon
    j'ai quand même les données ewas qu'il a utilisé. 
***** DONE Avant la fin de la semain putin !!!
      CLOSED: [2017-01-30 lun. 14:23]
     - [X] recupere des données GWAS pour faire un asssociation avec var envir
     - [X] lancer le script ReFACTor des autres branques.
     - [X] refaire leur association logistique donc X ~ G et avec la correction X
       ~ G + U + les autres co variables (ils disent qu'il y a la correction pour
       les batch mais d'après OF non... ils ont surement recopié un truc sans le
       comprendre...)
**** 2017-01-26 jeudi
***** G/EWAS and adjustment
    Entered on [2017-01-26 jeu. 10:44]
   
    Je me suis bien pris la tête hier pour savoir comment il faisait leur G/EWAS
    et "ajustait" pour la structure... C'est bien ce que je pensais ils ajoute
    simplement les scores (de la l'acp, ou autre) dans glm(Y ~ G + U...). D'après
    florian il utilise plutot plink pour faire leur regression logistic. On va
    utiliser l'algo de florian : https://github.com/privefl/bigstatsr
   
    *ATTENTION ALERT*  En faite en GWAS il font plusieurs regression univarié !!
    Flo lui veut faire avec lasso pour trouver les snips causaux par exemple.
    Mais dans la litérature ce qui se faire c'est de seuiller sur les score des
    regressions univariées :D !! 

    En faite c'est finalement pas différent de mon lm a la fin !! sauf que c'est
    dans l'autre sens !!! 
***** ReFACTor demo                                              :Rnotebook:
    Entered on [2017-01-26 jeu. 15:25]
   
    file:./3Article/LabNotebook/refractor.nb.html j'ai juste récupéré le code du [[https://github.com/cozygene/refactor/tree/master/R][github]].
   
****** TODO Comment ce jeux de données demo a été simulé ?
       Il plot le qqplot mais ca montre juste qu'il n'y a pas d'outlier en faite
       ! Il est tout plat !
**** 2017-01-27 vendredi
***** Le dossier BenchmarkDump 
    Entered on [2017-01-27 ven. 09:44]
   
    Je l'ai créer sur krakenator ici
    /home/cayek/Projects/Article3/Article3Package/BenchmarkDump/

    Sur timc-bcm-15 je vais mettre un lien symbolique.

***** Install Article3Package sur krakenator
    Entered on [2017-01-27 ven. 10:05]
   
    Sur krakenator je sais pas pk mais il faut installer le pacakge avec 
   
    #+BEGIN_SRC R
    devtools::install(dependencies = FALSE)
    #+END_SRC
    Sinon il essaie d'installer des pacakge qui sont deja installé et echoue... Je
    sais pas si ca ne vient pas du package =git2r= ...A voir.

    En faite si maintenant ca marche... il y a le =git2r= qui echoue a la fin
    mais le package est bien installé ! 

***** Fin de semaine
    Entered on [2017-01-27 ven. 16:51]
    Putin de semaine de merde !!! 
   
    Il faut que j'arrive a reproduire le reference based si je veux me comparer
    honettement. D'arpès OF il n'y a pas de batch effect correction car sinon on
    l'aurais eu dans les co variable !! Le mystère a perser c'est comment il
    trouve la composition céllualaire 

    Pour les GWAS on va dans frichot, les data c'est celle du HGDP + on prend les
    coordonnées des pop et on creer des var env avec le package raster !!!
    OF: il y a 3 pressions: 
    - le climat
    - la diete
    - les patogènes 

    A Lundi !!
**** 2017-01-30 lundi
***** Lasso, ridge et lambda                                     :Rnotebook:
    Entered on [2017-01-30 lun. 14:24]
   
    Objectif: touver des simulations où
    - lasso est meilleur que ridge
    - le choix du lambda pour lasso n'est pas un choix extrème 
    Je veux aussi trouver un critère de choix du lambda !!
   
    J'ai trouver des simulation ou le choix de lambda influe vraiment !! Sur les
    jeux de données simulé depuis le 1000 génome ! Voir les résultats :
    file:./3Article/LabNotebook/LassoRidgeEtLambda.nb.html .
**** 2017-01-31 mardi
***** Données simulé from le 1000 genomes                        :Rnotebook:
    Entered on [2017-01-31 mar. 13:56]
****** Objectif:
     reponds: Quelles sont les spécificités des dataset simulé from le
     1000 genomes et qui fait que lfmm echoue pour certaines valeurs de lambda ?
****** Résultats:
       de l'acp sur le chrm 22 du 1000 genomes :
       file:./3Article/LabNotebook/Validation_1000Genome.nb.html
      
       Les résultats montre qu'il y a un choix de lambda optimal : 
       file:./3Article/LabNotebook/DataFrom1000Genome.nb.html
****** Conlusion 
       Il y a un lambda optimal qui controle bien la corrélation avec la
       structure de fond ! 
      
       Il nous faut un critère pour le choisir ! 
      
       Il faut que je teste la version avec nuclear norme !!! Il me semble me
       souvenir que je l'avais bien vite abandonné ! Mais !!! je n'avais fait que
       des tests sur mes simulations générative bien propre et avec lambda à 0.
******* Le [2017-02-02 jeu.] :
        En fait je pense surtout que ces exemples sont très atypiques et
        dificil. Je vais essayer de simuler des covariable orthogonal a plusieurs
        axes ! 
       
        Les simulations que viens de faire à la fin montre bien sur des
        situations plus réaliste on dechire tout ;) et il faut un lambda petit ! 
******** DONE Ne pas rejeter cette situation ! 
         CLOSED: [2017-02-02 jeu. 10:22]
         Le lambda optimal n'existe que dans des cas particulier. Mais il
         faudrait quand même que je me penche sur la question !!
        
         Je pense que sur ses simulations particuliere la projection tuait plus
         vite la structure de fond que la partie de correlation avec X. Du coups
         quand le lambda était trop petit la structure de fond apprenait la
         partie de corrélation avec X. C'est pour ca que je fait moins bien que
         lm dans ce cas. 
        
         On retrouve ce phénomène quand je prend un K trop grand sur les
         simulations gausiennes. Il faut que lmbda soit suffisament petit pour
         empecher que la corrélation expliqué par X ne soit aprise par l'ACP.
         Voir file:./Article3Package/tests/testthat/test_NormalSAmpler2.R.

***** Nuclear norm LFMM                                          :Rnotebook:
    Entered on [2017-01-31 mar. 15:54]
****** Objectif: 
       on va faire une vrai evualuation de cette méthode pas seulement sur des
       belle simulations toutes propres !!
****** Resultats:
       file:./3Article/LabNotebook/NuclearLfmm.nb.html
****** Conclusion
       Je ne sais pas pk mais c'est moins bon avec la nuclear norme ... J'ai même
       essayer de corrigé avec le U trouvé par lfmm nuclear norme en co variable
       d'un lm a la fin. De plus quand je fais un hard thresholding plutot qu'un
       soft ca deviens très lent. Enfin je ne retombe pas sur le resultat de
       lfmm + ridge dans le cas d'une alternance de pca normal et lm ridge.
*** 2017-02 février
**** 2017-02-01 mercredi
***** HGDP experiment                                            :Rnotebook:
    Entered on [2017-02-01 mer. 15:34]
****** TODO Objectifs
       - [X] lancer l'acp
       - [X] lancer la crossvalidation
       - [ ] lancer lfmmRidge avec imputation par la moyen
       - [ ] lancer lfmmRidge alterné (=finalLfmmRdigeMethod=)
       - [ ] lancer lfmmRidge avec imputation par lotter
******* DONE Bug dans =HGDP_runs=
        CLOSED: [2017-03-01 mer. 10:57]
        #+BEGIN_SRC R
        > library(Article3Package)
        >
        > G.file <- "~/Projects/Data2016_2017/Hgdp_Li/Hgdp_Li.rds"
        > X.file <- "~/Projects/Data2016_2017/Hgdp_Li/X_tmp.rds"
        >
        > s <- TrueSampler(G.file = G.file,
        +                  X.file = X.file,
        +                  outlier.file = NULL,
        +                  n = NULL,
        +                  L = NULL)
        >
        >
        > lambdas <- c(1e-10, 1e0, 1e2, 1e3)
        > Ks <- c(5, 20)
        > HGDB_runs(s, Ks = Ks, lambdas = lambdas, save = TRUE)
        Error in tempfile(tmpdir = exp$benchmakdir, fileext = ".rds") :
        valeur 'tempdir' incorrecte
        De plus : Warning message:
        executing %dopar% sequentially: no parallel backend registered
        >
        #+END_SRC
        Ca vient surement de dumpExperiment !!! Du coup laner lfmmRidge alterné à
        planté !!
       
        C'est juste que je me suis pas lancé dans le bon dossier !!! ./Article3Package/
****** Resultats
       file:./3Article/LabNotebook/HGDP.nb.html
***** Bilan de cette journée
    Entered on [2017-02-01 mer. 16:55]

    J'ai pas de solutions pour trouver le lambda, mais au moins je suis en train
    de converger vers uniquement lfmmRidge. Mon critère de comme de la
    correlation entre U et X sur le HGDP donne le même paterne que sur mes
    simulations, voir: 
    - file:./3Article/LabNotebook/HGDP.nb.html
    - file:./3Article/LabNotebook/DataFrom1000Genome.nb.html
    C'est bizare !!! Il y a aurait pas un moyen automatique de choisir ce lambda.
   
    :( Ce qui est triste c'est que au final mes simulations sur les vrai jeux de
    données montre surtout que PCA+lm est pas si mal !!

****** Questions
       - Je pense pouvoir avoir des resultats avec lfmmRidge alterné, pourtant je
         le papier de cite:mazumder10_spect_regul_algor_learn_large_incom_matric
         il dit qu'il n'y a pas de resultats avec la hard thresholding ! 
       - Comment trouver lambda ? 
       - Comment valoriser la méthode par rapport à PCA+lm qui fait pas si mal !
         Mon idée de variance de bacground est a développer ! 
       - Est ce que sur les ewas je vais faire si bien que ca, surtout que les
         méthodes auquel je veux me comparer veulent apprendre un truc bien
         particulier (la composition cellulaire).
       - Je pense que la ou on gagnerais c'est avec un lfmm avec un lien
         logistique ! 
       - Il faudrait que je me compare au GWAS plygénique aussi a locasion ! Voir
         les papier de stephens !
**** 2017-02-02 jeudi
***** lfmmRidge cross validation                                 :Rnotebook:
    Entered on [2017-02-02 jeu. 09:17]
****** Objectifs
       Montrer les resultats de crossvalidation sur des simulations
****** Resultats
       :PROPERTIES:
       :CUSTOM_ID: cross_validation_exp
       :END:
       file:./3Article/LabNotebook/CrossValidation.nb.html
       On observe les mêmes paterns que avec les simultations from a true
       dataset : file:./3Article/LabNotebook/DataFrom1000Genome.nb.html. 
****** Conclusion
       C'est pas gagné pour trouver un critère pour choisir le lambda... Ce
       pattern est juste typique des données binaire...
      
       Au final il n'y qu'un seul exemple qui m'enmerde ! Et si cétait un cas
       très particulier ! Dans les vrais dataset les variables X est corrélé avec
       plusieurs axes ! C'est deja ce que je fais en sommant plusieurs X.
***** Calibration du test d'hypothèse                            :Rnotebook:
    Entered on [2017-02-02 jeu. 16:12]

    Bon on est en gros d'accord sur la méthode !! On va explorer la calibration.
    C'est un notebook interactif, cad que les experience sont pas longues du coup
    on peut jouer avec !!!

****** Objectifs
       Montrer que la méthode est bien calibré sur tous mon panel de test !! 
****** Resultats
       file:./3Article/LabNotebook/calibration.nb.html
      
       J'avais fait une erreur dans ma fonction calibration... 

       Il semblerait que quand il y a trop d'outlier le gif marche mal !!! Il
       rend le test beaucoup trop conservatif. C'est genant si je vends lfmm
       comme utile quand il y a beaucoup d'outlier.
****** Conclusion
       Il faut que je reflechisse au test d'hypothèse. Je sur estime l'erreur (la
       variance des estimateurs) surement a cause de l'auto-corrélation des
       intividus ! Je pense que c'est d'autant plus vrai que quand je fait G - C.
       Il faut que je trouve un moyen de corriger proprement pour ca ! (voir ma
       ccl a la fin du notebook). Le GIF semble ne pas marcher quand il y a trop
       d'outlier, c'est logique car c'est en faite juste une median donc si il a
       trop d'outlier ca la tire ! 

       On doit pouvoir mesurer cette autocorrelation !! 
      
       Je reviens ;D

******* DONE SSMPG 2015 
        CLOSED: [2017-02-16 jeu. 15:36]
        Les resultats sont vraiment pas terrible à par sur le case 2. Je pense que
        le modèle n'est pas adapté. Il faudrait un moyen de le detecter ! Un
        critere qui dise si ma modélisation est bonne ou pas.
******** Conclusion
         On ne peut pas le detecter, le modèle est pas adapté c'est tout ! En
         tout cas on ne dit pas de chose fausse, le FDR est controlé.

         Voir [[#model_choice][Sur le choix des modèles de test d'hypothèse]]

***** Bilan de cette journée ! 
    Entered on [2017-02-02 jeu. 18:08]

    Il faut bosser le test d'hypothèse ! Parfois tester B = 0 à pas l'aire bon du
    tout. Il faudrait définir clairement mon hypothèse, avec la variance de
    background et le B !

    Je veux un test parfaitement calibre demain bitch !!
**** 2017-02-03 vendredi
***** Partir en vacance serein... ou pas
    Entered on [2017-02-03 ven. 15:30]
****** Les mistère restant sur la méthode a ce jour
       - Comment calibrer le test, je suis sur qu'il y a coup a jouer ici. Voir
         mon cahier. Mais je ne veux pas faire appel a une méthode ad hoc à la
         fin.
       - L'algo d'alternance de lfmmRidge converge-t-il en théorie ? Je pense que
         oui mais il faudra faire un peut de biblio. Voir cite:josse2009gestion.
       - Cette algo est-il vraiment utile ? Je pense que oui aussi, les resultats
         de file:./3Article/LabNotebook/MissingValue.nb.html son bizare mais je pense
         qu'on va reussir trouver des simulations ou c'est mieux :D. Le top
         serais de montrer que on en viens a dire n'importe quoi quand
         l'imputation est faite a l'arrache. Mais si je recalibre mes tests pour
         le degre of freedom effectif ou un truc comme ca... Bon on verra.
       - On peut utiliser ca en EWAS ??
****** Bonne vacance
       On progresse !!!!!
**** 2017-02-14 mardi
***** Calibration des tests avec boostrap                        :Rnotebook:
    Entered on [2017-02-14 mar. 10:50]
****** Objectif
       On va ajouter une option boostrap au test en fin de chaine.
      
       On va faire un bootstrap du model de lfmm complet.
****** Resultats
       file:LabNotebook/bootstrapCalibration.nb.html
****** Conclusion
       Non c'est logique que sigma soit encore moins bien estimé ! Le bootstrap
       sous estime l'erreur car les datasets sont très corrélés ! 
***** Bilan de la journée
    Entered on [2017-02-14 mar. 18:21]
   
    Il faut que je trouve un moyen destimer le nombre de degré de liberté
    effectif ! Voir [[https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)][cette page wikipedia]].

    A demain !!
**** 2017-02-15 mercredi
***** Les deux gros problèmes à résoudre
    Entered on [2017-02-15 mer. 09:38]
****** Calibration des tests
       Je veux un test d'hypothèse calibré !!
       - bootstrap : donne comme lm théorique voir
         [[file:LabNotebook/bootstrapCalibration.nb.html]].
       - permutation : on va perdre en puissance. Mon intuition est que on test
         ne sachant pas X, or on connait X ! 
****** Choix du lambda (choix du model)
       :PROPERTIES:
       :CUSTOM_ID: lambda_choice
       :END:
       Comment choisir le lambda, c'est a dire un modèle ! 
       - cross validation ne marche pas car ce n'est pas la généralisation que
         l'on veut
       - on pourrait essayer la reproducibilité (cad est ce que on retrouve les
         même resultat quand on prend des sample d'indiv). Mais j'y crois pas !
****** Rmk
       Le plus important est peut être la calibration du test ! Car si on a un
       test bien calibré on ne dira pas de connerie à la fin ! On aura peut être
       moins de puissance ! Mais on dit la vérité ! 

       Go calibrarion ! 
***** Quelques experience pour la calibration des tests          :Rnotebook:
    Entered on [2017-02-15 mer. 11:47]

    On va essayer de calculer l'équivalent du gif mais sur le residue !
****** Objectif
       Trouver un moyen d'esimer une variance residuelle plus juste !
****** Resultats
       [[file:LabNotebook/gifExperiment.nb.html]]
****** Conclusion
       Je pense pas que la corrélation va se voir dans les resudus, ils sont
       construit pour etre indépendant ! C'est vraiment dans les beta que ca se
       voit ! 
      
       C'est la merde bradley ! Il faut que je reflechisse à un model stat ou je
       peux faire des tests !!!! Pour le moment j'ai pas la solution ! Mon lm à
       la fin marche pas car c'est pas iid ... Enfin je pense !
**** 2017-02-16 jeudi
***** Réu OF
      Entered on [2017-02-16 jeu. 11:59]
   
    - on arrête de se prendre la tête sur la calibration, je verrais plus tard.
      Surtout qu'il y a beaucoups de méthode de calibration des test (exemple:
      cite:stephens16_false_discov_rates ou les truc de lissage pour enlever le
      ld etc...)
    - <<ld>>: En parlant de LD, le V du modèle est censé le capter, a valider. Et c'est
      un problème pour les tests d'hypothèse.
    - On va partir des résultats et garder lfmm avec lm + gif ! On part des
      résultats et on remonte.
    - Méthode : on décrit le plus clairement ce qu'on fait ! Pas de mystique ;D
    - On verra à la fin pour se prendre la tête sur les stats à la fin :p 
***** Sur le choix du lambda (choix de model)
      :PROPERTIES:
      :CUSTOM_ID: lambda_model_choice
      :END:
      Entered on [2017-02-16 jeu. 14:29]
   
      J'en avait déja parlé ici : [[#lambda_choice][Choix du lambda (choix du model)]]. Je me répète
      c'est vraiment une affaire de choix de model ! Mes experiences sur case2 de
      ssmpg (voir [[*Calibration du test d'hypothèse][Calibration du test d'hypothèse]]) montre que case2 n'est pas
      adapté a ce model ! Et c'est tout ! De toute facon ce que je dit est bien
      qualibré à la fin ;)
   
      Si lfmm Lasso marchait bien on aurrait un critere simple : la proportion des
      non null. Mais je pense qu'il y a plus de boulot pour lfmm lasso ! On verra
      plus tard.

      Au final, le plus sage est d'appliquer le model au cas ou on sait que la
      structure est plus forte que le reste -> un lambda petit. On pourra le
      justifier avec mes petit raisonnement (voir cahier le 30/01/2017). C'est le
      cas le moins violant par rapport à lm. On pourra peut etre montrer un choix
      de lambda optimal.

****** Un critère pour lfmm ?    
       Dans mon cas la [[#cross_validation_exp][crossvalidation]] donne toujours le meilleur critère pour
       lambda grand. Mais ca permet de voir la gamme de lambda ou il se passe
       quelque chose. 

       On va proposer ce critère visuel! La méthode est rapide c'est l'occasion
       de tester plusieurs modèles.
      
****** Conclusion 
       Je m'adresse a des situation ou la structure est plus forte que XB (c'est
       l'hypothèse) => lambda doit être petit.


***** Sur le choix des modèles de test d'hypothèse
      :PROPERTIES:
      :CUSTOM_ID: model_choice
      :END:
      Entered on [2017-02-16 jeu. 15:37]
     
      Quand on construit un test d'hypothèse, c'est très dur de savoir si ce test
      est adapté à notre situation. Je veux dire q'uil n'y à pas de critère
      objectif pour ca, comme la crossvalidation ou autre...Car ce n'est pas le
      modèle qui explique le mieux les données qui correspond a mon test d'hypothèse.
**** 2017-02-17 Vendredi
***** Un plan d'attaque pour le seminaire BCM
      DEADLINE: <2017-03-03 Ven>
      Entered on [2017-02-17 Ven 09:59]
****** Les resultats
******* Validation sur simulation                                :Rnotebook:
        [[file:LabNotebook/simuValidation.nb.html]]
******** TODO Simulations
         From le 1000 genomes. 2 cas : 
         - peu d'outlier
         - beaucoups d'oulier
          
         Voir avec olivier les simus qu'avait fait eric dans
         cite:frichot13_testin_assoc_between_loci_envir. 

         Voir les simu qu'on peut faire d'autre

******** DONE Les méthodes
         CLOSED: [2017-03-01 mer. 15:29]
         - [X] lfmm ridge
         - [X] FAMT
         - [X] SVA
         - [X] PCA+lm
         - [X] méthode oracle+lm
         - [X] lm
         - [X] Refactor
         - [X] LEA
******** Le message
         - les facteurs lattents posent problèmes
         - quand il y a beaucoup d'outlier lfmm gagne sur lm et lm+PCA
         - Toutes les méthodes qui prennent en compte les facteur lattents disent
           en gros la même choses.
******** DONE Implementation
         CLOSED: [2017-02-17 Ven 16:22]
         Comparaison sur simulated data set function.
         J'implemente ca cette aprem !
******* TODO Missing values                                      :Rnotebook:
        Même experience que [[*Validation sur simulation][Validation sur simulation]] mais avec une strategie
        d'imputation des missing values
       
        [[file:LabNotebook/missingValuesSimuValidation.nb.html]]
******** Le message
         - La méthode alternée est meilleur quand il y a des missing values
         - je pense que je vais mettre juste deux lfmm avec imputation par la
           mean et lfmm alterner. Pour avoir un message clair.
          
******** TODO Implementation
         - [X] LEA with missing value 
         - [X] FAMT with missing value 
         - [X] lfmmRidge with missing value
         - [X] lm with missing value (on met des zeros, et on divise par le vrai
           nombre de données :D)
         - [ ] le notebook
******* Critere de reproductibilité                              :Rnotebook:
        J'espere que ca va marcher...Ok
        cite:crossValidated_PCACrossValidation_2017 m'a fait changer d'avis. On
        va essayer des missing values. 

        Ca marche !!! [[file:LabNotebook/crossValidationCriteria.nb.html]]
        Pas sur toutes mes simulations...
       
******** TODO La suite 
         Les bars d'erreurs ne sont pas pertinente par ce que d'un lambda a
         l'autre je suis sur que les erreur sont corrélé. Faut que je regarde
         plus en détail comment proprement faire de la cross validation (c'est
         vrai que je me suis jamais vraiment documenté). Peut être que de faire
         un vrai kfold et la moyen est plus pertinent !! La on sample au
         hasard...
        
         Donc : 
         - [X] faire un kfold pour la cross validation (k leave out truc ...):
          
           En faite non je pense que c'est pas trop mal mon [[https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Repeated_random_sub-sampling_validation][montecarlo crossvalidation]].

         - [ ] lancer sur les données ssmpg/simulation qui posait probleme !
         - [ ] lancer sur HGDP et GSE42861
         - [ ] cross valider sur K
******** Conclusion
         - avec beaucoup  de missing values pour la cross validation, on a des
           pattern plus franch. J'ai mis 0.5
         - C'est un critère de cross validation qui dit ce qui est mieux si on
           veut fitter les données... C'est pas forcément ce que l'on veut faire.
******* TODO GWAS                                                :Rnotebook:
        Le HGDP. Et on compare se qui sort par rapport aux autres papiers.
******** Résultats
         [[file:LabNotebook/HGDP.nb.html]]
******** Le message
         - On fait comme dans cite:frichot13_testin_assoc_between_loci_envir.   
        
******* EWAS                                                     :Rnotebook:
        On lance lfmm dessus et on compare se qui sort.
       
        [[file:LabNotebook/GSE42861.nb.html]]
******** DONE pas encore fait
         CLOSED: [2017-03-08 mer. 08:50]
         On retrouve bien les locus du papier cite:Rahmani_2016, mais les qqplot
         ne resemble pas trop a ceux du papier... Ce que je peux faire c'est : 
         - [X] Run de lfmm : 
           - correction de G pour les autres facteurs de confusion
           - G - C (de lfmm)
           - on glm(G_ ~ X)
         - [X] Run de Refactor
********* Ccl
          Avec GLM c'est pas tout a fait calibré mais avec un petit par dessus ca
          va ! On retrouve bien les locus du papier. 

          Par contre Refactor n'est pas bien calibré je sais si il recalibre dans
          le papier mais chez moi c'est pas au top ! Après il me manque les batch
          effect peut être que j'aurais du les trouvé finalement ...

          Bref, avec la recalibration ca marche ! 
******* TODO Robustesse au choix des parametres
        A voir comment on peut faire.
***** FAMT test                                                  :Rnotebook:
    Entered on [2017-02-17 Ven 13:10]
 
    Test of the [[http://famt.free.fr/][famt package]] [[file:LabNotebook/FAMT.nb.html]]
***** SVA test                                                   :Rnotebook:
    Entered on [2017-02-17 Ven 14:32]
   
    Test of [[http://www.bioconductor.org/packages/release/bioc/html/sva.html][SVA R package]] : [[file:LabNotebook/SVA.nb.html]]
***** Bilan de la semaine
    Entered on [2017-02-17 Ven 16:28]
   
    On avance bien !! La semaine prochaine on continue d'inmplementer les tests
    systématiques. On discute avec olivier pour s'assurer que ca va dans le bon
    sens ! 

    OUS !
**** 2017-02-20 Lundi
***** DONE Est ce que lfmm est sensé enlever le "problème" du ld dans les tests ?
      CLOSED: [2017-02-20 Lun 21:58]
    Entered on [2017-02-20 Lun 20:59]
   
    Pour réponde à [[ld]].

    Déja je veux revenir sur le fait que c'est un problème ? Est ce que c'est
    référencé comme etant un problème ? A voir dans la biblio.

    En tout cas lfmm ne va pas résoudre ce problème, car si les locus sont
    autocorélé, les $B_j$ le seront aussi ! Même d'un point de vu biologique
    c'est logique. Si un locus monte en fréquence quand il est nord alors les
    autre aussi, à cause de ce que l'on appel le déséquilibre de liaison en
    genetique des populations.

    Je pensais que l'on ne controlait pas le fdr parce que certain $B_j$ sont non
    null alors qu'il n'y a pas d'association ici. Mais la on confond l'hypothèse
    biologique et statistique. 
   
    Par contre, ce qui est vrai est que quand les tests sont corrélé ca biaise
    l'estimation du taux d'erreur. Comme expliqué sur [[https://en.wikipedia.org/wiki/Multiple_comparisons_problem#Assessing_whether_any_alternative_hypotheses_are_true][cet article wikipedia]].
**** 2017-02-21 mardi
***** Bilan de la journée
    Entered on [2017-02-21 mar. 16:39]
   
    Je pense que je vais articuler le papier et la présentation comme ca : 
    - présentation des modèles à facteur lattent et leurs applications
    - présentation des algos 
    - interêt pour notre domaine
    - nos algos
    - nos resultats

    On a les résultats, demain je fais la biblio final et j'identifie tous les LFMMLike.

    J'ai l'impression que tous se passe bien parce que je valide sur mon
    modèle... Il faut que j'ai une vision plus claire de la biblio pour avoir
    confiance en ma demarche. Comment les autres on valider ?
**** 2017-02-23 jeudi
***** Bilan de la journée et long week end
    Entered on [2017-02-23 jeu. 16:36]

    On a bien avancé aujourd'hui : 
    - plan de la résentation dans le cahier
    - critère de cross validation qui marche pas mal !
     
    A Mardi !! Mardi on commence a générer les figures final pour la présentation
    et on la fait en parallèle ! Voir mon cahier.
*** 2017-03 mars
**** 2017-03-01 mercredi
***** Deploy on krakenator with git
    Entered on [2017-03-01 mer. 11:04]

    - I create a repo on krakenator /home/cayek/GitRepo/Article3.git
    - [[file:hooks/post-receive.sh][post-receive hook]]
    - add a remote krakenator_deploy
**** 2017-03-02 jeudi
***** Illustration avec Arabidopsis Athaliana                    :Rnotebook:
    Entered on [2017-03-02 jeu. 08:49]

    Je veux faire un exemple pour illustrer les facteur de confusion, en
    replacant ma super carte :D
****** Resultats
       [[file:LabNotebook/AthalianaIllustration.nb.html]]
******* Avant et après le gif
        Avant le gif, on observe que rien n'est significatif ! Mon
        interpretation : le modèle linéaire simple n'est pas adapté, du coup la
        distribution sous H0 est fausse ! Avec le gif ce qu'on fait c'est une
        recalibration des pvaleur en utilisant le fait que presque tout le monde
        est sous H0 et on a une loi normal en gros, c'est l'idée de "Learning from
        the Experience of Others" dans cite:Efron_2009. Donc j'appel ca un gif
        mais c'est plutot une recalibration ! 

        Dans le modèle linéaire : $$G_j = Xb + e$$, les hypothèses fausses sont :
        - e gaussien mais à la limite c'est pas si grave (l'estimateur de B est
          gaussien)
        - les indiv sont iids. Ca donne une mauvaise estimation de la variance de
          $\hat{B}$
        - les locus sont iids. Ca donne une mauvaise estimation du FDR (je crois
          que dans BH il utilise ca pour le controle du FDR)

          Bon tout ca c'est de idées en vrac mais ca fait du bien de les écrire
          !!

          Suite de mes réflexions sur le cahier ! (3/3/17)
******* DONE Pourquoi ca ne marche pas comme je veux !!!
        CLOSED: [2017-03-03 ven. 11:35]
        Je m'attends a ce que lm donne beaucoup trop de pic, la quand je fais dfr
        control personne ne sort pour lm ...

        - [X] lancer lfmm sur une grille
        - [X] on va recalibrer avec autre chose que le gif c'est surement ca le
          pb (enfin un des pb)

          J'ai trop faim j'y vais !!
******** Conclusion 
         Ca marche avec le package =localfdr=. On a bien beaucoup plus de
         significativement corrélé avec lm. 

         Il faut que je comprenne bien les méthodes de recalibration !! Et que je
         justifie pk ce n'est pas mal honette ! Voir mon cachier le 3/3/2017
******** Conclusion 2 [2017-03-06 lun.]
         Il faudra forcement corrigé pour le test d'hypothèse, car on ne va ma
         mettre suffisament de variable lattente pour enlever tout le LD. Sinon
         ca pose des problèmes pour l'estimation des variables lattentes.
***** Les scipts long ! 
    Entered on [2017-03-02 jeu. 09:44]

    Je vais les mettre dans des fonctions plutots ! Comme ca j'ai juste a push
    sur krakenator et lancer la fonction ;D. En plus ca permet de documenter les
    scripts !!! Tout est package !!!

    Le workflow c'est package-notebook-orgmode: 
    - pacakge : un max de code et des test
    - notebook : le codé visuelle, rendu, plot,
    - orgmode : timeline, comment avance le projet
**** 2017-03-07 mardi
***** Programmation défensive
    Entered on [2017-03-07 mar. 08:56]
   
    On va utilisé [[https://github.com/hadley/assertthat][assertthat]] pour faire de la programmation defensive a fond !!
    Ca me permettra de comprendre se qui marche pas quand je reviendrais sur mon
    code :D
***** RUSH !!!!
    Entered on [2017-03-07 mar. 18:32]

    On y est presque pour le presentation demain je fini !!!!! Il me reste juste
    les resultats a generer même si ils sont mauvais je les ajoutes ! 

    Faut que je fasse la recalibration de cite:wang2015confounder (avec la median
    et le mad !!) et on est bon je genere ! 

** Tasks
*** DONE Test
    CLOSED: [2017-01-16 lun. 17:35]
   Test de capture
*** DONE Learn Rnotebook
    CLOSED: [2017-01-17 mar. 09:50]
    Il y a quand même quelque bug... pour regler la taile des fig il faut le
    mettre dans le chunk de setup il semblerait !!
    On Ne peut pas view in github... on doit ddl avant ! 
   
    Custum =Rmarkdown= html output: http://rmarkdown.rstudio.com/html_document_format.html
    Custum example: 
 #+BEGIN_SRC R
 ---
 title: "LFMM with missing value"
 author: "kevin caye"
 date: "16 janvier 2017"
 output: 
   html_notebook:
     toc: true
     toc_float:
       collapsed: false
       smooth_scroll: false
     theme: journal
     highlight: tango
 ---
 #+END_SRC
*** DONE Les questions qui restent en suspet le <2017-01-20 Ven> et a faire la semaine prochaine
    CLOSED: [2017-01-31 mar. 17:21]
    - [X] Pk mon calcule de B.sigma2 est mauvais ?
    - [X] Reussir a mettre lasso dans les graphes precision-recall
    - [X] Visualiser l'évolution de la precision en function du lambda dans le
      ridge !!
    - [X] Pk dans file:./3Article/LabNotebook/AlternatedVsAnaliticRidge.nb.html lfmm ridge
      et lfmm analytics ne donne pas le même resultat sur le premier exemple ! Je
      pense que c'est parce que je ne laisse pas l'algo aller a assez loin ! Pour
      le papier il faut que les deux donnent la même chose ! Sinon j'ai aucun
      espoir d'avoir des resultats de convergeance !
    - [X] C'est en dernier mais c'est le plus important. On va se trouver
      quelques jeux données réels. On en parlera avec OF a la réunion !!
*** DONE Le choix du lambda dans ridge
    CLOSED: [2017-01-31 mar. 17:21]
    - [X] cross validation (on peut le faire mais ne pas l'evaluer)
    - [X] genre de empirical bayes (lm et on regarde la variance des B)
    - [X] pour des raisons numerique d'inverse de P
*** DONE EWAS for the article
    CLOSED: [2017-02-03 ven. 11:31] DEADLINE: <2017-01-25 mer.>
   - [X] add Refactor au methods
   - [X] get data (see my mails)
   - [X] Comparison with the paper result !!
     Il va falloir que je refasse leur resultats si je veux ma comparer a des
     EWAS. Il faudra aussi que je me compare sur leur simultation. Je pense que
     leur méthode on pour but d'apprendre la repartition cellulaire alors que moi
     c'est une structure de fond quelconque... A méditer ! 

*** DONE L'avantage du lasso par rapport au ridge ?
    CLOSED: [2017-01-31 mar. 17:21]
    - [X] verifier l'influence de =sparse.prop=. Je m'attends a ce que si il est
      trop bas on fasse comme PCA + lm.
    - [X] trouver des cas de figure ou lasso meilleur ! Pour le moment ca faire
      toujours la même chose !
*** DONE GSE42861 experience
    CLOSED: [2017-01-27 ven. 15:33]
    GO !!!
**** DONE La vraie experience !
     CLOSED: [2017-02-16 jeu. 15:32]
     On va faire le même préprocessing que dans cite:Zou_2014 et verifier qu'on
     trouve bien la même chose que dans la méthode reference based ! C'est ce
     qu'il font dans cite:Zou_2014,Rahmani_2016. Idéalement il faudrait que
     j'arrive a reproduire la méthode dites reference-based.
    
     *ERATUM* : IL FAUT que j'arrive a faire la méthodes dite refecence-based si
     je veux me comparer !!! Je m'en fous des autres !!
***** Conclusion
      En fait non, je vais appliquer ma méthode et comparer à leur résultat et si
      ca ne marche pas je prendrais un autre EWAS ! 
    
*** DONE HGDP experiment
    CLOSED: [2017-02-01 mer. 15:33]
  
    J'ai commencé ./Article3Package/R/HGDP_function.R et
    ./Article3Package/tests/testthat/test_HGDP.R !!
*** DONE Checkpoint et tache a faire le <2017-01-31 mar.>
    CLOSED: [2017-02-16 jeu. 15:33]
    Je pense que je vais abandonner les algo alterné avec le lasso, ca ne donne
    pas de bon résultats. Je vais essayer un algo qui alterne du lfmm ridge, en
    plus je pourrais peut être le justifier avec les resultats du papier
    cite:mazumder10_spect_regul_algor_learn_large_incom_matric. L'utilité d'un
    algo pour les missing data n'est pas a remettre en cause je pense ! Enfin
    faudrais que j'y reflechisse mais lfmm alterné PCA + ridge ne donne pas les
    memes resultats que le lfmmRidge... De toute facon si j'alterne lfmmRidge ca
    regle le pb !!

    - [ ] lfmm ridge et laternance de lm ridge et PCA ne donne pas la même chose,
      pk ?
    - [X] on a montré que le choix du lambda a une importance dans lfmm ridge,
      mais comment le choisir ? trouver un critere !!!
**** Conclusion
     Je vais voir le point non fait plus tard, avec la théorie.

*** TODO On scale les datas ou pas ? 
    Ca change quoi de scale les données ?
    Voir dans l'acp ce qui est recommandé. 
*** TODO Simulations de data from true dataset
    Faire des simulation à la facon d'of ! C'est a dire on va simuler des locus

    $$ G_j = Bj X + E $$ 
   
    Où E est un bruit avec la même corrélation que dans les data observées. On
    peut mettre un lien logistic a voir. Le problème était que ca faisait sortir
    un groupe dans l'acp, je comprends pas pk ! A voir ! 
*** TODO GWAS method
    - Il me faut des méthodes de GWAS (celle de cite:Zhou_2013 a l'aire bien !)
    - On va faire des simulations de phénotype aussi, a réfléchire ! 
*** TODO Un critère de stabilité 
    Dans cite:article_Leek_Storey_2007 il dit que SVA permet de stabilisé le
    ranking des gênes. Donc un critère de reprudicibilité est a voir.
   
    Je parle de ce problem dans [[ref:lambda_model_choice][cette note.]]
   
