# -*- mode: org -*-
# -*- coding: utf-8 -*-
#+STARTUP: overview indent inlineimages logdrawer
#+TITLE:       Thesis Lab Notebook
#+AUTHOR:      Kevin Caye
#+LANGUAGE:    en
#+TAGS: noexport(n)
#+TAGS: 1Article(1) 2Article(2) 3Article(3) Thesis(T)
#+EXPORT_SELECT_TAGS: Blog
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) RUNNING(r!) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

* 2017
** 2017-03 mars
*** 2017-03-10 Vendredi
**** DONE Changement de git pour la Biblio
     CLOSED: [2017-03-13 lun. 13:38]
   Entered on [2017-03-10 Ven 16:30]

   - [X] je backup sur le server kimsufy
   - [X] rm sur mon pc de bureau et cp dans ici :D
   - [X] mettre biblio.bib a la racode de Thesis
   - [X] le reste est private on fait un Gits sur kimsuffy et ce qui faut dans le
     makefile !!

     #+BEGIN_SRC bash
     git remote add origin cayek@176.31.253.205:/home/cayek/Gits/2017/Biblio.git
     #+END_SRC

**** TODO Migration des git articles
   Entered on [2017-03-10 Ven 16:44]

   - [ ] rm sur mes poste
   - [ ] rm les gits et les liens vers ceux ci (mon site)
   - [X] les backup
     
     On va migrer tous ca au fure et à masure :D

*** 2017-03-13 lundi
**** DONE Data dir 
     CLOSED: [2017-03-13 lun. 16:11]
   Entered on [2017-03-13 lun. 13:49]

   For git annex see [[https://git-annex.branchable.com/direct_mode/][direct mode]]
   #+BEGIN_SRC bash
   git annex unannex
   #+END_SRC
**** GWAS RIZ                                                     :Rnotebook:
     Entered on [2017-03-13 lun. 16:08]

     [[file:Rnotebook/gwas_riz/gwas_riz.nb.html]]

***** TODO climate
      - K = 1 2 3
      - lambda différente values
      - avec X = tmaxPC2
      - on recalibre
      - lancer avec un genotype aléatoires 
        
***** TODO flowering
      - K  1 2 3 4
      - lambda plusieurs valeurs ...
      - gerer les missing values dans X (on va les enlever)
      - juste avec la variable 1
**** Fin de journee
   Entered on [2017-03-13 lun. 18:01]

   Petit a petit je met en place le repo et bosse en même temps. Je vais migrer
   3Article au fur et a mesure.
***** DONE Questions
      CLOSED: [2017-03-15 Mer 13:41]
      - Comment on gere les images (git annex ? NON, ca bouge trop souvent)
      - Comment on gere les notebook ? (git annex ?NON idem)

        Faudrait pas faire grossir pour rien le repo...

        Je m'en balek, je vais tous mettre dans le repo ! 
*** 2017-03-14 Mardi
**** DONE Cross-validation
     CLOSED: [2017-03-14 Mar 13:51]
   Entered on [2017-03-14 Mar 07:21]
   
   Je vais supprimer tout ce que j'avais fait sur la crossvalidation et qui ne
   marche pas ! 

   - [X] implementer predict_row
   - [X] implementer left.out func
   - [X] implementer CrossValidation_rowwise: 
***** DONE test avec tess3r 
      CLOSED: [2017-03-15 Mer 13:44]
      Il va falloir implementer mes samplers. Je vais recuperer tous le code de
      tess3r ! C'est le plus simple.

      Finalement, c'est pas la priorité. On vera la cross validation pour la
      these mais pour les reviews ils ne reclamaient pas ca.
***** TODO test avec lfmm
      Ca donne quoi sur les vrais dataset que je veux mettre dans le papier !
   
**** Writting tools
   Entered on [2017-03-14 Mar 08:03]

   - [[https://joelkuiper.eu/spellcheck_emacs][un blog sur les outils emacs]]
   - [[http://www.cs.umd.edu/~nspring/software/style-check-readme.html][un style checker]]
   - [[https://github.com/mhayashi1120/Emacs-langtool][language tools in emacs]]
   - [[http://www.techrepublic.com/blog/linux-and-open-source/automatically-analyze-text-with-these-simple-command-line-tools/][diction and style]]
   - [[http://www.afterthedeadline.com/][afterthedeadline]]
   - [[https://www.quora.com/What-is-the-best-free-spell-style-and-grammar-checker-for-English][quora: best style and grammar checker]]
**** Biblio
   Entered on [2017-03-14 Mar 11:10]

   #+BEGIN_SRC bash 
   git clone cayek@176.31.253.205:/home/cayek/Gits/2017/Biblio.git
   #+END_SRC
**** TODO Migration du code de l'article 2
   Entered on [2017-03-14 Mar 14:29]

   Pour le moment je ne fait pas de fork de tess3r, ca va trop compliquer mon
   package. Je vais récuperer tous le code et le mettre dans
   R/2Article/2Article_ et dans un environment !

   Reste toutes les images a migrer ...
**** TODO Reunir tous les notebook
   Entered on [2017-03-14 Mar 15:02]

   Tout est dans le titre faudrait que je puisse visualiser tous mes notes book
   :D
**** ms
   Entered on [2017-03-14 Mar 15:30]
   
   On peut le ddl [[http://home.uchicago.edu/rhudson1/source/mksamples.html][ici]]. C'est ouf que j'ai utilisé un soft aussi vieux...
*** 2017-03-15 Mercredi
**** Organisation des Notes                      :1Article:2Article:3Article:
   Entered on [2017-03-15 Mer 08:14]
   
   On va tous mettre dans ./Notes.org avec des tags pour les 3 articles.
**** tess3r                                                        :2Article:
   Entered on [2017-03-15 Mer 08:50]
   
   Je vais copy-paste un parti du code que j'utilise dans l'env tess3r.env
**** Point sur 3Article                                            :3Article:
   Entered on [2017-03-15 Mer 14:53]
***** Que falta ?
      - HGDP PCA+cv+run
      - GSE42861 PCA+cv+run
      - (interet de l'algo avec missing value (rmse(U,U_true)))
***** DONE Plan d'attaque 
      CLOSED: [2017-03-27 lun. 11:31]

      Voir [[Article3Figures]]

      On va generer les figures pour l'article !!!
      CAD:
      - [ ] comp de méthode sur simul (pcesision-recall et fdr control)
      - [ ] rmse de l'algo with missing value
      - [ ] HGDP (pca cv et result)
      - [ ] Refactor (pca cv et result)
      Après on envoie à olovier et on ecrit l'article ! 
****** DONE Figures
       CLOSED: [2017-03-27 lun. 11:31]
       - [ ] precision- recall
       - [ ] fdr control (comme dans cite:Song_2015)
       - [ ] more power with missing value algo
       - [ ] cross validation sur GSE42861 et HGDP on verra comment on met en
         formes
       
**** Fin de journée                                                :3Article:
   Entered on [2017-03-15 Mer 17:11]

   Bon j'ai impementé les trois functions utile pour l'analyse des true dataset.
   DEMAIN je lance pour faire l'analyse d'olivier, HGDP et refactor.
*** 2017-03-16 Jeudi
**** GSE42861 analyse                                             :Rnotebook:
   Entered on [2017-03-16 Jeu 10:04]

   Deuxieme tour :D cette fois on fait ca propre:
   [[file:Rnotebook/GSE42861/GSE42861.nb.html]]
**** HGDP analyse                                                 :Rnotebook:
   Entered on [2017-03-16 Jeu 10:07]
   
   [[file:Rnotebook/HGDP/HGDP.nb.html]]
**** Bilan de la journée
   Entered on [2017-03-16 jeu. 17:37]

   Demain on fait les plots pour le papier !!!!!!
*** 2017-03-17 vendredi
**** Bilan de la journée 
   Entered on [2017-03-17 ven. 16:27]

   - GSE42861 et HGDP CV tourne
   - j'ai recuperer le 1000genome il reste a le filtrer et le sauv dans un bon
     format ! BigMemery, rds etc. Je vais peut etre déjç tous passer en RDSa
     vant de filtrer
   - Le 1001 Genome, il a falloir trouver un moyen de passer ce truc enorme de
     python à R :D
*** 2017-03-20 lundi
**** Fin de journée
   Entered on [2017-03-20 lun. 16:43]
   
   - j'ai lancé le script pour lire le 1000 genome on verra de main si il a pas
     planté !
   - [[file:ThesisRpackage/R/tess3/tess3_noisyCoord.R]] : le variogram ne marche plus....

   DEMAIN: 
   + faire marcher le plot du variogram
   + changer la parralélisation sans
     file:ThesisRpackage/R/tess3/tess3_noisyCoord.R (c'est le sampling qui est
     long ! )
   + 1000 genome ! Peut-etre utiliser autre chose pour lire les vcf !
*** 2017-03-21 mardi
**** bug sur krakenator
   Entered on [2017-03-21 mar. 17:23]
   
   Le message : Fatal error: impossible de créer 'R_TempDir'
   
   Je pense que rochei à cassé un truc :D ... 
   
   Pour le resoudre j'ai set le TMP dir dans .Renviron

   Mais il y a encore des pb avec 
   #+BEGIN_SRC sh
   R -e "..."
   #+END_SRC
   
   PK ?? Pour le moment je vais garder une session R et lancer devtools .
*** 2017-03-22 mercredi
**** Patator
   Entered on [2017-03-22 mer. 08:34]

   Je vais faire comme sur krakenator. Il va falloir monter OUTPUT et Data.

   =devtools= ne veut pas s'installer je ne me rapelle plus comment j'ai fait
   sur krakenator... Je vais utiliser : 
   #+BEGIN_SRC sh
   R CMD INSTALL ThesisRpackage
   #+END_SRC
   
   Mount depuis krakenator, je ne doit pas etre dans le [[http://askubuntu.com/questions/502115/sshfs-you-do-not-have-the-permissions-necessary-to-view-the-contents-of-mounted][fuse group]]... Try [[http://askubuntu.com/questions/502115/sshfs-you-do-not-have-the-permissions-necessary-to-view-the-contents-of-mounted][that]].
   C'est fait :D
   
   Pour mount:
   #+BEGIN_SRC bash
   ssh patator
   cd Projects/Thesis/
   sshfs cayek@krakenator.imag.fr:/home/cayek/Projects/Thesis/OUTPUT OUTPUT/
   sshfs cayek@krakenator.imag.fr:/home/cayek/Projects/Thesis/Data Data
   #+END_SRC
   
*** 2017-03-24 vendredi
**** NuclearNorm + lasso
   Entered on [2017-03-24 ven. 11:44]

   On va pas jeter cette méthode :D. EN faite ca marche pas si mal !
   [[file:ThesisRpackage/tests/testthat/3Article_old/test_NuclearLFMMMethod.R]]

   Il faut l'ajouter un banc de test ! 
**** Fin de week
   Entered on [2017-03-24 ven. 18:02]

   La semaine prochaine: 
   - en finir avec les formatage de 100xGenome
     pour le 1001Genome faudra faire des test !! et j'ai pas reussis a mettre le
     nom de colonne...

   - faire les maj pour l'article 2
   - faire les resultats pour article 3
*** 2017-03-27 lundi
**** <<Article3Figures>> Figures de l'article 3                    :3Article:
     Entered on [2017-03-27 lun. 11:32]
     [[file:3Article/Article/Figures/figures.nb.html]]

***** Numerical validation
****** TODO Method comparison
       2 figures: 
       - fdr
       - precision-recall
       Sur mes simulations generatives du 1000genomes.


****** TODO With missing value
       1 figures: fdr + precision-recall methods: juste lfmm ridge pour le
       moment. Je fixerai des valeur pour lasso quand j'aurais des bon resultats
       

***** TODO True dataset
*** 2017-03-28 mardi
**** TODO Feature importance                                :3Article:Thesis:
   Entered on [2017-03-28 mar. 18:09]
   
   Feature importance pour remplacer la pvalue ? Il faut que je vois les
   alternative a la pvalue. C'est trop dépendant d'un modèle ! On le fait pour
   le folclore ! 

   Pour ma thèse faut que je parle de ces alternative a la pvalue ! Et de sont
   monopole :D
*** 2017-03-29 mercredi
**** bilan de la journée
Entered on [2017-03-29 mer. 17:29]

Je me perds un peut avec les simulations avec missing value. Ca marche très
bien sur le jeux de données que j'ai choisi. 

Demain ajouter lasso au protocole de validation sur des vrai jeux de données.
Faudrai que je trouve un moyen de comparer les sortie des différent algos,
pour valider que ma methode fait comme d'autre !! DU coup sur chaque jeux de
données GWAS/EWAS/EAS il me faut une méthode de reférence !! 

Je vais travailler sur les function Article3_cv/pca/runExp, il me faut un
protocole unifié !!

A demain !
*** 2017-03-30 Jeudi
**** On reproducibility talk
   Entered on [2017-03-30 Jeu 11:06]

   - to see [[https://github.com/alegrand]]
***** literate programming
****** knitr 
       - Rpubs to share markdown
       - everything is public
       - "knitr cache handling not that good"
       - "not to write paper more to share experiment"
       - "I use inkscape for publication because i can not do with R goor plots" NO
       - rmd with emacs work -> to see
****** jupyter
       - communitation between language : need to serialize data
       - beaker notebook
       - hard write article with jupyter
****** orgmode
       - see on his github
       - journall backup with cron
       - orgzly on smart phone
       - not well integrated everywhere

       - notepad (google doc text)
***** Example of article write with orgmode
See this [[http://mescal.imag.fr/membres/arnaud.legrand/research/publications.php][page]]
- [[https://raw.githubusercontent.com/viniciusvgp/vpa2016/master/vpa2016.org][vpa2006.org]]
- [[https://gitlab.inria.fr/stanisic/cache_reppar17/raw/master/article/ERROR_article.org][ERROR_article.org]]



**** Sur la method lasso LFMM                                      :3Article:
   Entered on [2017-03-30 Jeu 15:17]

   Dans l'algo alterné update d'abord B et après C converge plus vite...
**** CrossValidation sur lasso LFMM                                :3Article:
   Entered on [2017-03-30 Jeu 16:25]

   C'est pas super util de CV le lambda ! On peut le choisir avec sparse.prop !
   De plus il faudrait cross valider sur gamma !! Je vais pas me prendre la tete
   je vais vendre la CV pour lfmm ridge car c'est rapide et utiliser les valeus
   choisis pour lfmm lasso pour K.
**** Fin de journée
   Entered on [2017-03-30 Jeu 16:56]
***** DONE DEMAIN
      CLOSED: [2017-03-31 ven. 16:58]
      - c'est la copie de snmf qui merde : faire une version .geno du dataset !!
      - enlever tous le merdier que j'ai ajouté dans tess3r
      - faire l'étude du true dataset GSE42861. On va lancer sur refactor,
        ridge/lassoLfmm et on va comparer les tops lists !
      - ca peut etre ca la facon de se comparer au autres méthodes ...

     En tout cas demain j'ai des resultats péliminaire et je peux commencer a
     ecrire le papier :D
*** 2017-03-31 vendredi
**** Fin de semaine
   Entered on [2017-03-31 ven. 16:58]

   - Bon j'ai un peu arranger les choses avec futile logger... c'est encore
   bancal. 

   - J'ai lancé la comparaison entre entre les méthodes sur plusieurs jeux de
     données. On verra ce qui sort...

   - tess3r avec K = 2 c'est bon ca fait pareil on verra avec K = 3 mais ca va
     le faire :D

***** TODO Lundi 
      - [X] c'est quoi ce problem d'erreur de connexion quand je lance les tests ??
        Avant d'aller plus loin je regle ca !! Je veux des tests propres !! Et
        surtout une sortie propre pour les tests
      - on plot le resultat de la simulation. 
      - On fait la comparaison entre mes 2 méthode et refactor sur le dataset
       GSE42861.
      - Et on ecrit la méthode !!!
      - [X] On trouve un moyen de partager des objets quand je fais du parallel !!
** 2017-04 April
*** 2017-04-03 Monday
**** Diff entre version                                            :2Article:
   Entered on [2017-04-03 Mon 10:54]

   Je vais creer un faux commit avec lancienne version sur une autre branche
   juste pour faire les diffs. 
   #+BEGIN_SRC bash
   git tag -a 2Article_v1.0.1 -m "Article version submitted to aoas"
   git push --tags
   #+END_SRC
**** Biblio in latex 
   Entered on [2017-04-03 Mon 13:52]
   
   To understand what I say when I speak about bibtex: [[http://tex.stackexchange.com/questions/25701/bibtex-vs-biber-and-biblatex-vs-natbib][here]]

   How i reduce the number of author in text citations: [[http://tex.stackexchange.com/questions/26575/bibtex-how-can-i-automatically-reduce-long-author-lists-to-xxx-et-al][here]]
**** Bilan de la journée
   Entered on [2017-04-03 lun. 18:20]

   Je vais faire du litterate programming pour les data (pour essayer) et en même
   temps setup emacs pour R ! 

   Demain on s'occupe de GSE42861 !!! et on plot ce qui tourne !
*** 2017-04-04 mardi
**** Notebook !!!
   Entered on [2017-04-04 mar. 10:07]

   Aller je me lance :D !! On part de [[http://mescal.imag.fr/membres/arnaud.legrand/misc/init.php][ca]]. J'arrete les notebook et je met tous ici !!
**** From R studio to Emacs ESS
Entered on [2017-04-04 mar. 15:11]
***** jump to function
- C-c C-e C-t
- g C-] : find tags
***** to see
- https://github.com/vspinu/imenu-anywhere
- https://github.com/emacs-ess/ESS/issues/307
**** Fin de journée
Entered on [2017-04-04 mar. 18:29]

Bye Rstudio ! 

DEMAIN je fait propre [[file:ThesisRpackage/R/HypothesisTesting/HypothesisTesting_phenotypeWay.R][phenotypeReg_glm_score]] ! Et je lance les simus !!!
*** 2017-04-05 Wednesday
*** 2017-04-07 vendredi
**** [[http://stackoverflow.com/questions/2908822/speed-up-the-loop-operation-in-r][Speed up loop in R]]
Entered on [2017-04-07 ven. 11:19]
**** Fin de semaine
Entered on [2017-04-07 ven. 18:21]

La semaine prochaine il faut que je debug phenotypeWayReg_lm ([[file:ThesisRpackage/tests/testthat/HypothesisTesting/test_HypothesisTesting_glm.R][fichier de test]])
en comprant phenotypeWayReg_lm_score à phenotypeReg_glm_score. Je devrais avoir
la même chose ! 

Après je peux finir [[file:Notes.org::*Run%20of%20methods%20on%20OF%20GWAS%20simulation][ca]] !!! Et l'envoyer a OF....
*** 2017-04-11 Tuesday
**** fin de journée
Entered on [2017-04-11 Tue 21:20]

Demain: 
- on fini de debug LEA
- on fait des plto de inflation factor sur les neutres
- on conclut et sur ce qui reste a faire
- on commence a ecrire le papier
- on regle le pb des plots R
*** 2017-04-12 mercredi
**** Output plot name
Entered on [2017-04-12 mer. 10:16]

Problemes: 
- a chaque fois que je passe sur le chunk ca creer un plot vide
#+BEGIN_SRC bash
find ./Rfigures -size  0 -print0 |xargs -0 rm
#+END_SRC

#+RESULTS:

- même si le plot est plus dans Notes.org ilsera encore dans Rfigures/
- il envoie des path absolus (du coup sur le mac ca passe pas)
**** Fin de journée
Entered on [2017-04-12 mer. 17:21]

DEMAIN
- lancer des comparaisons avec cate
- faire ma liste dobjectif pour la rentré !
*** 2017-04-13 jeudi
**** Jury de thèse
Entered on [2017-04-13 jeu. 11:42]
Rapporteurs: 
- [[http://www.math-evry.cnrs.fr/members/cambroise/welcome][Christophe Ambroise]]
- [[http://w3.mi.parisdescartes.fr/~cbouveyr/][Charles Bouveyron]]
Examinateurs
- [[https://scholar.google.fr/citations?hl=fr&user=w-U2SwoAAAAJ&view_op=list_works&sortby=pubdate][Thomas Burger]]
- Mike Blum
Invités
- Olivier Michel
- Olivier Francois
**** Cours de stats de Philippe Besse
Entered on [2017-04-13 jeu. 11:46]
[[https://www.math.univ-toulouse.fr/~besse/enseignement.html][page perso de Philippe Besse]]
**** Shortcut
Entered on [2017-04-13 jeu. 14:56]
***** R
- execute code: C-c C-c
- reload R consol: C-c C-e r
- execute line: C-c C-n
- execute region: C-c C-r
****** package
- test: C-c C-w t
- doc: C-c C-W d
- install: C-c C-w i
***** Orgmode
[[http://orgmode.org/orgcard.pdf][Orgcard]]
- property: C-c C-x p
**** R in orgmode and babel 
Entered on [2017-04-13 jeu. 15:00]

Les problèmes
- arriver a exporter des notebook html comme etant des parties de ce documents !
- les chemains absolus des figures c'est la merde ! 

***** Property
Pour avoir des property pour seulement un subheader ([[http://orgmode.org/manual/Header-arguments-in-Org-mode-properties.html][source]])
***** Easy template
Avant j'utilisait ceux de [[http://mescal.imag.fr/membres/arnaud.legrand/misc/init.php][ALegrand]]. Mais ca marche mal avec les file output par
defaut.
#+BEGIN_SRC emacs-lisp
  (add-to-list 'org-structure-template-alist
               '("r" "#+begin_src R :results output :session *R* :exports both\n\n#+end_src" "<src lang=\"R\">\n\n</src>"))
  (add-to-list 'org-structure-template-alist
               '("R" "#+begin_src R :results output graphics :file Rplots/Rplots.png :exports both :width 600 :height 400 :session *R* \n\n#+end_src" "<src lang=\"R\">\n\n</src>"))
  (add-to-list 'org-structure-template-alist


#+END_SRC

***** Example
:PROPERTIES:
:header-args: :cache no :session *R* :dir ./ :eval no-export
:END:

#+begin_src R :results output :exports both
a <- rnorm(100)
a[1]
#+end_src

#+RESULTS[04382f8a0bb3af445af630a06be15ceddb4cdb60]:
: [1] 1.654555

#+begin_src R :results output graphics :file Rplots/Rplots.png :exports both :width 600 :height 400 
hist(a)
#+end_src

#+RESULTS[13ef627323823a65c25cf55e5a81b289217fc3af]:
[[file:Rplots/Rplots.png]]
**** De Rfigure à Rplots
Entered on [2017-04-13 jeu. 15:52]

J'ai changé ma facon de faire des notebook avec orgmode en cours de
route...encore. Du coup certain note book sont en absolute path => sur le mac ca
ne amrche pas !! :-(
**** Comment faire des notebooks pour les donner a quelqu'un ?
Entered on [2017-04-13 jeu. 15:54]

Soit je fais un nouveau fichier org dans un sous dossier... NON

Je mets tous Data et Rplots dans un sous dossier de ./Data et Rplots et après
avoir exporté on lance
#+BEGIN_SRC sh 
mkdir NOTEBOOK/
mkdir NOTEBOOK/Data
mkdir NOTEBOOK/Rplots
mv Notes.html NOTEBOOK/
cp -r Data/dir NOTEBOOK/Data
cp -r Rplots/dir NOTEBOOK/dir
#+END_SRC

Sinon voir [[*LEA::lfmm][LEA::lfmm]] pour exemple.
**** Partir en vacance serain ;)
Entered on [2017-04-13 jeu. 16:46]

LES DEADLINES:
- finir les resultats de l'article [2017-05-20 sam.]
- finir l'article [2017-06-15 jeu.]
- finir la these [2017-07-22 sam.]

C'est impossible a tenir, ou pas !! On verra ! 

Les details des plots dans mon cahier ! 
**** Layers spacemacs
Entered on [2017-04-13 jeu. 17:02]

Le [[https://github.com/fernandomayer/spacemacs][github]] d'un mec avec ses layers spacemacs !! 
***** [[https://github.com/fernandomayer/spacemacs][Polymode]]
C'est pour faire du Rmd dans emacs. Je vais clone me layer le layer: 
#+BEGIN_SRC bash :session *bash*
  mkdir ~/.emacs.d/private/polymode/
  cd ~/.emacs.d/private/polymode/
  curl -O https://raw.githubusercontent.com/fernandomayer/spacemacs/master/private/polymode/packages.el
#+END_SRC
*** 2017-04-14 vendredi
**** Emacs for prose
Entered on [2017-04-14 ven. 15:33]

To see: http://proselint.com/
** 2017-05 mai
*** 2017-05-02 mardi
**** Titre de la thèse
Entered on [2017-05-02 mar. 11:06]

Méthodes de factorisation matricielle pour la génomique des populations et les
tests d'association
* 1Article                                                         :1Article:
* 2Article                                                         :2Article:
** Revisions
   Recu le [2017-03-02 Jeu].
  
*** Mail

    Dear Olivier François,

    Thank you for submqitting your paper "Fast inference of individual admixture
    coefficients using geographic data" for possible publication in Annals of
    Applied Statistics. It has now been carefully reviewed and my decision is:
    Revision required.

**** My comments are the following:
     The reviewers all agree that this paper is an interesting methodological
     contribution to the field of inference of population structure. There were
     four main revisions that should be made to the work according to the
     reviewer comments.
***** First, 
      slightly more space should be devoted to connecting the new work with the
      related work -- the related work is very clearly written, but the exact
      methods proposed here and the inclusion of geographic data should be
      motivated a bit more carefully and put in the perspective of the related
      work.
****** TODO a faire
         Pk on fait ca par rapport au ancienne version de TESS3. Pk faire une new
         version de tess3
***** Second, 
      the selection of hyper parameters was not well discussed, and two of the
      reviewers would rather those details be included in the paper to have it
      self-contained.
****** TODO a faire
       discuter plus la validation croisée. Pas mettre en reference.
***** Third, 
      related, R1 asks about model misspecification and how to evaluate the
      impact of incorrect priors on the results --- I agree that this point
      should be addressed adequately.
****** TODO a faire
       Test pour l'ibd, on le voit dans le variogram si il n'y a pas de d'interet
       du spatial. Il y a une grosse litérature sur ces tests ! 

***** Fourth, 
      the results should be expanded to a larger data set. There were a handful
      of minor comments that should also be addressed.


      In addition to these comments you may also find review reports posted on EJMS.

****** TODO a faire
       Prendre le AT 1001 genome. Data set est propre. 
       *Rmk* : On peut pas le faire sur des humains, on a pas les coord
       geographique, ca serait pas anonime.
**** To submit your revision,
     please log in to EJMS and submit it as a revised file to original
     submission. Please also include a detailed description of how you addressed
     all the points raised by the reviewers.

**** IMPORTANT NOTICE CONCERNING FIGURES: 

     Printing figures in color adds significantly to the production cost of the
     journal. While color may be used in the online publication, we will use
     color in the printed version only when essential to the display. Please use
     dashed/dotted lines or symbols where possible and avoid referring to colors
     in the text and the figure caption.

**** other

     If you have been asked to modify the title of your submission, or if the
     order of author names has changed, please contact Geri Mattson at
     mattsonpublishingservices@comcast.net so that the submission’s metadata can
     be updated.

     Thank you for considering The Annals of Applied Statistics as a venue for your work.

     Sincerely,
     Edoardo M. Airoldi
     Editor, The Annals of Applied Statistics
    
    
     Submission URL: https://www.e-publications.org/ims/submission/AOAS/
    
     Title:
     Fast inference of individual admixture coefficients using geographic data
    
     Authors:
     Kevin Caye, Flora Jay, Olivier Michel, Olivier François
    
     Abstract: Accurately evaluating the distribution of genetic ancestry across
     geographic space is one of the main questions addressed by evolutionary
     biologists. This question has been commonly addressed through the
     application of Bayesian estimation programs allowing their users to estimate
     individual admixture proportions and allele frequencies among putative
     ancestral populations. Following the explosion of high-throughput sequencing
     technologies, several algorithms have been proposed to cope with
     computational burden generated by the massive data in those studies. In this
     context, incorporating geographic proximity in ancestry estimation
     algorithms is an open statistical and computational challenge. In this
     study, we introduce new algorithms that use geographic information to
     estimate ancestry proportions and ancestral genotype frequencies from
     population genetic data. Our algorithms combine matrix factorization methods
     and spatial statistics to provide estimates of ancestry matrices based on
     least-squares approximation. We demonstrate the benefit of using spatial
     algorithms through extensive computer simulations, and we provide an example
     of application of our new algorithms to a set of spatially referenced
     samples for the plant species Arabidopsis thaliana. Without loss of
     statistical accuracy, the new algorithms exhibit runtimes that are much
     shorter than those observed for previously developed spatial methods. Our
     algorithms are implemented in the R package, tess3r, which is available from
     https://github.com/BioShock38/TESS3_encho_sen.

*** [[file:Revisions/AOAS1610-012R1R1.txt][R1]]
**** Intro
     Inferring individual ancestry (IA) from geontype data is an important
     problem in population genetics that has received much attention from both
     statistics and genetics communities. Caye et al. focus on the IA estimation
     problem in the setting where geographic data is available. They cast this
     problem as a regularized matrix factorization problem. The goal is to find Q
     and G matrices that reside in a convex set and approximate the genotype
     matrix. The requirement that geographically proximal individuals have
     similar IA parameters enforces a regularization on the solution. The authors
     explore two algorithms to this convex optimization problem: one based on
     alternating quadratic programming (AQP) and the second based on alternating
     projected least squares (APLS). The latter is shown to provide statistically
     accurate estimates while being computationally efficient on simulated data.
    
    
     The paper proposes a novel formulation and approach to incorporate spatial
     information for estimating IA. This model could be useful in applications
     where geographic locations are available along with genetic data. I think
     the paper represents an interesting applied statistics work. However, I have
     some comments that I would like the authors to address -- specifically,
     related to their choice of regularizer, model misspecification and empirical
     comparisons.

**** Comments:
    
***** 1.  
      While it is clear that spatial information can naturally be incorporated as
      a regularizer, it is not clear what the motivation is for the specific
      choice of regularizer. For example, it is intuitively not clear why the
      regularizer is inversely proportional to K and lambda_max.

      Further, if I decide to choose the regularizer coefficient by
      cross-validation, does it matter if the regularizer is scaled by parameters
      such as K,lambda_max as long as I search over a large rage of values of the
      regularizer coefficient ?

      Given that this is the central aspect of the paper, I would like the
      authors to provide intuition for their model choice including the choice of
      regularizer.

****** TODO a faire
      Donner une intuition.  

***** 2. The empirical assessment can be improved. 

****** a) 
       One of the concerns is that the simulations appear to assume that the true
       locations are known. I would like to know how correlated the IA estimates are
       with location in the simulations. How does the performance improvement relative
       to a method that does not use spatial information change if the locations are
       noisy so that the correlation between IA estimates and location is lower.

******* TODO a faire
        Une simu : on va bruité les coordonnées géographique. On regarde comment
        le bruit sur les coordonnées influ sur l'esimation de Q. On peut faire
        varier la variance du bruit. 
****** b) 
       A second and more important concern is that it is unclear how the model
       performs in instances where genetics and geography do not correlate. For
       example, many of the instances of large-scale admxiture involve population
       migration that results in relatedness between populations that are
       separated by large genetic distances. Consider, African-Americans that are
       admixed between African and European populations. In terms of location,
       African-Americans are located in the US which is not proximal to ancestral
       Africans or Europeans. IT is unclear how the inferences would change in
       this setting.
******* TODO a faire 
        Se verifie avec les test d'autocorélation spatial, le variogram etc.
        C'est de la validation des hypothèses. 

        *MAIS* pour nous la VC ne marche pas

        *Une simu*: prendre du 1000 genomes (européen affricain et
        afro-americain) et leur donner des coords geographique et voir ce qui se
        passe (comment ca degrade par rapport à NMF). C'est un peu moins bien,
        mais faut faire des hypothèse a un moment !!
****** c) 
       An interesting question that would point to the utility of these spatial
       models is to ask how approximate or noisy does the location information
       need to be to obtain an advantage over models that do not use spatial
       information. This would be an interesting quantity that could strengthen
       the appeal of the current study.
******* TODO a faire
        Repondu, par le graphe de a)
****** d) 
       The authors should also compare to other spatially explicit methods for
       inferring IA. e.g. SpaceMix (Bradburd et al. 2015). These methods jointly
       estimate IA as well as geographic coordinates in a Bayesian framework.
******* TODO a faire
        SpaceMix est pop based ? On les citera.
*** [[file:Revisions/AOAS1610-012R1R2.pdf][R2]]
**** Intro
     The authors propose an extension to their tess3 software to allow spatial
     coordinates of samples to be used to smooth local estimates of ancestry
     proportions. They use a matrix factorization approximation to the STRUCTURE
     model, which they have previously shown to give comparable results at
     reduced computational cost. Spatial smoothness in the ancestry proportions
     is attained using a Gaussian kernel whose length scale is estimated offline.
     Two optimization approaches are proposed: the first using alternating
     quadratic programming which is guaranteed to obtain a local optimum
     (strictly critical point) of the objective, the second using a heuristic
     optimize-and-project scheme which gives very comparable empirical
     performance at significantly reduced computational cost. On simulated data
     with K=2 admixed ancestral populations leveraging the spatial information is
     shown to improve estimation of the original ancestral frequencies and
     ancestry proportions. On a N=1000 dataset of A. thaliana across Europe the
     method is applied to show a distribution of multiple populations across
     Europe, and to detect candidate SNPs under selective pressure.

**** The paper is generally clearly written with an appropriate level of detail. There are some important details which are deferred to references, in particular:
    - the cross-validation scheme/objective used for choosing K
    - the variogram approach for choosing sigma
    - how SNPs are tested as being outliers under selective pressure
    It's perhaps only a personal preference but since these are key, non-
    standard steps in the analysis it would be good if they were at least
    described in the supplement so that the paper is more self-contained.

***** TODO a faire
      Expliquer ce qu'on a mis en ref.
**** Some prior work which should probably be cited:
     - Fast spatial ancestry via flexible allele frequency surfaces. Rañola JM1,
       Novembre J1, Lange K. Bioinformatics 2014.
       https://www.ncbi.nlm.nih.gov/pubmed/25012181. This method smooths both
       latent allele frequencies and allocation proportions but using a grid/pixel
       based random field approach which I assume is more computationally
       expensive than tess3r. The setup is somewhat different but a quantitative
       comparison might still be possible? Code is available in the OriGen R
       package.
     - Novel probabilistic models of spatial genetic ancestry with applications to
       stratification correction in genome-wide association studies. Anand
       Bhaskar, Adel Javanmard, Thomas A. Courtade, David Tse
       https://arxiv.org/abs/1610.07306. The problem setup between this ("GAP")
       and the current paper is quite different: GAP estimates spatial coordinates
       of individuals given their genotype data, and so should be grouped with the
       citations on lines 79-80, page 3.
***** TODO a faire
      a voir ce c'est. 
**** An analysis of at least one human dataset,  
     the Simons diversity panel being one interesting recent possibility, would
     add significantly to the paper and given the impressive run-times of the
     method presumably wouldn't be difficult to do.
***** TODO a faire
      Le pb c'est les coord spatial pour les humains ! On met AT 1001 genome,
      comme ca on fait des simunaltions pour LFMM. 

      En fait si le dataset est pas mal : [[https://www.simonsfoundation.org/life-sciences/simons-genome-diversity-project-dataset/][Simons diversity dataset]]. On va filter
      la maf et faire une belle carte (si il y a pas de pop admixed le spatial va
      renforcer le clustering)
**** I've annotated minor corrections/suggestions on the manuscript itself, hopefully attached.
*** [[file:Revisions/AOAS1610-012R1R3.txt][R3]]
**** Intro
    In this paper, Caye et al. present the newest iteration of their tess
    algorithm, which constructs an STRUCTURE-like mixed membership model while
    taking the spatial origin of data into account. This is a highly relevant
    problem, as spatial awareness has the potential to increase power, and gives
    more sensible answers when sampling is highly uneven.

    The main purpose of this paper is the presentation of two new algorithms, AQP
    and APLS, that both ofter fast runtimes. The reason why a standard EM cannot
    be used for the present problem is that the spatial awareness enters the
    model in the from a penalty matrix, without explicitly constructing a model.

    As someone unfamiliar with the algorithms presented here, the details
    presented in the paper are enough to follow the basic ideas behind the two
    minimization procedures,
     

**** APLS
    The APLS aogorithm proceeds by first updating each locus individually
    (assuming knowledge of each individual (the Q matrix) unconstrained, and then
    the constraints are enforced by a projection onto the relevant subspaces. As
    someone interested in this approach without too much knowledge in the field,
    I found the description to be lacking, as I was neither informed on how the
    implementation works, nor how the approximation is justified. Spending some
    more space on on what is the major innovation of the project could greatly
    enhance this paper.
***** TODO a faire
      Description plus verbale d'APLS: idée clées.
   
**** Simulations
     The simulation study accompanying the paper is adequate, and convincing that
     the implementation is correct and appropriate. They empirically show that the
     approximations arrive at a solution without any substantial change in error,
     and show that, under the assumed model, that adding space as a covariate
     increases power and reduces error. The underlying problem that is not
     addressed, is what "homogeneity" assumptions are made regarding the spatial
     patterns. I would expect that for populations whose genetic make-up is only
     loosely associated with space, that there is some point where a non-spatial
     algorithm might perform better. This may also be the reason why tess is used
     a lot less than structure/admixture in empirical studies, since the apparent
     assumption of strong spatial structure is not always that easy to make. One
     set of simulations to address that may be to repeat the analysis of fig 1
     where individuals are assigned locations at random. However, since the paper
     is highly technical and empiricists are not likely to be the target audience,
     this may not be the appropriate place for this.
***** TODO a faire    
      Encore un fois c'est le variogramm les test d'autocorélation spatials. Et
      ca serais résolu par le CV. On va mettre les graphes qu'on a fait pour R1.

**** AT
     The application to Arabidopis lacks a comparison point, it would have been
     interesting to compare the result with sNMF or earlier versions of TESS. One
     interesting point, for example, is that the ancestry coefficients in Fig 6B
     appear to be less peaked than in e.g. the data from the Francois et al. 2008
     paper, is this a function of the larger data set or the new algorithm?
     Finally, figure 6A has some extrapolation artefacts that should be corrected.
     Regions in Anatolia and Scandinavia appear to not-have any samples, but are
     assigned clusters from different regions. I assume this is a weird
     tail-behaviour in the spatial smoothing algorithm.
***** TODO a faire
      - enlever l'artefact en turquie.

   Overall, I think this is a solid paper, but the presentation of the main
   algorithms could be a bit more detailed, if not in the main text, in a
   supplementary technical reference.
*** On résume à faire
**** TODO experiments
***** DONE on reprend les simulations et on bruite les coords. graph RMSE(Q) x sigma(bruit) x regularization param 
      CLOSED: [2017-03-22 mer. 10:00]
      Ok ca marche il reste à mettre en forme.
***** DONE CV si ca marche ! Je le ferai pour la thèse.  
      CLOSED: [2017-03-22 mer. 10:00]
      On va juste citer laliterature.
***** TODO simu 1000 genome (European Africain et Afro americain). 
      Que donne snmf et tess3r. Le fichier est énorme, on va faire un LD
      prunning et un filtrage par la maf ! 

      Prendre données ecric ? 

      On va regarder dans le variogram (3 classes) il ne devrait pas y avoir
      d'autocorélation spatial. On devrait trouver comme sNMF
***** DONE simons avec la maf 5%
      CLOSED: [2017-03-22 mer. 10:01]
      pas pertinant sur des données humaines, trop de facteur non spatiaux, les
      deplacement humains sont trops complexe. Pour les plantes c'est adapté, on
      a de la dispertion.

      On va juste les télécharger pour voir. 

      C'est la merde a ddl...
**** TODO implémentation
     - [ ] une fonction prédict sur un indiv pas vu ! Qui pourrait servir pour la
       cross validation.

       On vera plutard ! 
**** DONE Figures
     CLOSED: [2017-03-23 jeu. 10:03]
     - [X] style de ligne par method -> plus visble pour meilleurs methodes
     - [X] visible en noir et blanc
     - [X] point trop gros
     - [X] AT : 2 fig 1 couleur et 1 noir et blanc
     - [X] ManhattanPlot : le tasser + alternance de gris + taille des points
     - [X] rmk sur papier
**** DONE References
     CLOSED: [2017-03-22 mer. 17:28]
     Faudra que je reunisse toutes les citations dans un seul bib, plutard !!
     
**** TODO Relire
     - Tout est dans le titre.
     
     - Bien verifier les labels !!

     - Voir dans le cahier aussi !

** Rnotebook
*** TODO Cross validation                                         :Rnotebook:
    On va voir si la cross validation marche
   
    j'en suis a implémenter tess3_wrapper.R
*** Tess3r avec des coordonnées bruitées                          :Rnotebook:
    [[file:2Article/Rnotebook/Revisions/tess3NoisyCoord.nb.html]]
    
    On voit bien la perte de précision avec la bruit sur les coordonnées. On
    voit aussi que le variogramme permet d'évaluer l'autocorélation spatiale des
    données génétiques.
**** TODO Experience sur toutes les simu de l'article 
     

* 3Article                                                         :3Article:
** 2017
*** 2017-01 janvier
**** 2017-01-16 lundi
***** Test de capture d'un truc
    Entered on [2017-01-16 lun. 17:35]
    Test
***** R notebook
    Entered on [2017-01-16 lun. 17:38]
   
    Je vais arreter d'utiliser Bookdown, ca rend mon workflow trop compliqué !!
    Par contre R notebook semble le plus pratique !!
***** Labnotebook
    Entered on [2017-01-16 lun. 17:47]
   
    Only Rnotebook and I git =.nb.html= to capture results !!
**** 2017-01-17 mardi
***** Data with missing value                                    :Rnotebook:
      Entered on [2017-01-17 mar. 09:50]
    Le but est de montrer qu'on est meilleur avec la technique alterné !!
    file:./3Article/LabNotebook/MissingValue.nb.html
    En gros ca montre bien ce que je veux. Après il y a des cas ou ca merde
    surtout avec les missing values pas uniformément réparti... Je sais pas
    pourquoi j'ai pensé que ca serait plus dure dans ce cas.
    Demain on continue le papier :D et on fait des simulations a partir de jeux
    de données réel. 
    On va aussi faire les plots des data : cf mon cahier le
    [2017-01-17 mar.].
    Et il reste un mistere ! Pk le lambda de la reg ridge ne change rien ?
   
***** On ecrit l'article ù*$ù
    Entered on [2017-01-17 mar. 14:20] Bon l'objectif de l'article c'est de
    proposé une méthode d'association à facteurs lattents basé sur de un problème
    d'optimisation.
    C'est un modèle récurent car présent partout ...
    Nous on propose une méthode efficace avec des solutions analytics et un
    algorithme alterné dans le cas de présence de missing values.
    On montre que c'est bien qualibré, c'est rapide et ca marche sur des
    GWAS/EWAS.
**** 2017-01-18 mercredi
***** Bilan du mercredi [2017-01-18 mer.] 
    Entered on [2017-01-18 mer. 17:34]
    J'ai pas percé le mystère du lambda qui sert a rien dans lfmm Ridge. Par
    contre j'ai un nouveau sample de données a partir de vrai dataset. J'ai
    essayé de faire en sorte que les données en sortir resemble le plus possible
    a celle en entré. LFMM ridge fonctionne bien sur celle-ci aussi. Surtout
    quand la part de variance expliqué par X pour les outlier est forte =rho=0.9=! Dans ce
    cas PCA+lm se plante complet.
****** DONE Pour demain
       CLOSED: [2017-01-19 jeu. 10:31]
       - gerer les cas ou la variance est null pour eviter les zscore null
       - verifier la structure de covariance des données simulé (des indiv et des
         locus)
       - Percer le mystere du lambda
       - faire des simulation a la facon de OF, voir mon cahier 
      A demain :D
**** 2017-01-19 jeudi
***** Comparison of analytic and alternated lfmm                 :Rnotebook:
    Entered on [2017-01-19 jeu. 10:54]
    file:./3Article/LabNotebook/AlternatedVsAnaliticRidge.nb.html
    Je veux voir si ont a bien les mêmes solutions !! 
    et percer le mystere du lambda :D
    J'ai plusieurs problèmes:
    - le calcul du sigma dans le cas ridge donne des résultats très petit
      parfois ! pk ?
    - J'ai mis lambda = 0 dans lfmm ridge et alternatedSVD et la recalibration
      GIF ne marche plus !!
    - il s'emblerais finalement que lambda est un effet !!
    On va le mêtre en évidence et essayer de trouver comment le choisir !
***** Choix du lambda dans lfmm ridge                            :Rnotebook:
    Entered on [2017-01-19 jeu. 15:39]
    file:./3Article/LabNotebook/Lambda.nb.html

    Ca doit pouvoir se cross valider !
   
    Plus ca va, plus je me dit que la méthode lasso est pas mal du tout, elle
    permet vraiment de trouver le support ! Les outliers ! Il me faut un moyen de
    la comparer au autres sur les plots de precision-recall. 
***** Bilan de la journée
    Entered on [2017-01-19 jeu. 17:35]
    - Finalement lfmm lasso n'est pas à mettre à la poubelle
    - dans lfmm ridge lambda a une importance, si il est trop grand on a un
      shrinkage dégueulasse (mais est-il mauvais ?)! et si il est trop petit on n'arrive à inverser P.
      Mais dans mes examples c'est quand d'aller chercher l'acp sur l'orthogonal
      de X qui m'interesse ! Il faudrait que j'évalue la perte de puissance en
      fonction du lambda !
**** 2017-01-20 Vendredi
***** Fin de semaine
      Entered on [2017-01-20 Ven 15:31] J'ai une vision claire de l'article et de
      comment je vais l'organiser. En particulier je pense que je vais vendre en
      disant que je fait une estimation de la structure lattente mais sans
      prendre la variance du à la co-variable X (l'un est global l'autre ne
      concerne que quelque locus, d'ou l'interet pour le lasso). Je pourrais bien
      illustrer ca avec les exemples numeriques simples (comparaison avec lm, PCA +
      lm). Cette partie est vraiment que optimisation based dans le formalisme.
      On ajoute des statq quand on fait le test d'hypothèse. Et pourquoi pas
      ajouter le test d'hypothèse avec le lasso. 
      A la semaine prochaine !!!
**** 2017-01-23 lundi
***** Sample from true data set                                  :Rnotebook:
    Entered on [2017-01-23 lun. 12:44]
    file:./3Article/LabNotebook/SampleFromTrueDataSet.nb.html

    On va voir comment les méthodes réagisses en fonction de rho (la proportion
    de variance expliquée par X) et la correlation avec la structure. Je vais en
    profiter pour avoir un vrai test d'hypothèse pour lfmm ridge et lasso.
***** DONE C'est parti
      CLOSED: [2017-01-24 mar. 10:52]
    Entered on [2017-01-23 lun. 16:13] Réunion avec nous a permis de def les
    résultats ! c'est parti La je vais push mais je suis en train de mettre en
    place le lm a l'arrache a la fin, après lfmm. Je suis dans les test. Je
    comprends pas pk il y a besoin d'un gif. Et il faudrait que je réflechisse un
    peut a théoriquement comment l'expliquer a peut près proprement !!
    - [X] Aussi je voulais implementer une option pour choisir la proportion d'outlier
    dans le lasso.
**** 2017-01-24 mardi
***** lfmm ridge et PCA+lm
    Entered on [2017-01-24 mar. 09:19]
   
    Dans file:./Article3Package/tests/testthat/test_lm_zscore.R quand on prend un
    lambda très grand lfmm ridge et PCA+lm font la même chose logique car c'est
    comme ci il n'y avait pas de projection sur X quand lambda est grand !!
***** lfmm lasso avec sparse.prop
    Entered on [2017-01-24 mar. 10:49]
   
    C'est implémenté. Mais les premiers resultats ne sont pas tops. 
    En gros ca fait la même chose que lfmm ridge... 
    see file:./Article3Package/tests/testthat/test_lm_zscore.R
    Il faudrait trouver un exemple ou c'est mieux :D
***** Comparaison des méthodes sur une simu de 1000 genome       :Rnotebook:
    Entered on [2017-01-24 mar. 11:17]
   
    C'est parti c'est un résultat de validation pour le papier !!
    file:./3Article/LabNotebook/Validation_1000Genome.nb.html . Ca marche bien :D On
    arrive bin a montrer que : 
    - c'est robuste au choix de K
    - c'est conservatif mais c'est mieux que liberal
    - quand il y a trop d'outlier PCA + lm fait n'imp
****** DONE reste a faire
       CLOSED: [2017-01-24 mar. 17:26]
       - [X] lancer avec LEA et lasso
****** Conclusion 
       - lasso et ridge font pareil sur ses exemples la
       - LEA fait n'imp
       - on voit bien la force de lfmm ridge sur des exemples avec beaucoups de
         correlation en X et U1 et et beaucoups d'outlier.
       - Le FDR est un peut trop conservatif.
***** Run on krakenator
    Entered on [2017-01-24 mar. 16:57] 

    On va essayer de lancer les notebook long sur krakenator avec la command
    =rmarkdown::render(file)=

    ^_^': j'ai pas pandoc sur krakenator...

    Si je veux me lancer sur krakenator je vais devoir faire des scripts !!!
***** Bilan de mardi !! 
    Entered on [2017-01-24 mar. 17:21]
   
    Il y a la validation sur les data simulées a partir du 10000 genome qui
    tournent. Ca donne des bon résultats a par pour LEA::lfmm :(. Mais pour le
    reste on montre bien ce qu'on veut. Les petits bemols: 
    - le lasso et le ridge ont l'aire de donner la même chose.
    - parfois le test est trop conservatif. Je trouve que c'est mieux dans ce
      sens que trop libéral, au moins on controle le fdr.
   Globalement on avance :D et mon env de travail déchire sa race !
  
   Demain le <2017-01-25 mer.> on fait des EWAS !!!!! Et on dechire tout !!
**** 2017-01-25 mercredi
***** Mise a disposition du code et des données
    Entered on [2017-01-25 mer. 16:49]
    Pour le code github et pour les données torents :D
***** Fin de journée
    Entered on [2017-01-25 mer. 17:11]
    J'ai la putin de journée cette article de ù*^$ù*ù : cite:Rahmani_2016. Bon
    j'ai quand même les données ewas qu'il a utilisé. 
***** DONE Avant la fin de la semain putin !!!
      CLOSED: [2017-01-30 lun. 14:23]
     - [X] recupere des données GWAS pour faire un asssociation avec var envir
     - [X] lancer le script ReFACTor des autres branques.
     - [X] refaire leur association logistique donc X ~ G et avec la correction X
       ~ G + U + les autres co variables (ils disent qu'il y a la correction pour
       les batch mais d'après OF non... ils ont surement recopié un truc sans le
       comprendre...)
**** 2017-01-26 jeudi
***** G/EWAS and adjustment
    Entered on [2017-01-26 jeu. 10:44]
   
    Je me suis bien pris la tête hier pour savoir comment il faisait leur G/EWAS
    et "ajustait" pour la structure... C'est bien ce que je pensais ils ajoute
    simplement les scores (de la l'acp, ou autre) dans glm(Y ~ G + U...). D'après
    florian il utilise plutot plink pour faire leur regression logistic. On va
    utiliser l'algo de florian : https://github.com/privefl/bigstatsr
   
    *ATTENTION ALERT*  En faite en GWAS il font plusieurs regression univarié !!
    Flo lui veut faire avec lasso pour trouver les snips causaux par exemple.
    Mais dans la litérature ce qui se faire c'est de seuiller sur les score des
    regressions univariées :D !! 

    En faite c'est finalement pas différent de mon lm a la fin !! sauf que c'est
    dans l'autre sens !!! 
***** ReFACTor demo                                              :Rnotebook:
    Entered on [2017-01-26 jeu. 15:25]
   
    file:./3Article/LabNotebook/refractor.nb.html j'ai juste récupéré le code du [[https://github.com/cozygene/refactor/tree/master/R][github]].
   
****** TODO Comment ce jeux de données demo a été simulé ?
       Il plot le qqplot mais ca montre juste qu'il n'y a pas d'outlier en faite
       ! Il est tout plat !
**** 2017-01-27 vendredi
***** Le dossier BenchmarkDump 
    Entered on [2017-01-27 ven. 09:44]
   
    Je l'ai créer sur krakenator ici
    /home/cayek/Projects/Article3/Article3Package/BenchmarkDump/

    Sur timc-bcm-15 je vais mettre un lien symbolique.

***** Install Article3Package sur krakenator
    Entered on [2017-01-27 ven. 10:05]
   
    Sur krakenator je sais pas pk mais il faut installer le pacakge avec 
   
    #+BEGIN_SRC R
    devtools::install(dependencies = FALSE)
    #+END_SRC
    Sinon il essaie d'installer des pacakge qui sont deja installé et echoue... Je
    sais pas si ca ne vient pas du package =git2r= ...A voir.

    En faite si maintenant ca marche... il y a le =git2r= qui echoue a la fin
    mais le package est bien installé ! 

***** Fin de semaine
    Entered on [2017-01-27 ven. 16:51]
    Putin de semaine de merde !!! 
   
    Il faut que j'arrive a reproduire le reference based si je veux me comparer
    honettement. D'arpès OF il n'y a pas de batch effect correction car sinon on
    l'aurais eu dans les co variable !! Le mystère a perser c'est comment il
    trouve la composition céllualaire 

    Pour les GWAS on va dans frichot, les data c'est celle du HGDP + on prend les
    coordonnées des pop et on creer des var env avec le package raster !!!
    OF: il y a 3 pressions: 
    - le climat
    - la diete
    - les patogènes 

    A Lundi !!
**** 2017-01-30 lundi
***** Lasso, ridge et lambda                                     :Rnotebook:
    Entered on [2017-01-30 lun. 14:24]
   
    Objectif: touver des simulations où
    - lasso est meilleur que ridge
    - le choix du lambda pour lasso n'est pas un choix extrème 
    Je veux aussi trouver un critère de choix du lambda !!
   
    J'ai trouver des simulation ou le choix de lambda influe vraiment !! Sur les
    jeux de données simulé depuis le 1000 génome ! Voir les résultats :
    file:./3Article/LabNotebook/LassoRidgeEtLambda.nb.html .
**** 2017-01-31 mardi
***** Données simulé from le 1000 genomes                        :Rnotebook:
    Entered on [2017-01-31 mar. 13:56]
****** Objectif:
     reponds: Quelles sont les spécificités des dataset simulé from le
     1000 genomes et qui fait que lfmm echoue pour certaines valeurs de lambda ?
****** Résultats:
       de l'acp sur le chrm 22 du 1000 genomes :
       file:./3Article/LabNotebook/Validation_1000Genome.nb.html
      
       Les résultats montre qu'il y a un choix de lambda optimal : 
       file:./3Article/LabNotebook/DataFrom1000Genome.nb.html
****** Conlusion 
       Il y a un lambda optimal qui controle bien la corrélation avec la
       structure de fond ! 
      
       Il nous faut un critère pour le choisir ! 
      
       Il faut que je teste la version avec nuclear norme !!! Il me semble me
       souvenir que je l'avais bien vite abandonné ! Mais !!! je n'avais fait que
       des tests sur mes simulations générative bien propre et avec lambda à 0.
******* Le [2017-02-02 jeu.] :
        En fait je pense surtout que ces exemples sont très atypiques et
        dificil. Je vais essayer de simuler des covariable orthogonal a plusieurs
        axes ! 
       
        Les simulations que viens de faire à la fin montre bien sur des
        situations plus réaliste on dechire tout ;) et il faut un lambda petit ! 
******** DONE Ne pas rejeter cette situation ! 
         CLOSED: [2017-02-02 jeu. 10:22]
         Le lambda optimal n'existe que dans des cas particulier. Mais il
         faudrait quand même que je me penche sur la question !!
        
         Je pense que sur ses simulations particuliere la projection tuait plus
         vite la structure de fond que la partie de correlation avec X. Du coups
         quand le lambda était trop petit la structure de fond apprenait la
         partie de corrélation avec X. C'est pour ca que je fait moins bien que
         lm dans ce cas. 
        
         On retrouve ce phénomène quand je prend un K trop grand sur les
         simulations gausiennes. Il faut que lmbda soit suffisament petit pour
         empecher que la corrélation expliqué par X ne soit aprise par l'ACP.
         Voir file:./Article3Package/tests/testthat/test_NormalSAmpler2.R.

***** Nuclear norm LFMM                                          :Rnotebook:
    Entered on [2017-01-31 mar. 15:54]
****** Objectif: 
       on va faire une vrai evualuation de cette méthode pas seulement sur des
       belle simulations toutes propres !!
****** Resultats:
       file:./3Article/LabNotebook/NuclearLfmm.nb.html
****** Conclusion
       Je ne sais pas pk mais c'est moins bon avec la nuclear norme ... J'ai même
       essayer de corrigé avec le U trouvé par lfmm nuclear norme en co variable
       d'un lm a la fin. De plus quand je fais un hard thresholding plutot qu'un
       soft ca deviens très lent. Enfin je ne retombe pas sur le resultat de
       lfmm + ridge dans le cas d'une alternance de pca normal et lm ridge.
*** 2017-02 février
**** 2017-02-01 mercredi
***** HGDP experiment                                            :Rnotebook:
    Entered on [2017-02-01 mer. 15:34]
****** TODO Objectifs
       - [X] lancer l'acp
       - [X] lancer la crossvalidation
       - [ ] lancer lfmmRidge avec imputation par la moyen
       - [ ] lancer lfmmRidge alterné (=finalLfmmRdigeMethod=)
       - [ ] lancer lfmmRidge avec imputation par lotter
******* DONE Bug dans =HGDP_runs=
        CLOSED: [2017-03-01 mer. 10:57]
        #+BEGIN_SRC R
        > library(Article3Package)
        >
        > G.file <- "~/Projects/Data2016_2017/Hgdp_Li/Hgdp_Li.rds"
        > X.file <- "~/Projects/Data2016_2017/Hgdp_Li/X_tmp.rds"
        >
        > s <- TrueSampler(G.file = G.file,
        +                  X.file = X.file,
        +                  outlier.file = NULL,
        +                  n = NULL,
        +                  L = NULL)
        >
        >
        > lambdas <- c(1e-10, 1e0, 1e2, 1e3)
        > Ks <- c(5, 20)
        > HGDB_runs(s, Ks = Ks, lambdas = lambdas, save = TRUE)
        Error in tempfile(tmpdir = exp$benchmakdir, fileext = ".rds") :
        valeur 'tempdir' incorrecte
        De plus : Warning message:
        executing %dopar% sequentially: no parallel backend registered
        >
        #+END_SRC
        Ca vient surement de dumpExperiment !!! Du coup laner lfmmRidge alterné à
        planté !!
       
        C'est juste que je me suis pas lancé dans le bon dossier !!! ./Article3Package/
****** Resultats
       file:./3Article/LabNotebook/HGDP.nb.html
***** Bilan de cette journée
    Entered on [2017-02-01 mer. 16:55]

    J'ai pas de solutions pour trouver le lambda, mais au moins je suis en train
    de converger vers uniquement lfmmRidge. Mon critère de comme de la
    correlation entre U et X sur le HGDP donne le même paterne que sur mes
    simulations, voir: 
    - file:./3Article/LabNotebook/DataFrom1000Genome.nb.html
    - file:./3Article/LabNotebook/HGDP.nb.html
    C'est bizare !!! Il y a aurait pas un moyen automatique de choisir ce lambda.
   
    :( Ce qui est triste c'est que au final mes simulations sur les vrai jeux de
    données montre surtout que PCA+lm est pas si mal !!

****** Questions
       - Je pense pouvoir avoir des resultats avec lfmmRidge alterné, pourtant je
         le papier de cite:mazumder10_spect_regul_algor_learn_large_incom_matric
         il dit qu'il n'y a pas de resultats avec la hard thresholding ! 
       - Comment trouver lambda ? 
       - Comment valoriser la méthode par rapport à PCA+lm qui fait pas si mal !
         Mon idée de variance de bacground est a développer ! 
       - Est ce que sur les ewas je vais faire si bien que ca, surtout que les
         méthodes auquel je veux me comparer veulent apprendre un truc bien
         particulier (la composition cellulaire).
       - Je pense que la ou on gagnerais c'est avec un lfmm avec un lien
         logistique ! 
       - Il faudrait que je me compare au GWAS plygénique aussi a locasion ! Voir
         les papier de stephens !
**** 2017-02-02 jeudi
***** lfmmRidge cross validation                                 :Rnotebook:
    Entered on [2017-02-02 jeu. 09:17]
****** Objectifs
       Montrer les resultats de crossvalidation sur des simulations
****** Resultats
       :PROPERTIES:
       :CUSTOM_ID: cross_validation_exp
       :END:
       file:./3Article/LabNotebook/CrossValidation.nb.html
       On observe les mêmes paterns que avec les simultations from a true
       dataset : file:./3Article/LabNotebook/DataFrom1000Genome.nb.html. 
****** Conclusion
       C'est pas gagné pour trouver un critère pour choisir le lambda... Ce
       pattern est juste typique des données binaire...
      
       Au final il n'y qu'un seul exemple qui m'enmerde ! Et si cétait un cas
       très particulier ! Dans les vrais dataset les variables X est corrélé avec
       plusieurs axes ! C'est deja ce que je fais en sommant plusieurs X.
***** Calibration du test d'hypothèse                            :Rnotebook:
    Entered on [2017-02-02 jeu. 16:12]

    Bon on est en gros d'accord sur la méthode !! On va explorer la calibration.
    C'est un notebook interactif, cad que les experience sont pas longues du coup
    on peut jouer avec !!!

****** Objectifs
       Montrer que la méthode est bien calibré sur tous mon panel de test !! 
****** Resultats
       file:./3Article/LabNotebook/calibration.nb.html
      
       J'avais fait une erreur dans ma fonction calibration... 

       Il semblerait que quand il y a trop d'outlier le gif marche mal !!! Il
       rend le test beaucoup trop conservatif. C'est genant si je vends lfmm
       comme utile quand il y a beaucoup d'outlier.
****** Conclusion
       Il faut que je reflechisse au test d'hypothèse. Je sur estime l'erreur (la
       variance des estimateurs) surement a cause de l'auto-corrélation des
       intividus ! Je pense que c'est d'autant plus vrai que quand je fait G - C.
       Il faut que je trouve un moyen de corriger proprement pour ca ! (voir ma
       ccl a la fin du notebook). Le GIF semble ne pas marcher quand il y a trop
       d'outlier, c'est logique car c'est en faite juste une median donc si il a
       trop d'outlier ca la tire ! 

       On doit pouvoir mesurer cette autocorrelation !! 
      
       Je reviens ;D

******* DONE SSMPG 2015 
        CLOSED: [2017-02-16 jeu. 15:36]
        Les resultats sont vraiment pas terrible à par sur le case 2. Je pense que
        le modèle n'est pas adapté. Il faudrait un moyen de le detecter ! Un
        critere qui dise si ma modélisation est bonne ou pas.
******** Conclusion
         On ne peut pas le detecter, le modèle est pas adapté c'est tout ! En
         tout cas on ne dit pas de chose fausse, le FDR est controlé.

         Voir [[#model_choice][Sur le choix des modèles de test d'hypothèse]]

***** Bilan de cette journée ! 
    Entered on [2017-02-02 jeu. 18:08]

    Il faut bosser le test d'hypothèse ! Parfois tester B = 0 à pas l'aire bon du
    tout. Il faudrait définir clairement mon hypothèse, avec la variance de
    background et le B !

    Je veux un test parfaitement calibre demain bitch !!
**** 2017-02-03 vendredi
***** Partir en vacance serein... ou pas
    Entered on [2017-02-03 ven. 15:30]
****** Les mistère restant sur la méthode a ce jour
       - Comment calibrer le test, je suis sur qu'il y a coup a jouer ici. Voir
         mon cahier. Mais je ne veux pas faire appel a une méthode ad hoc à la
         fin.
       - L'algo d'alternance de lfmmRidge converge-t-il en théorie ? Je pense que
         oui mais il faudra faire un peut de biblio. Voir cite:josse2009gestion.
       - Cette algo est-il vraiment utile ? Je pense que oui aussi, les resultats
         de file:./3Article/LabNotebook/MissingValue.nb.html son bizare mais je pense
         qu'on va reussir trouver des simulations ou c'est mieux :D. Le top
         serais de montrer que on en viens a dire n'importe quoi quand
         l'imputation est faite a l'arrache. Mais si je recalibre mes tests pour
         le degre of freedom effectif ou un truc comme ca... Bon on verra.
       - On peut utiliser ca en EWAS ??
****** Bonne vacance
       On progresse !!!!!
**** 2017-02-14 mardi
***** Calibration des tests avec boostrap                        :Rnotebook:
    Entered on [2017-02-14 mar. 10:50]
****** Objectif
       On va ajouter une option boostrap au test en fin de chaine.
      
       On va faire un bootstrap du model de lfmm complet.
****** Resultats
       file:3Article/LabNotebook/bootstrapCalibration.nb.html
****** Conclusion
       Non c'est logique que sigma soit encore moins bien estimé ! Le bootstrap
       sous estime l'erreur car les datasets sont très corrélés ! 
***** Bilan de la journée
    Entered on [2017-02-14 mar. 18:21]
   
    Il faut que je trouve un moyen destimer le nombre de degré de liberté
    effectif ! Voir [[https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)][cette page wikipedia]].

    A demain !!
**** 2017-02-15 mercredi
***** Les deux gros problèmes à résoudre
    Entered on [2017-02-15 mer. 09:38]
****** Calibration des tests
       Je veux un test d'hypothèse calibré !!
       - bootstrap : donne comme lm théorique voir
         [[file:3Article/LabNotebook/bootstrapCalibration.nb.html]].
       - permutation : on va perdre en puissance. Mon intuition est que on test
         ne sachant pas X, or on connait X ! 
****** Choix du lambda (choix du model)
       :PROPERTIES:
       :CUSTOM_ID: lambda_choice
       :END:
       Comment choisir le lambda, c'est a dire un modèle ! 
       - cross validation ne marche pas car ce n'est pas la généralisation que
         l'on veut
       - on pourrait essayer la reproducibilité (cad est ce que on retrouve les
         même resultat quand on prend des sample d'indiv). Mais j'y crois pas !
****** Rmk
       Le plus important est peut être la calibration du test ! Car si on a un
       test bien calibré on ne dira pas de connerie à la fin ! On aura peut être
       moins de puissance ! Mais on dit la vérité ! 

       Go calibrarion ! 
***** Quelques experience pour la calibration des tests          :Rnotebook:
    Entered on [2017-02-15 mer. 11:47]

    On va essayer de calculer l'équivalent du gif mais sur le residue !
****** Objectif
       Trouver un moyen d'esimer une variance residuelle plus juste !
****** Resultats
       [[file:3Article/LabNotebook/gifExperiment.nb.html]]
****** Conclusion
       Je pense pas que la corrélation va se voir dans les resudus, ils sont
       construit pour etre indépendant ! C'est vraiment dans les beta que ca se
       voit ! 
      
       C'est la merde bradley ! Il faut que je reflechisse à un model stat ou je
       peux faire des tests !!!! Pour le moment j'ai pas la solution ! Mon lm à
       la fin marche pas car c'est pas iid ... Enfin je pense !
**** 2017-02-16 jeudi
***** Réu OF
      Entered on [2017-02-16 jeu. 11:59]
   
    - on arrête de se prendre la tête sur la calibration, je verrais plus tard.
      Surtout qu'il y a beaucoups de méthode de calibration des test (exemple:
      cite:stephens16_false_discov_rates ou les truc de lissage pour enlever le
      ld etc...)
    - <<ld>>: En parlant de LD, le V du modèle est censé le capter, a valider. Et c'est
      un problème pour les tests d'hypothèse.
    - On va partir des résultats et garder lfmm avec lm + gif ! On part des
      résultats et on remonte.
    - Méthode : on décrit le plus clairement ce qu'on fait ! Pas de mystique ;D
    - On verra à la fin pour se prendre la tête sur les stats à la fin :p 
***** Sur le choix du lambda (choix de model)
      :PROPERTIES:
      :CUSTOM_ID: lambda_model_choice
      :END:
      Entered on [2017-02-16 jeu. 14:29]
   
      J'en avait déja parlé ici : [[#lambda_choice][Choix du lambda (choix du model)]]. Je me répète
      c'est vraiment une affaire de choix de model ! Mes experiences sur case2 de
      ssmpg (voir [[*Calibration du test d'hypothèse][Calibration du test d'hypothèse]]) montre que case2 n'est pas
      adapté a ce model ! Et c'est tout ! De toute facon ce que je dit est bien
      qualibré à la fin ;)
   
      Si lfmm Lasso marchait bien on aurrait un critere simple : la proportion des
      non null. Mais je pense qu'il y a plus de boulot pour lfmm lasso ! On verra
      plus tard.

      Au final, le plus sage est d'appliquer le model au cas ou on sait que la
      structure est plus forte que le reste -> un lambda petit. On pourra le
      justifier avec mes petit raisonnement (voir cahier le 30/01/2017). C'est le
      cas le moins violant par rapport à lm. On pourra peut etre montrer un choix
      de lambda optimal.

****** Un critère pour lfmm ?    
       Dans mon cas la [[#cross_validation_exp][crossvalidation]] donne toujours le meilleur critère pour
       lambda grand. Mais ca permet de voir la gamme de lambda ou il se passe
       quelque chose. 

       On va proposer ce critère visuel! La méthode est rapide c'est l'occasion
       de tester plusieurs modèles.
      
****** Conclusion 
       Je m'adresse a des situation ou la structure est plus forte que XB (c'est
       l'hypothèse) => lambda doit être petit.


***** Sur le choix des modèles de test d'hypothèse
      :PROPERTIES:
      :CUSTOM_ID: model_choice
      :END:
      Entered on [2017-02-16 jeu. 15:37]
     
      Quand on construit un test d'hypothèse, c'est très dur de savoir si ce test
      est adapté à notre situation. Je veux dire q'uil n'y à pas de critère
      objectif pour ca, comme la crossvalidation ou autre...Car ce n'est pas le
      modèle qui explique le mieux les données qui correspond a mon test d'hypothèse.
**** 2017-02-17 Vendredi
***** Un plan d'attaque pour le seminaire BCM
      DEADLINE: <2017-03-03 Ven>
      Entered on [2017-02-17 Ven 09:59]
****** Les resultats
******* Validation sur simulation                                :Rnotebook:
[[file:3Article/LabNotebook/simuValidation.nb.html]]
******** DONE Simulations
CLOSED: [2017-03-16 Jeu 12:41]
         From le 1000 genomes. 2 cas : 
         - peu d'outlier
         - beaucoups d'oulier
          
         Voir avec olivier les simus qu'avait fait eric dans
         cite:frichot13_testin_assoc_between_loci_envir. 

         Voir les simu qu'on peut faire d'autre

******** DONE Les méthodes
CLOSED: [2017-03-01 mer. 15:29]
         - [X] lfmm ridge
         - [X] FAMT
         - [X] SVA
         - [X] PCA+lm
         - [X] méthode oracle+lm
         - [X] lm
         - [X] Refactor
         - [X] LEA
******** Le message
         - les facteurs lattents posent problèmes
         - quand il y a beaucoup d'outlier lfmm gagne sur lm et lm+PCA
         - Toutes les méthodes qui prennent en compte les facteur lattents disent
           en gros la même choses.
******** DONE Implementation
         CLOSED: [2017-02-17 Ven 16:22]
         Comparaison sur simulated data set function.
         J'implemente ca cette aprem !
******* DONE Missing values                                       :Rnotebook:
        CLOSED: [2017-03-16 Jeu 12:41]
        Même experience que [[*Validation sur simulation][Validation sur simulation]] mais avec une strategie
        d'imputation des missing values
       
        [[file:3Article/LabNotebook/missingValuesSimuValidation.nb.html]]
******** Le message
         - La méthode alternée est meilleur quand il y a des missing values
         - je pense que je vais mettre juste deux lfmm avec imputation par la
           mean et lfmm alterner. Pour avoir un message clair.
          
******** DONE Implementation
         CLOSED: [2017-03-16 Jeu 12:41]
         - [X] LEA with missing value 
         - [X] FAMT with missing value 
         - [X] lfmmRidge with missing value
         - [X] lm with missing value (on met des zeros, et on divise par le vrai
           nombre de données :D)
         - [ ] le notebook
******* Critere de reproductibilité                              :Rnotebook:
        J'espere que ca va marcher...Ok
        cite:crossValidated_PCACrossValidation_2017 m'a fait changer d'avis. On
        va essayer des missing values. 

        Ca marche !!! [[file:3Article/LabNotebook/crossValidationCriteria.nb.html]]
        Pas sur toutes mes simulations...
       
******** TODO La suite 
         Les bars d'erreurs ne sont pas pertinente par ce que d'un lambda a
         l'autre je suis sur que les erreur sont corrélé. Faut que je regarde
         plus en détail comment proprement faire de la cross validation (c'est
         vrai que je me suis jamais vraiment documenté). Peut être que de faire
         un vrai kfold et la moyen est plus pertinent !! La on sample au
         hasard...
        
         Donc : 
         - [X] faire un kfold pour la cross validation (k leave out truc ...):
          
           En faite non je pense que c'est pas trop mal mon [[https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Repeated_random_sub-sampling_validation][montecarlo crossvalidation]].

         - [ ] lancer sur les données ssmpg/simulation qui posait probleme !
         - [ ] lancer sur HGDP et GSE42861
         - [ ] cross valider sur K
******** Conclusion
         - avec beaucoup  de missing values pour la cross validation, on a des
           pattern plus franch. J'ai mis 0.5
         - C'est un critère de cross validation qui dit ce qui est mieux si on
           veut fitter les données... C'est pas forcément ce que l'on veut faire.
******* TODO GWAS                                                :Rnotebook:
        Le HGDP. Et on compare se qui sort par rapport aux autres papiers.
******** Résultats
         [[file:3Article/LabNotebook/HGDP.nb.html]]
******** Le message
         - On fait comme dans cite:frichot13_testin_assoc_between_loci_envir.   
        
******* EWAS                                                     :Rnotebook:
On lance lfmm dessus et on compare se qui sort.
       
[[file:3Article/LabNotebook/GSE42861.nb.html]]
******** DONE pas encore fait
         CLOSED: [2017-03-08 mer. 08:50]
         On retrouve bien les locus du papier cite:Rahmani_2016, mais les qqplot
         ne resemble pas trop a ceux du papier... Ce que je peux faire c'est : 
         - [X] Run de lfmm : 
           - correction de G pour les autres facteurs de confusion
           - G - C (de lfmm)
           - on glm(G_ ~ X)
         - [X] Run de Refactor
********* Ccl
          Avec GLM c'est pas tout a fait calibré mais avec un petit par dessus ca
          va ! On retrouve bien les locus du papier. 

          Par contre Refactor n'est pas bien calibré je sais si il recalibre dans
          le papier mais chez moi c'est pas au top ! Après il me manque les batch
          effect peut être que j'aurais du les trouvé finalement ...

          Bref, avec la recalibration ca marche ! 
******* TODO Robustesse au choix des parametres
A voir comment on peut faire.
***** FAMT test                                                  :Rnotebook:
    Entered on [2017-02-17 Ven 13:10]
 
    Test of the [[http://famt.free.fr/][famt package]] [[file:3Article/LabNotebook/FAMT.nb.html]]
***** SVA test                                                   :Rnotebook:
    Entered on [2017-02-17 Ven 14:32]
   
    Test of [[http://www.bioconductor.org/packages/release/bioc/html/sva.html][SVA R package]] : [[file:3Article/LabNotebook/SVA.nb.html]]
***** Bilan de la semaine
    Entered on [2017-02-17 Ven 16:28]
   
    On avance bien !! La semaine prochaine on continue d'inmplementer les tests
    systématiques. On discute avec olivier pour s'assurer que ca va dans le bon
    sens ! 

    OUS !
**** 2017-02-20 Lundi
***** DONE Est ce que lfmm est sensé enlever le "problème" du ld dans les tests ?
      CLOSED: [2017-02-20 Lun 21:58]
    Entered on [2017-02-20 Lun 20:59]
   
    Pour réponde à [[ld]].

    Déja je veux revenir sur le fait que c'est un problème ? Est ce que c'est
    référencé comme etant un problème ? A voir dans la biblio.

    En tout cas lfmm ne va pas résoudre ce problème, car si les locus sont
    autocorélé, les $B_j$ le seront aussi ! Même d'un point de vu biologique
    c'est logique. Si un locus monte en fréquence quand il est nord alors les
    autre aussi, à cause de ce que l'on appel le déséquilibre de liaison en
    genetique des populations.

    Je pensais que l'on ne controlait pas le fdr parce que certain $B_j$ sont non
    null alors qu'il n'y a pas d'association ici. Mais la on confond l'hypothèse
    biologique et statistique. 
   
    Par contre, ce qui est vrai est que quand les tests sont corrélé ca biaise
    l'estimation du taux d'erreur. Comme expliqué sur [[https://en.wikipedia.org/wiki/Multiple_comparisons_problem#Assessing_whether_any_alternative_hypotheses_are_true][cet article wikipedia]].
**** 2017-02-21 mardi
***** Bilan de la journée
    Entered on [2017-02-21 mar. 16:39]
   
    Je pense que je vais articuler le papier et la présentation comme ca : 
    - présentation des modèles à facteur lattent et leurs applications
    - présentation des algos 
    - interêt pour notre domaine
    - nos algos
    - nos resultats

    On a les résultats, demain je fais la biblio final et j'identifie tous les LFMMLike.

    J'ai l'impression que tous se passe bien parce que je valide sur mon
    modèle... Il faut que j'ai une vision plus claire de la biblio pour avoir
    confiance en ma demarche. Comment les autres on valider ?
**** 2017-02-23 jeudi
***** Bilan de la journée et long week end
    Entered on [2017-02-23 jeu. 16:36]

    On a bien avancé aujourd'hui : 
    - plan de la résentation dans le cahier
    - critère de cross validation qui marche pas mal !
     
    A Mardi !! Mardi on commence a générer les figures final pour la présentation
    et on la fait en parallèle ! Voir mon cahier.
*** 2017-03 mars
**** 2017-03-01 mercredi
***** Deploy on krakenator with git
    Entered on [2017-03-01 mer. 11:04]

    - I create a repo on krakenator /home/cayek/GitRepo/Article3.git
    - [[file:hooks/post-receive.sh][post-receive hook]]
    - add a remote krakenator_deploy
**** 2017-03-02 jeudi
***** Illustration avec Arabidopsis Athaliana                    :Rnotebook:
    Entered on [2017-03-02 jeu. 08:49]

    Je veux faire un exemple pour illustrer les facteur de confusion, en
    replacant ma super carte :D
****** Resultats
       [[file:3Article/LabNotebook/AthalianaIllustration.nb.html]]
******* Avant et après le gif
        Avant le gif, on observe que rien n'est significatif ! Mon
        interpretation : le modèle linéaire simple n'est pas adapté, du coup la
        distribution sous H0 est fausse ! Avec le gif ce qu'on fait c'est une
        recalibration des pvaleur en utilisant le fait que presque tout le monde
        est sous H0 et on a une loi normal en gros, c'est l'idée de "Learning from
        the Experience of Others" dans cite:Efron_2009. Donc j'appel ca un gif
        mais c'est plutot une recalibration ! 

        Dans le modèle linéaire : $$G_j = Xb + e$$, les hypothèses fausses sont :
        - e gaussien mais à la limite c'est pas si grave (l'estimateur de B est
          gaussien)
        - les indiv sont iids. Ca donne une mauvaise estimation de la variance de
          $\hat{B}$
        - les locus sont iids. Ca donne une mauvaise estimation du FDR (je crois
          que dans BH il utilise ca pour le controle du FDR)

          Bon tout ca c'est de idées en vrac mais ca fait du bien de les écrire
          !!

          Suite de mes réflexions sur le cahier ! (3/3/17)
******* DONE Pourquoi ca ne marche pas comme je veux !!!
        CLOSED: [2017-03-03 ven. 11:35]
        Je m'attends a ce que lm donne beaucoup trop de pic, la quand je fais dfr
        control personne ne sort pour lm ...

        - [X] lancer lfmm sur une grille
        - [X] on va recalibrer avec autre chose que le gif c'est surement ca le
          pb (enfin un des pb)

          J'ai trop faim j'y vais !!
******** Conclusion 
         Ca marche avec le package =localfdr=. On a bien beaucoup plus de
         significativement corrélé avec lm. 

         Il faut que je comprenne bien les méthodes de recalibration !! Et que je
         justifie pk ce n'est pas mal honette ! Voir mon cachier le 3/3/2017
******** Conclusion 2 [2017-03-06 lun.]
         Il faudra forcement corrigé pour le test d'hypothèse, car on ne va ma
         mettre suffisament de variable lattente pour enlever tout le LD. Sinon
         ca pose des problèmes pour l'estimation des variables lattentes.
***** Les scipts long ! 
    Entered on [2017-03-02 jeu. 09:44]

    Je vais les mettre dans des fonctions plutots ! Comme ca j'ai juste a push
    sur krakenator et lancer la fonction ;D. En plus ca permet de documenter les
    scripts !!! Tout est package !!!

    Le workflow c'est package-notebook-orgmode: 
    - pacakge : un max de code et des test
    - notebook : le codé visuelle, rendu, plot,
    - orgmode : timeline, comment avance le projet
**** 2017-03-07 mardi
***** Programmation défensive
    Entered on [2017-03-07 mar. 08:56]
   
    On va utilisé [[https://github.com/hadley/assertthat][assertthat]] pour faire de la programmation defensive a fond !!
    Ca me permettra de comprendre se qui marche pas quand je reviendrais sur mon
    code :D
***** RUSH !!!!
    Entered on [2017-03-07 mar. 18:32]

    On y est presque pour le presentation demain je fini !!!!! Il me reste juste
    les resultats a generer même si ils sont mauvais je les ajoutes ! 

    Faut que je fasse la recalibration de cite:wang2015confounder (avec la median
    et le mad !!) et on est bon je genere ! 

** Tasks
*** DONE Test
    CLOSED: [2017-01-16 lun. 17:35]
   Test de capture
*** DONE Learn Rnotebook
    CLOSED: [2017-01-17 mar. 09:50]
    Il y a quand même quelque bug... pour regler la taile des fig il faut le
    mettre dans le chunk de setup il semblerait !!
    On Ne peut pas view in github... on doit ddl avant ! 
   
    Custum =Rmarkdown= html output: http://rmarkdown.rstudio.com/html_document_format.html
    Custum example: 
 #+BEGIN_SRC R
 ---
 title: "LFMM with missing value"
 author: "kevin caye"
 date: "16 janvier 2017"
 output: 
   html_notebook:
     toc: true
     toc_float:
       collapsed: false
       smooth_scroll: false
     theme: journal
     highlight: tango
 ---
 #+END_SRC
*** DONE Les questions qui restent en suspet le <2017-01-20 Ven> et a faire la semaine prochaine
    CLOSED: [2017-01-31 mar. 17:21]
    - [X] Pk mon calcule de B.sigma2 est mauvais ?
    - [X] Reussir a mettre lasso dans les graphes precision-recall
    - [X] Visualiser l'évolution de la precision en function du lambda dans le
      ridge !!
    - [X] Pk dans file:./3Article/LabNotebook/AlternatedVsAnaliticRidge.nb.html lfmm ridge
      et lfmm analytics ne donne pas le même resultat sur le premier exemple ! Je
      pense que c'est parce que je ne laisse pas l'algo aller a assez loin ! Pour
      le papier il faut que les deux donnent la même chose ! Sinon j'ai aucun
      espoir d'avoir des resultats de convergeance !
    - [X] C'est en dernier mais c'est le plus important. On va se trouver
      quelques jeux données réels. On en parlera avec OF a la réunion !!
*** DONE Le choix du lambda dans ridge
    CLOSED: [2017-01-31 mar. 17:21]
    - [X] cross validation (on peut le faire mais ne pas l'evaluer)
    - [X] genre de empirical bayes (lm et on regarde la variance des B)
    - [X] pour des raisons numerique d'inverse de P
*** DONE EWAS for the article
    CLOSED: [2017-02-03 ven. 11:31] DEADLINE: <2017-01-25 mer.>
   - [X] add Refactor au methods
   - [X] get data (see my mails)
   - [X] Comparison with the paper result !!
     Il va falloir que je refasse leur resultats si je veux ma comparer a des
     EWAS. Il faudra aussi que je me compare sur leur simultation. Je pense que
     leur méthode on pour but d'apprendre la repartition cellulaire alors que moi
     c'est une structure de fond quelconque... A méditer ! 

*** DONE L'avantage du lasso par rapport au ridge ?
    CLOSED: [2017-01-31 mar. 17:21]
    - [X] verifier l'influence de =sparse.prop=. Je m'attends a ce que si il est
      trop bas on fasse comme PCA + lm.
    - [X] trouver des cas de figure ou lasso meilleur ! Pour le moment ca faire
      toujours la même chose !
*** DONE GSE42861 experience
    CLOSED: [2017-01-27 ven. 15:33]
    GO !!!
**** DONE La vraie experience !
     CLOSED: [2017-02-16 jeu. 15:32]
     On va faire le même préprocessing que dans cite:Zou_2014 et verifier qu'on
     trouve bien la même chose que dans la méthode reference based ! C'est ce
     qu'il font dans cite:Zou_2014,Rahmani_2016. Idéalement il faudrait que
     j'arrive a reproduire la méthode dites reference-based.
    
     *ERATUM* : IL FAUT que j'arrive a faire la méthodes dite refecence-based si
     je veux me comparer !!! Je m'en fous des autres !!
***** Conclusion
      En fait non, je vais appliquer ma méthode et comparer à leur résultat et si
      ca ne marche pas je prendrais un autre EWAS ! 
    
*** DONE HGDP experiment
    CLOSED: [2017-02-01 mer. 15:33]
  
    J'ai commencé ./Article3Package/R/HGDP_function.R et
    ./Article3Package/tests/testthat/test_HGDP.R !!
*** DONE Checkpoint et tache a faire le <2017-01-31 mar.>
    CLOSED: [2017-02-16 jeu. 15:33]
    Je pense que je vais abandonner les algo alterné avec le lasso, ca ne donne
    pas de bon résultats. Je vais essayer un algo qui alterne du lfmm ridge, en
    plus je pourrais peut être le justifier avec les resultats du papier
    cite:mazumder10_spect_regul_algor_learn_large_incom_matric. L'utilité d'un
    algo pour les missing data n'est pas a remettre en cause je pense ! Enfin
    faudrais que j'y reflechisse mais lfmm alterné PCA + ridge ne donne pas les
    memes resultats que le lfmmRidge... De toute facon si j'alterne lfmmRidge ca
    regle le pb !!

    - [ ] lfmm ridge et laternance de lm ridge et PCA ne donne pas la même chose,
      pk ?
    - [X] on a montré que le choix du lambda a une importance dans lfmm ridge,
      mais comment le choisir ? trouver un critere !!!
**** Conclusion
     Je vais voir le point non fait plus tard, avec la théorie.

*** TODO On scale les datas ou pas ? 
    Ca change quoi de scale les données ?
    Voir dans l'acp ce qui est recommandé. 
*** TODO Simulations de data from true dataset
    Faire des simulation à la facon d'of ! C'est a dire on va simuler des locus

    $$ G_j = Bj X + E $$ 
   
    Où E est un bruit avec la même corrélation que dans les data observées. On
    peut mettre un lien logistic a voir. Le problème était que ca faisait sortir
    un groupe dans l'acp, je comprends pas pk ! A voir ! 
*** TODO GWAS method
    - Il me faut des méthodes de GWAS (celle de cite:Zhou_2013 a l'aire bien !)
    - On va faire des simulations de phénotype aussi, a réfléchire ! 
*** TODO Un critère de stabilité 
    Dans cite:article_Leek_Storey_2007 il dit que SVA permet de stabilisé le
    ranking des gênes. Donc un critère de reprudicibilité est a voir.
   
    Je parle de ce problem dans [[ref:lambda_model_choice][cette note.]]
   
 
* Notebooks
:PROPERTIES:
:header-args: :cache no :session *R* :dir ./ :eval no-export
:END:
Les autres notebooks de ma thèse sont un peu partout... :D
** DONE Premier org notebook
CLOSED: [2017-04-04 mar. 11:05]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-04-04 mar. 11:05]
- State "STARTED"    from "TODO"       [2017-04-04 mar. 10:28]
- State "TODO"       from              [2017-04-04 mar. 10:27]
:END:
#+begin_src R :results output graphics :file Rplots/first_plot.png :exports both :width 600 :height 400 
plot(1)
#+end_src

#+RESULTS:
[[file:Rplots/first_plot.png]]

** DONE Comparison of methods on generative simu cor(U1,X)=c      :3Article:
CLOSED: [2017-04-13 jeu. 09:02]
:LOGBOOK:
- Note taken on [2017-04-13 jeu. 09:02] \\
  On a pas lancé sur toutes les méthodes (cate et lea) mais on passe sur des
  simulation plus dure !!
- State "DONE"       from "STARTED"    [2017-04-13 jeu. 09:02]
- Note taken on [2017-04-12 mer. 16:38] \\
  Il faut vraiment que je trouve des simulation plus facile, peut etre en
  augmentant la variance de B. Faut que j'essaie avec d'autre axe corrélé avec X
  peut être qu'on y verra plus clair !!
- Note taken on [2017-04-12 mer. 16:33] \\
  Les resultats avec K over estimated sont pas mal. Au final tout le lfmmLasso est
  bien robuste ! L'oracle fait comme PCAlm ... il faut que je modifie ca ! Je vais
  faire un vrai oracle !!
- Note taken on [2017-04-12 mer. 10:22] \\
  Je pense que ces simulation sont un peut trop dure, mais on voit quand même que
  mes lfmmRidge et lfmmLasso sont pas mal !
- Note taken on [2017-04-11 mar. 17:18] \\
  On a fait les courbe d'auc, ca rend pas mal. Ce qu'on voit c'est que FAMT et
  lassoLFMM font les meilleurs résultats. L'avantave de ma méthode est sur le
  control du FDR.
- Note taken on [2017-04-07 ven. 10:30] \\
  Courbe d'AUC ?
- Note taken on [2017-04-07 ven. 10:27] \\
  Les resultats sont pas clairs => mettre d'autre param (comme avant c(0.6,0.3)?)
- State "STARTED"    from "RUNNING"    [2017-04-05 mer. 16:33]
- State "RUNNING"    from "STARTED"    [2017-04-05 mer. 16:33]
- State "STARTED"    from "WAITING"    [2017-04-04 mar. 16:55]
- State "WAITING"    from "STARTED"    [2017-04-04 mar. 15:58]
- State "STARTED"    from "TODO"       [2017-04-04 mar. 13:01]
- State "TODO"       from              [2017-04-04 mar. 11:06]
:END:
*** With the same 10000 loci for every body 
**** Run on krak
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 10,
                                   fast.only = FALSE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)
#+end_src
**** Plots
:PROPERTIES:
:header-args: :cache no :session *R* :dir ./ :eval no-export :width 1000 :height 800
:END:

We retrieve the experiment
#+begin_src R :results output :exports both
  exp <- retrieveExperiment(96)
  exp$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/European_Chrm22.maf.05.sample.10000.rds K=4 n= L=10000 cs=0.2|0.4|0.6|0.8 outlier.props=0.01|0.05|0.1 nb.rep=10 "

***** C = 0.2
#+begin_src R :results output graphics :file Rplots/1000_loci_c02.png :exports both
  Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.2)
#+end_src

#+RESULTS:
[[file:Rplots/1000_loci_c02.png]]

***** C = 0.6
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.6)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-4989Cvd.png]]
***** precision-recall
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_precisionRecall(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-15107ugK.png]]

On y voit pas grand chose. Faire des courbes d'AUC comme dans 2Article ? Je vais
lancer sur tous le data set pour voir si c'est pas ces 10000 loci qui sont bizare.
***** AUC
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071UEP.png]]
***** Inflation factor
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071VFW.png]]

*** By sampling loci every time
**** DONE Run on krakenator or patator
CLOSED: [2017-04-07 ven. 08:32]
:LOGBOOK:
- Note taken on [2017-04-07 ven. 08:33] \\
  exp id = 100
- State "DONE"       from "RUNNING"    [2017-04-07 ven. 08:32]
- State "RUNNING"    from "WAITING"    [2017-04-06 jeu. 11:53]
- Note taken on [2017-04-05 mer. 09:03] \\
  Bug when running on krakenator
- State "WAITING"    from "RUNNING"    [2017-04-05 mer. 09:01]
- State "RUNNING"    from              [2017-04-04 mar. 16:56]
:END:
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 10,
                                   fast.only = FALSE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)
#+end_src
**** Plots
We retrieve exp results
#+begin_src R :results output :session *R* :exports both
library(ThesisRpackage)
exp <- retrieveExperiment(100)
#+end_src

#+RESULTS:

***** C = 0.2
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.2)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-5560Z9V.png]]

***** C = 0.6
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.6)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-5560Aco.png]]

***** C = 0.8
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.8)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-5560aw0.png]]

***** precision-recall
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_precisionRecall(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-5560ZEK.png]]

***** AUC
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071hOV.png]]

***** Inflation factor
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071vZi.png]]

*** We over estimate K (K+1)
**** DONE Run on krakenator
CLOSED: [2017-04-12 mer. 16:32]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-12 mer. 16:32]
- State "RUNNING"    from              [2017-04-12 mer. 10:56]
:END:
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   K.method = 5,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 5,
                                   fast.only = TRUE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)


#+end_src
**** plots
#+begin_src R :results output :session *R* :exports both
exp <- retrieveExperiment(103)
exp$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds K=4 K.method=5 fast.only=TRUE n= L=10000 cs=0.2|0.4|0.6|0.8 outlier.props=0.01|0.05|0.1 nb.rep=5 "
***** AUC
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-27994ouK.png]]

***** Inflation factor
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-2799414Q.png]]


*** We over estimate K (K+3)
**** DONE On krakenator
CLOSED: [2017-04-12 mer. 16:32]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-12 mer. 16:32]
- State "RUNNING"    from              [2017-04-12 mer. 10:57]
:END:
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   K.method = 7,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 5,
                                   fast.only = TRUE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)


#+end_src
**** plots
#+begin_src R :results output :session *R* :exports both
exp <- retrieveExperiment(104)
exp$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds K=4 K.method=7 fast.only=TRUE n= L=10000 cs=0.2|0.4|0.6|0.8 outlier.props=0.01|0.05|0.1 nb.rep=5 "
***** AUC
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-27994PNd.png]]
***** Inflation factor
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-27994php.png]]




** STARTED EWAS for LFMM article                                  :3Article:
:LOGBOOK:
- Note taken on [2017-04-13 jeu. 18:00] \\
  Ok c'est on va retrouver les même resultats par contre lasso donne pas les même
  reultats... A voir.
- Note taken on [2017-04-13 jeu. 17:25] \\
  Je vais essayer de reproduire les resultats que j'avais trouvé pour la pres
  [[file:3Article/Slides/BCMSeminar/experiments.nb.html][seminarBCM]].
- Note taken on [2017-04-11 mar. 12:39] \\
  Il y a quelque chose qui ne va pas avec ces données je n'arrive même pas a
  reproduire les resultats des papiers cite:Rahmani_2016 etc... Je voulais
  retrouver les loci connu sans correction mais ca n'a pas l'aire de marcher.
  Affaire a suivre !!
- Note taken on [2017-04-10 lun. 17:43] \\
  Il faut que je recalibre les tests. Pk. Je vais faire de la biblio la dessus et
  identifier les causes du fdr pas controlé !!!! 
  Debug ca aussi [[file:ThesisRpackage/tests/testthat/test_3Article_runExp.R::test_that("Article3_runExp_calibrate",%20{][Article3_runExp_calibrate]]
- State "STARTED"    from "TODO"       [2017-04-04 mar. 16:19]
- State "TODO"       from              [2017-04-04 mar. 12:06]
:END:
*** PCA on betanormalized_metylationlvl.filtered.rds
**** on krakenator
#+begin_src R :results output :session *R* :exports both
library(ThesisRpackage)
s <- TrueSampler(G.file = "../Data/GSE42861/betanormalized_metylationlvl.filtered.rds",
                 X.file = "../Data/GSE42861/X.rds",
                 outlier.file = NULL,
                 n = NULL,
                 L = NULL)
exp <- Article3_pcaExp(s = s,
                       s.name = "GSE42861 filtered",
                       cluster.nb = NULL,
                       save = TRUE, bypass = FALSE)
#+end_src
**** Plots
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  exp <- retrieveExperiment(40)
  plot(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-28683uFt.png]]
*** <<CV_GSE42861_not_corrected>> LFMM ridge crossvalidation on betanormalized_metylationlvl.filtered.rds
**** On krakenator
#+begin_src R :results output :session *R* :exports both
library(ThesisRpackage)
s <- TrueSampler(G.file = "../Data/GSE42861/betanormalized_metylationlvl.filtered.rds",
                 X.file = "../Data/GSE42861/X.rds",
                 outlier.file = NULL,
                 n = NULL,
                 L = NULL)
dat <- sampl(s)
exp <- Article3_cvExp(s = s,
                      s.name = "GSE42861 filtered",
                      Ks = c(1,2,3, 4, 5, 6, 7, 8, 10,15),
                      lambdas = c(1e-10, 1e0, 1e10, 1e20),
                      row.left.out.func = left.out.kfold(5),
                      col.left.out.func = left.out.sample(5, 0.2),
                      cluster.nb = 2,
                      save = TRUE, bypass = FALSE)
#+end_src
**** Plots
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
exp <- retrieveExperiment(41)
plot(exp$cv, color = "K")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-28683tZC.png]]
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
plot(exp$cv, color = "lambda")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-286836jI.png]]

*** LFMM ridge crossvalidation on betanormalized_metylationlvl.filtered.LMresidu.rds
**** DONE On krakenator
CLOSED: [2017-04-05 mer. 08:47]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-05 mer. 08:47]
- State "RUNNING"    from              [2017-04-04 mar. 16:56]
:END:
#+begin_src R :results output :session *R* :exports both
library(ThesisRpackage)
  s <- TrueSampler(G.file = "../Data/GSE42861/betanormalized_metylationlvl.filtered.LMresidu.rds",
                   X.file = "../Data/GSE42861/X.rds",
                   outlier.file = NULL,
                   n = NULL,
                   L = NULL)
  dat <- sampl(s)
  exp <- Article3_cvExp(dat = dat,
                        dat.name = "GSE42861 filtered and LM residual",
                        Ks = c(1,2,3, 4, 5, 6, 7, 8, 10,15),
                        lambdas = c(1e-10, 1e0, 1e10, 1e20),
                        row.left.out.func = left.out.kfold(5),
                        col.left.out.func = left.out.sample(5, 0.2),
                        cluster.nb = 2,
                        save = TRUE, bypass = FALSE)
#+end_src

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
exp <- retrieveExperiment(97)
plot(exp$cv, color = 'K')
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-15107iJj.png]]

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
plot(exp$cv, color = "lambda")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-151077xE.png]]

La cross validation donne plutot K = 2 et pas d'importance pour le choix de
lambda. Ce qui est interessant c'est que la [[CV_GSE42861_not_corrected][CV]] sur les données avec variables
lattente donne plutot K = 4 et lambda petit.
*** Run on betanormalized_metylationlvl.filtered.rds
**** DONE on krakenator
CLOSED: [2017-04-10 lun. 14:39]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-10 lun. 14:39]
- State "RUNNING"    from "DONE"       [2017-04-07 ven. 13:56]
- Note taken on [2017-04-07 ven. 13:17] \\
  exp id = 99
- State "DONE"       from "RUNNING"    [2017-04-07 ven. 13:17]
- State "RUNNING"    from "WAITING"    [2017-04-06 jeu. 09:15]
- State "WAITING"    from "RUNNING"    [2017-04-06 jeu. 08:35]
- State "RUNNING"    from "WAITING"    [2017-04-05 mer. 16:34]
- Note taken on [2017-04-05 mer. 16:22] \\
  krakenator va etre mis a jour, on relance après !
- State "WAITING"    from "RUNNING"    [2017-04-05 mer. 16:22]
- State "RUNNING"    from "TODO"       [2017-04-05 mer. 12:33]
- State "TODO"       from              [2017-04-05 mer. 08:58]
:END:
#+begin_src R :results output :session *R* :exports both
  library(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/GSE42861/betanormalized_metylationlvl.filtered.rds"
  X.file <- "~/Projects/Thesis/Data/GSE42861/X.rds"


  s <- TrueSampler(G.file = G.file,
                   X.file = X.file,
                   outlier.file = NULL)
  dat <- sampl(s)
  dat$X <- dat$X[,1,drop=FALSE] ## keep only first covariate
  exp <- Article3_GSE42861(dat = dat,
                           dat.name = "betanormalized_metylationlvl.filtered.rds",
                           cluster.nb = 4,
                           Ks = c(2,3,4),
                           lambdas = c(1e-4, 1e0, 1e10),
                           sparse.prop = c(0.1),
                           save = TRUE,
                           bypass = FALSE)

#+end_src
**** plots
#+begin_src R :results output :session *R* :exports both
  exp <- retrieveExperiment(101)
  exp$description
#+end_src

#+RESULTS:
: [1] "Article3_runExp with methods=lfmmRidge|glm|refactor|lfmmLasso lambdas=1e-04|1|1e+10|NA|0.0152324128831718|0.0120402443893896|0.00992138012483149 Ks=2|3|4|NA sparse.prop=NA|0.1 dat.name=betanormalized_metylationlvl.filtered.rds "

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
Article3_runExp_manhattan(exp, 0.05,'refactor')
#+end_src


*** Run on betanormalized_metylationlvl.filtered.LMresidu.rds
**** DONE on krakenator
CLOSED: [2017-04-10 lun. 14:39]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-10 lun. 14:39]
- State "RUNNING"    from "WAITING"    [2017-04-06 jeu. 09:16]
- State "WAITING"    from "RUNNING"    [2017-04-06 jeu. 08:35]
- State "RUNNING"    from "WAITING"    [2017-04-05 mer. 16:34]
- Note taken on [2017-04-05 mer. 16:23] \\
  krakenator va etre mis a jour...
- State "WAITING"    from "RUNNING"    [2017-04-05 mer. 16:23]
- State "RUNNING"    from "TODO"       [2017-04-05 mer. 12:33]
- State "TODO"       from              [2017-04-05 mer. 08:59]
:END:
#+begin_src R :results output :session *R* :exports both
  library(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/GSE42861/betanormalized_metylationlvl.filtered.LMresidu.rds"
  X.file <- "~/Projects/Thesis/Data/GSE42861/X.rds"


  s <- TrueSampler(G.file = G.file,
                   X.file = X.file,
                   outlier.file = NULL)
  dat <- sampl(s)
  dat$X <- dat$X[,1,drop=FALSE] ## keep only first covariate
  exp <- Article3_GSE42861(dat = dat,
                           dat.name = "betanormalized_metylationlvl.filtered.LMresidu.rds",
                           cluster.nb = 4,
                           Ks = c(2,3,4),
                           lambdas = c(1e-4, 1e0, 1e10),
                           sparse.prop = c(0.1),
                           save = TRUE,
                           bypass = FALSE)

#+end_src
**** plots
#+begin_src R :results output :session *R* :exports both
exp.LMresidu <- retrieveExperiment(102)
exp.LMresidu$description
#+end_src

#+RESULTS:
: [1] "Article3_runExp with methods=lfmmRidge|glm|refactor|lfmmLasso lambdas=1e-04|1|1e+10|NA|0.0118857550712915|0.00966331357938067|0.00901972710130546 Ks=2|3|4|NA sparse.prop=NA|0.1 dat.name=betanormalized_metylationlvl.filtered.LMresidu.rds "

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
Article3_runExp_manhattan(exp.LMresidu, 0.05,'refactor')
#+end_src

*** Interesting loci
List discuted in cite:Rahmani_2016 
#+begin_src R :results output :session *R* :exports both
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  exp.LMresidu$df.res %>%
    dplyr::filter(col.name %in% rahmani.outlier,
                  method == "refactor")
  exp$df.res %>%
    dplyr::filter(col.name %in% rahmani.outlier,
                  method == "refactor")

  exp$df.res %>%
    dplyr::filter(col.name %in% rahmani.outlier,
                  method == "glm")
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 9 × 10
   index   col.name       pvalue     score     B       qvalue   method lambda
   <int>      <chr>        <dbl>     <dbl> <dbl>        <dbl>    <chr>  <dbl>
1  36714 cg05428452 9.339330e-16 -8.035243    NA 2.081697e-13 refactor     NA
2  51546 cg07839457 1.286740e-10 -6.428731    NA 3.125326e-09 refactor     NA
3 101455 cg16411857 4.428888e-12 -6.922772    NA 2.005025e-10 refactor     NA
4  36714 cg05428452 4.787580e-13 -7.231196    NA 2.189824e-10 refactor     NA
5  51546 cg07839457 4.877471e-09 -5.851299    NA 2.533710e-07 refactor     NA
6 101455 cg16411857 5.670667e-11 -6.552171    NA 7.623022e-09 refactor     NA
7  36714 cg05428452 3.221914e-12 -6.967688    NA 9.739772e-08 refactor     NA
8  51546 cg07839457 2.888125e-09 -5.937834    NA 5.020182e-06 refactor     NA
9 101455 cg16411857 5.414775e-10 -6.206587    NA 2.104871e-06 refactor     NA
# ... with 2 more variables: K <dbl>, sparse.prop <dbl>
# A tibble: 9 × 10
   index   col.name       pvalue     score     B       qvalue   method lambda
   <int>      <chr>        <dbl>     <dbl> <dbl>        <dbl>    <chr>  <dbl>
1  36714 cg05428452 4.245903e-16 -8.131334    NA 1.108760e-13 refactor     NA
2  51546 cg07839457 6.395240e-11 -6.534195    NA 1.771405e-09 refactor     NA
3 101455 cg16411857 2.174284e-12 -7.022824    NA 1.117797e-10 refactor     NA
4  36714 cg05428452 1.466297e-13 -7.390180    NA 1.000277e-10 refactor     NA
5  51546 cg07839457 8.570508e-09 -5.756836    NA 4.075391e-07 refactor     NA
6 101455 cg16411857 1.028115e-10 -6.462758    NA 1.311893e-08 refactor     NA
7  36714 cg05428452 3.653304e-14 -7.572777    NA 6.668225e-12 refactor     NA
8  51546 cg07839457 4.747825e-09 -5.855778    NA 9.198646e-08 refactor     NA
9 101455 cg16411857 6.215250e-10 -6.184873    NA 1.747915e-08 refactor     NA
# ... with 2 more variables: K <dbl>, sparse.prop <dbl>
# A tibble: 3 × 10
   index   col.name       pvalue      score            B       qvalue method
   <int>      <chr>        <dbl>      <dbl>        <dbl>        <dbl>  <chr>
1  36714 cg05428452 6.772196e-20 -9.1312355 -0.045467876 2.888329e-19    glm
2  51546 cg07839457 5.077905e-01 -0.6622819 -0.002318433 1.710891e-01    glm
3 101455 cg16411857 1.138380e-02 -2.5306913 -0.004700647 6.103030e-03    glm
# ... with 3 more variables: lambda <dbl>, K <dbl>, sparse.prop <dbl>
#+end_example

**** Do we find these loci with lfmmLasso and lfmmRidge on betanormalized_metylationlvl.filtered.rds
#+begin_src R :results output :session *R* :exports both
exp <- retrieveExperiment(101)
#+end_src
***** Compute of the gif

#+begin_src R :results output :session *R* :exports both
  gif.func <- function(score) {
    score2 <- score ^ 2
    median(score2) / qchisq(0.5, df = 1)
  }

  exp$df.res %>%
    group_by(K, lambda, sparse.prop, method) %>%
    summarise(gif = gif.func(score))
#+end_src

#+RESULTS:
#+begin_example
Source: local data frame [16 x 5]
Groups: K, lambda, sparse.prop [?]

       K       lambda sparse.prop    method       gif
   <dbl>        <dbl>       <dbl>     <chr>     <dbl>
1      2 1.000000e-04          NA lfmmRidge 11.584908
2      2 1.523241e-02         0.1 lfmmLasso 10.000808
3      2 1.000000e+00          NA lfmmRidge 11.572514
4      2 1.000000e+10          NA lfmmRidge  8.064392
5      2           NA          NA  refactor  7.096974
6      3 1.000000e-04          NA lfmmRidge  6.222251
7      3 1.204024e-02         0.1 lfmmLasso  5.435089
8      3 1.000000e+00          NA lfmmRidge  6.220483
9      3 1.000000e+10          NA lfmmRidge  5.609513
10     3           NA          NA  refactor  4.795921
11     4 1.000000e-04          NA lfmmRidge  6.088887
12     4 9.921380e-03         0.1 lfmmLasso  5.697559
13     4 1.000000e+00          NA lfmmRidge  6.088300
14     4 1.000000e+10          NA lfmmRidge  5.371812
15     4           NA          NA  refactor  6.914059
16    NA           NA          NA       glm 17.280261
#+end_example
***** Test calibration

#+begin_src R :results output :session *R* :exports both
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  ## lfmm lasso with K = 4

  lasso.df <- exp$df.res %>% dplyr::filter(method == "lfmmLasso", K == 4)
  lasso.df %>% dplyr::filter(col.name %in% rahmani.outlier)

  Article3_runExp_hist(exp, 0.05, "lfmmLasso")

  lcfdr <- locfdr::locfdr(lasso.df$score, df = 9)

  ggplot(lasso.df, aes(x = index, -log10(pvalue), color = col.name %in% rahmani.outlier)) +
    geom_point()
#+end_src

#+RESULTS:
: # A tibble: 3 × 10
:    index   col.name       pvalue     score           B       qvalue    method
:    <int>      <chr>        <dbl>     <dbl>       <dbl>        <dbl>     <chr>
: 1  36714 cg05428452 1.841763e-17 -8.503363 -0.03504021 8.391866e-16 lfmmLasso
: 2  51546 cg07839457 4.022940e-10 -6.253135  0.00000000 4.573476e-09 lfmmLasso
: 3 101455 cg16411857 1.751052e-10 -6.381724  0.00000000 2.154437e-09 lfmmLasso

Ca va jusqu'a $10^{-30}$ ... on ne les a pas detecté.

**** Do we find these loci with lfmmLasso and lfmmRidge on betanormalized_metylationlvl.filtered.LMresidu.rds
#+begin_src R :results output :exports both
exp <- retrieveExperiment(102)
exp$description
#+end_src

#+RESULTS:
: [1] "Article3_runExp with methods=lfmmRidge|glm|refactor|lfmmLasso lambdas=1e-04|1|1e+10|NA|0.0118857550712915|0.00966331357938067|0.00901972710130546 Ks=2|3|4|NA sparse.prop=NA|0.1 dat.name=betanormalized_metylationlvl.filtered.LMresidu.rds "

***** Compute of the gif

#+begin_src R :results output :exports both
  gif.func <- function(score) {
    score2 <- score ^ 2
    median(score2) / qchisq(0.5, df = 1)
  }

  exp$df.res %>%
    group_by(K, lambda, sparse.prop, method) %>%
    summarise(gif = gif.func(score))

#+end_src

#+RESULTS:
#+begin_example
Source: local data frame [16 x 5]
Groups: K, lambda, sparse.prop [?]

       K       lambda sparse.prop    method       gif
   <dbl>        <dbl>       <dbl>     <chr>     <dbl>
1      2 1.000000e-04          NA lfmmRidge  6.231422
2      2 1.188576e-02         0.1 lfmmLasso  5.530324
3      2 1.000000e+00          NA lfmmRidge  6.229777
4      2 1.000000e+10          NA lfmmRidge  5.689075
5      2           NA          NA  refactor  7.618795
6      3 1.000000e-04          NA lfmmRidge  6.383900
7      3 9.663314e-03         0.1 lfmmLasso  5.923144
8      3 1.000000e+00          NA lfmmRidge  6.383613
9      3 1.000000e+10          NA lfmmRidge  5.690365
10     3           NA          NA  refactor  4.968611
11     4 1.000000e-04          NA lfmmRidge  2.432270
12     4 9.019727e-03         0.1 lfmmLasso  2.286301
13     4 1.000000e+00          NA lfmmRidge  2.431269
14     4 1.000000e+10          NA lfmmRidge  2.057842
15     4           NA          NA  refactor  2.409529
16    NA           NA          NA       glm 17.286869
#+end_example

***** Methods comparison

****** Ridge LFMM
#+begin_src R :results output graphics :file Rplots/GSE42861_LMResidu_rahmani_ridge.png :exports both :width 600 :height 400 
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  ## lfmm lasso with K = 4

  ridge.df <- exp$df.res %>% dplyr::filter(method == "lfmmRidge", K == 4, lambda == 1e-4)

  ggplot(ridge.df, aes(x = index, -log10(pvalue), color = col.name %in% rahmani.outlier)) +
    geom_point()

#+end_src

#+RESULTS:
[[file:Rplots/GSE42861_LMResidu_rahmani.png]]

Il sortent presque. Dans [[file:3Article/Slides/BCMSeminar/experiments.nb.html][la pres BCM]] on les retrouvait carément bien. Mais je
pense que avec K = 6 c'est on trouvera comme refactor !!

****** Refactor
#+begin_src R :results output graphics :file Rplots/GSE42861_LMResidu_rahmani_refactor.png :exports both :width 600 :height 400 
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  ## lfmm lasso with K = 4

  df <- exp$df.res %>% dplyr::filter(method == "refactor", K == 4)

  ggplot(df, aes(x = index, -log10(pvalue), color = col.name %in% rahmani.outlier)) +
    geom_point()

#+end_src

#+RESULTS:
[[file:Rplots/GSE42861_LMResidu_rahmani_refactor.png]]

On ne retrouve pas comme dans cite:Rahmani_2016 ca doit être a cause des batch
effect que l'on a pas !!

****** Lasso LFMM
#+begin_src R :results output graphics :file Rplots/GSE42861_LMResidu_rahmani_lasso.png :exports both :width 600 :height 400 
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  ## lfmm lasso with K = 4

  df <- exp$df.res %>% dplyr::filter(method == "lfmmLasso", K == 4)

  ggplot(df, aes(x = index, -log10(pvalue), color = col.name %in% rahmani.outlier)) +
    geom_point()

#+end_src

#+RESULTS:
[[file:Rplots/GSE42861_LMResidu_rahmani_lasso.png]]

Lasso ne trouve vraiment pas comme les autres ... bizare bizare. Il faudrait
voir la vrai valeur de K après convergeance.
** TODO GWAS for LFMM article                                     :3Article:
:LOGBOOK:
- State "TODO"       from              [2017-04-04 mar. 12:07]
:END:
** TODO EAS for LFMM article                                      :3Article:
:LOGBOOK:
- State "TODO"       from              [2017-04-04 mar. 12:09]
:END:
** STARTED Run of methods on OF GWAS simulation                   :3Article:
:LOGBOOK:
- Note taken on [2017-04-11 mar. 10:37] \\
  Il faut que je vois la litérature sur les methodes GWAS, comment il font pour
  simuler ? see [[file:Notes.org::*Mais%20avec%20un%20seul%20outlier][here]]
- Note taken on [2017-04-11 mar. 09:48] \\
  Ok c'est bon c'est bien les facteurs lattents qui expliquent que le test n'est
  pas calibré (mettre J = 0 et K = 40 pour les methods). see [[*Calibration du test quand il n'y a pas d'outlier][here]]
- Note taken on [2017-04-10 lun. 17:40] \\
  Il faut debuguer la simu : une methode oracle qui doit faire le top (ou alors je
  ne mets pas de var environmental) et fdr controlé !!
- Note taken on [2017-04-10 lun. 14:15] \\
  J'ai debuguer phenotypeWayReg_lm et ajouter les modifs de OF dans le sampler. Et
  maintenant ?
- Note taken on [2017-04-07 ven. 18:23] \\
  il faut debug + integrer les modif dans le sampler et après on pourra voir ce
  que ca fait
- Note taken on [2017-04-06 jeu. 11:28] \\
  C'est très long la boucle des glm !!
- Note taken on [2017-04-05 mer. 17:57] \\
  to be continued: finir le [[file:ThesisRpackage/R/Sampler/Sampler_PhenotypeFromTrueData.R][cette fonction]]
- Note taken on [2017-04-05 mer. 15:55] \\
  Premiere etape: faire le sampler
- State "STARTED"    from "TODO"       [2017-04-05 mer. 15:55]
- State "TODO"       from              [2017-04-04 mar. 13:07]
:END:
- [ ] pca
- [ ] run all methods
- [ ] Eigenstrat
- [ ] mesure de la précision ??
- [ ] Gemma

*** RMKs
**** Calibration du test quand il n'y a pas d'outlier
:LOGBOOK:
- State "DONE"       from              [2017-04-11 mar. 10:24]
:END:

#+begin_src R :results output :session *R* :exports both
## library
library(ThesisRpackage)

## sample
G.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.rds"
env.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.env.rds"
## pca.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.pca.rds"
pca.file <- NULL
coord.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.coord.rds"
chrm.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.chrm.rds"
K <- 5
s <- PhenotypeFromTrueSampler(G.file,
                              coord.file,
                              env.file,
                              pca.file,
                              n = NULL,
                              L = 3000,
                              K = K,
                              J = 0,
                              beta = 6,
                              delta = 0.0,
                              chrm.file = chrm.file,
                              chrm.window = 20)

dat <- sampl(s)

## methods
methods <- list()
K <- 50
hypothesis.testing.func <- phenotypeWayReg_lm_score(calibrate = FALSE)

## lm
methods$lm <- ClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                  nickname="lm")
## lm + PCA
methods$lmPCA <- PCAClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                        K = K, 
                                        nickname="lm+PCA")


## lfmm ridge
methods$ridgeLFMM <- RidgeLFMMMethod(K = K,
                                     lambda = 1e0,
                                     hypothesis.testing.method = hypothesis.testing.func,
                                     nickname = "ridgeLFMM")

## lfmm lasso
methods$lassoLFMM <- LassoLFMMMethod(K = K,
                                     lambda = NULL,
                                     sparse.prop = 0.01,
                                     hypothesis.testing.method = hypothesis.testing.func,
                                     nickname = "lassoLFMM")



exp <- do.call(FDRControlExperiment, c(list(nb.rep = 5,
                                            sampler = s), methods))
exp <- runExperiment(exp)


#+end_src

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  plot(exp, plot.type = "pvalue.grid")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-60712Bu.png]]

Le test est bien calibré.

**** Mais avec un seul outlier
#+begin_src R :results output :session *R* :exports both
  ## library
  library(ThesisRpackage)

  ## sample
  G.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.rds"
  env.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.env.rds"
  ## pca.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.pca.rds"
  pca.file <- NULL
  coord.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.coord.rds"
  chrm.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.chrm.rds"
  K <- 5
  s <- PhenotypeFromTrueSampler(G.file,
                                coord.file,
                                env.file,
                                pca.file,
                                n = NULL,
                                L = 3000,
                                K = K,
                                J = 1,
                                beta = 6,
                                delta = 0.0,
                                chrm.file = chrm.file,
                                chrm.window = 20)

  dat <- sampl(s)

  ## methods
  methods <- list()
  K <- 50
  hypothesis.testing.func <- phenotypeWayReg_lm_score(calibrate = FALSE)

  ## lm
  methods$lm <- ClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                    nickname="lm")
  ## lm + PCA
  methods$lmPCA <- PCAClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                          K = K, 
                                          nickname="lm+PCA")


  ## lfmm ridge
  methods$ridgeLFMM <- RidgeLFMMMethod(K = K,
                                       lambda = 1e0,
                                       hypothesis.testing.method = hypothesis.testing.func,
                                       nickname = "ridgeLFMM")

  ## lfmm lasso
  methods$lassoLFMM <- LassoLFMMMethod(K = K,
                                       lambda = NULL,
                                       sparse.prop = 0.01,
                                       hypothesis.testing.method = hypothesis.testing.func,
                                       nickname = "lassoLFMM")



  exp <- do.call(FDRControlExperiment, c(list(nb.rep = 5,
                                              sampler = s), methods))
  exp <- runExperiment(exp)


#+end_src

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  plot(exp, plot.type = "pvalue.grid")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071PqP.png]]

C'est plus calibré, en faite c'est logique a cause la structure ils sont tous
corélé à $G_j$. A voir comment il font dans les GWAS...
*** Install of ThesisRpackage
#+BEGIN_SRC bash
cd /home/cayek/Projects/Thesis
make Rpackage_install
#+END_SRC
*** Run of methods
#+begin_src R :results output :session *R* :exports both

  ## library
  library(ThesisRpackage)

  ## sample
  G.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.rds"
  env.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.env.rds"
  ## pca.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.pca.rds"
  pca.file <- NULL
  coord.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.coord.rds"
  chrm.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.chrm.rds"
  K <- 5
  s <- PhenotypeFromTrueSampler(G.file,
                                coord.file,
                                env.file,
                                pca.file,
                                n = NULL,
                                L = 3000,
                                K = K,
                                J = 0,
                                beta = 6,
                                delta = 0.0,
                                chrm.file = chrm.file,
                                chrm.window = 20)

  dat <- sampl(s)

  ## methods
  methods <- list()
  K <- 50
  hypothesis.testing.func <- phenotypeWayReg_lm_score(calibrate = FALSE)

  ## lm
  methods$lm <- ClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                    nickname="lm")
  ## lm + PCA
  methods$lmPCA <- PCAClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                          K = K, 
                                          nickname="lm+PCA")


  ## lfmm ridge
  methods$ridgeLFMM <- RidgeLFMMMethod(K = K,
                                       lambda = 1e0,
                                       hypothesis.testing.method = hypothesis.testing.func,
                                       nickname = "ridgeLFMM")

  ## lfmm lasso
  methods$lassoLFMM <- LassoLFMMMethod(K = K,
                                       lambda = NULL,
                                       sparse.prop = 0.01,
                                       hypothesis.testing.method = hypothesis.testing.func,
                                       nickname = "lassoLFMM")

  ## sva
  methods$sva <- SVAMethod(K = K,
                           hypothesis.testing.method = hypothesis.testing.func,
                           nickname = "sva")

  ## experiment
  exp <- do.call(FDRControlExperiment, c(list(nb.rep = 5,
                                              sampler = s), methods))
  exp <- runExperiment(exp)

  ## plot
  # plot(exp, plot.type = "pvalue.grid")
#+end_src
*** FDR control
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  plot(exp, plot.type = "pvalue.grid")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-4925ulr.png]]

*** Precision recall
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  plot(exp, plot.type = "precision.recall")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-49257vx.png]]

** STARTED LEA lfmm debug                                         :3Article:
:LOGBOOK:
- Note taken on [2017-04-12 mer. 09:01] \\
  IL faut que je vois avec OF pourquoi ca ne marche pas.
- Note taken on [2017-04-11 mar. 14:42] \\
  L'objectif est de comprendre pourquoi ca donne d'aussi mauvais résultat sur mes
  simu de [[file:Notes.org::*Comparaison%20of%20methods%20for%203Article][Comparaison of methods for 3Article]]
- State "STARTED"    from              [2017-04-11 mar. 14:42]
:END:

#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)

  ## sample data
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  K <- 4
  s <- FromTrueSampler(G.file = G.file,
                       n = NULL,
                       L = 1000,
                       K = K,
                       prop.outlier = 0.05,
                       rho = NULL,
                       cs = 0.4,
                       round = FALSE)
  dat <- sampl(s)

  ## run LEA
  m <- LeaLFMMMethod(K = K,
                     iterations = 20000,
                     CPU = 16)
  m <- run(m, dat)

  ## plot
  gplot_stat(m$pvalue[1,],
             outlier = dat$outlier) +
    geom_histogram(aes(stat, fill = outlier, y = ..density..))

  gplot_stat(m$pvalue[1,],
             outlier = dat$outlier) +
    geom_point(aes(x = index, color = outlier, y = -log10(stat)))

  #+end_src

*** LEA::lfmm
:PROPERTIES:
:header-args: :cache no :session *notebookR* :dir ./ :eval no-export
:END:
On krakenator
**** Install of ThesisRpackage on krakenator
#+BEGIN_SRC bash :dir /cayek@krakenator.imag.fr:~/Projects/Thesis/
cd /home/cayek/Projects/Thesis
make Rpackage_install
#+END_SRC

**** Simulate data with 0.05 % of outlier
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## sample data
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  K <- 4
  s <- FromTrueSampler(G.file = G.file,
                       n = NULL,
                       L = 1000,
                       K = K,
                       prop.outlier = 0.05,
                       rho = NULL,
                       cs = 0.4,
                       round = FALSE)

  dat <- sampl(s)
  names(dat)
  saveRDS(dat, "./Data/NotebookTMP/Simulation_outlier05_cor04.rds")
#+end_src

#+RESULTS:
: [1] "G"       "X"       "U"       "V"       "B"       "epsilon" "outlier"
: [8] "mu"

**** Run LEA::lfmm
#+begin_src R :results output :exports both
  library(LEA)

  ## read data
  dat <- readRDS("./Data/NotebookTMP/Simulation_outlier05_cor04.rds")

  ## write to lfmm format
  write.lfmm(dat$G, "./Simulation_outlier05_cor04.lfmm")
  write.env(dat$X, "./Simulation_outlier05_cor04.env")

  ## run lfmm
  lfmm.res <- lfmm(input.file="./Simulation_outlier05_cor04.lfmm",
                   environment.file="./Simulation_outlier05_cor04.env",
                   K = 4,
                   project="new",
                   CPU = 4)


#+end_src

#+RESULTS:
#+begin_example
[1] "./Simulation_outlier05_cor04.lfmm"
[1] "./Simulation_outlier05_cor04.env"
The project is saved into :
 Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject 

To load the project, use:
 project = load.lfmmProject("Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject")

To remove the project, use:
 remove.lfmmProject("Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject")

[1] "********************************"
[1] "* K = 4  repetition 1  d = 1   *"
[1] "********************************"
Summary of the options:

        -n (number of individuals)      503
        -L (number of loci)             1000
        -K (number of latent factors)   4
        -o (output file)                Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmm/K4/run1/Simulation_outlier05_cor04_r1
        -i (number of iterations)       10000
        -b (burnin)                     5000
        -s (seed random init)           61801602730908
        -p (number of processes (CPU))  4
        -x (genotype file)              Simulation_outlier05_cor04.lfmm
        -v (variable file)              Simulation_outlier05_cor04.env
        -D (number of covariables)      1
        -d (the dth covariable)         1

Read variable file:
 	Simulation_outlier05_cor04.env		OK.

Read genotype file:
 	Simulation_outlier05_cor04.lfmm		OK.

<<<<
	 Analyse for variable 1

		Start of the Gibbs Sampler algorithm.

	[                                                                           ]
	[===========================================================================]

		End of the Gibbs Sampler algorithm.

	ED:503000.1531	 DIC: 503001.0074 

	The statistics for the run are registered in:
 		Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmm/K4/run1/Simulation_outlier05_cor04_r1_s1.4.dic.

	The zscores for variable 1 are registered in:
 		Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmm/K4/run1/Simulation_outlier05_cor04_r1_s1.4.zscore.
	The columns are: zscores, -log10(p-values), p-values.

	-------------------------
	The execution for variable 1 worked without error.
>>>>

The project is saved into :
 Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject 

To load the project, use:
 project = load.lfmmProject("Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject")

To remove the project, use:
 remove.lfmmProject("Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject")
#+end_example

Histogram
#+begin_src R :results output graphics :file Rplots/LEA/lea_histo.png :exports both :width 600 :height 400 
## plot
pvalue <- LEA::p.values(lfmm.res, K = 4)
hist(pvalue)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lea_histo.png]]

Manhattan plot
#+begin_src R :results output graphics :file Rplots/LEA/lea_man.png :exports both :width 600 :height 400 
library(ggplot2)
index <- seq_along(pvalue)
qplot(index, -log10(pvalue), color = index %in% dat$outlier)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lea_man.png]]

**** Run of LassoLFMM
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## read data
  dat <- readRDS("./Data/NotebookTMP/Simulation_outlier05_cor04.rds")

  ## run of lfmmLasso 
  m <- finalLfmmLassoMethod(K = 4,
                            sparse.prop = 0.05)
  m <- run(m, dat)
#+end_src


Histogram
#+begin_src R :results output graphics :file Rplots/LEA/lasso_hist.png :exports both :width 600 :height 400 
  hist(m$pvalue)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lasso_hist.png]]

Manhattan plot
#+begin_src R :results output graphics :file Rplots/LEA/lasso_man.png :exports both :width 600 :height 400 
  library(ggplot2)
  pvalue <- as.numeric(m$pvalue)
  index <- seq_along(pvalue)

  qplot(x = index, y = -log10(pvalue), color = index %in% dat$outlier)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lasso_man.png]]

**** Run of lm 
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## read data
  dat <- readRDS("./Data/NotebookTMP/Simulation_outlier05_cor04.rds")

  ## run of lfmmLasso 
  m <- finalLm()
  m <- run(m, dat)
#+end_src


Histogram:
#+begin_src R :results output graphics :file Rplots/LEA/lm_histo.png :exports both :width 600 :height 400 
hist(m$pvalue)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lm_histo.png]]

C'est mal calibré.

Manhattan plot:
#+begin_src R :results output graphics :file Rplots/LEA/lm_man.png :exports both :width 600 :height 400 
  library(ggplot2)
  pvalue <- as.numeric(m$pvalue)
  index <- seq_along(pvalue)

  qplot(x = index, y = -log10(pvalue), color = index %in% dat$outlier)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lm_man.png]]

**** export notebook                                            :noexport:
:PROPERTIES:
:header-args: :cache no :session *bash* :dir ./ :eval no-export
:END:
#+BEGIN_SRC bash 
  mkdir NOTEBOOK/
  mkdir NOTEBOOK/Data
  mkdir NOTEBOOK/Rplots
  cp Notes.html NOTEBOOK/
  cp -r Data/NotebookTMP/ NOTEBOOK/Data/
  cp -r Rplots/LEA/ NOTEBOOK/Rplots/
  tar -czvf NOTEBOOK.tar.gz NOTEBOOK
  rm -rf NOTEBOOK
  scp NOTEBOOK.tar.gz cayek@krakenator.imag.fr:~/Notebook_LEAdebug.tar.gz
#+END_SRC




** DONE Test of [[https://cran.r-project.org/web/packages/cate/index.html][cate]] CRAN package                                 :3Article:
CLOSED: [2017-04-12 mer. 16:17]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-04-12 mer. 16:17]
- Note taken on [2017-04-12 mer. 16:17] \\
  Je vais l'ajouter au methodes !!
- State "STARTED"    from              [2017-04-12 mer. 15:45]
:END:
La [[file:Biblio/org-ref-pdfs/cate_vignette.pdf][vignette]]
#+begin_src R :results output :session *R* :exports both
  install.packages("cate")
  library(cate)

  data(gender.sm)
  names(gender.sm)

  ## compute t test
  t.stats <- apply(gender.sm$Y, 2, function(y, x) t.test(y~x)$statistic, gender.sm$X)
  hist(t.stats)

  ## estimation of the number of lattent factor
  n <- nrow(gender.sm$Y) # number of samples
  gender.data <- data.frame(gender = gender.sm$X, gender.sm$Z)
  factor.num <- est.confounder.num(~ gender | . - gender + 0,
                                   gender.data, gender.sm$Y,
                                   method = "bcv", bcv.plot = FALSE,
                                   rmax = 30, nRepeat = 20)
  factor.num$r

  cate.results <- cate(~ gender | . - gender + 0,
                       gender.data, gender.sm$Y, r = factor.num$r)
  names(cate.results)

  ## ....

  ## factor analysis
  mle <- factor.analysis(gender.sm$Y, r = 5) 
  names(mle)
#+end_src

** CANCELLED Comparison of methods on generative simu cor(U1/2,X)=c :3Article:
CLOSED: [2017-04-13 jeu. 18:16]
:LOGBOOK:
- Note taken on [2017-04-13 jeu. 18:16] \\
  On va faire l'experience final pour le papier dirrect !!
- State "CANCELLED"  from "STARTED"    [2017-04-13 jeu. 18:16]
- State "STARTED"    from              [2017-04-13 jeu. 09:02]
:END:
**** Run on krak
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 10,
                                   fast.only = FALSE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)
#+end_src

** DONE Correction $G - U V^T$ on generative simulations          :3Article:
CLOSED: [2017-04-14 ven. 14:56]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-04-14 ven. 14:56]
- State "STARTED"    from "TODO"       [2017-04-14 ven. 10:03]
- State "TODO"       from              [2017-04-14 ven. 10:01]
:END:

*** DONE On krakenator
CLOSED: [2017-04-14 ven. 14:49]
:PROPERTIES:
:CUSTOM_ID: simu with NA
:END:
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-14 ven. 14:49]
- State "RUNNING"    from              [2017-04-14 ven. 10:08]
:END:
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   cs = c(0.4, 0.6),
                                   nb.rep = 5,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)
#+end_src

*** plots
:PROPERTIES:
:header-args: :cache no :session *R* :dir ./ :eval no-export :width 800 :height 600
:END:

We retrieve the experiment
#+begin_src R :results output :exports both
  exp <- retrieveExperiment(106)
  exp$description
#+end_src

***** AUC
#+begin_src R :results output graphics :file Rplots/G_UV.auc.png :exports both 
Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:Rplots/G_UV.auc.png]]

***** gif
#+begin_src R :results output graphics :file Rplots/G_UV.gif.png :exports both 
Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:Rplots/G_UV.gif.png]]

** TODO Check NA in results
:LOGBOOK:
- Note taken on [2017-04-14 ven. 14:57] \\
  Tout est dans le titre, je veux m'assurer que les NA qu'on a en sorti parfois ne
  sont pas des outlier !! J'en ai observé sur [[#simu with NA][cette simu]].
- State "TODO"       from              [2017-04-14 ven. 14:57]
:END:

** DONE Redundancy Analysis (RDA)
CLOSED: [2017-05-02 mar. 15:40]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-02 mar. 15:40]
- Note taken on [2017-05-02 mar. 15:32] \\
  Il y a tout une litérature des ordination methods... J'ai l'impression que rda
  est bien une méthode pour faire des association. Mais ca ne prend pas en compte
  une structure lattente. Ou alors il faut la calculer avec une autre méthode et
  l'ajouté en covariable dans rda ([[cite:Forester_2017][see page 6]])
- Note taken on [2017-05-02 mar. 12:00] \\
  Faut que je comprenne le principe de cette methode ! A table.
- Note taken on [2017-05-02 mar. 10:20] \\
  Comment ca réagis sur mes simulations genérative. On l'ajoute dans les méthodes
  du papier ?
- State "TODO"       from              [2017-05-02 mar. 09:22]
:END:

Dans cite:Forester_2015 ils utilisent RDA pour trouver des locus outlier en
passant par un PCA de XB (dans le modèle G = XB + E). Après ils calculent des
pvaleur en ces locus plus précisement (avec un lm).

Je comprends que : 
- il n'y aura pas de correction pour la structure de populations
- c'est juste un moyen de ne pas passer par le controle du FDR
*** Sur une simulations

#+begin_src R :results output :exports both
  ## sampler data with lfmm generative model
  library(ThesisRpackage)
  s <- NormalSampler2(n = 100,
                      L = 1000,
                      K = 3,
                      prop.outlier = 0.02,
                      cs = c(0.6, 0.0, 0.0))
  dat <- sampl(s)

  ## run rda
  library(vegan)

  rda.res <- rda(dat$G ~ dat$X)
  names(rda.res)

#+end_src

#+RESULTS:
:  [1] "call"        "grand.total" "rowsum"      "colsum"      "tot.chi"    
:  [6] "pCCA"        "CCA"         "CA"          "method"      "inertia"    
: [11] "terms"       "terminfo"

#+begin_src R :results output graphics :file Rplots/RDA_1.png :exports both :width 600 :height 400
  plot(rda.res)
#+end_src

#+RESULTS:
[[file:Rplots/RDA_1.png]]

A quoi correspond les rouges et les autres ?

#+begin_src R :results output graphics :file Rplots/RDA_2.png :exports both :width 600 :height 400 
  library(tidyverse)

  toplot <- cbind(as.data.frame(rda.res$CA$v),
                  as.data.frame(rda.res$CCA$v))
  toplot <- toplot %>%
    mutate(index = 1:nrow(toplot),
           outlier = index %in% dat$outlier)

  ggplot(toplot, aes(x = RDA1, y = PC1, color = outlier)) +
    geom_point()
#+end_src

#+RESULTS:
[[file:Rplots/RDA_2.png]]

Je n'arrive pas a reproduire le graphe précédent.

MAIS on voit que RDA1 ne permet capte la variable lattente.

**** Si on utilise lfmm 

#+begin_src R :results output graphics :file Rplots/RDA_3.png :exports both :width 600 :height 400 
  ## run of lfmm ridge
  lfmm.ridge <- finalLfmmRdigeMethod(K = 3,lambda = 1e-1)
  lfmm.ridge <- run(lfmm.ridge, dat)

  gplot_stat(B = lfmm.ridge$B[1,], outlier = dat$outlier) +
    geom_point(aes(x = index, y = stat, color = outlier))
#+end_src

#+RESULTS:
[[file:Rplots/RDA_3.png]]

On arrive bien a avoir ceux qui sont vraiment associé a X et pas avec la
variable lattentes.

**** Si on utilise lm
#+begin_src R :results output graphics :file Rplots/RDA_4.png :exports both :width 600 :height 400 
  ## run of lfmm ridge
  lm.res <- finalLm()
  lm.res <- run(lm.res, dat)

  gplot_stat(B = lm.res$B[1,], outlier = dat$outlier) +
    geom_point(aes(x = index, y = stat, color = outlier))
#+end_src

#+RESULTS:
[[file:Rplots/RDA_4.png]]

C'est comparable a les loadings RDA1
