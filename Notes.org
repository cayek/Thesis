# -*- mode: org -*-
# -*- coding: utf-8 -*-
#+STARTUP: overview indent inlineimages logdrawer
#+TITLE:       Thesis Lab Notebook
#+AUTHOR:      Kevin Caye
#+LANGUAGE:    en
#+TAGS: noexport(n)
#+TAGS: 1Article(1) 2Article(2) 3Article(3) Thesis(T)
#+EXPORT_SELECT_TAGS: Blog
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) RUNNING(r!) DEBUG(D!) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

* Notebooks
:PROPERTIES:
:header-args: :cache no :session *R* :dir ./ :eval no-export
:END:
Les autres notebooks de ma thèse sont un peu partout... :D
** DONE Premier org notebook
CLOSED: [2017-04-04 mar. 11:05]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-04-04 mar. 11:05]
- State "STARTED"    from "TODO"       [2017-04-04 mar. 10:28]
- State "TODO"       from              [2017-04-04 mar. 10:27]
:END:
#+begin_src R :results output graphics :file Rplots/first_plot.png :exports both :width 600 :height 400 
plot(1)
#+end_src

#+RESULTS:
[[file:Rplots/first_plot.png]]

** DONE Comparison of methods on generative simu cor(U1,X)=c      :3Article:
CLOSED: [2017-04-13 jeu. 09:02]
:LOGBOOK:
- Note taken on [2017-04-13 jeu. 09:02] \\
  On a pas lancé sur toutes les méthodes (cate et lea) mais on passe sur des
  simulation plus dure !!
- State "DONE"       from "STARTED"    [2017-04-13 jeu. 09:02]
- Note taken on [2017-04-12 mer. 16:38] \\
  Il faut vraiment que je trouve des simulation plus facile, peut etre en
  augmentant la variance de B. Faut que j'essaie avec d'autre axe corrélé avec X
  peut être qu'on y verra plus clair !!
- Note taken on [2017-04-12 mer. 16:33] \\
  Les resultats avec K over estimated sont pas mal. Au final tout le lfmmLasso est
  bien robuste ! L'oracle fait comme PCAlm ... il faut que je modifie ca ! Je vais
  faire un vrai oracle !!
- Note taken on [2017-04-12 mer. 10:22] \\
  Je pense que ces simulation sont un peut trop dure, mais on voit quand même que
  mes lfmmRidge et lfmmLasso sont pas mal !
- Note taken on [2017-04-11 mar. 17:18] \\
  On a fait les courbe d'auc, ca rend pas mal. Ce qu'on voit c'est que FAMT et
  lassoLFMM font les meilleurs résultats. L'avantave de ma méthode est sur le
  control du FDR.
- Note taken on [2017-04-07 ven. 10:30] \\
  Courbe d'AUC ?
- Note taken on [2017-04-07 ven. 10:27] \\
  Les resultats sont pas clairs => mettre d'autre param (comme avant c(0.6,0.3)?)
- State "STARTED"    from "RUNNING"    [2017-04-05 mer. 16:33]
- State "RUNNING"    from "STARTED"    [2017-04-05 mer. 16:33]
- State "STARTED"    from "WAITING"    [2017-04-04 mar. 16:55]
- State "WAITING"    from "STARTED"    [2017-04-04 mar. 15:58]
- State "STARTED"    from "TODO"       [2017-04-04 mar. 13:01]
- State "TODO"       from              [2017-04-04 mar. 11:06]
:END:
*** With the same 10000 loci for every body 
**** Run on krak
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 10,
                                   fast.only = FALSE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)
#+end_src
**** Plots
:PROPERTIES:
:header-args: :cache no :session *R* :dir ./ :eval no-export :width 1000 :height 800
:END:

We retrieve the experiment
#+begin_src R :results output :exports both
  exp <- retrieveExperiment(96)
  exp$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/European_Chrm22.maf.05.sample.10000.rds K=4 n= L=10000 cs=0.2|0.4|0.6|0.8 outlier.props=0.01|0.05|0.1 nb.rep=10 "

***** C = 0.2
#+begin_src R :results output graphics :file Rplots/1000_loci_c02.png :exports both
  Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.2)
#+end_src

#+RESULTS:
[[file:Rplots/1000_loci_c02.png]]

***** C = 0.6
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.6)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-4989Cvd.png]]
***** precision-recall
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_precisionRecall(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-15107ugK.png]]

On y voit pas grand chose. Faire des courbes d'AUC comme dans 2Article ? Je vais
lancer sur tous le data set pour voir si c'est pas ces 10000 loci qui sont bizare.
***** AUC
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071UEP.png]]
***** Inflation factor
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071VFW.png]]

*** By sampling loci every time
**** DONE Run on krakenator or patator
CLOSED: [2017-04-07 ven. 08:32]
:LOGBOOK:
- Note taken on [2017-04-07 ven. 08:33] \\
  exp id = 100
- State "DONE"       from "RUNNING"    [2017-04-07 ven. 08:32]
- State "RUNNING"    from "WAITING"    [2017-04-06 jeu. 11:53]
- Note taken on [2017-04-05 mer. 09:03] \\
  Bug when running on krakenator
- State "WAITING"    from "RUNNING"    [2017-04-05 mer. 09:01]
- State "RUNNING"    from              [2017-04-04 mar. 16:56]
:END:
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 10,
                                   fast.only = FALSE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)
#+end_src
**** Plots
We retrieve exp results
#+begin_src R :results output :session *R* :exports both
library(ThesisRpackage)
exp <- retrieveExperiment(100)
#+end_src

#+RESULTS:

***** C = 0.2
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.2)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-5560Z9V.png]]

***** C = 0.6
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.6)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-5560Aco.png]]

***** C = 0.8
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.8)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-5560aw0.png]]

***** precision-recall
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_precisionRecall(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-5560ZEK.png]]

***** AUC
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071hOV.png]]

***** Inflation factor
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071vZi.png]]

*** We over estimate K (K+1)
**** DONE Run on krakenator
CLOSED: [2017-04-12 mer. 16:32]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-12 mer. 16:32]
- State "RUNNING"    from              [2017-04-12 mer. 10:56]
:END:
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   K.method = 5,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 5,
                                   fast.only = TRUE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)


#+end_src
**** plots
#+begin_src R :results output :session *R* :exports both
exp <- retrieveExperiment(103)
exp$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds K=4 K.method=5 fast.only=TRUE n= L=10000 cs=0.2|0.4|0.6|0.8 outlier.props=0.01|0.05|0.1 nb.rep=5 "
***** AUC
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-27994ouK.png]]

***** Inflation factor
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-2799414Q.png]]


*** We over estimate K (K+3)
**** DONE On krakenator
CLOSED: [2017-04-12 mer. 16:32]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-12 mer. 16:32]
- State "RUNNING"    from              [2017-04-12 mer. 10:57]
:END:
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   K.method = 7,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 5,
                                   fast.only = TRUE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)


#+end_src
**** plots
#+begin_src R :results output :session *R* :exports both
exp <- retrieveExperiment(104)
exp$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds K=4 K.method=7 fast.only=TRUE n= L=10000 cs=0.2|0.4|0.6|0.8 outlier.props=0.01|0.05|0.1 nb.rep=5 "
***** AUC
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-27994PNd.png]]
***** Inflation factor
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-27994php.png]]




** CANCELLED EWAS for LFMM article                                :3Article:
CLOSED: [2017-05-10 mer. 11:05]
:LOGBOOK:
- State "CANCELLED"  from "STARTED"    [2017-05-10 mer. 11:05]
- Note taken on [2017-05-10 mer. 11:04] \\
  On va reprendre cette analyse depuis le debut, au propre !
- Note taken on [2017-04-13 jeu. 18:00] \\
  Ok c'est on va retrouver les même resultats par contre lasso donne pas les même
  reultats... A voir.
- Note taken on [2017-04-13 jeu. 17:25] \\
  Je vais essayer de reproduire les resultats que j'avais trouvé pour la pres
  [[file:3Article/Slides/BCMSeminar/experiments.nb.html][seminarBCM]].
- Note taken on [2017-04-11 mar. 12:39] \\
  Il y a quelque chose qui ne va pas avec ces données je n'arrive même pas a
  reproduire les resultats des papiers cite:Rahmani_2016 etc... Je voulais
  retrouver les loci connu sans correction mais ca n'a pas l'aire de marcher.
  Affaire a suivre !!
- Note taken on [2017-04-10 lun. 17:43] \\
  Il faut que je recalibre les tests. Pk. Je vais faire de la biblio la dessus et
  identifier les causes du fdr pas controlé !!!! 
  Debug ca aussi [[file:ThesisRpackage/tests/testthat/test_3Article_runExp.R::test_that("Article3_runExp_calibrate",%20{][Article3_runExp_calibrate]]
- State "STARTED"    from "TODO"       [2017-04-04 mar. 16:19]
- State "TODO"       from              [2017-04-04 mar. 12:06]
:END:
*** PCA on betanormalized_metylationlvl.filtered.rds
**** on krakenator
#+begin_src R :results output :session *R* :exports both
library(ThesisRpackage)
s <- TrueSampler(G.file = "../Data/GSE42861/betanormalized_metylationlvl.filtered.rds",
                 X.file = "../Data/GSE42861/X.rds",
                 outlier.file = NULL,
                 n = NULL,
                 L = NULL)
exp <- Article3_pcaExp(s = s,
                       s.name = "GSE42861 filtered",
                       cluster.nb = NULL,
                       save = TRUE, bypass = FALSE)
#+end_src
**** Plots
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  exp <- retrieveExperiment(40)
  plot(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-28683uFt.png]]
*** <<CV_GSE42861_not_corrected>> LFMM ridge crossvalidation on betanormalized_metylationlvl.filtered.rds
**** On krakenator
#+begin_src R :results output :session *R* :exports both
library(ThesisRpackage)
s <- TrueSampler(G.file = "../Data/GSE42861/betanormalized_metylationlvl.filtered.rds",
                 X.file = "../Data/GSE42861/X.rds",
                 outlier.file = NULL,
                 n = NULL,
                 L = NULL)
dat <- sampl(s)
exp <- Article3_cvExp(s = s,
                      s.name = "GSE42861 filtered",
                      Ks = c(1,2,3, 4, 5, 6, 7, 8, 10,15),
                      lambdas = c(1e-10, 1e0, 1e10, 1e20),
                      row.left.out.func = left.out.kfold(5),
                      col.left.out.func = left.out.sample(5, 0.2),
                      cluster.nb = 2,
                      save = TRUE, bypass = FALSE)
#+end_src
**** Plots
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
exp <- retrieveExperiment(41)
plot(exp$cv, color = "K")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-28683tZC.png]]
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
plot(exp$cv, color = "lambda")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-286836jI.png]]

*** LFMM ridge crossvalidation on betanormalized_metylationlvl.filtered.LMresidu.rds
**** DONE On krakenator
CLOSED: [2017-04-05 mer. 08:47]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-05 mer. 08:47]
- State "RUNNING"    from              [2017-04-04 mar. 16:56]
:END:
#+begin_src R :results output :session *R* :exports both
library(ThesisRpackage)
  s <- TrueSampler(G.file = "../Data/GSE42861/betanormalized_metylationlvl.filtered.LMresidu.rds",
                   X.file = "../Data/GSE42861/X.rds",
                   outlier.file = NULL,
                   n = NULL,
                   L = NULL)
  dat <- sampl(s)
  exp <- Article3_cvExp(dat = dat,
                        dat.name = "GSE42861 filtered and LM residual",
                        Ks = c(1,2,3, 4, 5, 6, 7, 8, 10,15),
                        lambdas = c(1e-10, 1e0, 1e10, 1e20),
                        row.left.out.func = left.out.kfold(5),
                        col.left.out.func = left.out.sample(5, 0.2),
                        cluster.nb = 2,
                        save = TRUE, bypass = FALSE)
#+end_src

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
exp <- retrieveExperiment(97)
plot(exp$cv, color = 'K')
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-15107iJj.png]]

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
plot(exp$cv, color = "lambda")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-151077xE.png]]

La cross validation donne plutot K = 2 et pas d'importance pour le choix de
lambda. Ce qui est interessant c'est que la [[CV_GSE42861_not_corrected][CV]] sur les données avec variables
lattente donne plutot K = 4 et lambda petit.
*** Run on betanormalized_metylationlvl.filtered.rds
**** DONE on krakenator
CLOSED: [2017-04-10 lun. 14:39]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-10 lun. 14:39]
- State "RUNNING"    from "DONE"       [2017-04-07 ven. 13:56]
- Note taken on [2017-04-07 ven. 13:17] \\
  exp id = 99
- State "DONE"       from "RUNNING"    [2017-04-07 ven. 13:17]
- State "RUNNING"    from "WAITING"    [2017-04-06 jeu. 09:15]
- State "WAITING"    from "RUNNING"    [2017-04-06 jeu. 08:35]
- State "RUNNING"    from "WAITING"    [2017-04-05 mer. 16:34]
- Note taken on [2017-04-05 mer. 16:22] \\
  krakenator va etre mis a jour, on relance après !
- State "WAITING"    from "RUNNING"    [2017-04-05 mer. 16:22]
- State "RUNNING"    from "TODO"       [2017-04-05 mer. 12:33]
- State "TODO"       from              [2017-04-05 mer. 08:58]
:END:
#+begin_src R :results output :session *R* :exports both
  library(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/GSE42861/betanormalized_metylationlvl.filtered.rds"
  X.file <- "~/Projects/Thesis/Data/GSE42861/X.rds"


  s <- TrueSampler(G.file = G.file,
                   X.file = X.file,
                   outlier.file = NULL)
  dat <- sampl(s)
  dat$X <- dat$X[,1,drop=FALSE] ## keep only first covariate
  exp <- Article3_GSE42861(dat = dat,
                           dat.name = "betanormalized_metylationlvl.filtered.rds",
                           cluster.nb = 4,
                           Ks = c(2,3,4),
                           lambdas = c(1e-4, 1e0, 1e10),
                           sparse.prop = c(0.1),
                           save = TRUE,
                           bypass = FALSE)

#+end_src
**** plots
#+begin_src R :results output :session *R* :exports both
  exp <- retrieveExperiment(101)
  exp$description
#+end_src

#+RESULTS:
: [1] "Article3_runExp with methods=lfmmRidge|glm|refactor|lfmmLasso lambdas=1e-04|1|1e+10|NA|0.0152324128831718|0.0120402443893896|0.00992138012483149 Ks=2|3|4|NA sparse.prop=NA|0.1 dat.name=betanormalized_metylationlvl.filtered.rds "

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
Article3_runExp_manhattan(exp, 0.05,'refactor')
#+end_src


*** Run on betanormalized_metylationlvl.filtered.LMresidu.rds
**** DONE on krakenator
CLOSED: [2017-04-10 lun. 14:39]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-10 lun. 14:39]
- State "RUNNING"    from "WAITING"    [2017-04-06 jeu. 09:16]
- State "WAITING"    from "RUNNING"    [2017-04-06 jeu. 08:35]
- State "RUNNING"    from "WAITING"    [2017-04-05 mer. 16:34]
- Note taken on [2017-04-05 mer. 16:23] \\
  krakenator va etre mis a jour...
- State "WAITING"    from "RUNNING"    [2017-04-05 mer. 16:23]
- State "RUNNING"    from "TODO"       [2017-04-05 mer. 12:33]
- State "TODO"       from              [2017-04-05 mer. 08:59]
:END:
#+begin_src R :results output :session *R* :exports both
  library(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/GSE42861/betanormalized_metylationlvl.filtered.LMresidu.rds"
  X.file <- "~/Projects/Thesis/Data/GSE42861/X.rds"


  s <- TrueSampler(G.file = G.file,
                   X.file = X.file,
                   outlier.file = NULL)
  dat <- sampl(s)
  dat$X <- dat$X[,1,drop=FALSE] ## keep only first covariate
  exp <- Article3_GSE42861(dat = dat,
                           dat.name = "betanormalized_metylationlvl.filtered.LMresidu.rds",
                           cluster.nb = 4,
                           Ks = c(2,3,4),
                           lambdas = c(1e-4, 1e0, 1e10),
                           sparse.prop = c(0.1),
                           save = TRUE,
                           bypass = FALSE)

#+end_src
**** plots
#+begin_src R :results output :session *R* :exports both
exp.LMresidu <- retrieveExperiment(102)
exp.LMresidu$description
#+end_src

#+RESULTS:
: [1] "Article3_runExp with methods=lfmmRidge|glm|refactor|lfmmLasso lambdas=1e-04|1|1e+10|NA|0.0118857550712915|0.00966331357938067|0.00901972710130546 Ks=2|3|4|NA sparse.prop=NA|0.1 dat.name=betanormalized_metylationlvl.filtered.LMresidu.rds "

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
Article3_runExp_manhattan(exp.LMresidu, 0.05,'refactor')
#+end_src

*** Interesting loci
List discuted in cite:Rahmani_2016 
#+begin_src R :results output :session *R* :exports both
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  exp.LMresidu$df.res %>%
    dplyr::filter(col.name %in% rahmani.outlier,
                  method == "refactor")
  exp$df.res %>%
    dplyr::filter(col.name %in% rahmani.outlier,
                  method == "refactor")

  exp$df.res %>%
    dplyr::filter(col.name %in% rahmani.outlier,
                  method == "glm")
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 9 × 10
   index   col.name       pvalue     score     B       qvalue   method lambda
   <int>      <chr>        <dbl>     <dbl> <dbl>        <dbl>    <chr>  <dbl>
1  36714 cg05428452 9.339330e-16 -8.035243    NA 2.081697e-13 refactor     NA
2  51546 cg07839457 1.286740e-10 -6.428731    NA 3.125326e-09 refactor     NA
3 101455 cg16411857 4.428888e-12 -6.922772    NA 2.005025e-10 refactor     NA
4  36714 cg05428452 4.787580e-13 -7.231196    NA 2.189824e-10 refactor     NA
5  51546 cg07839457 4.877471e-09 -5.851299    NA 2.533710e-07 refactor     NA
6 101455 cg16411857 5.670667e-11 -6.552171    NA 7.623022e-09 refactor     NA
7  36714 cg05428452 3.221914e-12 -6.967688    NA 9.739772e-08 refactor     NA
8  51546 cg07839457 2.888125e-09 -5.937834    NA 5.020182e-06 refactor     NA
9 101455 cg16411857 5.414775e-10 -6.206587    NA 2.104871e-06 refactor     NA
# ... with 2 more variables: K <dbl>, sparse.prop <dbl>
# A tibble: 9 × 10
   index   col.name       pvalue     score     B       qvalue   method lambda
   <int>      <chr>        <dbl>     <dbl> <dbl>        <dbl>    <chr>  <dbl>
1  36714 cg05428452 4.245903e-16 -8.131334    NA 1.108760e-13 refactor     NA
2  51546 cg07839457 6.395240e-11 -6.534195    NA 1.771405e-09 refactor     NA
3 101455 cg16411857 2.174284e-12 -7.022824    NA 1.117797e-10 refactor     NA
4  36714 cg05428452 1.466297e-13 -7.390180    NA 1.000277e-10 refactor     NA
5  51546 cg07839457 8.570508e-09 -5.756836    NA 4.075391e-07 refactor     NA
6 101455 cg16411857 1.028115e-10 -6.462758    NA 1.311893e-08 refactor     NA
7  36714 cg05428452 3.653304e-14 -7.572777    NA 6.668225e-12 refactor     NA
8  51546 cg07839457 4.747825e-09 -5.855778    NA 9.198646e-08 refactor     NA
9 101455 cg16411857 6.215250e-10 -6.184873    NA 1.747915e-08 refactor     NA
# ... with 2 more variables: K <dbl>, sparse.prop <dbl>
# A tibble: 3 × 10
   index   col.name       pvalue      score            B       qvalue method
   <int>      <chr>        <dbl>      <dbl>        <dbl>        <dbl>  <chr>
1  36714 cg05428452 6.772196e-20 -9.1312355 -0.045467876 2.888329e-19    glm
2  51546 cg07839457 5.077905e-01 -0.6622819 -0.002318433 1.710891e-01    glm
3 101455 cg16411857 1.138380e-02 -2.5306913 -0.004700647 6.103030e-03    glm
# ... with 3 more variables: lambda <dbl>, K <dbl>, sparse.prop <dbl>
#+end_example

**** Do we find these loci with lfmmLasso and lfmmRidge on betanormalized_metylationlvl.filtered.rds
#+begin_src R :results output :session *R* :exports both
exp <- retrieveExperiment(101)
#+end_src
***** Compute of the gif

#+begin_src R :results output :session *R* :exports both
  gif.func <- function(score) {
    score2 <- score ^ 2
    median(score2) / qchisq(0.5, df = 1)
  }

  exp$df.res %>%
    group_by(K, lambda, sparse.prop, method) %>%
    summarise(gif = gif.func(score))
#+end_src

#+RESULTS:
#+begin_example
Source: local data frame [16 x 5]
Groups: K, lambda, sparse.prop [?]

       K       lambda sparse.prop    method       gif
   <dbl>        <dbl>       <dbl>     <chr>     <dbl>
1      2 1.000000e-04          NA lfmmRidge 11.584908
2      2 1.523241e-02         0.1 lfmmLasso 10.000808
3      2 1.000000e+00          NA lfmmRidge 11.572514
4      2 1.000000e+10          NA lfmmRidge  8.064392
5      2           NA          NA  refactor  7.096974
6      3 1.000000e-04          NA lfmmRidge  6.222251
7      3 1.204024e-02         0.1 lfmmLasso  5.435089
8      3 1.000000e+00          NA lfmmRidge  6.220483
9      3 1.000000e+10          NA lfmmRidge  5.609513
10     3           NA          NA  refactor  4.795921
11     4 1.000000e-04          NA lfmmRidge  6.088887
12     4 9.921380e-03         0.1 lfmmLasso  5.697559
13     4 1.000000e+00          NA lfmmRidge  6.088300
14     4 1.000000e+10          NA lfmmRidge  5.371812
15     4           NA          NA  refactor  6.914059
16    NA           NA          NA       glm 17.280261
#+end_example
***** Test calibration

#+begin_src R :results output :session *R* :exports both
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  ## lfmm lasso with K = 4

  lasso.df <- exp$df.res %>% dplyr::filter(method == "lfmmLasso", K == 4)
  lasso.df %>% dplyr::filter(col.name %in% rahmani.outlier)

  Article3_runExp_hist(exp, 0.05, "lfmmLasso")

  lcfdr <- locfdr::locfdr(lasso.df$score, df = 9)

  ggplot(lasso.df, aes(x = index, -log10(pvalue), color = col.name %in% rahmani.outlier)) +
    geom_point()
#+end_src

#+RESULTS:
: # A tibble: 3 × 10
:    index   col.name       pvalue     score           B       qvalue    method
:    <int>      <chr>        <dbl>     <dbl>       <dbl>        <dbl>     <chr>
: 1  36714 cg05428452 1.841763e-17 -8.503363 -0.03504021 8.391866e-16 lfmmLasso
: 2  51546 cg07839457 4.022940e-10 -6.253135  0.00000000 4.573476e-09 lfmmLasso
: 3 101455 cg16411857 1.751052e-10 -6.381724  0.00000000 2.154437e-09 lfmmLasso

Ca va jusqu'a $10^{-30}$ ... on ne les a pas detecté.

**** Do we find these loci with lfmmLasso and lfmmRidge on betanormalized_metylationlvl.filtered.LMresidu.rds
#+begin_src R :results output :exports both
exp <- retrieveExperiment(102)
exp$description
#+end_src

#+RESULTS:
: [1] "Article3_runExp with methods=lfmmRidge|glm|refactor|lfmmLasso lambdas=1e-04|1|1e+10|NA|0.0118857550712915|0.00966331357938067|0.00901972710130546 Ks=2|3|4|NA sparse.prop=NA|0.1 dat.name=betanormalized_metylationlvl.filtered.LMresidu.rds "

***** Compute of the gif

#+begin_src R :results output :exports both
  gif.func <- function(score) {
    score2 <- score ^ 2
    median(score2) / qchisq(0.5, df = 1)
  }

  exp$df.res %>%
    group_by(K, lambda, sparse.prop, method) %>%
    summarise(gif = gif.func(score))

#+end_src

#+RESULTS:
#+begin_example
Source: local data frame [16 x 5]
Groups: K, lambda, sparse.prop [?]

       K       lambda sparse.prop    method       gif
   <dbl>        <dbl>       <dbl>     <chr>     <dbl>
1      2 1.000000e-04          NA lfmmRidge  6.231422
2      2 1.188576e-02         0.1 lfmmLasso  5.530324
3      2 1.000000e+00          NA lfmmRidge  6.229777
4      2 1.000000e+10          NA lfmmRidge  5.689075
5      2           NA          NA  refactor  7.618795
6      3 1.000000e-04          NA lfmmRidge  6.383900
7      3 9.663314e-03         0.1 lfmmLasso  5.923144
8      3 1.000000e+00          NA lfmmRidge  6.383613
9      3 1.000000e+10          NA lfmmRidge  5.690365
10     3           NA          NA  refactor  4.968611
11     4 1.000000e-04          NA lfmmRidge  2.432270
12     4 9.019727e-03         0.1 lfmmLasso  2.286301
13     4 1.000000e+00          NA lfmmRidge  2.431269
14     4 1.000000e+10          NA lfmmRidge  2.057842
15     4           NA          NA  refactor  2.409529
16    NA           NA          NA       glm 17.286869
#+end_example

***** Methods comparison

****** Ridge LFMM
#+begin_src R :results output graphics :file Rplots/GSE42861_LMResidu_rahmani_ridge.png :exports both :width 600 :height 400 
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  ## lfmm lasso with K = 4

  ridge.df <- exp$df.res %>% dplyr::filter(method == "lfmmRidge", K == 4, lambda == 1e-4)

  ggplot(ridge.df, aes(x = index, -log10(pvalue), color = col.name %in% rahmani.outlier)) +
    geom_point()

#+end_src

#+RESULTS:
[[file:Rplots/GSE42861_LMResidu_rahmani.png]]

Il sortent presque. Dans [[file:3Article/Slides/BCMSeminar/experiments.nb.html][la pres BCM]] on les retrouvait carément bien. Mais je
pense que avec K = 6 c'est on trouvera comme refactor !!

****** Refactor
#+begin_src R :results output graphics :file Rplots/GSE42861_LMResidu_rahmani_refactor.png :exports both :width 600 :height 400 
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  ## lfmm lasso with K = 4

  df <- exp$df.res %>% dplyr::filter(method == "refactor", K == 4)

  ggplot(df, aes(x = index, -log10(pvalue), color = col.name %in% rahmani.outlier)) +
    geom_point()

#+end_src

#+RESULTS:
[[file:Rplots/GSE42861_LMResidu_rahmani_refactor.png]]

On ne retrouve pas comme dans cite:Rahmani_2016 ca doit être a cause des batch
effect que l'on a pas !!

****** Lasso LFMM
#+begin_src R :results output graphics :file Rplots/GSE42861_LMResidu_rahmani_lasso.png :exports both :width 600 :height 400 
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  ## lfmm lasso with K = 4

  df <- exp$df.res %>% dplyr::filter(method == "lfmmLasso", K == 4)

  ggplot(df, aes(x = index, -log10(pvalue), color = col.name %in% rahmani.outlier)) +
    geom_point()

#+end_src

#+RESULTS:
[[file:Rplots/GSE42861_LMResidu_rahmani_lasso.png]]

Lasso ne trouve vraiment pas comme les autres ... bizare bizare. Il faudrait
voir la vrai valeur de K après convergeance.
** STARTED EAS for LFMM article                                   :3Article:
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-05-23 mar. 15:59]
- Note taken on [2017-05-19 ven. 16:04] \\
  1000  genome + climat
- State "TODO"       from              [2017-04-04 mar. 12:09]
:END:
*** DONE Preprocessing genotype data
CLOSED: [2017-05-29 lun. 13:29]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-29 lun. 13:29]
- Note taken on [2017-05-23 mar. 16:52] \\
  ask to OF
- State "STARTED"    from "TODO"       [2017-05-23 mar. 16:52]
- State "TODO"       from              [2017-05-23 mar. 16:34]
- Note taken on [2017-05-23 mar. 16:31] \\
  On garde qui ???? Il y 3 pops ancestrals pour les humains: asie européen et
  affricain. Mais ca c'est a une echelle de temps !! Tout le monde est metisse en
  faite. Il faut que je sache a quelle echelle de temps je cherche a detecter de
  l'adaptation causé par la présssion environmental que j'ai choisie.
:END:

We remove admxed individual (see [[http://www.internationalgenome.org/category/population/][1000genome pops]]). IL nous faut ceux qui vivent
dans leur milieu depuis longtemps. Je vais garder les européens, africain et
asiatique.

#+begin_src R :results output :exports both
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds")
  indiv.df <- readRDS("~/Projects/Thesis/Data/1000Genomes/Phase3/indiv_df.rds")

  ## keep only indiv in G
  indiv.df <- indiv.df %>%
    dplyr::filter(sample %in% rownames(G))


  ## indiv metadata
  indiv.df <- indiv.df %>%
    dplyr::filter(super_pop %in% c("EUR", "SAS", "AFR", "EAS"))
  indiv.df <- indiv.df %>%
    dplyr::filter(!(pop %in% c("ASW")))
  indiv.df


  G <- G[indiv.df$sample,]
  dim(G)

  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds")
  saveRDS(indiv.df, "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
#+end_src

#+RESULTS:
#+begin_example
  > dim(G)
  [1]    670 342478
#+end_example
*** DONE Compute of X
CLOSED: [2017-05-29 lun. 16:03]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-29 lun. 16:03]
- State "STARTED"    from "TODO"       [2017-05-23 mar. 16:52]
- State "TODO"       from              [2017-05-23 mar. 16:52]
:END:

On prend les données climatique de worldclim et on fait l'acp ;-)
#+begin_src R :results output :exports both
  ## get pop information
  library(rvest)

  pop.tbl <- read_html("http://www.internationalgenome.org/faq/which-populations-are-part-your-study/")%>%
    html_nodes("table") %>%
    html_table() %>%
    .[[1]]

  head(pop.tbl)
  names(pop.tbl)[1] <- "pop"


  ## pop location
  library(ggmap)

  indiv.df <- readRDS( "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
  indiv.df <-indiv.df %>% inner_join(pop.tbl)

  indiv.df

  ## match pop localisation
  indiv.df <- indiv.df %>%
    mutate(citie = NA)
  indiv.df[indiv.df$pop == "IBS",]$citie = "Spain"
  indiv.df[indiv.df$pop == "PJL",]$citie = "Pakistan"
  indiv.df[indiv.df$pop == "CDX",]$citie = "China"
  indiv.df[indiv.df$pop == "ACB",]$citie = "Barbados"
  indiv.df[indiv.df$pop == "GWD",]$citie = "Gambia"
  indiv.df[indiv.df$pop == "BEB",]$citie = "Bangladesh"
  indiv.df[indiv.df$pop == "MSL",]$citie = "Sierra Leone"
  indiv.df[indiv.df$pop == "STU",]$citie = "Sri Lanka"
  indiv.df[indiv.df$pop == "ITU",]$citie = "Telangana"
  indiv.df[indiv.df$pop == "CEU",]$citie = "United Kingdom"
  indiv.df[indiv.df$pop == "LWK",]$citie = "Kenya"
  indiv.df[indiv.df$pop == "JPT",]$citie = "Japan"
  indiv.df[indiv.df$pop == "YRI",]$citie = "Nigeria"
  indiv.df[indiv.df$pop == "TSI",]$citie = "Italia"
  indiv.df[indiv.df$pop == "GIH",]$citie = "Gujarat"


  ## get location
  cities <- indiv.df %>% group_by(pop) %>%
    dplyr::filter(row_number(citie) == 1) %>%
    ungroup() %>%
    dplyr::select(citie, pop, `Population Description`)
  cities <- cbind(cities, geocode(cities$citie))

  ## plot with leaflet
  library(leaflet)
  m <- leaflet() %>%
    addTiles() %>%  # Add default OpenStreetMap map tiles
    addMarkers(lng = cities$lon, lat = cities$lat, popup = cities$`Population Description`)
  m  # Print the map


  ## compute X
  library(raster)
  climate <- getData('worldclim', var='bio', res = 2.5)
  bio <- extract(climate, y = as.matrix(cities[c("lon","lat")]))
  pc.bio <- prcomp(bio,scale = T)
  X <- pc.bio$x[,1]

  cities <- cbind(cities, X)


  ## add to indiv
  indiv.df <- indiv.df %>%
    inner_join(cities)


  ## save 
  saveRDS(indiv.df, "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
  saveRDS(as.matrix(indiv.df$X), "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/X_EAS.rds")

  ## plot X
  indiv.df <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
  pl <- ggplot(indiv.df, aes(x = lon, y = lat, color = X, size = X, text = `Population Description`)) +
    geom_point()
  pl


  ## try plotly :D
  library(plotly)
  ggplotly(pl)

#+end_src
*** STARTED Run methods
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-05-29 lun. 16:38]
- State "TODO"       from              [2017-05-29 lun. 16:03]
:END:
**** DEBUG Run on krakenator
:LOGBOOK:
- State "DEBUG"      from "DONE"       [2017-06-02 ven. 08:45]
- State "DONE"       from "RUNNING"    [2017-06-02 ven. 08:45]
- Note taken on [2017-06-01 jeu. 18:24] \\
  16554.pts-3.krakenator
- State "RUNNING"    from "WAITING"    [2017-06-01 jeu. 18:24]
- Note taken on [2017-05-30 mar. 11:17] \\
  waiting from cate...
- State "WAITING"    from "RUNNING"    [2017-05-30 mar. 11:17]
- State "RUNNING"    from "DEBUG"      [2017-05-30 mar. 10:31]
- State "DEBUG"      from "RUNNING"    [2017-05-29 lun. 18:45]
- State "RUNNING"    from              [2017-05-29 lun. 16:36]
:END:
On va prendre K = 10, voir ici [[1000Genome_pca][file:~/Projects/Thesis/Notes.org::1000Genome_pca]]
pour les valeur singuliere

#+begin_src R :results output :exports both
  library(ThesisRpackage)
  method.batch <- list()
  K <- 10
  ## famt
  method.batch$m.famt <- finalFamtMethod(K)
  method.batch$m.famt$center <- FALSE
  ## sva
  method.batch$m.sva <- finalSVAMethod(K)
  method.batch$m.sva$center <- FALSE
  ## lm
  method.batch$m.lm <- finalLm()
  method.batch$m.lm$center <- FALSE
  ## pca
  method.batch$m.pca <- finalPcaLm(K)
  method.batch$m.pca$center <- FALSE
  ## lfmm lasso
  method.batch$m.lfmmLasso <- finalLfmmLassoMethod(K, 0.05)
  method.batch$m.lfmmLasso$center <- FALSE
  ## lfmm ridge
  method.batch$m.lfmmRidge <- finalLfmmRdigeMethod(K, 1e-10)
  method.batch$m.lfmmRidge$center <- FALSE
  ## cate
  method.batch$m.cate <- finalcateMethod(K)
  method.batch$m.cate$center <- FALSE


  ## sampler
  s <- TrueSampler(G.file = "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds",
                   X.file = "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/X_EAS.rds",
                   outlier.file = NULL)

  expr <- MethodBatchExperiment("1000 Genome EAS",
                                s = s,
                                method.batch = method.batch,
                                cluster.nb = 7)

  expr <- runExperiment(expr, TRUE)

#+end_src

#+RESULTS:
#+begin_example
  DEBUG [2017-06-01 18:50:03] missingValueImputationLoop: it =  1 | err =  0.913409825550464
  DEBUG [2017-06-01 18:54:38] D_thau: K =  10

  DEBUG [2017-06-01 19:06:18] missingValueImputationLoop: it =  2 | err =  0.91338938207813
  DEBUG [2017-06-01 19:11:06] D_thau: K =  10

  DEBUG [2017-06-01 19:23:02] missingValueImputationLoop: it =  3 | err =  0.913381012080782
  DEBUG [2017-06-01 19:26:21] FAMT::modelFAMT said:
  --------------------------------
  [1] "Fitting Factor Analysis Model with 10 factors"
  [1] "Fitting Factor Analysis Model with 10 factors"
  --------------------------------
  DEBUG [2017-06-01 19:27:42] D_thau: K =  10

  DEBUG [2017-06-01 19:40:35] missingValueImputationLoop: it =  4 | err =  0.91337742530545
  DEBUG [2017-06-01 19:46:06] D_thau: K =  10

  DEBUG [2017-06-01 19:59:39] missingValueImputationLoop: it =  5 | err =  0.91337584643065
  DEBUG [2017-06-01 20:03:53] D_thau: K =  10

  DEBUG [2017-06-01 20:13:46] sva::sva said:
  --------------------------------
  Number of significant surrogate variables is:  10
  Iteration (out of 5 ):1  2  3  4  5
  --------------------------------
  DEBUG [2017-06-01 20:14:23] fit.LassoLFMMMethod: B not null prop=0.0404726726972243
  DEBUG [2017-06-01 20:14:23] fit.LassoLFMMMethod: i=2 / 100|lambda = 0.0446606864782912
  DEBUG [2017-06-01 20:14:27] missingValueImputationLoop: it =  0 | err =  0.913375142885555
  DEBUG [2017-06-01 20:18:38] D_thau: K =  10

  DEBUG [2017-06-01 20:20:39] sva::fstats said:
  --------------------------------
  --------------------------------
  DEBUG [2017-06-01 20:28:11] sva::f.pvalue said:
  --------------------------------
  --------------------------------
  DEBUG [2017-06-01 20:29:38] missingValueImputationLoop: it =  1 | err =  0.913365242323615
  DEBUG [2017-06-01 20:33:49] D_thau: K =  10

  DEBUG [2017-06-01 20:44:25] missingValueImputationLoop: it =  2 | err =  0.913360725989644
  DEBUG [2017-06-01 20:48:39] D_thau: K =  10

  DEBUG [2017-06-01 20:59:41] missingValueImputationLoop: it =  3 | err =  0.913358649587905
  DEBUG [2017-06-01 21:04:02] D_thau: K =  10

  DEBUG [2017-06-01 21:14:12] missingValueImputationLoop: it =  4 | err =  0.913357687143264
  DEBUG [2017-06-01 21:18:18] D_thau: K =  10

  DEBUG [2017-06-01 21:28:38] fit.LassoLFMMMethod: B not null prop=0.059781942197747
  DEBUG [2017-06-01 21:28:41] run.Method: running  lm+zscore|calibrate=FALSE
  Error in { :
    task 4 failed - "'data' doit être de type vecteur, il était 'NULL'"

#+end_example

**** TODO Plot
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
:LOGBOOK:
- State "TODO"       from              [2017-05-29 lun. 16:43]
:END:

#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(?)
  expr$description
  expr$outlier
  expr <- MethodBatchExperiment_calibrate(expr)
#+end_src


#+begin_src R :results output :exports both
  print.data.frame(MethodBatchExperiment_count_intersect(expr, top = 10, plot = NULL))
#+end_src


#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_count_intersect(expr, top = 100, plot = "tile")
  save_plot_timc_bcm_15(pl, "1000Genome_EAS_count_intersect_top100.png")
#+end_src


#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_count_intersect(expr, fdr.threshold = 0.01, plot = "point")
  save_plot_timc_bcm_15(pl, "1000Genome_EAS_count_intersect_fdr01.png")
#+end_src
**** TODO SNPs annotation
:LOGBOOK:
- State "TODO"       from              [2017-05-29 lun. 16:44]
:END:

** STARTED Run of methods on OF GWAS simulation                   :3Article:
:LOGBOOK:
- Note taken on [2017-05-03 mer. 09:03] \\
  Je m'occupe des résultats de l'article 3, on reviendra la dessus après !
- Note taken on [2017-04-11 mar. 10:37] \\
  Il faut que je vois la litérature sur les methodes GWAS, comment il font pour
  simuler ? see [[file:Notes.org::*Mais%20avec%20un%20seul%20outlier][here]]
- Note taken on [2017-04-11 mar. 09:48] \\
  Ok c'est bon c'est bien les facteurs lattents qui expliquent que le test n'est
  pas calibré (mettre J = 0 et K = 40 pour les methods). see [[*Calibration du test quand il n'y a pas d'outlier][here]]
- Note taken on [2017-04-10 lun. 17:40] \\
  Il faut debuguer la simu : une methode oracle qui doit faire le top (ou alors je
  ne mets pas de var environmental) et fdr controlé !!
- Note taken on [2017-04-10 lun. 14:15] \\
  J'ai debuguer phenotypeWayReg_lm et ajouter les modifs de OF dans le sampler. Et
  maintenant ?
- Note taken on [2017-04-07 ven. 18:23] \\
  il faut debug + integrer les modif dans le sampler et après on pourra voir ce
  que ca fait
- Note taken on [2017-04-06 jeu. 11:28] \\
  C'est très long la boucle des glm !!
- Note taken on [2017-04-05 mer. 17:57] \\
  to be continued: finir le [[file:ThesisRpackage/R/Sampler/Sampler_PhenotypeFromTrueData.R][cette fonction]]
- Note taken on [2017-04-05 mer. 15:55] \\
  Premiere etape: faire le sampler
- State "STARTED"    from "TODO"       [2017-04-05 mer. 15:55]
- State "TODO"       from              [2017-04-04 mar. 13:07]
:END:
- [ ] pca
- [ ] run all methods
- [ ] Eigenstrat
- [ ] mesure de la précision ??
- [ ] Gemma

*** RMKs
**** Calibration du test quand il n'y a pas d'outlier
:LOGBOOK:
- State "DONE"       from              [2017-04-11 mar. 10:24]
:END:

#+begin_src R :results output :session *R* :exports both
## library
library(ThesisRpackage)

## sample
G.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.rds"
env.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.env.rds"
## pca.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.pca.rds"
pca.file <- NULL
coord.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.coord.rds"
chrm.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.chrm.rds"
K <- 5
s <- PhenotypeFromTrueSampler(G.file,
                              coord.file,
                              env.file,
                              pca.file,
                              n = NULL,
                              L = 3000,
                              K = K,
                              J = 0,
                              beta = 6,
                              delta = 0.0,
                              chrm.file = chrm.file,
                              chrm.window = 20)

dat <- sampl(s)

## methods
methods <- list()
K <- 50
hypothesis.testing.func <- phenotypeWayReg_lm_score(calibrate = FALSE)

## lm
methods$lm <- ClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                  nickname="lm")
## lm + PCA
methods$lmPCA <- PCAClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                        K = K, 
                                        nickname="lm+PCA")


## lfmm ridge
methods$ridgeLFMM <- RidgeLFMMMethod(K = K,
                                     lambda = 1e0,
                                     hypothesis.testing.method = hypothesis.testing.func,
                                     nickname = "ridgeLFMM")

## lfmm lasso
methods$lassoLFMM <- LassoLFMMMethod(K = K,
                                     lambda = NULL,
                                     sparse.prop = 0.01,
                                     hypothesis.testing.method = hypothesis.testing.func,
                                     nickname = "lassoLFMM")



exp <- do.call(FDRControlExperiment, c(list(nb.rep = 5,
                                            sampler = s), methods))
exp <- runExperiment(exp)


#+end_src

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  plot(exp, plot.type = "pvalue.grid")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-60712Bu.png]]

Le test est bien calibré.

**** Mais avec un seul outlier
#+begin_src R :results output :session *R* :exports both
  ## library
  library(ThesisRpackage)

  ## sample
  G.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.rds"
  env.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.env.rds"
  ## pca.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.pca.rds"
  pca.file <- NULL
  coord.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.coord.rds"
  chrm.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.chrm.rds"
  K <- 5
  s <- PhenotypeFromTrueSampler(G.file,
                                coord.file,
                                env.file,
                                pca.file,
                                n = NULL,
                                L = 3000,
                                K = K,
                                J = 1,
                                beta = 6,
                                delta = 0.0,
                                chrm.file = chrm.file,
                                chrm.window = 20)

  dat <- sampl(s)

  ## methods
  methods <- list()
  K <- 50
  hypothesis.testing.func <- phenotypeWayReg_lm_score(calibrate = FALSE)

  ## lm
  methods$lm <- ClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                    nickname="lm")
  ## lm + PCA
  methods$lmPCA <- PCAClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                          K = K, 
                                          nickname="lm+PCA")


  ## lfmm ridge
  methods$ridgeLFMM <- RidgeLFMMMethod(K = K,
                                       lambda = 1e0,
                                       hypothesis.testing.method = hypothesis.testing.func,
                                       nickname = "ridgeLFMM")

  ## lfmm lasso
  methods$lassoLFMM <- LassoLFMMMethod(K = K,
                                       lambda = NULL,
                                       sparse.prop = 0.01,
                                       hypothesis.testing.method = hypothesis.testing.func,
                                       nickname = "lassoLFMM")



  exp <- do.call(FDRControlExperiment, c(list(nb.rep = 5,
                                              sampler = s), methods))
  exp <- runExperiment(exp)


#+end_src

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  plot(exp, plot.type = "pvalue.grid")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071PqP.png]]

C'est plus calibré, en faite c'est logique a cause la structure ils sont tous
corélé à $G_j$. A voir comment il font dans les GWAS...
*** Install of ThesisRpackage
#+BEGIN_SRC bash
cd /home/cayek/Projects/Thesis
make Rpackage_install
#+END_SRC
*** Run of methods
#+begin_src R :results output :session *R* :exports both

  ## library
  library(ThesisRpackage)

  ## sample
  G.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.rds"
  env.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.env.rds"
  ## pca.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.pca.rds"
  pca.file <- NULL
  coord.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.coord.rds"
  chrm.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.chrm.rds"
  K <- 5
  s <- PhenotypeFromTrueSampler(G.file,
                                coord.file,
                                env.file,
                                pca.file,
                                n = NULL,
                                L = 3000,
                                K = K,
                                J = 0,
                                beta = 6,
                                delta = 0.0,
                                chrm.file = chrm.file,
                                chrm.window = 20)

  dat <- sampl(s)

  ## methods
  methods <- list()
  K <- 50
  hypothesis.testing.func <- phenotypeWayReg_lm_score(calibrate = FALSE)

  ## lm
  methods$lm <- ClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                    nickname="lm")
  ## lm + PCA
  methods$lmPCA <- PCAClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                          K = K, 
                                          nickname="lm+PCA")


  ## lfmm ridge
  methods$ridgeLFMM <- RidgeLFMMMethod(K = K,
                                       lambda = 1e0,
                                       hypothesis.testing.method = hypothesis.testing.func,
                                       nickname = "ridgeLFMM")

  ## lfmm lasso
  methods$lassoLFMM <- LassoLFMMMethod(K = K,
                                       lambda = NULL,
                                       sparse.prop = 0.01,
                                       hypothesis.testing.method = hypothesis.testing.func,
                                       nickname = "lassoLFMM")

  ## sva
  methods$sva <- SVAMethod(K = K,
                           hypothesis.testing.method = hypothesis.testing.func,
                           nickname = "sva")

  ## experiment
  exp <- do.call(FDRControlExperiment, c(list(nb.rep = 5,
                                              sampler = s), methods))
  exp <- runExperiment(exp)

  ## plot
  # plot(exp, plot.type = "pvalue.grid")
#+end_src
*** FDR control
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  plot(exp, plot.type = "pvalue.grid")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-4925ulr.png]]

*** Precision recall
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  plot(exp, plot.type = "precision.recall")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-49257vx.png]]

** DONE LEA lfmm debug                                            :3Article:
CLOSED: [2017-05-03 mer. 08:57]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-03 mer. 08:57]
- Note taken on [2017-05-03 mer. 08:57] \\
  Il faut combiner des run et recalibrer ! De toute facon je ne vais pas utiliser
  LEA pour les resultat de l'article.
- Note taken on [2017-04-12 mer. 09:01] \\
  IL faut que je vois avec OF pourquoi ca ne marche pas.
- Note taken on [2017-04-11 mar. 14:42] \\
  L'objectif est de comprendre pourquoi ca donne d'aussi mauvais résultat sur mes
  simu de [[file:Notes.org::*Comparaison%20of%20methods%20for%203Article][Comparaison of methods for 3Article]]
- State "STARTED"    from              [2017-04-11 mar. 14:42]
:END:

#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)

  ## sample data
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  K <- 4
  s <- FromTrueSampler(G.file = G.file,
                       n = NULL,
                       L = 1000,
                       K = K,
                       prop.outlier = 0.05,
                       rho = NULL,
                       cs = 0.4,
                       round = FALSE)
  dat <- sampl(s)

  ## run LEA
  m <- LeaLFMMMethod(K = K,
                     iterations = 20000,
                     CPU = 16)
  m <- run(m, dat)

  ## plot
  gplot_stat(m$pvalue[1,],
             outlier = dat$outlier) +
    geom_histogram(aes(stat, fill = outlier, y = ..density..))

  gplot_stat(m$pvalue[1,],
             outlier = dat$outlier) +
    geom_point(aes(x = index, color = outlier, y = -log10(stat)))

#+end_src

*** LEA::lfmm
:PROPERTIES:
:header-args: :cache no :session *notebookR* :dir ./ :eval no-export
:END:
On krakenator
**** Install of ThesisRpackage on krakenator
#+BEGIN_SRC bash :dir /cayek@krakenator.imag.fr:~/Projects/Thesis/
cd /home/cayek/Projects/Thesis
make Rpackage_install
#+END_SRC

**** Simulate data with 0.05 % of outlier
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## sample data
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  K <- 4
  s <- FromTrueSampler(G.file = G.file,
                       n = NULL,
                       L = 1000,
                       K = K,
                       prop.outlier = 0.05,
                       rho = NULL,
                       cs = 0.4,
                       round = FALSE)

  dat <- sampl(s)
  names(dat)
  saveRDS(dat, "./Data/NotebookTMP/Simulation_outlier05_cor04.rds")
#+end_src

#+RESULTS:
: [1] "G"       "X"       "U"       "V"       "B"       "epsilon" "outlier"
: [8] "mu"

**** Run LEA::lfmm
#+begin_src R :results output :exports both
  library(LEA)

  ## read data
  dat <- readRDS("./Data/NotebookTMP/Simulation_outlier05_cor04.rds")

  ## write to lfmm format
  write.lfmm(dat$G, "./Simulation_outlier05_cor04.lfmm")
  write.env(dat$X, "./Simulation_outlier05_cor04.env")

  ## run lfmm
  lfmm.res <- lfmm(input.file="./Simulation_outlier05_cor04.lfmm",
                   environment.file="./Simulation_outlier05_cor04.env",
                   K = 4,
                   project="new",
                   CPU = 4)


#+end_src

#+RESULTS:
#+begin_example
[1] "./Simulation_outlier05_cor04.lfmm"
[1] "./Simulation_outlier05_cor04.env"
The project is saved into :
 Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject 

To load the project, use:
 project = load.lfmmProject("Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject")

To remove the project, use:
 remove.lfmmProject("Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject")

[1] "********************************"
[1] "* K = 4  repetition 1  d = 1   *"
[1] "********************************"
Summary of the options:

        -n (number of individuals)      503
        -L (number of loci)             1000
        -K (number of latent factors)   4
        -o (output file)                Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmm/K4/run1/Simulation_outlier05_cor04_r1
        -i (number of iterations)       10000
        -b (burnin)                     5000
        -s (seed random init)           61801602730908
        -p (number of processes (CPU))  4
        -x (genotype file)              Simulation_outlier05_cor04.lfmm
        -v (variable file)              Simulation_outlier05_cor04.env
        -D (number of covariables)      1
        -d (the dth covariable)         1

Read variable file:
 	Simulation_outlier05_cor04.env		OK.

Read genotype file:
 	Simulation_outlier05_cor04.lfmm		OK.

<<<<
	 Analyse for variable 1

		Start of the Gibbs Sampler algorithm.

	[                                                                           ]
	[===========================================================================]

		End of the Gibbs Sampler algorithm.

	ED:503000.1531	 DIC: 503001.0074 

	The statistics for the run are registered in:
 		Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmm/K4/run1/Simulation_outlier05_cor04_r1_s1.4.dic.

	The zscores for variable 1 are registered in:
 		Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmm/K4/run1/Simulation_outlier05_cor04_r1_s1.4.zscore.
	The columns are: zscores, -log10(p-values), p-values.

	-------------------------
	The execution for variable 1 worked without error.
>>>>

The project is saved into :
 Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject 

To load the project, use:
 project = load.lfmmProject("Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject")

To remove the project, use:
 remove.lfmmProject("Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject")
#+end_example

Histogram
#+begin_src R :results output graphics :file Rplots/LEA/lea_histo.png :exports both :width 600 :height 400 
## plot
pvalue <- LEA::p.values(lfmm.res, K = 4)
hist(pvalue)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lea_histo.png]]

Manhattan plot
#+begin_src R :results output graphics :file Rplots/LEA/lea_man.png :exports both :width 600 :height 400 
library(ggplot2)
index <- seq_along(pvalue)
qplot(index, -log10(pvalue), color = index %in% dat$outlier)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lea_man.png]]

**** Run of LassoLFMM
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## read data
  dat <- readRDS("./Data/NotebookTMP/Simulation_outlier05_cor04.rds")

  ## run of lfmmLasso 
  m <- finalLfmmLassoMethod(K = 4,
                            sparse.prop = 0.05)
  m <- run(m, dat)
#+end_src


Histogram
#+begin_src R :results output graphics :file Rplots/LEA/lasso_hist.png :exports both :width 600 :height 400 
  hist(m$pvalue)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lasso_hist.png]]

Manhattan plot
#+begin_src R :results output graphics :file Rplots/LEA/lasso_man.png :exports both :width 600 :height 400 
  library(ggplot2)
  pvalue <- as.numeric(m$pvalue)
  index <- seq_along(pvalue)

  qplot(x = index, y = -log10(pvalue), color = index %in% dat$outlier)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lasso_man.png]]

**** Run of lm 
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## read data
  dat <- readRDS("./Data/NotebookTMP/Simulation_outlier05_cor04.rds")

  ## run of lfmmLasso 
  m <- finalLm()
  m <- run(m, dat)
#+end_src


Histogram:
#+begin_src R :results output graphics :file Rplots/LEA/lm_histo.png :exports both :width 600 :height 400 
hist(m$pvalue)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lm_histo.png]]

C'est mal calibré.

Manhattan plot:
#+begin_src R :results output graphics :file Rplots/LEA/lm_man.png :exports both :width 600 :height 400 
  library(ggplot2)
  pvalue <- as.numeric(m$pvalue)
  index <- seq_along(pvalue)

  qplot(x = index, y = -log10(pvalue), color = index %in% dat$outlier)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lm_man.png]]

**** export notebook                                            :noexport:
:PROPERTIES:
:header-args: :cache no :session *bash* :dir ./ :eval no-export
:END:
#+BEGIN_SRC bash 
  mkdir NOTEBOOK/
  mkdir NOTEBOOK/Data
  mkdir NOTEBOOK/Rplots
  cp Notes.html NOTEBOOK/
  cp -r Data/NotebookTMP/ NOTEBOOK/Data/
  cp -r Rplots/LEA/ NOTEBOOK/Rplots/
  tar -czvf NOTEBOOK.tar.gz NOTEBOOK
  rm -rf NOTEBOOK
  scp NOTEBOOK.tar.gz cayek@krakenator.imag.fr:~/Notebook_LEAdebug.tar.gz
#+END_SRC




** DONE Test of [[https://cran.r-project.org/web/packages/cate/index.html][cate]] CRAN package                                 :3Article:
CLOSED: [2017-04-12 mer. 16:17]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-04-12 mer. 16:17]
- Note taken on [2017-04-12 mer. 16:17] \\
  Je vais l'ajouter au methodes !!
- State "STARTED"    from              [2017-04-12 mer. 15:45]
:END:
La [[file:Biblio/org-ref-pdfs/cate_vignette.pdf][vignette]]
#+begin_src R :results output :session *R* :exports both
  install.packages("cate")
  library(cate)

  data(gender.sm)
  names(gender.sm)

  ## compute t test
  t.stats <- apply(gender.sm$Y, 2, function(y, x) t.test(y~x)$statistic, gender.sm$X)
  hist(t.stats)

  ## estimation of the number of lattent factor
  n <- nrow(gender.sm$Y) # number of samples
  gender.data <- data.frame(gender = gender.sm$X, gender.sm$Z)
  factor.num <- est.confounder.num(~ gender | . - gender + 0,
                                   gender.data, gender.sm$Y,
                                   method = "bcv", bcv.plot = FALSE,
                                   rmax = 30, nRepeat = 20)
  factor.num$r

  cate.results <- cate(~ gender | . - gender + 0,
                       gender.data, gender.sm$Y, r = factor.num$r)
  names(cate.results)

  ## ....

  ## factor analysis
  mle <- factor.analysis(gender.sm$Y, r = 5) 
  names(mle)
#+end_src

** CANCELLED Comparison of methods on generative simu cor(U1/2,X)=c :3Article:
CLOSED: [2017-04-13 jeu. 18:16]
:LOGBOOK:
- Note taken on [2017-04-13 jeu. 18:16] \\
  On va faire l'experience final pour le papier dirrect !!
- State "CANCELLED"  from "STARTED"    [2017-04-13 jeu. 18:16]
- State "STARTED"    from              [2017-04-13 jeu. 09:02]
:END:
**** Run on krak
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 10,
                                   fast.only = FALSE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)
#+end_src

** DONE Correction $G - U V^T$ on generative simulations          :3Article:
CLOSED: [2017-04-14 ven. 14:56]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-04-14 ven. 14:56]
- State "STARTED"    from "TODO"       [2017-04-14 ven. 10:03]
- State "TODO"       from              [2017-04-14 ven. 10:01]
:END:

*** DONE On krakenator
CLOSED: [2017-04-14 ven. 14:49]
:PROPERTIES:
:CUSTOM_ID: simu with NA
:END:
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-14 ven. 14:49]
- State "RUNNING"    from              [2017-04-14 ven. 10:08]
:END:
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   cs = c(0.4, 0.6),
                                   nb.rep = 5,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)
#+end_src

*** plots
:PROPERTIES:
:header-args: :cache no :session *R* :dir ./ :eval no-export :width 800 :height 600
:END:

We retrieve the experiment
#+begin_src R :results output :exports both
  exp <- retrieveExperiment(106)
  exp$description
#+end_src

***** AUC
#+begin_src R :results output graphics :file Rplots/G_UV.auc.png :exports both 
Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:Rplots/G_UV.auc.png]]

***** gif
#+begin_src R :results output graphics :file Rplots/G_UV.gif.png :exports both 
Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:Rplots/G_UV.gif.png]]

** DONE Check NA in results                                       :3Article:
CLOSED: [2017-05-03 mer. 08:56]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-03 mer. 08:56]
- Note taken on [2017-04-14 ven. 14:57] \\
  Tout est dans le titre, je veux m'assurer que les NA qu'on a en sorti parfois ne
  sont pas des outlier !! J'en ai observé sur [[#simu with NA][cette simu]].
- State "TODO"       from              [2017-04-14 ven. 14:57]
:END:
#+begin_src R :results output :exports both
  ## sample data
  s <- FromTrueSampler(G.file = "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000.rds",
                       n = NULL,
                       L = 10000,
                       K = 4,
                       cs = 0.4,
                       rho = NULL,
                       prop.outlier = 0.01,
                       round = FALSE)
  dat <- sampl(s)

  ## var of loci
  sum( apply(dat$G, 2, var) == 0)

  ## run of a method
  m <- finalLfmmRdigeMethod(K = 4, lambda = 1e-3)
  m <- run(m, dat)

  ## NA ?
  sum(is.na(m$score))

  ## NA and var = 0 ?
  m$score[1, apply(dat$G, 2, var) == 0]
#+end_src

#+RESULTS:
: [1] 1
: DEBUG [2017-05-03 08:54:26] run.Method: running  lm+zscore|calibrate=FALSE
: [1] 1
: rs1747928 
:       NaN

Il y a un locus sans variance .... De toute facon je vais regénérer des dataset
pour les resultats ! 

** DONE Redundancy Analysis (RDA)                                 :3Article:
CLOSED: [2017-05-02 mar. 15:40]
:LOGBOOK:
- Note taken on [2017-05-02 mar. 16:07] \\
  On laisse ca de coté les papiers de Forester sont trop légé sur les méthodes...
- State "DONE"       from "TODO"       [2017-05-02 mar. 15:40]
- Note taken on [2017-05-02 mar. 15:32] \\
  Il y a tout une litérature des ordination methods... J'ai l'impression que rda
  est bien une méthode pour faire des association. Mais ca ne prend pas en compte
  une structure lattente. Ou alors il faut la calculer avec une autre méthode et
  l'ajouté en covariable dans rda ([[cite:Forester_2017][see page 6]])
- Note taken on [2017-05-02 mar. 12:00] \\
  Faut que je comprenne le principe de cette methode ! A table.
- Note taken on [2017-05-02 mar. 10:20] \\
  Comment ca réagis sur mes simulations genérative. On l'ajoute dans les méthodes
  du papier ?
- State "TODO"       from              [2017-05-02 mar. 09:22]
:END:

Dans cite:Forester_2015 ils utilisent RDA pour trouver des locus outlier en
passant par un PCA de XB (dans le modèle G = XB + E). Après ils calculent des
pvaleur en ces locus plus précisement (avec un lm).

Je comprends que : 
- il n'y aura pas de correction pour la structure de populations
- c'est juste un moyen de ne pas passer par le controle du FDR
*** Sur une simulations

#+begin_src R :results output :exports both
  ## sampler data with lfmm generative model
  library(ThesisRpackage)
  s <- NormalSampler2(n = 100,
                      L = 1000,
                      K = 3,
                      prop.outlier = 0.02,
                      cs = c(0.6, 0.0, 0.0))
  dat <- sampl(s)

  ## run rda
  library(vegan)

  rda.res <- rda(dat$G ~ dat$X)
  names(rda.res)

#+end_src

#+RESULTS:
:  [1] "call"        "grand.total" "rowsum"      "colsum"      "tot.chi"    
:  [6] "pCCA"        "CCA"         "CA"          "method"      "inertia"    
: [11] "terms"       "terminfo"

#+begin_src R :results output graphics :file Rplots/RDA_1.png :exports both :width 600 :height 400
  plot(rda.res)
#+end_src

#+RESULTS:
[[file:Rplots/RDA_1.png]]

A quoi correspond les rouges et les autres ? C'est les indiv et les locus...

#+begin_src R :results output graphics :file Rplots/RDA_2.png :exports both :width 600 :height 400 
  library(tidyverse)

  toplot <- cbind(as.data.frame(rda.res$CA$v),
                  as.data.frame(rda.res$CCA$v))
  toplot <- toplot %>%
    mutate(index = 1:nrow(toplot),
           outlier = index %in% dat$outlier)

  ggplot(toplot, aes(x = RDA1, y = PC1, color = outlier)) +
    geom_point()
#+end_src

#+RESULTS:
[[file:Rplots/RDA_2.png]]

Je n'arrive pas a reproduire le graphe précédent.

MAIS on voit que RDA1 ne permet capte la variable lattente.

**** Si on utilise lfmm 

#+begin_src R :results output graphics :file Rplots/RDA_3.png :exports both :width 600 :height 400 
  ## run of lfmm ridge
  lfmm.ridge <- finalLfmmRdigeMethod(K = 3,lambda = 1e-1)
  lfmm.ridge <- run(lfmm.ridge, dat)

  gplot_stat(B = lfmm.ridge$B[1,], outlier = dat$outlier) +
    geom_point(aes(x = index, y = stat, color = outlier))
#+end_src

#+RESULTS:
[[file:Rplots/RDA_3.png]]

On arrive bien a avoir ceux qui sont vraiment associé a X et pas avec la
variable lattentes.

**** Si on utilise lm
#+begin_src R :results output graphics :file Rplots/RDA_4.png :exports both :width 600 :height 400 
  ## run of lfmm ridge
  lm.res <- finalLm()
  lm.res <- run(lm.res, dat)

  gplot_stat(B = lm.res$B[1,], outlier = dat$outlier) +
    geom_point(aes(x = index, y = stat, color = outlier))
#+end_src

#+RESULTS:
[[file:Rplots/RDA_4.png]]

C'est comparable a les loadings RDA1

** STARTED Validation numérique pour l'article "LFMM"             :3Article:
:LOGBOOK:
- State "STARTED"    from "DONE"       [2017-06-01 jeu. 18:21]
- State "DONE"       from "STARTED"    [2017-05-29 lun. 09:01]
- Note taken on [2017-05-18 jeu. 10:49] \\
  Ok on part du 1000 genome bien netoyé avec plink :D
- Note taken on [2017-05-11 jeu. 17:46] \\
  On va utiliser le simons dataset par cohérence ! cf cahier le 10/05/2017
- Note taken on [2017-05-10 mer. 10:55] \\
  J'ai joué avec les datasets ([[file:ThesisRpackage/tests/testthat/test_3Article_ValidationNumerique.R::test_that("Play%20with%20experiment",%20{][ici]]), avec si outlier.prop < 0.05 on ne voit pas
  l'avantage de lfmm sur PCA+lm. alors que avec 0.05 c'est bien clair ! Je me
  demande si avec vraiment beaucoup d'indiv (donc beucoup de puissance) 0.05 c'est
  si aberrant ? Il faut que j'en parle avec OF. 
  
  Aussi, avec ce dataset il y a vraiment paut de structure (1 %), du coup si je
  baisse pas l'erreur la variance des estimateurs des effets sont du meme ordre
  que les B. Je peut prendre un dataset avec plus de structure. Ou plus d'indiv
  
  To be continued.
- Note taken on [2017-05-10 mer. 08:55] \\
  Si l'oracle n'a pas de bonne performance, on trouve n'imp ! C'est des simu trop
  dure pour dire quoi que ce soit !
CLOCK: [2017-05-05 ven. 13:03]--[2017-05-05 ven. 13:29] =>  0:26
- Note taken on [2017-05-05 ven. 10:56] \\
  Je vais travailler sur un dataset centré et normalisé !
CLOCK: [2017-05-05 ven. 10:48]--[2017-05-05 ven. 11:13] =>  0:25
CLOCK: [2017-05-05 ven. 09:47]--[2017-05-05 ven. 10:12] =>  0:25
- Note taken on [2017-05-03 mer. 18:10] \\
  J'en suis a sample les dataset et faire la svd sur la matrice STANDARDISED !!!!
- State "STARTED"    from "TODO"       [2017-05-03 mer. 09:49]
- State "TODO"       from              [2017-05-03 mer. 09:05]
:END:
*** CANCELLED COMMENT Sample dataset
CLOSED: [2017-05-18 jeu. 10:50]
:LOGBOOK:
- Note taken on [2017-05-18 jeu. 10:50] \\
  on recommence au propre
- State "CANCELLED"  from              [2017-05-18 jeu. 10:50]
:END:
**** structure de population faible
On sample sur tout le 1000Genome et que les européens.
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  file.res <- Article3_ValidationNumerique_Sample(L = 5e5, only.EUR = TRUE,
                                                  dat.file = "~/Projects/Thesis/Data/1000Genomes/Phase3/Eu_Af_Afam.maf.05.rds")

#+end_src

#+begin_src R :results output graphics :file Rplots/faible_struct_pop_vps.png :exports both :width 600 :height 400 
  ## test and PCA
  file.res <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/ValidationNumerique_EU_L5e+05.G.rds"
  G <- readRDS(file.res)
  dim(G)
  anyNA(G)

  ## PCA
  svd.res <- svd(G, nu = 0, nv = 0)
  variances <- svd.res$d / sum(svd.res$d)
  ## plot
  pl <- qplot(x = seq_along(variances), y = variances, geom='line') +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  pl
#+end_src

#+RESULTS:
[[file:Rplots/faible_struct_pop_vps.png]]

On va prendre $K = 2$ variables latentes.

Var explained with 2 variables:
#+begin_src R :results output :exports both
  print(sum(variances[1:2]))
#+end_src

#+RESULTS:
: [1] 0.01235195


***** Choix de K pour les méthodes
Pour le moment on va prendre le K de la simulation.
***** Run on krak 
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/ValidationNumerique_EU_L5e+05.G.rds"

  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = 0.0005,
                                   n = NULL, L = 10000,
                                   K = 2,
                                   K.method = 2,
                                   cs = c(0.1, 0.2, 0.6, 0.8, 1.0),
                                   cs.sum = TRUE,
                                   sd.V.rho = 2, 
                                   nb.rep = 5,
                                   fast.only = TRUE,
                                   cluster.nb = 20,
                                   save = TRUE, bypass = FALSE)

  Article3_MethodComparison_plot_relative_diff_AUC(exp)
#+end_src
**** structure de population forte
On sample sur tout le 1000Genome et que les européens.
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  file.res <- Article3_ValidationNumerique_Sample(L = 5e5, only.EUR = FALSE,
                                                  dat.file = "~/Projects/Thesis/Data/1000Genomes/Phase3/Eu_Af_Afam.maf.05.rds")

#+end_src

On va pendre $K = 4$.
#+begin_src R :results output graphics :file Rplots/forte_struct_pop_vps.png :exports both :width 600 :height 400 
  ## test and PCA
  file.res <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/ValidationNumerique_ALL_L5e+05.G.rds"
  G <- readRDS(file.res)
  dim(G)
  anyNA(G)

  ## PCA
  svd.res <- svd(G, nu = 0, nv = 0)
  variances <- svd.res$d / sum(svd.res$d)
  ## plot
  pl <- qplot(x = seq_along(variances), y = variances, geom='line') +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  pl
#+end_src

#+RESULTS:
[[file:Rplots/forte_struct_pop_vps.png]]

Var explained with 4 variables:
#+begin_src R :results output :exports both
  print(sum(variances[1:2]))
  print(sum(variances[1:4]))
#+end_src

#+RESULTS:
: [1] 0.02006896
: [1] 0.02561421
*** DONE Sample dataset
CLOSED: [2017-05-22 lun. 10:59]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-22 lun. 10:59]
- State "STARTED"    from "TODO"       [2017-05-18 jeu. 15:44]
- State "TODO"       from              [2017-05-18 jeu. 10:52]
:END:
**** DONE 1000Genome dataset
CLOSED: [2017-05-18 jeu. 13:09]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-18 jeu. 13:09]
- State "RUNNING"    from              [2017-05-18 jeu. 11:43]
:END:
We scale the dataset
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  G <- readRDS("./Data/1000Genomes/Phase3/plink/1000GenomePhase3_QC_norel_prunned.rds")
  G <- scale(G)

  pl <- plotable(function() {hist(G)})
  print(pl)
  save_plot_timc_bcm_15(pl, "1000Genome_scale.png")

  saveRDS(G, "./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled.rds")

#+end_src

#+RESULTS:
[[./Rplots/1000Genome_scale.png]]

Some filter
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  G <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled.rds")
  G.filtered <- Preprocessing_filter_sd(G, 0)
  G.filtered <- Preprocessing_filter_maf(G.filtered, 0.05)
#+end_src

#+RESULTS:
#+begin_example
  > G.filtered <- Preprocessing_filter_sd(G, 0)
  TRACE [2017-05-18 13:13:52] proportion of removed loci =  NA
  > dim(G.filtered)
  [1]    919 345156
  > dim(G)
  [1]    919 345156
  > G.filtered <- Preprocessing_filter_maf(G.filtered, 0.05)
  TRACE [2017-05-18 13:15:29] proportion of removed loci =  NA
  > 
#+end_example

There is nothing to remove.

Si les na :D
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  G <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled.rds")
  G <- Preprocessing_filter_na(G)
  saveRDS(G, "./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds")
#+end_src

#+RESULTS:
#+begin_example
  TRACE [2017-05-18 16:19:27] proportion of removed loci =  0.00775881050887135
  > dim(G)
  [1]    919 342478
#+end_example

**** DONE PCA 
<<1000Genome_pca>>
CLOSED: [2017-05-18 jeu. 14:10]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-18 jeu. 14:10]
- State "RUNNING"    from "TODO"       [2017-05-18 jeu. 13:13]
- State "TODO"       from              [2017-05-18 jeu. 11:45]
:END:

Run: 
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  s <- TrueSampler("./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled.rds", NULL, NULL)

  expr <- PCAExperiment(s,
                        description = "PCA on 1000GenomesPhase3_QC_norel_prunned_scaled.rds")
  expr <- runExperiment(expr)
  dumpExperiment(expr)
#+end_src

Plot: 
#+begin_src R :results output graphics :file Rplots/1000Genome_pca.png :exports both :width 600 :height 400 
  expr <- retrieveExperiment(122)
  variances <- expr$res.df$sdev / sum(expr$res.df$sdev)
  ## plot
  pl <- qplot(x = seq_along(variances), y = variances, geom='line') +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  pl
#+end_src

#+RESULTS:
[[file:Rplots/1000Genome_pca.png]]

Remark: la structure est bien partagé entre axe contrairement à [[*structure de population forte][ce plot]]. C'est a
cause du LD prunning ?? 

Var explained with 10 variables:
#+begin_src R :results output :exports both
  print(sum(variances[1:8]))
  print(sum(variances[1:10]))
#+end_src

#+RESULTS:
: [1] 0.02160972
: [1] 0.02424479

*** DONE Run on a sample on patator
CLOSED: [2017-05-22 lun. 18:36]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-22 lun. 18:36]
- State "STARTED"    from "TODO"       [2017-05-22 lun. 09:44]
- State "TODO"       from              [2017-05-22 lun. 09:44]
:END:

We first sample the big dataset and compute pca.
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds"

  G <- readRDS(G.file)

  L <- ncol(G)
  n <- nrow(G)
  ## sample
  sample.locus <- sample.int(L, 100000)
  G.sample <- G[,sample.locus]
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA_sampleL100000.rds"
  saveRDS(G.sample, "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA_sampleL100000.rds")

  ## load sampler
  s <- FromTrueSampler(G.file = G.file,
                  n = 1,
                  L = 1,
                  K = 1,
                  pca.file = sub("\\.rds", "_PCA.rds", G.file),
                  prop.outlier = NULL,
                  rho = NULL,
                  cs = NULL,
                  sd.V.rho = 1,
                  rho.E = 1,
                  round = FALSE)
  s <- Sampler_load(s)
#+end_src


**** DONE LIL' with 0.05 0.5 1 5 % outlier and L = 100 000
CLOSED: [2017-05-22 lun. 10:53]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-22 lun. 10:53]
- State "TODO"       from              [2017-05-22 lun. 09:41]
:END:
***** Run
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA_sampleL100000.rds"

  expr <- Article3_MethodComparison(G.file,
                                    outlier.props = c(0.0005, 0.005),
                                    n = NULL, L = 10000,
                                    K = 10,
                                    K.method = 10,
                                    lasso.sparse.prop = 0.05,
                                    ridge.lambda = 1e-5,
                                    cs = c( 0.2, 0.6),
                                    cs.sum = FALSE,
                                    sd.V.rho = 1,
                                    nb.rep = 1,
                                    fast.only = TRUE,
                                    cluster.nb = 2,
                                    save = TRUE, bypass = FALSE)

  Article3_MethodComparison_plot_relative_diff_AUC(expr)
  Article3_MethodComparison_plot_GIF(expr)
#+end_src
***** plot
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(128)
  expr$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA_sampleL100000.rds K=10 K.method=10 correctionByC=FALSE fast.only=TRUE n= L=10000 cs=0.2|0.6 cs.sum=FALSE sd.V.rho=1 rho.E=1 outlier.props=5e-04|0.005 ridge.lambda=1e-05 lasso.sparse.prop=0.05 nb.rep=1 "

#+begin_src R :results output :exports both
  pl <- Article3_MethodComparison_plot_relative_diff_AUC(expr)
  save_plot_timc_bcm_15(pl, "LilNumericVal_auc.png")
  pl <- Article3_MethodComparison_plot_GIF(expr)
  save_plot_timc_bcm_15(pl, "LilNumericVal_gif.png")
#+end_src

#+RESULTS:
: # A tibble: 4 × 5
:   method outlier.prop `cor(U,X)`   rep       auc
:    <chr>        <dbl>      <chr> <dbl>     <dbl>
: 1 Oracle        5e-04        0.2     1 0.7001983
: 2 Oracle        5e-04        0.6     1 0.7000757
: 3 Oracle        5e-03        0.2     1 0.9712594
: 4 Oracle        5e-03        0.6     1 0.9700619
[[./Rplots/LilNumericVal_auc.png]]
[[./Rplots/LilNumericVal_gif.png]]

Attendu: 
- gif de lm de plus en plus quand, plus on est corrélé
- plus il y a de d'outlier plus PCALm a un mauvais auc
Inattendu
- famt pas comme les autres
- PcaLm est meilleur quand c est grand... je pense que le hasard si on augment
  K, ca devrait desavantager PcaLm.
**** DONE LIL' with 0.05 0.5 1 5 % outlier and L = 100 000 with lfmm lasso
CLOSED: [2017-05-22 lun. 15:06]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-22 lun. 15:06]
- State "RUNNING"    from "TODO"       [2017-05-22 lun. 10:56]
- State "TODO"       from "DONE"       [2017-05-22 lun. 10:54]
:END:
***** Run
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA_sampleL100000.rds"

  expr <- Article3_MethodComparison(G.file,
                                    outlier.props = c(0.0005, 0.005),
                                    n = NULL, L = 10000,
                                    K = 10,
                                    K.method = 10,
                                    lasso.sparse.prop = 0.05,
                                    ridge.lambda = 1e-5,
                                    cs = c( 0.2, 0.6),
                                    cs.sum = FALSE,
                                    sd.V.rho = 1,
                                    nb.rep = 1,
                                    fast.only = FALSE,
                                    cluster.nb = 2,
                                    save = TRUE, bypass = FALSE)
#+end_src
***** plot
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(129)
  expr$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA_sampleL100000.rds K=10 K.method=10 correctionByC=FALSE fast.only=FALSE n= L=10000 cs=0.2|0.6 cs.sum=FALSE sd.V.rho=1 rho.E=1 outlier.props=5e-04|0.005 ridge.lambda=1e-05 lasso.sparse.prop=0.05 nb.rep=1 "


#+begin_src R :results output :exports both
  pl <- Article3_MethodComparison_plot_relative_diff_AUC(expr)
  save_plot_timc_bcm_15(pl, "LilNumericVal_withLasso_auc.png")
  pl <- Article3_MethodComparison_plot_GIF(expr)
  save_plot_timc_bcm_15(pl, "LilNumericVal_withLasso_gif.png")
#+end_src

#+RESULTS:
: # A tibble: 4 × 5
:   method outlier.prop `cor(U,X)`   rep       auc
:    <chr>        <dbl>      <chr> <dbl>     <dbl>
: 1 Oracle        5e-04        0.2     1 0.7006266
: 2 Oracle        5e-04        0.6     1 0.7001076
: 3 Oracle        5e-03        0.2     1 0.9700533
: 4 Oracle        5e-03        0.6     1 0.9700517
[[./Rplots/LilNumericVal_withLasso_auc.png]]
[[./Rplots/LilNumericVal_withLasso_gif.png]]

lfmm lasso donne bien comme l'oracle. Il y a toujours ce truc bizare avec l'ACP
mais je pense que c'est une particularité des data.
*** DONE K = 10 
CLOSED: [2017-06-12 lun. 11:42]
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-06-12 lun. 11:42]
- State "STARTED"    from "DONE"       [2017-06-01 jeu. 18:26]
- State "DONE"       from "STARTED"    [2017-05-29 lun. 09:01]
- Note taken on [2017-05-19 ven. 13:24] \\
  Je pense que je met trop de variable lattentes pour l'acp et pour je ne sais
  quelle raison il capte X.... De toute facon j'utilise un critère objectif pour
  trouver le nombre de variable lattentes... SI l'acp se plante ! tant mieux !
- Note taken on [2017-05-19 ven. 13:03] \\
  C'est bizare pour PCA + lm et il manque cate
- State "STARTED"    from "RUNNING"    [2017-05-19 ven. 11:45]
- State "RUNNING"    from "TODO"       [2017-05-18 jeu. 15:18]
:END:

We first load the sampler to compute pca.
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds"
  s <- FromTrueSampler(G.file = G.file,
                  n = 1,
                  L = 1,
                  K = 1,
                  pca.file = sub("\\.rds", "_PCA.rds", G.file),
                  prop.outlier = NULL,
                  rho = NULL,
                  cs = NULL,
                  sd.V.rho = 1,
                  rho.E = 1,
                  round = FALSE)
  s <- Sampler_load(s)
#+end_src

**** DONE with 1 % outlier
CLOSED: [2017-05-19 ven. 16:42]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-19 ven. 16:42]
- State "STARTED"    from "DONE"       [2017-05-19 ven. 13:03]
- State "DONE"       from "RUNNING"    [2017-05-19 ven. 13:03]
- State "RUNNING"    from              [2017-05-19 ven. 11:41]
:END:
***** Run
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds"

  expr <- Article3_MethodComparison(G.file,
                                   outlier.props = 0.01,
                                   n = NULL, L = 10000,
                                   K = 10,
                                   K.method = 10,
                                   cs = c(0.1, 0.2, 0.6, 0.8),
                                   cs.sum = FALSE,
                                   sd.V.rho = 1, 
                                   nb.rep = 5,
                                   fast.only = TRUE,
                                   cluster.nb = 20,
                                   save = TRUE, bypass = FALSE)

  Article3_MethodComparison_plot_GIF(expr)
#+end_src

***** plot
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(125)
  expr$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds K=10 K.method=10 correctionByC=FALSE fast.only=TRUE n= L=10000 cs=0.1|0.2|0.6|0.8 cs.sum=FALSE sd.V.rho=1 rho.E=1 outlier.props=0.01 nb.rep=5 "

#+begin_src R :results output :exports both
  pl <- Article3_MethodComparison_plot_relative_diff_AUC(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_auc_1.png")
  pl <- Article3_MethodComparison_plot_GIF(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_gif_1.png")
#+end_src

#+RESULTS:
[[./Rplots/NumericVal_gif_1.png]]
[[./Rplots/NumericVal_auc_1.png]]
#+begin_example
# A tibble: 20 × 5
   method outlier.prop `cor(U,X)`   rep       auc
    <chr>        <dbl>      <chr> <dbl>     <dbl>
1  Oracle         0.01        0.1     1 0.9850510
2  Oracle         0.01        0.1     2 0.9851842
3  Oracle         0.01        0.1     3 0.9852716
4  Oracle         0.01        0.1     4 0.9852063
5  Oracle         0.01        0.1     5 0.9850772
6  Oracle         0.01        0.2     1 0.9850568
7  Oracle         0.01        0.2     2 0.9851064
8  Oracle         0.01        0.2     3 0.9850596
9  Oracle         0.01        0.2     4 0.9854058
10 Oracle         0.01        0.2     5 0.9850795
11 Oracle         0.01        0.6     1 0.9852875
12 Oracle         0.01        0.6     2 0.9854125
13 Oracle         0.01        0.6     3 0.9850586
14 Oracle         0.01        0.6     4 0.9878571
15 Oracle         0.01        0.6     5 0.9851148
16 Oracle         0.01        0.8     1 0.9787368
17 Oracle         0.01        0.8     2 0.9756866
18 Oracle         0.01        0.8     3 0.9826669
19 Oracle         0.01        0.8     4 0.9847617
20 Oracle         0.01        0.8     5 0.9834062
#+end_example

**** DONE with 0.05 0.5 1 5 % outlier and L = 100 000
CLOSED: [2017-05-25 Thu 14:45]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-25 Thu 14:45]
- State "STARTED"    from "RUNNING"    [2017-05-23 mar. 15:47]
- State "RUNNING"    from "DEBUG"      [2017-05-22 lun. 09:32]
- State "DEBUG"      from "RUNNING"    [2017-05-22 lun. 08:49]
- Note taken on [2017-05-19 ven. 17:06] \\
  En esperant que ca tienne le coup :D : 25452.pts-1.patator et =tail -f
  Article3_MethodComparison.log=
- State "RUNNING"    from "DEBUG"      [2017-05-19 ven. 16:46]
- Note taken on [2017-05-19 ven. 16:43] \\
  Ca sert a rien de lancer avec plus de locus ! pour les grosses données on a celiac :D
- State "DEBUG"      from              [2017-05-19 ven. 15:41]
- State ""           from "STARTED"    [2017-05-19 ven. 15:40]
- State "STARTED"    from "RUNNING"    [2017-05-19 ven. 15:13]
- State "RUNNING"    from "RUNNING"    [2017-05-19 ven. 15:13]
- Note taken on [2017-05-19 ven. 15:13] \\
  Ok il y a un truc qui merde !!
- Note taken on [2017-05-19 ven. 15:01] \\
  Avec 20 process c'est viré par krak... Il faudrait que je gere mieux la memoire..
- Note taken on [2017-05-19 ven. 13:54] \\
  C'est partie !! : 29005.pts-4.krakenator Ca devrait prendre pas mal de temps !
  On vera lundi
- State "RUNNING"    from "TODO"       [2017-05-19 ven. 13:47]
- State "TODO"       from              [2017-05-19 ven. 11:41]
:END:
***** DONE Run without lfmm Lasso
CLOSED: [2017-05-24 mer. 08:41]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-24 mer. 08:41]
- State "RUNNING"    from              [2017-05-23 mar. 15:47]
:END:
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds"

  expr <- Article3_MethodComparison(G.file,
                                    outlier.props = c(0.0005, 0.005, 0.01, 0.05),
                                    n = NULL, L = 100000,
                                    K = 10,
                                    K.method = 10,
                                    lasso.sparse.prop = 0.05,
                                    ridge.lambda = 1e-5,
                                    cs = c(0.1, 0.2, 0.4, 0.6, 0.8),
                                    cs.sum = FALSE,
                                    sd.V.rho = 1,
                                    nb.rep = 4,
                                    fast.only = TRUE,
                                    cluster.nb = 8,
                                    save = TRUE, bypass = FALSE)

  Article3_MethodComparison_plot_relative_diff_AUC(expr)
  Article3_MethodComparison_plot_GIF(expr)
#+end_src
***** DONE plot
CLOSED: [2017-05-24 mer. 10:33]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-24 mer. 10:33]
- State "RUNNING"    from "STARTED"    [2017-05-24 mer. 08:44]
- State "STARTED"    from "WAITING"    [2017-05-24 mer. 08:42]
- State "WAITING"    from              [2017-05-23 mar. 15:47]
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(130)
  expr$description
#+end_src

#+RESULTS:
#+begin_example
  [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds K=10 K.method=10 correctionByC=FALSE fast.only=TRUE n= L=1e+05 cs=0.1|0.2|0.4|0.6|0.8 cs.sum=FALSE sd.V.rho=1 rho.E=1 outlier.props=5e-04|0.005|0.01|0.05 ridge.lambda=1e-05 lasso.sparse.prop=0.05 nb.rep=4 "
#+end_example

#+begin_src R :results output :exports both
  pl <- Article3_MethodComparison_plot_relative_diff_AUC(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_auc_without_lasso.png")
  pl <- Article3_MethodComparison_plot_GIF(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_gif_without_lasso.png")
#+end_src

#+RESULTS:
[[./Rplots/NumericVal_auc_without_lasso.png]]
[[./Rplots/NumericVal_gif_without_lasso.png]]

C'est les résultats attendus, a par pour famt qui fait n'imp... c'est peut atre
a cause du param max.nbcluster qui était à 8 mais je pense qu'il ne sert que
quand K n'est pas specifié.

**** DONE with 0.05 0.5 1 % outlier and L = 50 000
CLOSED: [2017-05-29 lun. 09:01]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-29 lun. 09:01]
- State "STARTED"    from "TODO"       [2017-05-24 mer. 16:17]
- State "TODO"       from              [2017-05-24 mer.16:13]
:END:
***** DONE Run all even with lfmm lasso :D
CLOSED: [2017-05-26 Ven 17:41]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-26 Ven 17:41]
- Note taken on [2017-05-26 Ven 17:40] \\
  C'est fini: 134
- Note taken on [2017-05-24 mer. 16:21] \\
  Ca tourne sur krakenator 26414.pts-8.krakenator
- State "RUNNING"    from "TODO"       [2017-05-24 mer. 16:17]
- Note taken on [2017-05-23 mar. 17:15] \\
  hahaha je vais etre obligé de tout relancer....pour etre sur les même dataset...
- State "TODO"       from              [2017-05-23 mar. 17:14]
:END:

#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds"

  expr <- Article3_MethodComparison(G.file,
                                    outlier.props = c(0.0005, 0.005, 0.01),
                                    n = NULL, L = 50000,
                                    K = 10,
                                    K.method = 10,
                                    lasso.sparse.prop = 0.05,
                                    ridge.lambda = 1e-5,
                                    cs = c(0.1, 0.2, 0.4, 0.6),
                                    cs.sum = FALSE,
                                    sd.V.rho = 1,
                                    nb.rep = 4,
                                    fast.only = FALSE,
                                    cluster.nb = 4,
                                    save = TRUE, bypass = FALSE)

#+end_src
***** DONE plot
CLOSED: [2017-06-01 jeu. 18:12]
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-06-01 jeu. 18:12]
- State "TODO"       from              [2017-05-26 Ven 17:42]
:END:

#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(134)
  expr$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds K=10 K.method=10 correctionByC=FALSE fast.only=FALSE n= L=50000 cs=0.1|0.2|0.4|0.6 cs.sum=FALSE sd.V.rho=1 rho.E=1 outlier.props=5e-04|0.005|0.01 ridge.lambda=1e-05 lasso.sparse.prop=0.05 nb.rep=4 "

#+begin_src R :results output :exports both
  pl <- Article3_MethodComparison_plot_relative_diff_AUC(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_auc_with_lasso_L5e4.png")
  pl <- Article3_MethodComparison_plot_GIF(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_gif_with_lasso_L5e4.png")
#+end_src

#+RESULTS:
[[./Rplots/NumericVal_auc_with_lasso_L5e4.png]]
[[./Rplots/NumericVal_gif_with_lasso_L5e4.png]]
#+begin_example
# A tibble: 48 × 5
   method outlier.prop `cor(U,X)`   rep       auc
    <chr>        <dbl>      <chr> <dbl>     <dbl>
1  Oracle        5e-04        0.1     1 0.9405889
2  Oracle        5e-04        0.1     2 0.9402349
3  Oracle        5e-04        0.1     3 0.9401196
4  Oracle        5e-04        0.1     4 0.9400257
5  Oracle        5e-04        0.2     1 0.9400108
6  Oracle        5e-04        0.2     2 0.9400122
7  Oracle        5e-04        0.2     3 0.9400716
8  Oracle        5e-04        0.2     4 0.9400251
9  Oracle        5e-04        0.4     1 0.9400155
10 Oracle        5e-04        0.4     2 0.9401116
# ... with 38 more rows
#+end_example

On a le bon message, plus il y a d'outlier moins acp+lm est puissant. Plus la
corrélation est forte moin lm est puissant. Sinon ils sont tout calibré a part
lm. FAMT on sait pas pour ca merde....

**** DONE with 2 5 10 % outlier and L = 50 000
CLOSED: [2017-06-06 mar. 09:26]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-06-06 mar. 09:26]
- State "STARTED"    from "TODO"       [2017-06-01 jeu. 18:26]
- State "TODO"       from "DONE"       [2017-06-01 jeu. 18:12]
:END:
***** DONE Run all even with lfmm lasso :D
CLOSED: [2017-06-06 mar. 09:07]
:LOGBOOK:
- Note taken on [2017-06-06 mar. 09:08] \\
  148
- State "DONE"       from "RUNNING"    [2017-06-06 mar. 09:07]
- Note taken on [2017-06-01 jeu. 18:27] \\
  16668.pts-8.krakenator
- Note taken on [2017-06-01 jeu. 18:20] \\
  6604.pts-0.patator
- State "RUNNING"    from "TODO"       [2017-06-01 jeu. 18:20]
- State "TODO"       from "DONE"       [2017-06-01 jeu. 18:13]
:END:

#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds"

  expr <- Article3_MethodComparison(G.file,
                                    outlier.props = c(0.01, 0.05, 0.1),
                                    n = NULL, L = 50000,
                                    K = 10,
                                    K.method = 10,
                                    lasso.sparse.prop = 0.05,
                                    ridge.lambda = 1e-5,
                                    cs = c(0.1, 0.2, 0.4, 0.6),
                                    cs.sum = FALSE,
                                    sd.V.rho = 1,
                                    nb.rep = 4,
                                    fast.only = FALSE,
                                    cluster.nb = 4,
                                    save = TRUE, bypass = FALSE)

#+end_src
***** DONE plot
CLOSED: [2017-06-06 mar. 09:21]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-06-06 mar. 09:21]
- State "TODO"       from "DONE"       [2017-06-01 jeu. 18:14]
:END:
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:

#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(148)
  expr$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds K=10 K.method=10 correctionByC=FALSE fast.only=FALSE n= L=50000 cs=0.1|0.2|0.4|0.6 cs.sum=FALSE sd.V.rho=1 rho.E=1 outlier.props=0.01|0.05|0.1 ridge.lambda=1e-05 lasso.sparse.prop=0.05 nb.rep=4 "


#+begin_src R :results output :exports both
  pl <- Article3_MethodComparison_plot_relative_diff_AUC(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_auc_with_lasso_L5e4_moreOutlier.png")
  pl <- Article3_MethodComparison_plot_GIF(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_gif_with_lasso_L5e4_moreOutlier.png")
#+end_src

#+RESULTS:
[[./Rplots/NumericVal_auc_with_lasso_L5e4_moreOutlier.png]]
[[./Rplots/NumericVal_gif_with_lasso_L5e4_moreOutlier.png]]
#+begin_example
# A tibble: 48 × 5
   method outlier.prop `cor(U,X)`   rep       auc
    <chr>        <dbl>      <chr> <dbl>     <dbl>
1  Oracle         0.01        0.1     1 0.9970106
2  Oracle         0.01        0.1     2 0.9970722
3  Oracle         0.01        0.1     3 0.9970173
4  Oracle         0.01        0.1     4 0.9970141
5  Oracle         0.01        0.2     1 0.9970641
6  Oracle         0.01        0.2     2 0.9970148
7  Oracle         0.01        0.2     3 0.9970192
8  Oracle         0.01        0.2     4 0.9970236
9  Oracle         0.01        0.4     1 0.9970304
10 Oracle         0.01        0.4     2 0.9970177
# ... with 38 more rows
#+end_example

*Remarks:*
- lasso lfmm est pas très bon avec p=0.1 et même p=0.5, c'est normal on a mis
  lasso proportion à 0.05 !!
- Tous le monde fait trop bien avec ces simu !!! on va changer la correlation
  entre X et U :D


**** DONE with p = 0.005 0.01 0.1 outlier and L = 50 000 and cor(X,U) = 0.6,0.4,0.2,0.1
CLOSED: [2017-06-09 ven. 16:15]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-06-09 ven. 16:15]
- State "STARTED"    from              [2017-06-06 mar. 09:26]
:END:
***** DONE Run all even with lfmm lasso :D
CLOSED: [2017-06-09 Ven 10:14]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-06-09 Ven 10:14]
- Note taken on [2017-06-06 mar. 09:32] \\
  28717.pts-4.krakenator
- State "RUNNING"    from "TODO"       [2017-06-06 mar. 09:32]
- State "TODO"       from              [2017-06-06 mar. 09:28]
:END:

#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds"

  expr <- Article3_MethodComparison(G.file,
                                    outlier.props = c(0.005, 0.01, 0.1),
                                    n = NULL, L = 50000,
                                    K = 10,
                                    K.method = 10,
                                    lasso.sparse.prop = 0.05,
                                    ridge.lambda = 1e-5,
                                    cs = list(c1 = c(0.6, 0.4, 0.2, 0.1)),
                                    cs.sum = FALSE,
                                    sd.V.rho = 1,
                                    nb.rep = 4,
                                    fast.only = FALSE,
                                    cluster.nb = 4,
                                    save = TRUE, bypass = FALSE)

#+end_src
***** DONE plot
CLOSED: [2017-06-09 ven. 16:15]
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-06-09 ven. 16:15]
- State "TODO"       from "WAITING"    [2017-06-09 Ven 10:14]
- State "WAITING"    from              [2017-06-06 mar. 09:28]
:END:

#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(151)
  expr$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds K=10 K.method=10 correctionByC=FALSE fast.only=FALSE n= L=50000 cs=c(0.6, 0.4, 0.2, 0.1) cs.sum=FALSE sd.V.rho=1 rho.E=1 outlier.props=0.005|0.01|0.1 ridge.lambda=1e-05 lasso.sparse.prop=0.05 nb.rep=4 "

#+begin_src R :results output :exports both
  pl <- Article3_MethodComparison_plot_relative_diff_AUC(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_auc_with_lasso_L5e4_CorOn4U.png")
  pl <- Article3_MethodComparison_plot_GIF(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_gif_with_lasso_L5e4_CorOn4U.png")
#+end_src

#+RESULTS:
[[./Rplots/NumericVal_auc_with_lasso_L5e4_CorOn4U.png]]
[[./Rplots/NumericVal_gif_with_lasso_L5e4_CorOn4U.png]]
#+begin_example
# A tibble: 12 × 5
   method outlier.prop      `cor(U,X)`   rep       auc
    <chr>        <dbl>           <chr> <dbl>     <dbl>
1  Oracle        0.005 0.6|0.4|0.2|0.1     1 0.9940107
2  Oracle        0.005 0.6|0.4|0.2|0.1     2 0.9940149
3  Oracle        0.005 0.6|0.4|0.2|0.1     3 0.9943613
4  Oracle        0.005 0.6|0.4|0.2|0.1     4 0.9940127
5  Oracle        0.010 0.6|0.4|0.2|0.1     1 0.9970173
6  Oracle        0.010 0.6|0.4|0.2|0.1     2 0.9970179
7  Oracle        0.010 0.6|0.4|0.2|0.1     3 0.9971932
8  Oracle        0.010 0.6|0.4|0.2|0.1     4 0.9970162
9  Oracle        0.100 0.6|0.4|0.2|0.1     1 0.9997203
10 Oracle        0.100 0.6|0.4|0.2|0.1     2 0.9997458
11 Oracle        0.100 0.6|0.4|0.2|0.1     3 0.9997103
12 Oracle        0.100 0.6|0.4|0.2|0.1     4 0.9997137
#+end_example

Rien de discriminant, toujours PCA et lm qui derive.

*** DONE Robustness to K choice
CLOSED: [2017-06-12 lun. 11:42]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-06-12 lun. 11:42]
- State "TODO"       from              [2017-06-06 mar. 09:35]
:END:
**** DONE with 2 5 10 % outlier and L = 50 000 K well estimated
CLOSED: [2017-06-12 lun. 11:41]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-06-12 lun. 11:41]
- State "TODO"       from              [2017-06-07 Mer 14:16]
:END:
***** DONE Run all even with lfmm lasso :D
CLOSED: [2017-06-12 lun. 11:27]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-06-12 lun. 11:27]
- Note taken on [2017-06-09 ven. 16:18] \\
  32517.pts-8.krakenator
- State "RUNNING"    from "DEBUG"      [2017-06-09 ven. 16:18]
- Note taken on [2017-06-09 Ven 10:12] \\
  ca a crash sur krak a cause de la mémoire ....
- State "DEBUG"      from "RUNNING"    [2017-06-09 Ven 10:12]
- Note taken on [2017-06-07 Mer 14:24] \\
  KWE
- State "RUNNING"    from              [2017-06-07 Mer 14:24]
:END:
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds"

  expr <- Article3_MethodComparison(G.file,
                                    outlier.props = c(0.01, 0.05, 0.1, 0.2, 0.3, 0.4),
                                    n = NULL, L = 50000,
                                    K = 5,
                                    K.method = 5,
                                    lasso.sparse.prop = 0.4,
                                    ridge.lambda = 1e-5,
                                    cs = list(c1 = c(0.6, 0.4, 0.2, 0.1, 0.05)),
                                    cs.sum = FALSE,
                                    sd.V.rho = 1,
                                    nb.rep = 4,
                                    fast.only = FALSE,
                                    cluster.nb = 2,
                                    save = TRUE, bypass = FALSE)

#+end_src
***** DONE plot
CLOSED: [2017-06-12 lun. 11:41]
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
:LOGBOOK:
- State "DONE"       from "WAITING"    [2017-06-12 lun. 11:41]
- State "WAITING"    from              [2017-06-07 Mer 14:25]
:END:

#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(154)
  expr$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds K=5 K.method=5 correctionByC=FALSE fast.only=FALSE n= L=50000 cs=c(0.6, 0.4, 0.2, 0.1, 0.05) cs.sum=FALSE sd.V.rho=1 rho.E=1 outlier.props=0.01|0.05|0.1|0.2|0.3|0.4 ridge.lambda=1e-05 lasso.sparse.prop=0.4 nb.rep=4 "


#+begin_src R :results output :exports both
  pl <- Article3_MethodComparison_plot_relative_diff_AUC(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_auc_with_lasso_L5e4_KWE.png")
  pl <- Article3_MethodComparison_plot_GIF(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_gif_with_lasso_L5e4_KWE.png")
#+end_src

#+RESULTS:
[[./Rplots/NumericVal_auc_with_lasso_L5e4_KWE.png]]
[[./Rplots/NumericVal_gif_with_lasso_L5e4_KWE.png]]
#+begin_example
# A tibble: 24 × 5
   method outlier.prop           `cor(U,X)`   rep       auc
    <chr>        <dbl>                <chr> <dbl>     <dbl>
1  Oracle         0.01 0.6|0.4|0.2|0.1|0.05     1 0.9970198
2  Oracle         0.01 0.6|0.4|0.2|0.1|0.05     2 0.9970179
3  Oracle         0.01 0.6|0.4|0.2|0.1|0.05     3 0.9970174
4  Oracle         0.01 0.6|0.4|0.2|0.1|0.05     4 0.9970153
5  Oracle         0.05 0.6|0.4|0.2|0.1|0.05     1 0.9994422
6  Oracle         0.05 0.6|0.4|0.2|0.1|0.05     2 0.9994182
7  Oracle         0.05 0.6|0.4|0.2|0.1|0.05     3 0.9994654
8  Oracle         0.05 0.6|0.4|0.2|0.1|0.05     4 0.9994129
9  Oracle         0.10 0.6|0.4|0.2|0.1|0.05     1 0.9997119
10 Oracle         0.10 0.6|0.4|0.2|0.1|0.05     2 0.9997287
# ... with 14 more rows
#+end_example



**** DONE with 2 5 10 % outlier and L = 50 000 K over estimated
CLOSED: [2017-06-12 lun. 11:41]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-06-12 lun. 11:41]
- State "TODO"       from              [2017-06-07 Mer 14:16]
:END:
***** DONE Run all even with lfmm lasso :D
CLOSED: [2017-06-12 lun. 11:02]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-06-12 lun. 11:02]
- State "RUNNING"    from "TODO"       [2017-06-09 ven. 16:20]
- Note taken on [2017-06-09 ven. 16:19] \\
  32585.pts-11.krakenator
- State "TODO"       from "DONE"       [2017-06-09 ven. 16:18]
- State "DONE"       from "RUNNING"    [2017-06-09 Ven 10:09]
- Note taken on [2017-06-07 Mer 14:28] \\
  KOW
- State "RUNNING"    from              [2017-06-07 Mer 14:28]
:END:
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds"

  expr <- Article3_MethodComparison(G.file,
                                    outlier.props = c(0.01, 0.05, 0.1, 0.2, 0.3, 0.4),
                                    n = NULL, L = 50000,
                                    K = 5,
                                    K.method = 10,
                                    lasso.sparse.prop = 0.4,
                                    ridge.lambda = 1e-5,
                                    cs = list(c1 = c(0.6, 0.4, 0.2, 0.1, 0.05)),
                                    cs.sum = FALSE,
                                    sd.V.rho = 1,
                                    nb.rep = 4,
                                    fast.only = FALSE,
                                    cluster.nb = 2,
                                    save = TRUE, bypass = FALSE)

#+end_src
***** DONE plot
CLOSED: [2017-06-12 lun. 11:41]
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-06-12 lun. 11:41]
- State "TODO"       from "DONE"       [2017-06-09 Ven 10:09]
- State "DONE"       from "WAITING"    [2017-06-09 Ven 10:09]
- Note taken on [2017-06-09 Ven 10:09] \\
  id = 152
- State "WAITING"    from              [2017-06-07 Mer 14:28]
:END:

#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(153)
  expr$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds K=5 K.method=10 correctionByC=FALSE fast.only=FALSE n= L=50000 cs=c(0.6, 0.4, 0.2, 0.1, 0.05) cs.sum=FALSE sd.V.rho=1 rho.E=1 outlier.props=0.01|0.05|0.1|0.2|0.3|0.4 ridge.lambda=1e-05 lasso.sparse.prop=0.4 nb.rep=4 "


#+begin_src R :results output :exports both
  pl <- Article3_MethodComparison_plot_relative_diff_AUC(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_auc_with_lasso_L5e4_KOE.png")
  pl <- Article3_MethodComparison_plot_GIF(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_gif_with_lasso_L5e4_KOE.png")
#+end_src

#+RESULTS:
[[./Rplots/NumericVal_auc_with_lasso_L5e4_KOE.png]]
[[./Rplots/NumericVal_gif_with_lasso_L5e4_KOE.png]]
#+begin_example
# A tibble: 24 × 5
   method outlier.prop           `cor(U,X)`   rep       auc
    <chr>        <dbl>                <chr> <dbl>     <dbl>
1  Oracle         0.01 0.6|0.4|0.2|0.1|0.05     1 0.9970131
2  Oracle         0.01 0.6|0.4|0.2|0.1|0.05     2 0.9970106
3  Oracle         0.01 0.6|0.4|0.2|0.1|0.05     3 0.9970198
4  Oracle         0.01 0.6|0.4|0.2|0.1|0.05     4 0.9970247
5  Oracle         0.05 0.6|0.4|0.2|0.1|0.05     1 0.9994148
6  Oracle         0.05 0.6|0.4|0.2|0.1|0.05     2 0.9994308
7  Oracle         0.05 0.6|0.4|0.2|0.1|0.05     3 0.9994177
8  Oracle         0.05 0.6|0.4|0.2|0.1|0.05     4 0.9994423
9  Oracle         0.10 0.6|0.4|0.2|0.1|0.05     1 0.9997821
10 Oracle         0.10 0.6|0.4|0.2|0.1|0.05     2 0.9997262
# ... with 14 more rows
Error in save_plot_timc_bcm_15(pl, "NumericVal_auc_with_lasso_L5e4_KOE.png") (from utils.R#75) : 
  file exists
#+end_example


**** DONE with 2 5 10 % outlier and L = 50 000 K under estimated
CLOSED: [2017-06-12 lun. 11:41]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-06-12 lun. 11:41]
- State "TODO"       from              [2017-06-07 Mer 14:16]
:END:
***** DONE Run all even with lfmm lasso :D
CLOSED: [2017-06-12 lun. 10:45]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-06-12 lun. 10:45]
- Note taken on [2017-06-09 ven. 16:21] \\
  32674.pts-14.krakenator
- State "RUNNING"    from "DEBUG"      [2017-06-09 ven. 16:20]
- Note taken on [2017-06-09 Ven 10:11] \\
  ca a craché sur krakenator, mais c'est juste un problème avec la mémoire !
  faudra le relancer.
- State "DEBUG"      from "DONE"       [2017-06-09 Ven 10:11]
- State "DONE"       from "RUNNING"    [2017-06-09 Ven 10:10]
- Note taken on [2017-06-07 Mer 14:30] \\
  KUE
- State "RUNNING"    from              [2017-06-07 Mer 14:30]
:END:
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds"

  expr <- Article3_MethodComparison(G.file,
                                    outlier.props = c(0.01, 0.05, 0.1, 0.2, 0.3, 0.4),
                                    n = NULL, L = 50000,
                                    K = 5,
                                    K.method = 3,
                                    lasso.sparse.prop = 0.4,
                                    ridge.lambda = 1e-5,
                                    cs = list(c1 = c(0.6, 0.4, 0.2, 0.1, 0.05)),
                                    cs.sum = FALSE,
                                    sd.V.rho = 1,
                                    nb.rep = 4,
                                    fast.only = FALSE,
                                    cluster.nb = 2,
                                    save = TRUE, bypass = FALSE)

#+end_src
***** DONE plot
CLOSED: [2017-06-12 lun. 11:02]
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
:LOGBOOK:
- State "DONE"       from "WAITING"    [2017-06-12 lun. 11:02]
- State "WAITING"    from              [2017-06-07 Mer 14:30]
:END:

#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(155)
  expr$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds K=5 K.method=3 correctionByC=FALSE fast.only=FALSE n= L=50000 cs=c(0.6, 0.4, 0.2, 0.1, 0.05) cs.sum=FALSE sd.V.rho=1 rho.E=1 outlier.props=0.01|0.05|0.1|0.2|0.3|0.4 ridge.lambda=1e-05 lasso.sparse.prop=0.4 nb.rep=4 "


#+begin_src R :results output :exports both
  pl <- Article3_MethodComparison_plot_relative_diff_AUC(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_auc_with_lasso_L5e4_KUE.png")
  pl <- Article3_MethodComparison_plot_GIF(expr)
  save_plot_timc_bcm_15(pl, "NumericVal_gif_with_lasso_L5e4_KUE.png")
#+end_src

#+RESULTS:
[[./Rplots/NumericVal_auc_with_lasso_L5e4_KUE.png]]
[[./Rplots/NumericVal_gif_with_lasso_L5e4_KUE.png]]
#+begin_example
# A tibble: 24 × 5
   method outlier.prop           `cor(U,X)`   rep       auc
    <chr>        <dbl>                <chr> <dbl>     <dbl>
1  Oracle         0.01 0.6|0.4|0.2|0.1|0.05     1 0.9970335
2  Oracle         0.01 0.6|0.4|0.2|0.1|0.05     2 0.9970476
3  Oracle         0.01 0.6|0.4|0.2|0.1|0.05     3 0.9970142
4  Oracle         0.01 0.6|0.4|0.2|0.1|0.05     4 0.9970716
5  Oracle         0.05 0.6|0.4|0.2|0.1|0.05     1 0.9994106
6  Oracle         0.05 0.6|0.4|0.2|0.1|0.05     2 0.9995337
7  Oracle         0.05 0.6|0.4|0.2|0.1|0.05     3 0.9994458
8  Oracle         0.05 0.6|0.4|0.2|0.1|0.05     4 0.9994209
9  Oracle         0.10 0.6|0.4|0.2|0.1|0.05     1 0.9997133
10 Oracle         0.10 0.6|0.4|0.2|0.1|0.05     2 0.9997141
# ... with 14 more rows
#+end_example

**** conclusion
c'est pas avec ce jeu de données que je vais reussir à faire la différence entre
les méthodes... Lasso merde mais je sais pas trop pk..

*** TODO =FromTrueSampler2=
:LOGBOOK:
- State "TODO"       from              [2017-06-13 mar. 10:54]
:END:

**** STARTED run
:LOGBOOK:
- Note taken on [2017-06-14 mer. 08:23] \\
  je joue avec les params
- State "STARTED"    from "RUNNING"    [2017-06-14 mer. 08:23]
- State "RUNNING"    from              [2017-06-13 mar. 12:13]
:END:
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA_sampleL100000.rds"
  pca.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA_sampleL100000_PCA.rds"

  K <- 5
  ## sample cs such that Sigma si positives
  cs <- cs_sampler(K)
  s <- FromTrueSampler2(G.file = G.file,
                        K = K,
                        pca.file = pca.file,
                        prop.outlier = 0.2,
                        cs = cs,
                        n = NULL, L = 10000,
                        rho.B = 1.0)
  expr <- Article3_MethodComparison(G.file,
                                    outlier.props = c( 0.1, 0.2, 0.3),
                                    K = K,
                                    n = s$n,
                                    L = s$L,
                                    K.method = K,
                                    lasso.sparse.prop = 0.4,
                                    ridge.lambda = 1e-5,
                                    cs = list(c1 = cs),
                                    cs.sum = FALSE,
                                    nb.rep = 4,
                                    fast.only = TRUE,
                                    cluster.nb = 4,
                                    s = s,
                                    save = FALSE, bypass = FALSE)


#+end_src
** Dataset
How dataset in ./Data/ was generated. Some script and urls...
*** ./Data/SSMPG2015/ 
Dataset simulated by Katie Lotterhos for the school SSMPG2015
*** ./Data/MathieuGautier/
Dataset used in *Genome scan methods against more complex models: when and how much should we trust them?* of piere de villemereuil et al.
**** CANCELLED Convert 
CLOSED: [2017-05-17 mer. 15:40]
:LOGBOOK:
- State "CANCELLED"  from "TODO"       [2017-05-17 mer. 15:40]
:END:
.csv into .RData
**** =mec12705-sup-0002-Pythonscripts/=
Python script that generated dataset 
**** Monogenic
I find this in an older .Rmd in my first LFMM project of 2016
#+BEGIN_SRC R
 outlier = c(546) # for monogenic
#+END_SRC

**** Polygenic
I find this in an older .Rmd in my first LFMM project of 2016
#+BEGIN_SRC R 
 outlier = c(2793,1850,583,4083,3349,860,4785,706,947,939,1819,925,403,2867,2897,97,3102,2618,708,1190,2471,1533,3924,2395,2690,2926,1511,668,4826,4755,638,4148,1777,1869,2252,4326,397,3416,3171,2451,1233,2055,3013,3202,1055,3484,2984,2145,4547,4831) + 1
#+END_SRC
*** ./Data/AthalianaGegMapLines/
- Data download from: http://bergelson.uchicago.edu/?page_id=790
- [[http://bergelson.uchicago.edu/wp-content/uploads/2015/04/call_method_75.tar.gz][download the data]]
  There are data I used in TESS3 second article
  
*** ./Data/1000Genomes/
**** ./Data/1000Genomes/Phase3Chrm22/
Phase 3 version of the 1000 genome, only the chromosom 22. I ddl the vcf
file [[ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/][here]]
- ddl file: 
  #+BEGIN_SRC bash
     curl -O ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
     curl -O ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel
  #+END_SRC
    
  - ddl all chromosom:
    #+BEGIN_SRC R
      ids <- 1:22
      for (i in ids) {
        url <- paste0("ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr", i, ".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz")
        system(paste("curl -O",url))
      }
    #+END_SRC

  - zip and unzip
    #+BEGIN_SRC bash
    gzip ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
    gzip ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf     
    #+END_SRC
***** Eu_Af_Afam.maf.05.rds

A dataset with only European, African and Aro-american population. We also fiter
maf at 5%.

#+begin_src R :results output :exports both
  ## data set with African European and AfroAmerican

  ## libs
  library(ThesisRpackage)
  library(tidyverse)
  library(crayon)
  options(ThesisRpackage.debug = "TRUE")

  ## read indiv informations
  indiv <- read_delim("~/Projects/Thesis/Data/1000Genomes/Phase3/integrated_call_samples_v3.20130502.ALL.panel",
                      delim = "\t",
                      skip = 1,
                      col_names = FALSE)
  names(indiv) <- c("sample", "pop", "super_pop","gender")

  ## saveRDS(indiv, "~/Projects/Thesis/Data/1000Genomes/Phase3/indiv_df.rds")

  unique(indiv %>% select(super_pop))

  Eu <- c("TSI", "GBR")
  Af <- c("ASW")
  Afam <- c("YRI", "LWK")

  ## indiv
  indiv.index <- which(indiv$pop %in% c(Eu, Af, Afam))


  ## read data
  maf.threshold <- 0.05
  ploidy <- 2
  ### list files
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.maf.05.rds$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)


  dat <- list()
  for (f in files) {
    cat(green(paste0("== reading ",f,"\n")))

    ## read file
    dat.aux <- readRDS(f)

    ## filter indiv
    dat.aux$G <- dat.aux$G[indiv.index,]

    ## filter maf
    maf <- apply(dat.aux$G, 2, function(locus) {p <- mean(locus, na.rm = TRUE) / ploidy; min(p, 1 - p)})
    cat(green(paste0("Removing ", mean(maf <= maf.threshold),"% loci\n")))
    dat.aux$G <- dat.aux$G[,maf > maf.threshold, drop = FALSE]
    dat.aux$snps.info <- dat.aux$snps.info[maf > maf.threshold,]


    ## bind
    dat$G <- cbind(dat$G, dat.aux$G)
    dat$snps.info <- rbind(dat$snps.info, dat.aux$snps.info)

    cat(green(paste0("== ncol ",ncol(dat$G),"\n")))
  }

  ## subsample ?

  ## coord of indiv
  dat$indiv <- indiv[indiv.index,]
  dat$coord <- matrix(NA, nrow = nrow(dat$indiv), ncol = 2)

  ## map: https://www.coordonnees-gps.fr/
  ## pops: http://www.internationalgenome.org/category/population/
  aux <- function(dat, pop, coord) {
    aux.indiv <- dat$indiv$pop == pop
    dat$coord[aux.indiv,] <- matrix(coord,sum(aux.indiv),2, byrow = TRUE)
    dat
  }
  ## Toscani in Italia
  dat <- aux(dat, "TSI", c(11.25581360000001, 43.7695604)) ## florance
  ## British in England and Scotland
  dat <- aux(dat, "GBR", c(-2.2426305000000184, 53.4807593)) ## manchester
  ## Americans of African Ancestry in SW USA
  dat <- aux(dat, "ASW", c(-122.41941550000001, 37.7749295)) ## san francisco
  ## Yoruba in Ibadan, Nigeria
  dat <- aux(dat, "YRI", c(3.947039600000039,7.377535500000001)) ## Idaban
  ## Luhya in Webuye, Kenya
  dat <- aux(dat, "LWK", c(34.77960299999995, 0.5992059)) ## Webuye

  ## check
  assertthat::assert_that(mean(rownames(dat$G) == dat$indiv$sample) == 1)

  ## compute a W matrix
  dat$dist.matrix <- geosphere::distm(dat$coord) ## geodesic on hearth
  sigma <- mean(dat$dist.matrix) * 0.05 ## tess3 default param
  dat$W <- exp( -dat$dist.matrix ^ 2 / sigma / sigma)

  saveRDS(dat, "Eu_Af_Afam.maf.05.rds")

#+end_src
***** FromVcfToRds

Conversion of =.vcf= into R data format =.R=.

#+begin_src R :results output :exports both
  # libs
  library(ThesisRpackage)
  library(tidyverse)
  library(crayon)
  options(ThesisRpackage.debug = "TRUE")

  ## We filter maf to 0.05%
  maf.threshold <- 0.05

  ### list files
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)


  for (f in files) {
    cat(green(paste0("== reading ",f,"\n")))

    ## read file
    dat.aux <- read_vcf(f = f, maf.threshold = maf.threshold, block.size = 1e5)

    ### save in rds format
    saveRDS(dat.aux, sub("\\.vcf$", ".maf.05.rds", f))
    rm(dat.aux)
    gc()
  }
#+end_src
***** Eu_Af_Afam_to_geno

Create a =.geno= format file.

#+begin_src R :results output :exports both
  dat <- readRDS("~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.maf.05.rds")
  X <- t(dat$G)
  rm(dat)
  gc()
  file.remove("~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.maf.05.geno")
  chunks <- split(1:nrow(X), ceiling(1:nrow(X) / 5e5))
  for (c in chunks) {
    write.table(X[c,], file = "~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.maf.05.geno",
                sep = "",
                row.names = FALSE,
                col.names = FALSE, append = TRUE)
  }

  ## write G.geno
  dat <- readRDS("~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.maf.05.rds")
  dat$G.geno <- "~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.maf.05.geno"
  saveRDS(dat, "~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.maf.05.rds")
#+end_src
***** European_Chrm22

A dataset with only European and chromosome 22, maf filter to 5%.

#+begin_src R :results output :exports both
  # We want to extract a snips matrix with only european

  # libs
  library(tidyverse)

  # read indiv informations
  indiv <- read_delim("./integrated_call_samples_v3.20130502.ALL.panel",
                      delim = "\t",
                      skip = 1,
                      col_names = FALSE)

  names(indiv) <- c("sample", "pop", "super_pop","gender")

  unique(indiv %>% select(super_pop))
  unique(indiv[indiv$super_pop == "EUR","pop"])
  EUR.index <- which(indiv$super_pop == "EUR")
  length(EUR.index)


  ## read dataset
  dat <- readRDS("ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.maf.05.rds")

  # keep only europe
  # geno.EUR <- matrix(as.raw(geno[EUR.index,]),
  #                    nrow = length(EUR.index),
  #                    ncol = ncol(geno))
  G.EUR <- dat$G[EUR.index,]

  # Filter
  ## maf > 0.05 %
  maf <- apply(G.EUR, 2, function(locus) {p <- mean(locus) / 2; min(p, 1 - p)})
  maf.threshold <- 0.05
  mean(maf <= maf.threshold)
  filtered.index <- (maf > maf.threshold)
  G.EUR.filtered <- G.EUR[,filtered.index]

  # names con and row
  ## already set
  #rownames(G.EUR.filtered) <- indiv$sample[EUR.index]
  #colnames(G.EUR.filtered) <- snps.info$X3[filtered.index]

  # save
  saveRDS(G.EUR.filtered, file = "European_Chrm22.maf.05.rds")
#+end_src
***** DONE Data preprocessing with plink
CLOSED: [2017-05-30 mar. 17:53]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-30 mar. 17:53]
- State "STARTED"    from "TODO"       [2017-05-17 mer. 15:38]
- Note taken on [2017-05-17 mer. 15:37] \\
  On va faire les chose proprement avec plink ! ca a l'air de bien tourner, du
  coup tout le preprocess on va le faire a vec plink et bigsnpr :D
- State "TODO"       from              [2017-05-17 mer. 15:32]
:END:
****** DONE Quality controle
CLOSED: [2017-05-18 jeu. 09:12]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-18 jeu. 09:12]
- Note taken on [2017-05-17 mer. 16:52] \\
  14722.pts-1.krakenator
- State "RUNNING"    from              [2017-05-17 mer. 16:52]
:END:
#+begin_src R :results output :exports both
  ## file list
  setwd("~/Projects/Thesis/Data/1000Genomes/Phase3/")

  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)

  maf <- 0.05
  mind <- 0.05
  hwe <- 1e-10
  geno <- 0.05
  for (f in files) {
    cmd <- paste("plink",
                 "--vcf", f,
                 "--maf", maf,
                 "--mind", mind,
                 "--geno", geno,
                 "--hwe", hwe,
                 "--snps-only",
                 "--autosome",
                 "--make-bed",
                 "--out", paste0("./plink/", sub(".vcf.gz", "",f)),
                 ">> plink_GC.out")

    system("rm -f plink_QC.out")
    system(cmd)

  }
#+end_src

#+begin_src shell :session *ssh krakenator* :results output :exports both 
  cd ~/Projects/Thesis/Data/1000Genomes/Phase3/plink/
  for f in ALL.chr*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log
  do
      echo "=====FILE:$f====="
      cat "$f"
  done
#+end_src

#+RESULTS:
#+begin_example

> > > > =====FILE:ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 16:51:39 2017

Random number seed: 1495032699
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
3837178 out of 3992219 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999945.
806 variants removed due to missing genotype data (--geno).
--hwe: 75986 variants removed due to Hardy-Weinberg exact test.
3481563 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
278823 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 16:55:55 2017
=====FILE:ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 16:55:55 2017

Random number seed: 1495032955
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
3891530 out of 4045628 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999947.
747 variants removed due to missing genotype data (--geno).
--hwe: 74342 variants removed due to Hardy-Weinberg exact test.
3548109 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
268332 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:00:10 2017
=====FILE:ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:00:10 2017

Random number seed: 1495033210
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
3710299 out of 3868428 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999954.
657 variants removed due to missing genotype data (--geno).
--hwe: 73200 variants removed due to Hardy-Weinberg exact test.
3377092 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
259350 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:04:16 2017
=====FILE:ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:04:16 2017

Random number seed: 1495033456
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2737034 out of 2857916 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999951.
497 variants removed due to missing genotype data (--geno).
--hwe: 52494 variants removed due to Hardy-Weinberg exact test.
2484161 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
199882 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:07:18 2017
=====FILE:ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:07:18 2017

Random number seed: 1495033638
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2548064 out of 2655067 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999952.
479 variants removed due to missing genotype data (--geno).
--hwe: 53291 variants removed due to Hardy-Weinberg exact test.
2320025 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
174269 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:10:07 2017
=====FILE:ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:10:07 2017

Random number seed: 1495033807
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2328557 out of 2424689 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999948.
434 variants removed due to missing genotype data (--geno).
--hwe: 51148 variants removed due to Hardy-Weinberg exact test.
2123668 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
153307 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:12:41 2017
=====FILE:ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:12:41 2017

Random number seed: 1495033961
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2607034 out of 2697949 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999947.
518 variants removed due to missing genotype data (--geno).
--hwe: 51346 variants removed due to Hardy-Weinberg exact test.
2387326 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
167844 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:15:30 2017
=====FILE:ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:15:30 2017

Random number seed: 1495034130
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2234710 out of 2329288 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999951.
413 variants removed due to missing genotype data (--geno).
--hwe: 46649 variants removed due to Hardy-Weinberg exact test.
2044443 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
143205 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:17:58 2017
=====FILE:ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:17:58 2017

Random number seed: 1495034278
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2178759 out of 2267185 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999949.
392 variants removed due to missing genotype data (--geno).
--hwe: 39690 variants removed due to Hardy-Weinberg exact test.
1980142 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
158535 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:20:20 2017
=====FILE:ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:20:20 2017

Random number seed: 1495034420
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
1758443 out of 1832506 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999942.
402 variants removed due to missing genotype data (--geno).
--hwe: 36837 variants removed due to Hardy-Weinberg exact test.
1591671 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
129533 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:22:17 2017
=====FILE:ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 16:44:50 2017

Random number seed: 1495032290
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
6216035 out of 6468094 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999953.
1033 variants removed due to missing genotype data (--geno).
--hwe: 128213 variants removed due to Hardy-Weinberg exact test.
5676255 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
410534 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 16:51:39 2017
=====FILE:ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:29:40 2017

Random number seed: 1495034980
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
1745171 out of 1812841 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999959.
278 variants removed due to missing genotype data (--geno).
--hwe: 35426 variants removed due to Hardy-Weinberg exact test.
1592817 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
116650 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:31:43 2017
=====FILE:ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:31:43 2017

Random number seed: 1495035103
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
1058549 out of 1105538 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999928.
279 variants removed due to missing genotype data (--geno).
--hwe: 23191 variants removed due to Hardy-Weinberg exact test.
956556 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
78523 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:32:53 2017
=====FILE:ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:32:53 2017

Random number seed: 1495035173
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
1059735 out of 1103547 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999946.
222 variants removed due to missing genotype data (--geno).
--hwe: 25833 variants removed due to Hardy-Weinberg exact test.
960163 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
73517 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:34:01 2017
=====FILE:ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:22:17 2017

Random number seed: 1495034537
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
6808742 out of 7081600 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999954.
1184 variants removed due to missing genotype data (--geno).
--hwe: 138884 variants removed due to Hardy-Weinberg exact test.
6233305 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
435369 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:29:40 2017
=====FILE:ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:34:01 2017

Random number seed: 1495035241
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
5603261 out of 5832276 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999949.
1069 variants removed due to missing genotype data (--geno).
--hwe: 111493 variants removed due to Hardy-Weinberg exact test.
5104864 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
385835 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:40:14 2017
=====FILE:ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:40:14 2017

Random number seed: 1495035614
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
5500093 out of 5732585 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999948.
1080 variants removed due to missing genotype data (--geno).
--hwe: 115329 variants removed due to Hardy-Weinberg exact test.
4985272 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
398412 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:46:21 2017
=====FILE:ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:46:21 2017

Random number seed: 1495035981
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
5055536 out of 5265763 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999953.
909 variants removed due to missing genotype data (--geno).
--hwe: 91958 variants removed due to Hardy-Weinberg exact test.
4620648 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
342021 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:51:47 2017
=====FILE:ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:51:47 2017

Random number seed: 1495036307
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
4816881 out of 5024119 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999935.
1292 variants removed due to missing genotype data (--geno).
--hwe: 101026 variants removed due to Hardy-Weinberg exact test.
4346787 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
367776 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:57:03 2017
=====FILE:ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:57:03 2017

Random number seed: 1495036623
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
4533180 out of 4716715 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.99995.
842 variants removed due to missing genotype data (--geno).
--hwe: 87612 variants removed due to Hardy-Weinberg exact test.
4119828 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
324898 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 18:01:58 2017
=====FILE:ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 18:01:58 2017

Random number seed: 1495036918
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
4434371 out of 4597105 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999944.
921 variants removed due to missing genotype data (--geno).
--hwe: 90154 variants removed due to Hardy-Weinberg exact test.
4048413 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
294883 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 18:06:48 2017
=====FILE:ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 18:06:48 2017

Random number seed: 1495037208
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
3427241 out of 3560687 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999948.
689 variants removed due to missing genotype data (--geno).
--hwe: 68557 variants removed due to Hardy-Weinberg exact test.
3121045 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
236950 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 18:10:32 2017
#+end_example

****** DONE Merge bep file
CLOSED: [2017-05-18 jeu. 10:10]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-18 jeu. 10:10]
- Note taken on [2017-05-18 jeu. 09:22] \\
  see: http://zzz.bwh.harvard.edu/plink/dataman.shtml#merge
- State "TODO"       from              [2017-05-17 mer. 17:05]
:END:

******* Remove multiple allele name
#+begin_src R :results output :exports both
  setwd("~/Projects/Thesis/Data/1000Genomes/Phase3/plink/")

  ## list prefix
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)
  prefix <- sub(pattern = ".bed", replacement = "", files)

  ## exclude variant
  write("rs6658405\n.\nrs145926341\nrs141927528" , file = "excluded_variant.txt")

  for (f in prefix) {
    cmd <- paste("plink",
                 "--bfile", f,
                 "--exclude excluded_variant.txt",
                   "--make-bed",
                 "--out", paste0(f, "_excluded"))
    system(cmd)
  }
#+end_src

#+begin_src shell :session *ssh krakenator* :results output :exports both 
  grep "rs6658405" -R *_excluded.bim
  grep "\." -R *_excluded.bim
  grep "rs145926341" -R *_excluded.bim
  grep "rs141927528" -R *_excluded.bim
#+end_src

#+RESULTS:
: ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_excluded.bim:16	rs66584058	0	25445314	G	A
: ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_excluded.bim:5	rs66584056	0	36516119	T	A


******* Merge
#+begin_src R :results output :exports both
  setwd("~/Projects/Thesis/Data/1000Genomes/Phase3/plink/")

  ## list prefix
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_excluded.bed$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)
  prefix <- sub(pattern = ".bed", replacement = "", files)


  ## create list of file
  prefix1 <- prefix[1]
  prefix <- prefix[-1]
  list.file <- tempfile(tmpdir=".", fileext=".txt")
  for (p in prefix) {
    line <- paste(paste0(p, ".bed"), paste0(p, ".bim"), paste0(p, ".fam"))
    write(line, list.file, append = TRUE)
  }

    ## cmd
  cmd <- paste("plink",
               "--bfile",
               prefix1,
               "--merge-list",
               list.file,
               "--make-bed --out", "1000GenomePhase3_QC")

  system(cmd)
#+end_src

#+begin_src shell :session *ssh krakenator* :results output :exports both 
  cat 1000GenomePhase3_QC.log
#+end_src

#+RESULTS:
#+begin_example
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_excluded
  --make-bed
  --merge-list ./file290c4546eae6.txt
  --out 1000GenomePhase3_QC

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/plink
Start time: Thu May 18 09:55:14 2017

Random number seed: 1495094114
193793 MB RAM detected; reserving 96896 MB for main workspace.
Performing single-pass merge (2504 people, 5398440 variants).
Merged fileset written to 1000GenomePhase3_QC-merge.bed +
1000GenomePhase3_QC-merge.bim + 1000GenomePhase3_QC-merge.fam .
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to 1000GenomePhase3_QC.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to 1000GenomePhase3_QC.bed + 1000GenomePhase3_QC.bim +
1000GenomePhase3_QC.fam ... done.

End time: Thu May 18 09:57:32 2017
#+end_example

****** DONE Remove correlated indiv
CLOSED: [2017-05-18 jeu. 10:43]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-18 jeu. 10:43]
- State "TODO"       from              [2017-05-17 mer. 17:05]
:END:
#+begin_src R :results output :exports both
  library(bigsnpr)
  setwd("~/Projects/Thesis/Data/1000Genomes/Phase3/plink")
  plink <- "/home/cayek/BiocompSoftware/plink/plink"
  bedfileQC <- "1000GenomePhase3_QC.bed"
  rel <- snp_plinkIBDQC(plink, bedfileQC, ncores = 4,
                        bedfile.out = sub("\\.bed$", "_norel.bed", bedfileQC),
                        pruning.args = NULL,
                        do.blind.QC = TRUE)

  bedfileQC2 <- snp_plinkRmSamples(
    plink, 
    bedfile.in = bedfileQC, 
    bedfile.out = sub("\\.bed$", "_norel.bed", bedfileQC), 
    df.or.files = subset(rel, PI_HAT > 0.08)
    )
  print(bedfileQC2)
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_QC.log.
  Options in effect:
    --bfile 1000GenomePhase3_QC
    --genome
    --min 0.08
    --out 1000GenomePhase3_QC
    --threads 4

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_QC.nosex .
  Using up to 4 threads (change this with --threads).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  IBD calculations complete.  
  Finished writing 1000GenomePhase3_QC.genome .
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_QC_norel.log.
  Options in effect:
    --bfile 1000GenomePhase3_QC
    --make-bed
    --out 1000GenomePhase3_QC_norel
    --remove /home/cayek/tmp/RtmpVBcWMh/file577662272180

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_QC_norel.nosex .
  --remove: 919 people remaining.
  Warning: At least 146315 duplicate IDs in --remove file.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 919 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate in remaining samples is 0.999923.
  5398440 variants and 919 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_QC_norel.bed + 1000GenomePhase3_QC_norel.bim +
  1000GenomePhase3_QC_norel.fam ... done.
#+end_example
Remark: Il des duplica dans le fichier des idiv a enlever, pk?

****** DONE LD prunning/clumping
CLOSED: [2017-05-18 jeu. 13:10]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-18 jeu. 13:10]
- Note taken on [2017-05-18 jeu. 11:15] \\
  ATTENTION: j'ai merdé j'ai ecrasé 1000GenomePhase3_QC !!
- State "RUNNING"    from "TODO"       [2017-05-18 jeu. 10:46]
- State "TODO"       from              [2017-05-17 mer. 17:06]
:END:

LD prunning with plink
#+begin_src shell :results output :exports both 
  cd ~/Projects/Thesis/Data/1000Genomes/Phase3/plink/
  plink --bfile 1000GenomePhase3_QC_norel --indep-pairwise 100 1 0.2 --out 1000GenomePhase3_QC_norel --threads 8
  plink --bfile 1000GenomePhase3_QC_norel --extract 1000GenomePhase3_QC_norel.prune.in --make-bed --out 1000GenomePhase3_QC_norel_prunned --threads 8
#+end_src

#+RESULTS:
#+begin_example
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile 1000GenomePhase3_QC_norel
  --indep-pairwise 100 1 0.2
  --out 1000GenomePhase3_QC_norel
  --threads 8

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/plink
Start time: Thu May 18 10:54:56 2017

Random number seed: 1495097696
193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
919 people (0 males, 0 females, 919 ambiguous) loaded from .fam.
Ambiguous sex IDs written to 1000GenomePhase3_QC_norel.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 919 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999923.
5398440 variants and 919 people pass filters and QC.
Note: No phenotypes present.
Pruned 383736 variants from chromosome 1, leaving 26796.
Pruned 409231 variants from chromosome 2, leaving 26138.
Pruned 362671 variants from chromosome 3, leaving 23164.
Pruned 376046 variants from chromosome 4, leaving 22366.
Pruned 321739 variants from chromosome 5, leaving 20282.
Pruned 346793 variants from chromosome 6, leaving 20983.
Pruned 305297 variants from chromosome 7, leaving 19601.
Pruned 277248 variants from chromosome 8, leaving 17633.
Pruned 221055 variants from chromosome 9, leaving 15895.
Pruned 261309 variants from chromosome 10, leaving 17514.
Pruned 252249 variants from chromosome 11, leaving 16083.
Pruned 242441 variants from chromosome 12, leaving 16907.
Pruned 187619 variants from chromosome 13, leaving 12263.
Pruned 162678 variants from chromosome 14, leaving 11591.
Pruned 141956 variants from chromosome 15, leaving 11349.
Pruned 155359 variants from chromosome 16, leaving 12485.
Pruned 131431 variants from chromosome 17, leaving 11774.
Pruned 147368 variants from chromosome 18, leaving 11167.
Pruned 119426 variants from chromosome 19, leaving 10107.
Pruned 107554 variants from chromosome 20, leaving 9096.
Pruned 72900 variants from chromosome 21, leaving 5623.
Pruned 67178 variants from chromosome 22, leaving 6339.
Pruning complete.  5053284 of 5398440 variants removed.
Marker lists written to 1000GenomePhase3_QC_norel.prune.in and
1000GenomePhase3_QC_norel.prune.out .

End time: Thu May 18 10:55:08 2017

PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to 1000GenomePhase3_QC_norel_prunned.log.
Options in effect:
  --bfile 1000GenomePhase3_QC_norel
  --extract 1000GenomePhase3_QC_norel.prune.in
  --make-bed
  --out 1000GenomePhase3_QC_norel_prunned
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
919 people (0 males, 0 females, 919 ambiguous) loaded from .fam.
Ambiguous sex IDs written to 1000GenomePhase3_QC_norel_prunned.nosex .
--extract: 345156 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 919 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999904.
345156 variants and 919 people pass filters and QC.
Note: No phenotypes present.
--make-bed to 1000GenomePhase3_QC_norel_prunned.bed +
1000GenomePhase3_QC_norel_prunned.bim + 1000GenomePhase3_QC_norel_prunned.fam
... done.

#+end_example

****** DONE Convert the dataset into bigmatrix
CLOSED: [2017-05-18 jeu. 11:17]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-18 jeu. 11:17]
- State "TODO"       from "DONE"       [2017-05-18 jeu. 10:57]
- State "DONE"       from "STARTED"    [2017-05-18 jeu. 10:45]
- State "STARTED"    from "DONE"       [2017-05-18 jeu. 10:43]
- State "TODO"       from              [2017-05-17 mer. 17:13]
:END:
#+begin_src R :results output :exports both
  library(bigsnpr)
  setwd("~/Projects/Thesis/Data/1000Genomes/Phase3/plink")
  bedfile <- "1000GenomePhase3_QC_norel_prunned.bed"

  snp_readBed(bedfile, "1000GenomePhase3")
#+end_src

****** DONE Convert into R matrix
CLOSED: [2017-05-18 jeu. 11:23]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-18 jeu. 11:23]
- State "TODO"       from              [2017-05-17 mer. 17:07]
:END:

#+begin_src R :results output :exports both
  library(bigsnpr)
  genome1000 <- snp_attach("backingfiles/1000GenomePhase3.rds")

  names(genome1000)
  dim(genome1000$genotypes)

  ## G
  G <- attach.BM(genome1000$genotypes)[]
  rownames(G) <- genome1000$fam$sample.ID
  colnames(G) <- genome1000$map$marker.ID
  n <- nrow(G)
  L <- ncol(G)
  saveRDS(G, "1000GenomePhase3_QC_norel_prunned.rds")
  dim(G)
#+end_src

#+RESULTS:
#+begin_example
  > library(bigsnpr)
  > genome1000 <- snp_attach("backingfiles/1000GenomePhase3.rds")
  > 
  > names(genome1000)
  [1] "genotypes" "fam"       "map"       "savedIn"  
  > dim(genome1000$genotypes)
  [1]    919 345156
  > 
  > ## G
  > G <- attach.BM(genome1000$genotypes)[]
  > rownames(G) <- genome1000$fam$sample.ID
  > colnames(G) <- genome1000$map$marker.ID
  > n <- nrow(G)
  > L <- ncol(G)
  > saveRDS(G, "1000GenomePhase3_QC_norel_prunned.rds")
  > dim(G)
  [1]    919 345156
#+end_example

*** ./Data/GSE42861/
Données trouvé ici:
https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE42861
Utilisé dans ce papier cite:Rahmani_2016.
**** Retrieve dataset
C'est le fichier qu'olivier a utilisé pour pour ddl les données. Ca marche
pas chez moi...
#+BEGIN_SRC R
       ## try http:// if https:// URLs are not supported
       source("https://bioconductor.org/biocLite.R")
       biocLite("Biobase")

       ## try http:// if https:// URLs are not supported
       source("https://bioconductor.org/biocLite.R")
       biocLite("GEOquery")


       require(Biobase)
       require(GEOquery)

       ## get le jeu de données dans le format biobase
       obj861 <- getGEO("GSE42861",GSEMatrix = T)

       ## extrait les phenotypes (factors)
       disease.state <- pData(phenoData(obj861[[1]]))[,11]

       ## extrait les covariables (subject, age, gender, smocking.status)
       ## age est converti en numeric

       subject <- pData(phenoData(obj861[[1]]))[,12]

       age.f <- pData(phenoData(obj861[[1]]))[,13]
       write.table(file = "age.txt", as.character(age.f))
       age <- as.numeric(read.table(file = "age.txt")[,1])


       gender <- pData(phenoData(obj861[[1]]))[,14]

       smocking.status <- pData(phenoData(obj861[[1]]))[,15]

       ## download la matrice d'expression. Attention elle est transposée (individus en colonnes)
       expmat861 <- exprs(obj861[[1]])
#+END_SRC
    
**** ./GSE42861/exp861.RData
C'est les variables defs dans file:./GSE42861/script_methylome.R. Output par
olivier.
**** Format data
    
#+BEGIN_SRC R
       ## load data send by OF
       load("exp861.RData")
       ls()

       ## save G and X
       G <- t(expmat861)
       ### G
       rm(expmat861)
       dim(G)
       saveRDS(G, "betanormalized_metylationlvl.rds")

       ## we scale and center data
       X <- data.frame(disease.state = as.numeric(disease.state),
                       age = as.numeric(age),
                       gender = as.numeric(gender),
                       smocking.status = as.numeric(smocking.status))
       X <- scale(X)
       X <- as.matrix(X)
       rownames(X) <- rownames(G)
       saveRDS(X, "X.rds")

       ## downsample for test
       sample.row <- sample.int(nrow(G), size = 100)
       sample.col <- sample.int(ncol(G), size = 2000)
       saveRDS(G[sample.row, sample.col], "betanormalized_metylationlvl.sample.rds")
       saveRDS(X[sample.row,], "X.sample.rds")

#+END_SRC

**** Data pre-processing
CLOSED: [2017-02-22 mer. 10:54]
Goal: repruduce data processing of paper cite:Zou_2014 
    
#+BEGIN_SRC R
       setwd("~/Projects/Thesis/Data/GSE42861/")
       X <- readRDS("X.rds")
       G <- readRDS("betanormalized_metylationlvl.rds")

       ## filter maf !
       maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
       out.index <- which(maf <= 0.2)

       G.filtered <- G[,-out.index]
       dim(G.filtered)

       saveRDS(G.filtered, "betanormalized_metylationlvl.filtered.rds")

       ## linear reg res
       library(ThesisRpackage)
       ## G.filtered <- readRDS("betanormalized_metylationlvl.filtered.rds")
       lm.method <- ClassicLinearMethod()
       dat <- list(G = G.filtered, X = X[,-1])

       lm.method <- fit(lm.method, dat)
       saveRDS(lm.method$epsilon, "betanormalized_metylationlvl.filtered.LMresidu.rds")

       ## subsample
       ## G <- readRDS("betanormalized_metylationlvl.filtered.LMresidu.rds")
       G <- lm.method$epsilon
       row.sample <- sample.int(nrow(G), 100)
       col.sample <- sample.int(ncol(G), 1000)
       X.sample <- X[row.sample,,drop = FALSE]
       G.sample <- G[row.sample,col.sample]
       sds <- apply(G.sample, 2, sd)
       mean(sds == 0)
       saveRDS(G.sample, "betanormalized_metylationlvl.filtered.LMresidu.sample.rds")
       saveRDS(X.sample, "X.sample.rds")
#+END_SRC

*** ./Data/refractorDemo/
data found here: https://github.com/cozygene/refactor. There are data used in
the demo of refractor method.
*** ./Data/Hgdp_Li/
Hgdp data used in cite:frichot13_testin_assoc_between_loci_envir anylisis. I
I found this dataset on patator.imag.fr.
*** [[file:Data/gwas_riz][Gwas_Riz]]
Données de riz.
*** [[file:Data/Simons][Simons]]
- [[https://www.simonsfoundation.org/life-sciences/simons-genome-diversity-project-dataset/][website]]
***** to donwload the dataset
I copy the docx file found [[http://simonsfoundation.s3.amazonaws.com/share/SCDA/datasets/2014_11_12/StepstodownloadtheSGDPdataset_v4.docx][here]]:
****** Steps to download the SGDP dataset:	
Get a personal grid x509 certificate to download data using GridFTP from
Fermi Lab. To get a personal certificate follow the instructions from this
link: https://fermi.service-now.com/kb_view.do?sysparm_article=KB0010815
and use the VO as: SCDA Alternatively if you are from an institute
included in cilogon (other than google) you can use https://cilogon.org
      
Once you get your certificate follow the instructions in the email and
upload it to your browser, and send the subject (which will look something
like /DC=org/DC=cilogon/C=US/O=Google/CN=User Name A16321) and mail it to
ifisk@simonsfoundation.org

      
Follow instructions from the below link if you will be using Globus tools
for submitting grid jobs from Linux/UNIX:
https://fermi.service-now.com/kb_view.do?sysparm_article=KB0010815. Make
sure you do this step as soon as you get your certificate and use the same
browser window. Note: If you wait too long the certificate is no longer in
the PKCS#12 format that you need for this step.

Install osg-ca-certs and osg-client on your machine; will probably need
help from the Systems group to do this. The instructions for this are at:
https://twiki.grid.iu.edu/bin/view/Documentation/Release3/InstallOSGClient#6_2_Stopping_and_Disabling_Servi
Note for regular users without root access there is an OSG tarball option:
https://twiki.grid.iu.edu/bin/view/Documentation/Release3/InstallOSGClientTarball

Send the certificate to Yujun Wu (yujun@fnal.gov) or Dmitry O Litvintsev
(litvinse@fnal.gov) to ensure that things are set up properly.
 
Run the following command: . /opt/globus-5.2.5/etc/globus-user-env.sh, to
ensure you are running the correct version of globus

Run the command grid-proxy-init -valid 168:0 (This will allow keep the
proxy active for a week; after which you will need to renew it again)

Test if the download is working using the following command:
“globus-url-copy -vb  -dbg –nodcau
gsiftp://fndca1.fnal.gov:2811//temp/testfnal.txt  file:////tmp/testfile”


Copy a file called COMPLETE_FILE_LISTING in your folder using the below
command: globus-url-copy gsiftp://fndca1.fnal.gov/COMPLETE_FILE_LISTING
file:////`pwd`/COMPLETE_FILE_LISTING

Copy the script complete.sh (see below) in the same folder as where you
have the COMPLETE_FILE_LISTING file; and run ./complete.sh to copy all the
files. Script: complete.sh: #!/bin/bash


cat COMPLETE_FILE_LISTING | grep SGDP | while read path size cksum do
#  echo "globus-url-copy -c gsiftp://fndca1.fnal.gov${path} file:////`pwd`/${path}"
globus-url-copy -c -vb -nodcau -cd -bs 2000000 -sync
gsiftp://fndca1.fnal.gov${path} file:////`pwd`/${path} done
 

Once you have succeeded, you will find the transfers are much faster if
parallel streams are enabled. You may need to speak with the local network
administrator to open ports in the firewall

Two environment variables need to be set export
GLOBUS_TCP_PORT_RANGE=50000,50100 export
GLOBUS_HOSTNAME=Name_of_the_external_IP


And ports 50000-50100 need to be open in the firewall

Then add “-p 10” to the list of options in the globus-url-copy command
above
*** [[file:Data/1001Genomes][1001Genomes]]
- [[http://1001genomes.org/index.html][Website]]
- ddl data: 
  #+BEGIN_SRC bash
  curl -O http://1001genomes.org/data/GMI-MPI/releases/v3.1/SNP_matrix_imputed_hdf5/1001_SNP_MATRIX.tar.gz
  #+END_SRC
**** From h5f to rds
Very long script....
#+begin_src python :results output :exports both
       # from http://stackoverflow.com/questions/28170623/how-to-read-hdf5-files-in-python
       import h5py
       import numpy as np

       filename = "./imputed_snps_binary.hdf5"
       f = h5py.File(filename, 'r')

       # List all groups
       print("Keys: %s" % f.keys())
    
       # Get the data
       acc = f['accessions'][()]
       positions = f['positions'][()]
       # snps = f['snps'][()] ## dangerous

       ## filter maf
       maf_threshold = 0.05
       snps = f['snps']
       L = snps.shape[0]
       maf = np.zeros(L)
       snps_matrix = snps[:,:]
       for i in range(L):
           p = np.mean(snps_matrix[i,:])
           maf[i] = min(p, 1-p)

       np.mean(maf > maf_threshold)
       np.sum(maf > maf_threshold)

       ## max and min ?
       snps.min() ## 0
       snps.max() ## 1


       ## write the whole dataset

       np.savetxt("sample.txt",snps_matrix[1:10,1:10], "%u")
       np.savetxt("snps_matrix.txt",snps_matrix, "%u")

       np.savetxt("snps_matrix.maf05.txt",snps_matrix[maf > maf_threshold,:], "%u")

#+end_src
    

#+begin_src R :results output :session *R* :exports both
       ## reading snps matrix

       library(tidyverse)
       snps.matrix <- read_delim("~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/sample.txt",
                                 delim = " ", col_types = cols(.default = col_logical()),
                                 col_names = FALSE)
       data.matrix(snps.matrix)

       dat <- list()
       ## read by chunck... ugly
       L = 10709949
       # L = 9
       n = 1135
       # n = 9
       step = seq.int(1, L, by = 500000)[-1]
       dat$snps.matrix = NULL ##
       skip = 0
       for (s in step) {
         print(s)
         n_max <- s - skip
         aux <- data.matrix(read_delim("~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/snps_matrix.txt",
                           delim = " ", col_types = cols(.default = col_integer()),
                           col_names = FALSE, skip = skip, n_max = n_max))
         dat$snps.matrix <- rbind(dat$snps.matrix, matrix(as.raw(aux), nrow(aux), ncol(aux)))
         skip <- skip + n_max
       }
       ## I miss the end...
       n_max <- L - skip
       aux <- data.matrix(read_delim("~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/snps_matrix.txt",
                                     delim = " ", col_types = cols(.default = col_integer()),
                                     col_names = FALSE, skip = skip, n_max = n_max))
       dat$snps.matrix <- rbind(dat$snps.matrix, matrix(as.raw(aux), nrow(aux), ncol(aux)))


       assertthat::assert_that(nrow(dat$snps.matrix) == L)
       assertthat::assert_that(ncol(dat$snps.matrix) == n)

       library(rhdf5)
       file.h5 <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/imputed_snps_binary.hdf5"
       h5ls(file.h5)

       ## col.names
       acc <- h5read(file.h5,"accessions")
       colnames(dat$snps.matrix) <- acc

       ## row.names
       pos <- h5read(file.h5,"positions")
       rownames(dat$snps.matrix) <- pos

       ## retrieve coord
       dat$accessions <- read_delim("~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/accessions.txt", delim = "\t")



       ## Save
       saveRDS(dat, "snps_matrix.rds")

       ## filter maf
       library(crayon)
       maf.threshold <- 0.05
       maf <- apply(dat$snps.matrix, 1, function(r) {p <- mean(as.integer(r)); min(p, 1 - p)})
       cat(green(paste0("Removing ", mean(maf <= maf.threshold),"% loci\n")))
       dat.maf <- list()
       dat.maf$accessions <- dat$accessions
       dat.maf$maf.threshold <- maf.threshold
       dat.maf$G <- t(dat$snps.matrix[maf > maf.threshold,])
       rm(dat)
       gc()
       rnames <- rownames(dat.maf$G)
       cnames <- colnames(dat.maf$G)
       dat.maf$G <- matrix(as.integer(dat.maf$G), nrow(dat.maf$G), ncol(dat.maf$G))
       colnames(dat.maf$G) <- cnames
       rownames(dat.maf$G) <- rnames

       assertthat::assert_that(nrow(dat.maf$G) == n)
       assertthat::assert_that(ncol(dat.maf$G) == 1783980)
       assertthat::assert_that(nrow(dat.maf$accession) == nrow(dat.maf$G))

       saveRDS(dat.maf, "snps_matrix_maf05.rds")


#+end_src
**** Subsample
#+begin_src R :results output :session *R* :exports both
       dat <- readRDS("~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/snps_matrix_maf05.rds")
       n <- nrow(dat$G)
       L <- ncol(dat$G)
       G.sample <- dat$G[,sample.int(L,100000)]
       saveRDS(G.sample, "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/snps_matrix_maf05.sample.rds")
#+end_src
**** OF GWAS simulations
#+begin_src R :results output :session *R* :exports both
       setwd("/home/cayek/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/")
       library(raster)
       library(LEA)

       load("/home/francois/Athaliana_1001G/athaliana.Rdata")
       attach(athaliana)

       climate = getData('worldclim', var='bio', res = 2.5)
       bio = extract(climate, y = as.matrix(metadata[,6:5]))
       pc.bio = prcomp(bio,scale = T)
       env = pc.bio$x[,1]

       write.geno(R = G, output = "G_OF_filtered.geno")
       pc = pca("G_OF_filtered.geno", K = 995)
       plot(pc, lwd=5, col="red",xlab=("PCs"),ylab="eigen")

       K = 40
       sigma = sqrt( sum(pc$sdev^2) - sum(pc$sdev[1:K]^2) )
       base.effect = sqrt( sum(pc$sdev^2) )

       ##parametres de la simu:
       J = 10
       beta = 6*base.effect
       delta = 0.3*base.effect ##G X E

       ## definition des SNPs ref
       window = 201

       lch = 0

       ref.set = NULL

       for (i in 1:5){
         chromosome = which(chr == i)
         set = seq(lch + 1+(window-1)/2, lch + length(chromosome) , by = window )
         ref.set = c(ref.set, set)
         lch = lch + length(chromosome)
       }
       loc.J = sort(sample(ref.set, J))
       table(chr[loc.J])

       ##simu du phenotype
       x = beta*rowSums(G[,loc.J]) +
         delta*rowSums(G[,loc.J])*env +
         rowSums(pc$projections[,1:K]) + rnorm(995, sd = sigma)

       cor(x, G[,loc.J])

       ##associations:
       r = as.numeric( cor(x, G) )
       sum( loc.J %in% which(r > 0.3) )

       ## save into RDS
       saveRDS(G,"G_OF_filtered.rds")
       sample.loci <- sample.int(ncol(G), 50000)
       saveRDS(G[,sample.loci],"G_OF_filtered.sample.rds")


       ## save chrm
       saveRDS(chr, "G_OF_filtered.chrm.rds")
       saveRDS(chr[sample.loci], "G_OF_filtered.sample.chrm.rds")



       ## save coord
       coord <- as.matrix(metadata[,c(6,5)])
       saveRDS(coord, "G_OF_filtered.coord.rds")

       detach(athaliana)
#+end_src
*** DONE ./Data/Celiac/
CLOSED: [2017-05-17 mer. 14:59]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-17 mer. 14:59]
- Note taken on [2017-05-17 mer. 14:58] \\
  J'ai un dataset clumpé, il y a plus qu'a faire les analyse.
- State "STARTED"    from              [2017-05-15 lun. 11:07]
:END:
Celiac dataset cite:dubois2010multiple
- ./Data/Celiac/dubois_2010/
(récupéré de FP)
**** Pre-processing
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :dir ./ :eval no-export
:END:
FromTrueSampler these [[https://privefl.github.io/bigsnpr/articles/bcm-seminar-packages.html#28][slides]]

***** Control quality

#+begin_src R :results output :exports both
  library(bigsnpr)
  library(ggplot2)


  plink <- "/home/cayek/BiocompSoftware/plink/plink"
  prefix <- "/home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300"
  bedfileQC <- snp_plinkQC(plink.path = plink,
                           prefix.in = prefix,
                           geno = 0.05, ## Maximum proportion of missing values for a SNP to be kept
                           mind = 0.05, ## Maximum proportion of missing values for a sample to be kept.
                           maf = 0.05, ## Minimum Minor Allele Frequency (MAF) for a SNP to be kept.
                           hwe = 1e-10, ## Filters out all variants which have Hardy-Weinberg equilibrium exact test p-value below the provided threshold
                           autosome.only = TRUE)

  print(bedfileQC)
#+end_src

#+RESULTS:
#+begin_example
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC.log.
Options in effect:
  --autosome
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC

7761 MB RAM detected; reserving 3880 MB for main workspace.
287385 out of 295453 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Total genotyping rate is 0.999579.
67 variants removed due to missing genotype data (--geno).
--hwe: 17 variants removed due to Hardy-Weinberg exact test.
6179 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--make-bed to
/home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC.bed
+
/home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC.bim
+
/home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC.fam
[1] "/home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC.bed"
#+end_example

***** Remove correlated indiv
#+begin_src R :results output :exports both
  library(bigsnpr)
  plink <- "/home/cayek/BiocompSoftware/plink/plink"
  bedfileQC <- "/home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC.bed"
  rel <- snp_plinkIBDQC(plink, bedfileQC, ncores = 4, 
                        do.blind.QC = FALSE)
#+end_src

#+RESULTS:
#+begin_example
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to /tmp/Rtmpx3IbX5/file5479304015c0.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC
  --indep-pairwise 100 1 0.2
  --out /tmp/Rtmpx3IbX5/file5479304015c0

7761 MB RAM detected; reserving 3880 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Total genotyping rate is 0.999596.
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
Pruning complete.  200847 of 281122 variants removed.
Writing...Marker lists written to /tmp/Rtmpx3IbX5/file5479304015c0.prune.in and
/tmp/Rtmpx3IbX5/file5479304015c0.prune.out .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC
  --extract /tmp/Rtmpx3IbX5/file5479304015c0.prune.in
  --genome
  --min 0.08
  --out /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC
  --threads 4

7761 MB RAM detected; reserving 3880 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
--extract: 80275 variants remaining.
Using up to 4 threads (change this with --threads).
Before main variant filters, 15283 founders and 0 nonfounders present.
Total genotyping rate is 0.999591.
80275 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
Writing... 99%Finished writing
/home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC.genome
.
#+end_example

plot (0.08 adviced by FP)
#+begin_src R :results output graphics :file Rplots/celiac_rel.png :exports both :width 600 :height 400 
MY_THEME <- bigstatsr:::MY_THEME

MY_THEME(qplot(y = PI_HAT, data = rel)) + 
  geom_hline(yintercept = 0.08) # visual inspection threshold
#+end_src

#+RESULTS:
[[file:Rplots/celiac_rel.png]]

generate bed file without correlated indiv
#+begin_src R :results output :exports both
  bedfileQC2 <- snp_plinkRmSamples(
    plink, 
    bedfile.in = bedfileQC, 
    bedfile.out = sub("\\.bed$", "_norel.bed", bedfileQC), 
    df.or.files = subset(rel, PI_HAT > 0.08)
  )
  print(bedfileQC2)
#+end_src

#+RESULTS:
#+begin_example
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC_norel.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC
  --make-bed
  --out /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC_norel
  --remove /tmp/Rtmpx3IbX5/file547977caa73d

7761 MB RAM detected; reserving 3880 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
--remove: 15155 people remaining.
Warning: At least 1 duplicate ID in --remove file.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15155 founders and 0 nonfounders present.
Calculating allele frequencies...  done.
Total genotyping rate in remaining samples is 0.999597.
281122 variants and 15155 people pass filters and QC.
Among remaining phenotypes, 4496 are cases and 10659 are controls.
--make-bed to
/home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC_norel.bed
+
/home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC_norel.bim
+
/home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC_norel.fam
... 0%done.
[1] "/home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_QC_norel.bed"
#+end_example

***** Convert the dataset into bigmatrix
#+begin_src R :results output :exports both
snp_readBed(bedfileQC2, "celiacQC")
#+end_src

#+RESULTS:
: Creating directory "backingfiles" which didn't exist..
: [1] "backingfiles/celiacQC.rds"

Test to attach
#+begin_src R :results output :exports both
  ## Then, just attach the data
  celiac <- snp_attach("./Data/Celiac/dubois_2010/backingfiles/celiacQC.rds")
  dim(celiac$genotype)
#+end_src

#+RESULTS:
: [1]  15155 281122
**** Formated dataset by FP
Avec:
- param de [[*Control quality][Control quality]] 
- indiv parenté à 0.2
- sans missing value (imputation with xgboost)

#+begin_src R :results output :exports both
  setwd("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/")
#+end_src

#+begin_src R :results output :exports both
  snp_readBed("celiacQC.bed",
              "celiacQC_flo")
  celiac <- snp_attach("./Data/Celiac/dubois_2010/backingfiles/celiacQC.rds")
  dim(celiac$genotype)
#+end_src
**** DONE LD pruning/clumping
CLOSED: [2017-05-17 mer. 13:30]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-17 mer. 13:30]
- Note taken on [2017-05-17 mer. 11:02] \\
  On va utiliser sa fonction.
- Note taken on [2017-05-16 mar. 16:36] \\
  Il me faut les data de FP
- Note taken on [2017-05-16 mar. 12:36] \\
  il faut que j'impute avant d'après la doc. A voir si je peux pas le faire
  dirrect avec plink !!
- State "TODO"       from              [2017-05-16 mar. 12:26]
:END:

On part d'un dataset deja imputé pour trouver une liste d'indice a garder ! 
#+begin_src R :results output :exports both
  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")
  ind.keep2 <- snp_clumping(G = celiac$genotypes,
                            infos.chr = celiac$map$chromosome,
                            thr.r2 = 0.2)
  saveRDS(ind.keep2, "~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/celiacQC_clumping_ind.rds")
#+end_src

#+RESULTS:

**** DONE vep annotation
CLOSED: [2017-05-22 lun. 17:31]
:LOGBOOK:
- Note taken on [2017-05-22 lun. 17:31] \\
  un peut fait main, mais c'est bon c''est bien dans ce fichier !
- State "DONE"       from "RUNNING"    [2017-05-22 lun. 17:31]
- State "RUNNING"    from "TODO"       [2017-05-22 lun. 15:36]
- State "TODO"       from              [2017-05-22 lun. 15:24]
:END:
#+begin_src R :results output :exports both
  library(bigsnpr)

  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")

  ## run of vep
  celiac.vcf <- celiac$map %>%
    transmute(chromosome = chromosome,
              start = physical.pos,
              end = physical.pos,
              allele = paste0(allele1,"/",allele2),
              strand = NA,
              identifier = marker.ID)
  head(celiac.vcf)


  celiac.vep <- variant_effect_predictor(celiac.vcf)
  save(celiac.vep, file = "~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/celiacQC_flo_vep.rds")
#+end_src
**** DONE From big matrix to matrix and scalling
CLOSED: [2017-05-19 ven. 11:39]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-19 ven. 11:39]
- Note taken on [2017-05-19 ven. 11:38] \\
  ca a l'aire bon
- Note taken on [2017-05-19 ven. 11:30] \\
  le test
- Note taken on [2017-05-19 ven. 10:10] \\
  juste la partie sans le clumping.
- State "RUNNING"    from "STARTED"    [2017-05-19 ven. 10:09]
- State "STARTED"    from "DONE"       [2017-05-19 ven. 10:06]
- State "DONE"       from "RUNNING"    [2017-05-18 jeu. 13:12]
- State "RUNNING"    from "DONE"       [2017-05-18 jeu. 11:53]
- State "DONE"       from "TODO"       [2017-05-17 mer. 14:58]
- State "TODO"       from              [2017-05-16 mar. 12:27]
:END:
#+begin_src R :results output :exports both :session *ssh krakenator*
  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")
  ind.clumping <- readRDS("./Data/Celiac/dubois_2010/celiacQC_flo/celiacQC_clumping_ind.rds")

  ## save clumped loci
  saveRDS(ind.clumping, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  ## filter correlated indiv to  0.08
  celiac.aux <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/backingfiles/celiacQC.rds")
  ind.indiv <- which(celiac$fam$sample.ID %in% celiac.aux$fam$sample.ID)

  ## G
  G <- attach.BM(celiac$genotypes)[ind.indiv,]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID
  n <- nrow(G)
  L <- ncol(G)

  ## memory cleaning
  rm(celiac)
  rm(celiac.aux)
  gc()

  ## G <- scale(G) ## too much memory used...
  mu <- apply(G, 2, mean)
  sigma <- apply(G,2,sd)
  gc()
  G <- sweep(G, 2, mu)
  rm(mu)
  gc()
  G <- sweep(G, 2, sigma, FUN = "/")
  rm(sigma)
  gc()

  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  dim(G)


  ## G clumped
  G <- attach.BM(celiac$genotypes)[ind.indiv,ind.clumping]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID[ind.clumping]
  n <- nrow(G)
  L <- ncol(G)
  G <- scale(G)
  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  dim(G)

  ## X
  X <- matrix(celiac$fam$affection[ind.indiv], n, 1)
  X <- scale(X)
  rownames(X) <- celiac$fam$sample.ID[ind.indiv]
  saveRDS(X, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/X.rds")
  dim(X)
#+end_src

#+RESULTS:
: [1]  15155 281122
: [1] 15155 94497
: [1] 15155     1

A lil'test
#+begin_src R :results output :exports both
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  G.clumped <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  ind.clumping <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  mean(abs(G[,ind.clumping] - G.clumped))
#+end_src

#+RESULTS:
#+begin_example
  [1] 2.356696e-17
#+end_example

*** DONE GWAS catalog
CLOSED: [2017-05-22 lun. 18:32]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-22 lun. 18:32]
- State "STARTED"    from              [2017-05-22 lun. 14:40]
:END:
I download all association from [[https://www.ebi.ac.uk/gwas/home][gwas catalogue]]
#+begin_src R :results output :exports both
  library(tidyverse)
  df <- read_delim("~/Projects/Thesis/Data/GWASCatalog/gwas_catalog_v1.0.1-associations_e88_r2017-04-24.tsv",
                   delim = "\t",
                   col_types = cols(
                     .default = col_character(),
                     `DATE ADDED TO CATALOG` = col_date(format = ""),
                     PUBMEDID = col_integer(),
                     DATE = col_character(),
                     UPSTREAM_GENE_ID = col_integer(),
                     DOWNSTREAM_GENE_ID = col_integer(),
                     UPSTREAM_GENE_DISTANCE = col_integer(),
                     DOWNSTREAM_GENE_DISTANCE = col_integer(),
                     MERGED = col_integer(),
                     SNP_ID_CURRENT = col_character(),
                     INTERGENIC = col_integer(),
                     `P-VALUE` = col_double(),
                     PVALUE_MLOG = col_double(),
                     `OR or BETA` = col_double()
                   ))

  trait <- df %>%
    select(`DISEASE/TRAIT`) %>%
           unique()

  saveRDS(df, "~/Projects/Thesis/Data/GWASCatalog/gwas_catalog_v1.0.1-associations_e88_r2017-04-24.rds")
#+end_src
** STARTED Étude de [[#Liu_2013][GSE42861]]                                      :3Article:
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-06-21 mer. 16:28]
- State "TODO"       from "DONE"       [2017-06-21 mer. 16:22]
- State "DONE"       from "STARTED"    [2017-05-23 mar. 15:56]
- Note taken on [2017-05-16 mar. 16:32] \\
  Au passage, tous le monde detecte les outlier des autres papier. PCA detect que
  ceux la, c'est normal les autre méthodes sons sencé avoir plus de puissance :D
- Note taken on [2017-05-16 mar. 16:31] \\
  Il va falloir étudier la liste des candidats. Et justifier K = 28 pour tous le monde.
- Note taken on [2017-05-16 mar. 16:30] \\
  Il y a all qui tourne ! Pour le moment, on voit bien que plus la contrainte sur
  B est petite plus on a de puissance a detecter des outlier. C'est PCA qui
  detecte le moins de monde.
- Note taken on [2017-05-12 Ven 15:05] \\
  J'espere montrer:
        - ma méthodes a plus de puissance (il trouve des liste plus longue pour un fdr
        controlé) par rapport à PCA+lm. Ca devrait etre pareil pour les autres méthodes.
        - on retrouve tous les outliers touvés dans les autres papiers (ca c'est bon)
        - avec lm ca fait n'imp : c'est bon aussi.
        - on va facilement reussir à analyser les resultats (annotation etc) et
          tomber sur des locus interessant...
- Note taken on [2017-05-11 jeu. 17:43] \\
  TODO: 
  - plot param1 X param2
  - comparaison des methode du batch (top 10, 100 etc)
- Note taken on [2017-05-11 jeu. 16:19] \\
  Les méthodes sont en train de tourner. On arrive bien a recuperer les locus
  candidats des autre papiers ! Il reste a esperer que quand on controle le à 5%
  la liste est pas trop longue ET que toutes les méthode renvoie en gros la même
  chose. 
  
  Sinon c'est cool par ce que c'est la version non corrigé !
- Note taken on [2017-05-10 mer. 16:58] \\
  Il faut que je trouve les locus interessant indentifié dans les papiers qui ont
  bosser sur GSE42861 et les mettre dans les outlier.
- State "STARTED"    from "TODO"       [2017-05-10 mer. 16:58]
- State "TODO"       from              [2017-05-10 mer. 16:58]
:END:
*** Data pre-processing
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  X <- readRDS("~/Projects/Thesis/Data/GSE42861/X.rds")
  G <- readRDS("~/Projects/Thesis/Data/GSE42861/betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G <- G[,-out.index]
  dim(G)

  ## check variable without variance
  G <- Preprocessing_filter_sd(G)
  dim(G)

  ## scale and center
  G <- scale(G)

  ## save
  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/G.rds")
  saveRDS(X, "~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/X.rds")
#+end_src
*** DONE Interesting loci 
CLOSED: [2017-05-15 lun. 17:26]
:LOGBOOK:
- Note taken on [2017-05-15 lun. 17:26] \\
  faute de frappe
- State "DONE"       from "TODO"       [2017-05-15 lun. 17:26]
- Note taken on [2017-05-11 jeu. 11:20] \\
  Il me manque 1 cadidat dans G, pk ?
- State "TODO"       from              [2017-05-11 jeu. 11:20]
:END:
Les loci relevé par cite:Rahmani_2016
#+begin_src R :results output :exports both
  rahmani.loci <- c("cg05428452",
                     "cg07839457",
                     "cg16411857")
#+end_src
Ceux de cite:Zou_2014
#+begin_src R :results output :exports both
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
#+end_src

On retrouve les 3 mêmes. On va prend cela  
#+begin_src R :results output :exports both :session *ssh krakenator*
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/G.rds")
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
  cols <- colnames(G)
  candidates <- which(colnames(G) %in% Zou.loci)
  cols[candidates]
  saveRDS(candidates, "~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+end_src

#+RESULTS:
: [1] "cg05428452" "cg07839457" "cg16411857" "cg20821042" "cg25372449"

#+begin_src R :results output :exports both :session *ssh krakenator*
candidates
#+end_src

#+RESULTS:
: [1]  36714  51546 101455 125220 149131

*** Choix des paramètres
**** PCA
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## we keep only disease.state
  X <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/X.rds")
  X <- X[,1]
  head(X)

  s <- TrueSampler(G.file = "~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/G.rds",
                   X.file = X,
                   outlier.file = NULL,
                   n = NULL,
                   L = NULL)
  expr <- PCAExperiment(s = s,
                        description = "GSE42861 PCA")
  expr <- runExperiment(expr)
  dumpExperiment(expr)
#+end_src

#+begin_src R :results output graphics :file Rplots/GSE42861_pca.png :exports both :width 600 :height 400 
  expr <- retrieveExperiment(109)
  variances <- expr$res.df$sdev / sum(expr$res.df$sdev)
  ## plot
  pl <- qplot(x = seq_along(variances), y = variances, geom='line') +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  pl
#+end_src

#+RESULTS:
[[file:Rplots/GSE42861_pca.png]]

**** lfmm ridge
 
**** sva
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  dat <- Article3_GSE42861_dat()

  sva.m <- finalSVAMethod(K = NULL)
  numLatentVarEstimation(sva.m, dat)
#+end_src

#+RESULTS:
: 687

Il doit y avoir un probleme

**** famt
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  dat <- Article3_GSE42861_dat()

  famt.m <- finalFamtMethod(K = NULL)
  numLatentVarEstimation(famt.m, dat)
#+end_src

#+RESULTS:
#+begin_example
TRACE [2017-05-15 16:03:12] attaching FAMT
Loading required package: mnormt
Loading required package: impute
DEBUG [2017-05-15 16:03:33] FAMT::as.FAMTdata said:
--------------------------------
$`Rows with missing values`
integer(0)

$`Columns with missing values`
integer(0)

--------------------------------
DEBUG [2017-05-15 17:40:01] FAMT::nbfactors said:
--------------------------------
[1] "Fitting Factor Analysis Model with 1 factors"
[1] "Fitting Factor Analysis Model with 2 factors"
[1] "Fitting Factor Analysis Model with 3 factors"
[1] "Fitting Factor Analysis Model with 4 factors"
[1] "Fitting Factor Analysis Model with 5 factors"
[1] "Fitting Factor Analysis Model with 6 factors"
[1] "Fitting Factor Analysis Model with 7 factors"
[1] "Fitting Factor Analysis Model with 8 factors"
[1] "Calculating criterion for the model with 0 factors"
[1] "Calculating criterion for the model with 1 factors"
[1] "Calculating criterion for the model with 2 factors"
[1] "Calculating criterion for the model with 3 factors"
[1] "Calculating criterion for the model with 4 factors"
[1] "Calculating criterion for the model with 5 factors"
[1] "Calculating criterion for the model with 6 factors"
[1] "Calculating criterion for the model with 7 factors"
[1] "Calculating criterion for the model with 8 factors"
--------------------------------
[1] 8
#+end_example

Il a juste atteint son max, il faudra le relancer...

**** cate
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  dat <- Article3_GSE42861_dat()

  cate.m <- finalcateMethod(K = NULL)
  numLatentVarEstimation(cate.m, dat)
#+end_src

#+RESULTS:
: [1] 28

*** Run des méthodes
**** lm
***** run
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  m <- finalLm()

  expr <- MethodBatchExperiment("GSE42861",
                                s = Article3_GSE42861_sampler(),
                                method.batch = list(m = m))
  expr <- runExperiment(expr, TRUE)
#+end_src
***** plot
#+begin_src R :results output :exports both
  expr <- retrieveExperiment(110)
#+end_src

qqplot
#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_qqplot_lm.png")
#+end_src

#+RESULTS:
:        pvalue1 method     id  rank
: 1 1.616133e-24     lm  36714 11881
: 2 2.028086e-15     lm 149131 22334
: 3 3.013906e-08     lm 125220 40931
: 4 1.078110e-02     lm 101455 86961
[[./Rplots/GSE42861_qqplot_lm.png]]

We calibrate
#+begin_src R :results output :exports both
  expr <- MethodBatchExperiment_calibrate(expr)
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_calibrated_qqplot_lm.png")
#+end_src

#+RESULTS:
: pvalue1 method     id  rank
: 1 0.01474925     lm  36714 11733
: 2 0.05785257     lm 149131 21989
: 3 0.18453007     lm 125220 40388
: 4 0.53759995     lm 101455 86067
[[./Rplots/GSE42861_calibrated_qqplot_lm.png]]

**** PCA
***** run
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  m <- finalPcaLm(K = 30)
  expr <- MethodBatchExperiment("GSE42861",
                                s = Article3_GSE42861_sampler(),
                                method.batch = list(m = m))
  expr <- runExperiment(expr, TRUE)
#+end_src
***** plot
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:

#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(120)
  expr$description
  expr$outlier
#+end_src

#+RESULTS:
: [1] "Run on GSE42861 with PcaLm|"
: [1]  36714  51546 101455 125220 149131


qqplot
#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_qqplot_PcaLm.png")
#+end_src

#+RESULTS:
:        pvalue1 method     id rank
: 1 1.088531e-13  PcaLm 101455    1
: 2 4.101541e-13  PcaLm  51546    2
: 3 1.362223e-12  PcaLm  36714    3
: 4 4.834266e-09  PcaLm 125220    6
: 5 8.449928e-09  PcaLm 149131    9
[[./Rplots/GSE42861_qqplot_PcaLm.png]]


We calibrate
#+begin_src R :results output :exports both
  expr <- MethodBatchExperiment_calibrate(expr)
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_calibrated_qqplot_PcaLm.png")
#+end_src

#+RESULTS:
#+begin_example
[1] "PcaLm"
[1] "== calibrate: median"
disease.state 
 -0.003446807 
[1] "== calibrate: mad"
disease.state 
     1.119271
       pvalue1 method     id rank
1 3.247347e-11  PcaLm 101455    1
2 9.400547e-11  PcaLm  51546    2
3 2.460012e-10  PcaLm  36714    3
4 1.731964e-07  PcaLm 125220    6
5 2.711935e-07  PcaLm 149131    9
#+end_example
[[./Rplots/GSE42861_calibrated_qqplot_PcaLm.png]]


**** lfmm lasso
***** run

#+begin_src R :results output :exports both
  library(ThesisRpackage)
  m <- finalLfmmLassoMethod(K = 30, sparse.prop = 0.01)
  expr <- MethodBatchExperiment("GSE42861",
                                s = Article3_GSE42861_sampler(),
                                method.batch = list(m = m))
  expr <- runExperiment(expr, TRUE)
#+end_src
***** plot
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(116)
  expr$description
  expr$outlier <- c(36714,51546, 101455, 125220, 149131)
#+end_src

#+RESULTS:
: [1] "Run on GSE42861 with LassoLfmm|"

qqplot
#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_qqplot_LfmmLasso.png")
#+end_src

#+RESULTS:
:        pvalue1    method     id rank
: 1 7.735380e-14 LassoLfmm 101455    1
: 2 2.967146e-13 LassoLfmm  51546    2
: 3 5.356916e-13 LassoLfmm  36714    3
: 4 2.482284e-09 LassoLfmm 125220    5
: 5 5.031122e-09 LassoLfmm 149131    9
[[./Rplots/GSE42861_qqplot_LfmmLasso.png]]

We calibrate
#+begin_src R :results output :exports both
  expr <- MethodBatchExperiment_calibrate(expr)
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_calibrated_qqplot_LfmmLasso.png")
#+end_src

#+RESULTS:
[[./Rplots/GSE42861_calibrated_qqplot_LfmmLasso.png]]
#+begin_example
[1] "== calibrate: median"
disease.state 
 -0.003189651 
[1] "== calibrate: mad"
disease.state 
     1.122399
       pvalue1    method     id rank
1 2.799044e-11 LassoLfmm 101455    1
2 1.308532e-10 LassoLfmm  36714    3
3 1.098989e-07 LassoLfmm 125220    5
4 1.931946e-07 LassoLfmm 149131    9
#+end_example

**** lfmm ridge
***** run
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  method.batch <- paramGrid(finalLfmmRdigeMethod,
                            'lfmmRidge', K = c(10, 30, 60),
                            lambda = c(1e-10))

  expr <- MethodBatchExperiment("GSE42861",
                                s = Article3_GSE42861_sampler(),
                                method.batch = method.batch,
                                cluster.nb = 3)
  expr <- runExperiment(expr, TRUE)
#+end_src
***** plot
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(115)
  expr$description
#+end_src

#+RESULTS:
: [1] "Run on GSE42861 with lfmmRidge|K=10|lambda=1e-10|lfmmRidge|K=30|lambda=1e-10|lfmmRidge|K=60|lambda=1e-10|"

qqplot
#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_qqplot_LfmmRidge.png")
#+end_src

#+RESULTS:
#+begin_example
        pvalue1                      method     id rank
1  2.268143e-18 lfmmRidge|K=10|lambda=1e-10 101455    1
2  2.060924e-16 lfmmRidge|K=10|lambda=1e-10  36714    2
3  1.928065e-15 lfmmRidge|K=30|lambda=1e-10  36714    1
4  2.825195e-15 lfmmRidge|K=30|lambda=1e-10 101455    2
5  5.590577e-15 lfmmRidge|K=60|lambda=1e-10 101455    1
6  4.597272e-13 lfmmRidge|K=60|lambda=1e-10  36714    3
7  1.577695e-11 lfmmRidge|K=10|lambda=1e-10 125220   11
8  5.270711e-11 lfmmRidge|K=30|lambda=1e-10 125220    4
9  1.763606e-10 lfmmRidge|K=10|lambda=1e-10 149131   25
10 3.622480e-10 lfmmRidge|K=30|lambda=1e-10 149131   12
11 2.198761e-09 lfmmRidge|K=60|lambda=1e-10 149131    9
12 4.711237e-09 lfmmRidge|K=60|lambda=1e-10 125220   13
#+end_example
[[./Rplots/GSE42861_qqplot_LfmmRidge.png]]

We calibrate
#+begin_src R :results output :exports both
  expr <- MethodBatchExperiment_calibrate(expr)
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_calibrated_qqplot_LfmmRidge.png")
#+end_src

#+RESULTS:
#+begin_example
[1] "== calibrate: median"
disease.state 
   0.04853954 
[1] "== calibrate: mad"
disease.state 
      1.27457 
[1] "== calibrate: median"
disease.state 
   0.01105044 
[1] "== calibrate: mad"
disease.state 
     1.185217 
[1] "== calibrate: median"
disease.state 
   0.01255809 
[1] "== calibrate: mad"
disease.state 
     1.149169
        pvalue1                      method     id rank
1  5.284202e-12 lfmmRidge|K=10|lambda=1e-10 101455    1
2  9.784903e-12 lfmmRidge|K=60|lambda=1e-10 101455    1
3  1.900259e-11 lfmmRidge|K=30|lambda=1e-10  36714    1
4  2.499142e-11 lfmmRidge|K=30|lambda=1e-10 101455    2
5  8.807053e-11 lfmmRidge|K=10|lambda=1e-10  36714    2
6  2.821823e-10 lfmmRidge|K=60|lambda=1e-10  36714    3
7  2.909836e-08 lfmmRidge|K=30|lambda=1e-10 125220    4
8  1.000757e-07 lfmmRidge|K=10|lambda=1e-10 125220    9
9  1.164002e-07 lfmmRidge|K=30|lambda=1e-10 149131   12
10 1.820639e-07 lfmmRidge|K=60|lambda=1e-10 149131    9
11 3.260855e-07 lfmmRidge|K=60|lambda=1e-10 125220   12
12 4.554521e-07 lfmmRidge|K=10|lambda=1e-10 149131   22
#+end_example
[[./Rplots/GSE42861_calibrated_qqplot_LfmmRidge.png]]

A candidate list: 
#+begin_src R :results output :exports both
  qvalue.df <- MethodBatchExperiment_qvalue(expr, 0.05)
  print.data.frame(qvalue.df %>% dplyr::filter(qvalue < 0.005))
#+end_src

#+RESULTS:
#+begin_example
         pvalue       qvalue                      method
1  3.296920e-07 4.109433e-03 lfmmRidge|K=60|lambda=1e-10
2  2.984600e-08 1.209047e-03 lfmmRidge|K=60|lambda=1e-10
3  2.821823e-10 1.524142e-05 lfmmRidge|K=60|lambda=1e-10
4  2.258831e-07 3.660165e-03 lfmmRidge|K=60|lambda=1e-10
5  1.069282e-10 8.663212e-06 lfmmRidge|K=60|lambda=1e-10
6  6.701838e-08 1.809921e-03 lfmmRidge|K=60|lambda=1e-10
7  4.135744e-08 1.340295e-03 lfmmRidge|K=60|lambda=1e-10
8  9.784903e-12 1.585526e-06 lfmmRidge|K=60|lambda=1e-10
9  1.527991e-07 3.094907e-03 lfmmRidge|K=60|lambda=1e-10
10 3.260855e-07 4.109433e-03 lfmmRidge|K=60|lambda=1e-10
11 1.164052e-07 2.694582e-03 lfmmRidge|K=60|lambda=1e-10
12 1.820639e-07 3.277920e-03 lfmmRidge|K=60|lambda=1e-10
13 2.779951e-07 4.095069e-03 lfmmRidge|K=60|lambda=1e-10
14 4.944705e-07 4.005454e-03 lfmmRidge|K=30|lambda=1e-10
15 2.854097e-07 2.719951e-03 lfmmRidge|K=30|lambda=1e-10
16 4.549969e-08 1.228566e-03 lfmmRidge|K=30|lambda=1e-10
17 1.646964e-07 1.962680e-03 lfmmRidge|K=30|lambda=1e-10
18 2.152991e-07 2.325371e-03 lfmmRidge|K=30|lambda=1e-10
19 3.063381e-07 2.757210e-03 lfmmRidge|K=30|lambda=1e-10
20 1.900259e-11 2.024428e-06 lfmmRidge|K=30|lambda=1e-10
21 1.696040e-07 1.962680e-03 lfmmRidge|K=30|lambda=1e-10
22 1.030234e-10 5.563603e-06 lfmmRidge|K=30|lambda=1e-10
23 5.539194e-08 1.282006e-03 lfmmRidge|K=30|lambda=1e-10
24 6.457732e-07 4.981981e-03 lfmmRidge|K=30|lambda=1e-10
25 2.695880e-07 2.719951e-03 lfmmRidge|K=30|lambda=1e-10
26 2.499142e-11 2.024428e-06 lfmmRidge|K=30|lambda=1e-10
27 1.137606e-07 1.571498e-03 lfmmRidge|K=30|lambda=1e-10
28 1.007518e-07 1.571498e-03 lfmmRidge|K=30|lambda=1e-10
29 2.909836e-08 1.178555e-03 lfmmRidge|K=30|lambda=1e-10
30 3.513663e-07 2.996041e-03 lfmmRidge|K=30|lambda=1e-10
31 1.164002e-07 1.571498e-03 lfmmRidge|K=30|lambda=1e-10
32 3.672015e-08 1.189805e-03 lfmmRidge|K=30|lambda=1e-10
33 7.286870e-08 1.475681e-03 lfmmRidge|K=30|lambda=1e-10
34 1.004989e-07 1.571498e-03 lfmmRidge|K=30|lambda=1e-10
35 2.518212e-07 2.400271e-03 lfmmRidge|K=10|lambda=1e-10
36 4.186555e-07 3.117174e-03 lfmmRidge|K=10|lambda=1e-10
37 1.111891e-07 1.801687e-03 lfmmRidge|K=10|lambda=1e-10
38 1.576624e-07 2.128941e-03 lfmmRidge|K=10|lambda=1e-10
39 2.813039e-08 7.596988e-04 lfmmRidge|K=10|lambda=1e-10
40 6.095269e-07 3.798712e-03 lfmmRidge|K=10|lambda=1e-10
41 3.778430e-08 7.750750e-04 lfmmRidge|K=10|lambda=1e-10
42 7.772781e-07 4.498164e-03 lfmmRidge|K=10|lambda=1e-10
43 4.373329e-07 3.117174e-03 lfmmRidge|K=10|lambda=1e-10
44 8.807053e-11 5.241876e-06 lfmmRidge|K=10|lambda=1e-10
45 5.574971e-07 3.613429e-03 lfmmRidge|K=10|lambda=1e-10
46 9.704901e-11 5.241876e-06 lfmmRidge|K=10|lambda=1e-10
47 4.061762e-07 3.117174e-03 lfmmRidge|K=10|lambda=1e-10
48 2.193259e-07 2.221196e-03 lfmmRidge|K=10|lambda=1e-10
49 1.919014e-07 2.221196e-03 lfmmRidge|K=10|lambda=1e-10
50 2.074019e-07 2.221196e-03 lfmmRidge|K=10|lambda=1e-10
51 3.826633e-08 7.750750e-04 lfmmRidge|K=10|lambda=1e-10
52 5.284202e-12 8.562415e-07 lfmmRidge|K=10|lambda=1e-10
53 3.080313e-07 2.772932e-03 lfmmRidge|K=10|lambda=1e-10
54 4.587696e-07 3.117174e-03 lfmmRidge|K=10|lambda=1e-10
55 1.000757e-07 1.801687e-03 lfmmRidge|K=10|lambda=1e-10
56 1.371227e-07 2.019917e-03 lfmmRidge|K=10|lambda=1e-10
57 2.080305e-07 2.221196e-03 lfmmRidge|K=10|lambda=1e-10
58 4.554521e-07 3.117174e-03 lfmmRidge|K=10|lambda=1e-10
59 4.616953e-07 3.117174e-03 lfmmRidge|K=10|lambda=1e-10
60 1.430510e-08 4.635938e-04 lfmmRidge|K=10|lambda=1e-10
61 4.194535e-09 1.699185e-04 lfmmRidge|K=10|lambda=1e-10
62 6.564743e-07 3.939770e-03 lfmmRidge|K=10|lambda=1e-10
#+end_example

**** sva
:LOGBOOK:
- Note taken on [2017-05-11 jeu. 16:38] \\
  Vu les résultats, il y a eu un problème quelque part !!! Je ne me suis jamais
  interessé au autre parame de sva. En plus il y a des NaN dans les pvalue !!
:END:
***** run
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  m <- finalSVAMethod(30)
  expr <- MethodBatchExperiment("GSE42861",
                                s = Article3_GSE42861_sampler(),
                                method.batch = list(m = m))
  expr <- runExperiment(expr, TRUE)
#+end_src
***** plot
:PROPERTIES:
:header-args: :cache no :session *krakenatoR* :eval no-export
:END:
#+begin_src R :results output :exports both
  expr <- retrieveExperiment(114)
  expr$description
#+end_src

#+RESULTS:
: [1] "Run on GSE42861 with SVA|"

qqplot
#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_qqplot_sva.png")
#+end_src

#+RESULTS:
:        pvalue1 method     id  rank
: 1 0.000000e+00    SVA  36714  2000
: 2 3.486322e-12    SVA 149131 12286
: 3 2.717537e-11    SVA 125220 13277
: 4 3.686296e-11    SVA 101455 13413
: Warning message:
: Removed 8786 rows containing non-finite values (stat_qq).
[[./Rplots/GSE42861_qqplot_sva.png]]

We calibrate
#+begin_src R :results output :exports both
  expr <- MethodBatchExperiment_calibrate(expr)
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_calibrated_qqplot_sva.png")
#+end_src

#+RESULTS:
[[./Rplots/GSE42861_calibrated_qqplot_sva.png]]
#+begin_example
[1] "== calibrate: median"
[1] 2.433452
[1] "== calibrate: mad"
[1] 3.432042
        pvalue1 method     id  rank
1 5.991942e-123    SVA  36714  7683
2  3.859961e-44    SVA 149131 12286
3  8.002992e-37    SVA 125220 13277
4  8.445964e-36    SVA 101455 13413
Warning message:
Removed 4362 rows containing non-finite values (stat_qq).
#+end_example

**** cate
***** run 
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  m <- finalcateMethod(30)
  expr <- MethodBatchExperiment("GSE42861",
                                s = Article3_GSE42861_sampler(),
                                method.batch = list(m = m))
  expr <- runExperiment(expr, TRUE)
#+end_src
***** plot
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(117)
  expr$description
  expr$outlier <- c(36714,51546, 101455, 125220, 149131)
#+end_src

#+RESULTS:
: [1] "Run on GSE42861 with cate|"

qqplot
#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_qqplot_cate.png")
#+end_src

#+RESULTS:
:        pvalue1 method     id rank
: 1 2.220446e-16   cate 101455    1
: 2 3.108624e-15   cate  51546    2
: 3 4.884981e-15   cate  36714    3
: 4 1.077418e-10   cate 125220    5
: 5 6.509535e-10   cate 149131   15
[[./Rplots/GSE42861_qqplot_cate.png]]

We calibrate
#+begin_src R :results output :exports both
  expr <- MethodBatchExperiment_calibrate(expr)
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_calibrated_qqplot_cate.png")
#+end_src

#+RESULTS:
#+begin_example
[1] "== calibrate: median"
[1] 0.01657819
[1] "== calibrate: mad"
[1] 1.163034
       pvalue1 method     id rank
1 1.729877e-12   cate 101455    1
2 1.055260e-11   cate  51546    2
3 1.523298e-11   cate  36714    3
4 2.622003e-08   cate 125220    5
5 1.004800e-07   cate 149131   15
#+end_example
[[./Rplots/GSE42861_calibrated_qqplot_cate.png]]

**** famt
***** run 
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  m <- finalFamtMethod(30)
  expr <- MethodBatchExperiment("GSE42861",
                                s = Article3_GSE42861_sampler(),
                                method.batch = list(m = m))
  expr <- runExperiment(expr, TRUE)
#+end_src
***** plot
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(118)
  expr$description
  expr$outlier <- c(36714,51546, 101455, 125220, 149131)
#+end_src

#+RESULTS:
: [1] "Run on GSE42861 with FAMT|"

qqplot
#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_qqplot_famt.png")
#+end_src

#+RESULTS:
:        pvalue1 method     id  rank
: 1 1.398055e-23   FAMT  36714 10023
: 2 3.516649e-15   FAMT 149131 16026
: 3 5.583005e-13   FAMT 125220 18697
: 4 2.712504e-12   FAMT 101455 19712
: 5 1.481923e-09   FAMT  51546 24802
[[./Rplots/GSE42861_qqplot_famt.png]]

We calibrate
#+begin_src R :results output :exports both
  expr <- MethodBatchExperiment_calibrate(expr)
  pl <- MethodBatchExperiment_qqplot(expr)
  save_plot_timc_bcm_15(pl, "GSE42861_calibrated_qqplot_famt.png")
#+end_src

#+RESULTS:
[[./Rplots/GSE42861_calibrated_qqplot_famt.png]]
#+begin_example
[1] "== calibrate: median"
[1] 4.119201
[1] "== calibrate: mad"
[1] 6.004386
       pvalue1 method     id  rank
1 5.754391e-67   FAMT  36714 10023
2 4.517393e-24   FAMT 149131 16026
3 9.163019e-17   FAMT 125220 18697
4 8.579049e-15   FAMT 101455 19712
5 2.517192e-08   FAMT  51546 24802
Warning message:
Removed 3948 rows containing non-finite values (stat_qq).
#+end_example

**** All
***** run 
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  method.batch <- list()
  K = 28
  ## famt
  method.batch$m.famt <- finalFamtMethod(K)
  ## cate
  method.batch$m.sva <- finalcateMethod(K)
  ## lm
  method.batch$m.lm <- finalLm()
  ## pca
  method.batch$m.pca <- finalPcaLm(K)
  ## lfmm lasso
  method.batch$m.lfmmLasso <- finalLfmmLassoMethod(K, 0.05)
  ## lfmm ridge
  method.batch$m.lfmmRidge <- finalLfmmRdigeMethod(K, 1e-10)
  ## sva
  method.batch$m.cate <- finalSVAMethod(K)

  expr <- MethodBatchExperiment("GSE42861",
                                s = Article3_GSE42861_sampler(),
                                method.batch = method.batch,
                                cluster.nb = 7)

  expr <- runExperiment(expr, TRUE)
#+end_src
***** plot
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(121)
  expr$description
  expr$outlier
  expr <- MethodBatchExperiment_calibrate(expr)
#+end_src

#+RESULTS:
#+begin_example
[1] "Run on GSE42861 with FAMT|cate|lm|PcaLm|LassoLfmm|RidgeLfmm|SVA|"
[1]  36714  51546 101455 125220 149131
[1] "FAMT"
[1] "== calibrate: median"
[1] 4.045254
[1] "== calibrate: mad"
[1] 5.895885
[1] "cate"
[1] "== calibrate: median"
[1] 0.01449029
[1] "== calibrate: mad"
[1] 1.16504
[1] "lm"
[1] "== calibrate: median"
disease.state 
   0.04531018 
[1] "== calibrate: mad"
disease.state 
     4.209653 
[1] "PcaLm"
[1] "== calibrate: median"
disease.state 
 -0.004352184 
[1] "== calibrate: mad"
disease.state 
     1.123469 
[1] "LassoLfmm"
[1] "== calibrate: median"
disease.state 
  -0.01364105 
[1] "== calibrate: mad"
disease.state 
     1.139065 
[1] "RidgeLfmm"
[1] "== calibrate: median"
disease.state 
   0.01155879 
[1] "== calibrate: mad"
disease.state 
     1.183109 
[1] "SVA"
[1] "== calibrate: median"
[1] 2.502576
[1] "== calibrate: mad"
[1] 3.530778
#+end_example

#+begin_src R :results output :exports both
  print.data.frame(MethodBatchExperiment_count_intersect(expr, top = 10, plot = NULL))
#+end_src

#+RESULTS:
#+begin_example
     method nb observed.fdr observed.puissance
1      cate 10          0.6                0.8
2      FAMT 10          1.0                0.0
3 LassoLfmm 10          0.6                0.8
4        lm 10          1.0                0.0
5     PcaLm 10          0.5                1.0
6 RidgeLfmm 10          0.6                0.8
7       SVA 10          1.0                0.0
     method cate FAMT LassoLfmm lm PcaLm RidgeLfmm SVA
1      cate   10   NA         5  1     5         7  NA
2      FAMT   NA   10        NA NA    NA        NA  10
3 LassoLfmm    5   NA        10 NA     9         8  NA
4        lm    1   NA        NA 10    NA         1  NA
5     PcaLm    5   NA         9 NA    10         7  NA
6 RidgeLfmm    7   NA         8  1     7        10  NA
7       SVA   NA   10        NA NA    NA        NA  10
#+end_example

#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_count_intersect(expr, top = 100, plot = "tile")
  save_plot_timc_bcm_15(pl, "GSE42861_count_intersect_top100.png")
#+end_src

#+RESULTS:
:      method  nb observed.fdr observed.puissance
: 1      cate 100         0.95                  1
: 2      FAMT 100         1.00                  0
: 3 LassoLfmm 100         0.95                  1
: 4        lm 100         1.00                  0
: 5     PcaLm 100         0.95                  1
: 6 RidgeLfmm 100         0.95                  1
: 7       SVA 100         1.00                  0
[[./Rplots/GSE42861_count_intersect_top100.png]]

#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_count_intersect(expr, fdr.threshold = 0.01, plot = "point")
  save_plot_timc_bcm_15(pl, "GSE42861_count_intersect_fdr01.png")
#+end_src

#+RESULTS:
:      method    nb observed.fdr observed.puissance
: 1      cate    46    0.8913043                  1
: 2      FAMT 37487    0.9998666                  1
: 3 LassoLfmm    30    0.8333333                  1
: 4     PcaLm    12    0.5833333                  1
: 5 RidgeLfmm    44    0.8863636                  1
: 6       SVA 34404    0.9998547                  1
[[./Rplots/GSE42861_count_intersect_fdr01.png]]

*** TODO Identifier les autres candidats
:LOGBOOK:
- State "TODO"       from              [2017-06-21 mer. 16:22]
:END:

Je vais fournir une liste de candidats trouver par ma méthodes, comme dans les
autres papiers. Pk ca foruni une liste plus grande ? Car ajoute plus de
variables de confusion que dans les méthode type refactor, car on prend en
compte la variable X dans l'estimation de celle ci. Du coup des sites qui avant
était noyé dans la masse peuvent sortir associé :D.

** STARTED Étude de celiac                                        :3Article:
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-05-19 ven. 17:29]
- Note taken on [2017-05-12 Ven 14:53] \\
  Bon, tout changer le code pour reduire la mémoire utilisé ca risque d'etre
  cassse %$ù^%¨. On va deja lancer sur le dataset apres clumping, quitte a
  utiliser tous le monde dans le test d'hypothèse (dataset clumper seulement sur
  pour trouver U). Faut voir de combien ca reduit le dataset !!
- Note taken on [2017-05-12 Ven 11:02] \\
  Cf cachier 12/01/2017
- Note taken on [2017-05-11 jeu. 17:44] \\
  On va partir de ce papier cite:Abraham_2014, ils cite plusieurs papier pour sont
  dataset... Faut que je comprenne plus [[https://privefl.github.io/bigsnpr/articles/bcm-seminar-packages.html][cette analyse]].
- State "TODO"       from              [2017-05-11 jeu. 16:35]
:END:
*** Data preprocessing
see [[*From big matrix to matrix and scalling][here]] 
**** DONE GWAS catalogue
CLOSED: [2017-05-23 mar. 14:23]
:LOGBOOK:
- State "DONE"       from "DEBUG"      [2017-05-23 mar. 14:23]
- Note taken on [2017-05-22 lun. 18:22] \\
  c'est pas les même position ... pourant c'est les meme non rs.... Est ce que les
  nom reste les même d'un release a une autre des génome ???
- State "DEBUG"      from "DONE"       [2017-05-22 lun. 18:22]
- State "DONE"       from "TODO"       [2017-05-22 lun. 18:22]
- State "TODO"       from              [2017-05-22 lun. 18:22]
:END:
We retrieve SNPs associated with Celiac disease in GWAS catalogue.
#+begin_src R :results output :exports both :session *ssh krakenator*
  GWAS.catalog <- readRDS("~/Projects/Thesis/Data/GWASCatalog/gwas_catalog_v1.0.1-associations_e88_r2017-04-24.rds")

  celiac.catalog <- GWAS.catalog %>%
    dplyr::filter(grepl(".*[cC]eliac.*", `DISEASE/TRAIT`)) %>%
    mutate(marker.ID = SNPS)

  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")


  ## join by marker_ID
  celiac.outlier <- celiac$map %>%
    inner_join(celiac.catalog) %>%
    as_tibble()

  ## not same pos
  ## celiac.outlier %>%
  ##   dplyr::select(marker.ID, chromosome, physical.pos, CHR_ID, CHR_POS) %>%
  ##   print.data.frame()

  ## a candidate list
  cat("nb of candidates:", nrow(celiac.outlier), "\n")
  celiac.outlier$SNPS
  candidates <- which(celiac$map$marker.ID %in% celiac.outlier$SNPS)
  saveRDS(candidates,
          "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
#+end_src

#+RESULTS:
#+begin_example
Le chargement a nécessité le package : bigmemory
Le chargement a nécessité le package : bigmemory.sri

Attachement du package : ‘bigmemory.sri’

The following object is masked from ‘package:testthat’:

    describe

Le chargement a nécessité le package : bigstatsr
Joining, by = "marker.ID"
nb of candidates: 60
 [1] "rs3748816"  "rs12727642" "rs10903122" "rs6691768"  "rs864537"  
 [6] "rs864537"   "rs859637"   "rs2157453"  "rs2816316"  "rs2816316" 
[11] "rs296547"   "rs13003464" "rs10188217" "rs13015714" "rs917997"  
[16] "rs13010713" "rs7574865"  "rs4675374"  "rs13098911" "rs6441961" 
[21] "rs17810546" "rs17810546" "rs10936599" "rs1464510"  "rs1464510" 
[26] "rs13151961" "rs13151961" "rs1020388"  "rs1033180"  "rs2187668" 
[31] "rs2187668"  "rs2474619"  "rs10806425" "rs531930"   "rs802734"  
[36] "rs2327832"  "rs1738074"  "rs1738074"  "rs212402"   "rs212388"  
[41] "rs6974491"  "rs9792269"  "rs975730"   "rs1953126"  "rs1250552" 
[46] "rs10876993" "rs653178"   "rs653178"   "rs653178"   "rs2762051" 
[51] "rs1958589"  "rs4899260"  "rs12928822" "rs2074404"  "rs1893217" 
[56] "rs1893217"  "rs157640"   "rs4819388"  "rs2298428"  "rs2298428"
#+end_example


Je ne sais pas ou Flo a récupéré ces datas mais c'est surement que la release du
genome humain est GRCh37, alors que ce que j'ai ddl sur gwas catalog repose sur
GRCh38. 

*Ccl*: on va prendre ces outliers car les rs reste les mêmes d'après Thomas K.

*Candidates for G_clumped and test*:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  dat <- Article3_Celiac_sampler(clumped = FALSE) %>%
    sampl()

  snps.name <- colnames(dat$G)[dat$outlier]
  snps.name
  length(snps.name)


  ## for clumped dataset
  rm(dat)
  gc()
  G <- readRDS('~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds')
  candidates.clumped <- which(colnames(G) %in% snps.name)
  length(candidates.clumped)
  colnames(G)[candidates.clumped]
  saveRDS(candidates.clumped, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates_clumped.rds")
#+end_src

#+RESULTS:
#+begin_example
  > snps.name
   [1] "rs3748816"  "rs12727642" "rs10903122" "rs6691768"  "rs864537"  
   [6] "rs859637"   "rs2157453"  "rs2816316"  "rs296547"   "rs13003464"
  [11] "rs10188217" "rs13015714" "rs917997"   "rs13010713" "rs7574865" 
  [16] "rs4675374"  "rs13098911" "rs6441961"  "rs17810546" "rs10936599"
  [21] "rs1464510"  "rs13151961" "rs1020388"  "rs1033180"  "rs2187668" 
  [26] "rs2474619"  "rs10806425" "rs531930"   "rs802734"   "rs2327832" 
  [31] "rs1738074"  "rs212402"   "rs212388"   "rs6974491"  "rs9792269" 
  [36] "rs975730"   "rs1953126"  "rs1250552"  "rs10876993" "rs653178"  
  [41] "rs2762051"  "rs1958589"  "rs4899260"  "rs12928822" "rs2074404" 
  [46] "rs1893217"  "rs157640"   "rs4819388"  "rs2298428" 
  > length(snps.name)
  [1] 49
  > length(candidates.clumped)
  [1] 10
  > colnames(G)[candidates.clumped]
   [1] "rs10903122" "rs859637"   "rs13010713" "rs1464510"  "rs1020388" 
   [6] "rs1738074"  "rs653178"   "rs1958589"  "rs1893217"  "rs157640" 
#+end_example
**** CANCELLED Convert G into bigmatrix
CLOSED: [2017-05-24 mer. 14:00]
:LOGBOOK:
- Note taken on [2017-05-24 mer. 14:14] \\
  bigmatrix n'arrive pas a me gerrer une matrix de cette taille.... On va faire ca
  a l'arrache !!
- State "CANCELLED"  from "RUNNING"    [2017-05-24 mer. 14:00]
- State "RUNNING"    from "TODO"       [2017-05-24 mer. 11:38]
- State "TODO"       from              [2017-05-24 mer. 11:38]
:END:
#+begin_src R :results output :exports both
  library(bigmemory)
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  G.big <- as.big.matrix(G,
                         backingpath = "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/",
                         backingfile = "G.bigmemory")

  saveRDS(describe(G.big), "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_bigmemory_desc.rds")

#+end_src
**** DONE Split G
CLOSED: [2017-05-24 mer. 15:13]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-24 mer. 15:13]
- State "RUNNING"    from "TODO"       [2017-05-24 mer. 14:13]
- State "TODO"       from              [2017-05-24 mer. 14:00]
:END:

Je vais faire un truc à l'arrache qui marche de paire avec [[file:ThesisRpackage/R/3Article_Celiac.R::Article3_Celiac_lm%20<-%20function(m,%20dat)%20{][Article3_Celiac_lm]].
#+begin_src R :results output :exports both
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")

  L <- ncol(G)
  chunk.size <- L / 20
  chunks <- split(1:L, ceiling(1:L / chunk.size))
  it <- 1
  for (ch in chunks) {

    saveRDS(list(G = G[,ch], ch = ch),
            paste0("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_splits/G_", it,".rds"))
    it <- it + 1
  }

#+end_src

*un test*:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  library(assertthat)

  ## colnames
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  col.names <- colnames(G)
  row.names <- rownames(G)
  rm(G)
  gc()

  files <- Article3_Celiac_list_G_split_files()
  for (f in files) {
    aux <- readRDS(f)
    print(f)
    assert_that(mean(colnames(aux$G) == col.names[aux$ch]) == 1)
    assert_that(mean(rownames(aux$G) == row.names) == 1)
  }


#+end_src

C'est bon :D

Je creer un G_fake.rds pour que ca rentre dans mon workflow
#+begin_src R :results output :exports both
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  saveRDS(G[1,,drop = FALSE], "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_fake.rds")
#+end_src

*** choix des paramètres
**** DONE PCA
CLOSED: [2017-05-19 ven. 15:36]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-19 ven. 15:36]
- Note taken on [2017-05-17 mer. 15:07] \\
  sreen: =4016.pts-8.krakenator=
- State "RUNNING"    from "TODO"       [2017-05-17 mer. 15:06]
- State "TODO"       from              [2017-05-17 mer. 15:06]
:END:

#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## we keep only disease.state
  X <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/X.rds")
  head(X)

  s <- TrueSampler(G.file = "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                   X.file = X,
                   outlier.file = NULL,
                   n = NULL,
                   L = NULL)
  expr <- PCAExperiment(s = s,
                        description = "celiac clumped PCA")
  expr <- runExperiment(expr)
  dumpExperiment(expr)
#+end_src

#+begin_src R :results output graphics :file Rplots/celiac_pca.png :exports both :width 600 :height 400 
  expr <- retrieveExperiment(124)
  expr$description
  variances <- expr$res.df$sdev / sum(expr$res.df$sdev)
  ## plot
  pl <- qplot(x = seq_along(variances), y = variances, geom='line') +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  pl
#+end_src

#+RESULTS:
[[file:Rplots/celiac_pca.png]]

On prend K = 9 variables lattentes.
*** STARTED Run only on clumped data
:LOGBOOK:
- State "STARTED"    from              [2017-05-19 ven. 15:37]
:END:
**** DONE lfmmRidge
CLOSED: [2017-05-22 lun. 08:55]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-22 lun. 08:55]
- Note taken on [2017-05-19 ven. 16:46] \\
  18255.pts-4.krakenator
- State "RUNNING"    from "TODO"       [2017-05-19 ven. 16:21]
- State "TODO"       from "RUNNING"    [2017-05-19 ven. 16:00]
:END:
***** run
:LOGBOOK:
- State "TODO"       from              [2017-05-22 lun. 08:55]
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  method.batch <- list()
  K <- 9
  ## lfmm ridge
  method.batch$m.lfmmRidge <- finalLfmmRdigeMethod(K, 1e-10)

  expr <- MethodBatchExperiment("celiac",
                                s = Article3_Celiac_sampler(clumped = TRUE),
                                method.batch = method.batch,
                                cluster.nb = NULL)

  expr <- runExperiment(expr, TRUE)
#+end_src

***** plot
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(127)
  expr$description
  expr$outlier <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates_clumped.rds")
  expr$outlier
  expr <- MethodBatchExperiment_calibrate(expr)
#+end_src

#+RESULTS:
: [1] "Run on GSE42861 with RidgeLfmm|func=run"
:  [1]  1053  4838 12948 20749 28748 38105 66375 71660 83729 90549
: [1] "RidgeLfmm"
: [1] "== calibrate: median"
: [1] 0.001673503
: [1] "== calibrate: mad"
: [1] 1.050637

****** Candidates
#+begin_src R :results output :exports both
  cat("============= candidates with fdr < 0.01  \n")
  res <- MethodBatchExperiment_candidates(expr, fdr.threshold = 0.01, print = TRUE)
  cat('============= all candidates \n')
  pl <- MethodBatchExperiment_qqplot(expr)
#+end_src

#+RESULTS:
#+begin_example
============= candidates with fdr < 0.01
     method  nb observed.fdr observed.puissance
1 RidgeLfmm 140    0.9642857                0.5
============= all candidates
        pvalue1    method    id  rank
1  9.305136e-23 RidgeLfmm 20749    50
2  2.129392e-11 RidgeLfmm 66375    89
3  2.008585e-08 RidgeLfmm 38105   111
4  5.872772e-06 RidgeLfmm 12948   134
5  1.363655e-05 RidgeLfmm 83729   139
6  7.534954e-05 RidgeLfmm  1053   163
7  5.001705e-04 RidgeLfmm 28748   240
8  1.347504e-03 RidgeLfmm  4838   336
9  5.794449e-01 RidgeLfmm 71660 54728
10 5.982918e-01 RidgeLfmm 90549 56482
#+end_example

Il faut lancer l'association sur tout le génome !

*RMK*: Le clumping ca sert a n'avoir qu'un représentant par zone de LD !! Du
coup la on a peut être des outlier qui sorte mais son contabilisé dans les
candidat par un autre snps en LD !!

****** count plots
#+begin_src R :results output :exports both
  print.data.frame(MethodBatchExperiment_count_intersect(expr, top = 10, plot = NULL))
#+end_src

#+RESULTS:
:      method RidgeLfmm
: 1 RidgeLfmm        10


#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_count_intersect(expr, top = 100, plot = "tile")
  save_plot_timc_bcm_15(pl, "celiac_lfmmridge_count_intersect_top100.png")
#+end_src

#+RESULTS:
[[./Rplots/celiac_lfmmridge_count_intersect_top100.png]]


#+begin_src R :results output :exports both
  pl <- MethodBatchExperiment_count_intersect(expr, fdr.threshold = 0.01, plot = "point")
  save_plot_timc_bcm_15(pl, "celiac_lfmmridge_count_intersect_fdr01.png")
#+end_src

#+RESULTS:
[[./Rplots/celiac_lfmmridge_count_intersect_fdr01.png]]


**** DONE pca
CLOSED: [2017-05-26 Ven 17:37]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-26 Ven 17:37]
- Note taken on [2017-05-26 Ven 17:36] \\
  C'est bon c'est passé !!! 133
- Note taken on [2017-05-25 Thu 14:40] \\
  j'ai relancé sur krakenator :D
- State "RUNNING"    from "DEBUG"      [2017-05-25 Thu 14:40]
- Note taken on [2017-05-25 Thu 09:35] \\
  Le processus c'est fait tué ! Je vais ajouter un flag light a [[file:ThesisRpackage/R/LFMethod.R::fit%20<-%20function(m,%20dat,%20reuse%20=%20FALSE,%20...){][fit]] !! On vera ca
  lundi, je peux pas coder sur le mac !!
- State "DEBUG"      from "RUNNING"    [2017-05-25 Thu 09:35]
- Note taken on [2017-05-24 mer. 15:52] \\
  ca tourne sur krakenator pour le long we : 26581.pts-1.krakenator
- State "RUNNING"    from "TODO"       [2017-05-24 mer. 15:52]
- Note taken on [2017-05-24 mer. 15:23] \\
  Je coupe en deux experiment pour ne pas avoir d'experiment trop lourde !!
- State "TODO"       from "STARTED"    [2017-05-24 mer. 15:22]
:END:

We only run the computation of lattent factor score. 
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  K <- 9
  ## pca
  method.batch <- list()
  method.batch$m.pca <- finalPcaLm(K)
  method.batch$m.pca$center <- FALSE ## useless because G was scaled

  expr <- MethodBatchExperiment("celiac",
                                s = Article3_Celiac_sampler(clumped = TRUE),
                                method.batch = method.batch,
                                cluster.nb = NULL,
                                func = fit)
  expr <- runExperiment(expr, save = TRUE)
  rm(expr)
  gc()
#+end_src

**** TODO lfmmLasso
:LOGBOOK:
- Note taken on [2017-05-29 lun. 13:22] \\
  C'est trop long, je pense que je vais pas pouvoir le lancer...
- State "TODO"       from              [2017-05-25 Thu 14:15]
:END:

#+begin_src R :results output :exports both
  library(ThesisRpackage)
  K <- 9
  
  ## lfmm lasso
  method.batch <- list()
  method.batch$m.lfmmLasso <- finalLfmmLassoMethod(K, 0.05)
  
  expr <- MethodBatchExperiment("celiac",
                                s = Article3_Celiac_sampler(clumped = TRUE),
                                method.batch = method.batch,
                                cluster.nb = NULL,
                                func = fit)
  expr <- runExperiment(expr, save = TRUE)
  rm(expr)
  gc()

#+end_src

**** DONE cate
CLOSED: [2017-06-01 jeu. 16:45]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-06-01 jeu. 16:45]
- Note taken on [2017-05-31 mer. 08:54] \\
  ok il y avait un bug...
- State "RUNNING"    from "DONE"       [2017-05-31 mer. 08:52]
- State "DONE"       from "RUNNING"    [2017-05-31 mer. 08:35]
- Note taken on [2017-05-29 lun. 13:25] \\
  C'est parti sur krakenator, on va voir si ca passe !!
- State "RUNNING"    from "TODO"       [2017-05-29 lun. 13:25]
- State "TODO"       from "DONE"       [2017-05-29 lun. 13:23]
:END:

We only run the computation of lattent factor score. 
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  K <- 9
  ## pca
  method.batch <- list()
  method.batch$m.cate <- finalcateMethod(K)

  expr <- MethodBatchExperiment("celiac",
                                s = Article3_Celiac_sampler(clumped = TRUE),
                                method.batch = method.batch,
                                cluster.nb = NULL,
                                func = fit)
  expr <- runExperiment(expr, save = TRUE)
  rm(expr)
  gc()

#+end_src


*** STARTED Run on the whole dataset
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-05-24 mer. 15:52]
- State "TODO"       from              [2017-05-23 mar. 15:12]
:END:
**** DONE lfmmRidge
CLOSED: [2017-05-24 mer. 16:38]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-24 mer. 16:38]
- State "STARTED"    from "RUNNING"    [2017-05-24 mer. 16:22]
- Note taken on [2017-05-24 mer. 15:18] \\
  sur patator
- State "RUNNING"    from "DEBUG"      [2017-05-24 mer. 15:15]
- State "DEBUG"      from "DONE"       [2017-05-24 mer. 11:39]
- State "DONE"       from "RUNNING"    [2017-05-24 mer. 11:39]
- Note taken on [2017-05-24 mer. 10:54] \\
  il tourne sur patator !!
- State "RUNNING"    from "DEBUG"      [2017-05-24 mer. 10:52]
- State "DEBUG"      from "DONE"       [2017-05-24 mer. 08:47]
- State "RUNNING"    from "TODO"       [2017-05-23 Tue 23:37]
- State "TODO"       from              [2017-05-23 mar. 15:35]
:END:
We use computed score in G ~ X + U
***** run
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## we retrieve fitted method
  expr <- retrieveExperiment(127)
  m <- expr$method.batch[[1]]
  rm(expr)
  m$epsilon <- NULL
  m$C <- NULL
  m$P <- NULL
  gc()
  object.size(m)

  ## run lm
  expr <- MethodBatchExperiment("Celiac lm whole dataset with U",
                                s = Article3_Celiac_fake_sampler(), 
                                method.batch = list(m = m),
                                func = Article3_Celiac_lm)
  expr <- runExperiment(expr, save = TRUE)

#+end_src

***** plot
:PROPERTIES:
:header-args: :cache no :session *ssh patator* :eval no-export
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(131)
  expr$description
  expr <- MethodBatchExperiment_calibrate(expr)
#+end_src

#+RESULTS:
: [1] "Run on Celiac lm whole dataset with U with RidgeLfmm|func=Article3_Celiac_lm"
: [1] "RidgeLfmm"
: [1] "== calibrate: median"
: [1] 0.007643403
: [1] "== calibrate: mad"
: [1] 1.061488

****** Candidates
#+begin_src R :results output :exports both
  cat("============= candidates with fdr < 0.05  \n")
  res <- MethodBatchExperiment_candidates(expr, fdr.threshold = 0.05, print = TRUE)
  cat('============= all candidates \n')
  pl <- MethodBatchExperiment_qqplot(expr)
#+end_src

#+RESULTS:
#+begin_example
============= candidates with fdr < 0.05
     method   nb observed.fdr observed.puissance
1 RidgeLfmm 1166    0.9691252          0.7346939
============= all candidates
        pvalue1    method     id   rank
1  0.000000e+00 RidgeLfmm 103828     31
2  2.371219e-22 RidgeLfmm  63274    476
3  3.498751e-15 RidgeLfmm  60508    600
4  9.674894e-14 RidgeLfmm  75334    624
5  9.699760e-12 RidgeLfmm  31804    664
6  3.266453e-11 RidgeLfmm 203233    674
7  5.616458e-11 RidgeLfmm 114103    680
8  8.436232e-11 RidgeLfmm  31789    686
9  8.211414e-10 RidgeLfmm  50070    718
10 5.778457e-09 RidgeLfmm  15649    751
11 1.198882e-08 RidgeLfmm  50080    766
12 2.705133e-08 RidgeLfmm 116598    787
13 1.235358e-07 RidgeLfmm  40409    828
14 3.590099e-07 RidgeLfmm 116599    843
15 1.332407e-06 RidgeLfmm  28630    864
16 2.114836e-06 RidgeLfmm 116602    877
17 2.579529e-06 RidgeLfmm 276792    883
18 2.603027e-06 RidgeLfmm  28631    884
19 2.679245e-06 RidgeLfmm 113029    885
20 4.100769e-06 RidgeLfmm 172879    902
21 6.062160e-06 RidgeLfmm  13423    919
22 7.114791e-06 RidgeLfmm  38837    924
23 1.141864e-05 RidgeLfmm 109444    941
24 1.626703e-05 RidgeLfmm 250870    949
25 1.829045e-05 RidgeLfmm 209311    955
26 3.149488e-05 RidgeLfmm     88    989
27 3.510917e-05 RidgeLfmm  99224    999
28 3.745052e-05 RidgeLfmm    813   1004
29 4.618707e-05 RidgeLfmm  61280   1017
30 4.715884e-05 RidgeLfmm 234846   1018
31 7.222080e-05 RidgeLfmm   5864   1057
32 9.129374e-05 RidgeLfmm   2620   1075
33 1.443142e-04 RidgeLfmm  16326   1123
34 1.501310e-04 RidgeLfmm 109441   1127
35 1.539928e-04 RidgeLfmm 221199   1129
36 1.959969e-04 RidgeLfmm 275804   1156
37 2.184960e-04 RidgeLfmm 147445   1174
38 2.306231e-04 RidgeLfmm 122882   1176
39 3.415331e-04 RidgeLfmm 147434   1246
40 5.828767e-04 RidgeLfmm  86896   1353
41 7.425196e-04 RidgeLfmm 245524   1416
42 1.480292e-03 RidgeLfmm  14037   1678
43 2.826462e-03 RidgeLfmm 197911   2101
44 5.933679e-03 RidgeLfmm  39545   3115
45 8.688135e-02 RidgeLfmm 162427  25997
46 8.732873e-02 RidgeLfmm  14048  26127
47 4.114918e-01 RidgeLfmm 112718 115852
48 5.794731e-01 RidgeLfmm 218005 162793
49 6.059601e-01 RidgeLfmm 269927 170254
#+end_example

On recupère presque tous les outlier de GWAS catalogue. C'est pas mal vu qu'on
c'est lancé sur un gros dataset ! On peut d'attendre à ne pas avoir une bonne puissance ! 

**** DONE pca
CLOSED: [2017-05-29 lun. 08:42]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-05-29 lun. 08:42]
- State "RUNNING"    from "TODO"       [2017-05-26 Ven 17:39]
- State "TODO"       from              [2017-05-23 mar. 15:35]
:END:
We use computed score in G ~ X + U

***** run
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## we retrieve fitted method
  expr <- retrieveExperiment(133)
  m <- expr$method.batch[[1]]
  rm(expr)
  m$epsilon <- NULL
  m$C <- NULL
  m$P <- NULL
  gc()
  object.size(m)

  m$nickname
  ## run lm
  expr <- MethodBatchExperiment("Celiac lm whole dataset with U",
                                s = Article3_Celiac_fake_sampler(), 
                                method.batch = list(m = m),
                                func = Article3_Celiac_lm)
  expr <- runExperiment(expr, save = TRUE)

#+end_src
***** plot
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(135)
  expr$description
  expr <- MethodBatchExperiment_calibrate(expr)
#+end_src

#+RESULTS:
: [1] "Run on Celiac lm whole dataset with U with PcaLm|func=Article3_Celiac_lm"
: [1] "PcaLm"
: [1] "== calibrate: median"
: [1] 0.009601749
: [1] "== calibrate: mad"
: [1] 1.037876


****** Candidates
#+begin_src R :results output :exports both
  cat("============= candidates with fdr < 0.05  \n")
  res <- MethodBatchExperiment_candidates(expr, fdr.threshold = 0.05, print = TRUE)
  cat('============= all candidates \n')
  pl <- MethodBatchExperiment_qqplot(expr)
#+end_src

#+RESULTS:
#+begin_example
============= candidates with fdr < 0.05
  method  nb observed.fdr observed.puissance
1  PcaLm 931    0.9731472          0.5102041
============= all candidates
        pvalue1 method     id   rank
1  0.000000e+00  PcaLm 103828      1
2  4.617156e-19  PcaLm  63274    261
3  5.772660e-13  PcaLm  60508    365
4  2.659369e-11  PcaLm  75334    411
5  9.002770e-10  PcaLm 114103    457
6  4.087058e-09  PcaLm 203233    487
7  5.243616e-09  PcaLm  31804    492
8  2.057905e-08  PcaLm  31789    529
9  2.532802e-08  PcaLm 116598    539
10 4.207813e-08  PcaLm  50070    555
11 3.615079e-07  PcaLm  50080    610
12 4.552497e-07  PcaLm 116599    614
13 6.183613e-07  PcaLm  15649    622
14 9.268653e-07  PcaLm  40409    639
15 5.057776e-06  PcaLm 116602    701
16 9.947658e-06  PcaLm 113029    728
17 1.483828e-05  PcaLm 109444    739
18 1.601684e-05  PcaLm 276792    745
19 4.301990e-05  PcaLm  28631    805
20 4.680456e-05  PcaLm 209311    814
21 9.851797e-05  PcaLm  13423    866
22 1.004862e-04  PcaLm  28630    867
23 1.054958e-04  PcaLm    813    875
24 1.285412e-04  PcaLm  99224    900
25 1.672076e-04  PcaLm 109441    931
26 2.410613e-04  PcaLm 172879    971
27 2.430565e-04  PcaLm  16326    973
28 2.603479e-04  PcaLm  38837    984
29 3.201834e-04  PcaLm 221199   1019
30 3.628296e-04  PcaLm 147445   1041
31 3.630059e-04  PcaLm 250870   1042
32 4.610480e-04  PcaLm 275804   1083
33 5.183564e-04  PcaLm     88   1108
34 5.431577e-04  PcaLm 234846   1116
35 5.802832e-04  PcaLm   2620   1134
36 8.665041e-04  PcaLm   5864   1244
37 1.106089e-03  PcaLm 122882   1344
38 1.200209e-03  PcaLm  61280   1367
39 1.312198e-03  PcaLm  86896   1402
40 3.420760e-03  PcaLm 147434   2028
41 4.443618e-03  PcaLm  14037   2370
42 8.226520e-03  PcaLm  39545   3521
43 1.064279e-02  PcaLm 197911   4180
44 1.596013e-02  PcaLm 245524   5805
45 6.882650e-02  PcaLm  14048  20811
46 4.178394e-01  PcaLm 162427 117634
47 5.132954e-01  PcaLm 112718 144306
48 6.143502e-01  PcaLm 218005 172649
49 9.302648e-01  PcaLm 269927 261863
#+end_example


**** DONE lm
CLOSED: [2017-05-24 mer. 16:56]
:LOGBOOK:
- State "DONE"       from "RUNNING"       [2017-05-24 mer. 16:56]
- State "RUNNING"    from "TODO"       [2017-05-24 mer. 16:46]
- State "TODO"       from              [2017-05-23 mar. 15:35]
:END:

***** run
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## run lm
  expr <- MethodBatchExperiment("Celiac lm whole dataset with U",
                                s = Article3_Celiac_fake_sampler(), 
                                method.batch = list(m = finalLm()),
                                func = Article3_Celiac_lm)
  expr <- runExperiment(expr, save = TRUE)

#+end_src

***** DONE plot
CLOSED: [2017-05-24 mer. 16:54]
:PROPERTIES:
:header-args: :cache no :session *ssh patator* :eval no-export
:END:
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-24 mer. 16:54]
- State "TODO"       from              [2017-05-24 mer. 16:51]
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(132)
  expr$description
  expr <- MethodBatchExperiment_calibrate(expr)
#+end_src

#+RESULTS:
: [1] "Run on Celiac lm whole dataset with U with lm|func=Article3_Celiac_lm"
: [1] "lm"
: [1] "== calibrate: median"
: [1] -0.02361021
: [1] "== calibrate: mad"
: [1] 1.201294

Il y a une plus forte inflation car le mad est à 1.2

****** Candidates
#+begin_src R :results output :exports both
  cat("============= candidates with fdr < 0.05  \n")
  res <- MethodBatchExperiment_candidates(expr, fdr.threshold = 0.05, print = TRUE)
  cat('============= all candidates \n')
  pl <- MethodBatchExperiment_qqplot(expr)
#+end_src

#+RESULTS:
#+begin_example
============= candidates with fdr < 0.05
  method   nb observed.fdr observed.puissance
1     lm 1490    0.9812081          0.5714286
============= all candidates
        pvalue1 method     id   rank
1  0.000000e+00     lm 103828     57
2  3.547765e-18     lm  63274    840
3  4.960419e-13     lm  75334    958
4  5.458312e-12     lm  60508    982
5  7.189596e-12     lm  31804    984
6  6.598389e-11     lm 203233    999
7  8.404523e-11     lm  31789   1002
8  2.771070e-09     lm  15649   1043
9  6.601078e-09     lm  50080   1061
10 8.223723e-09     lm 114103   1067
11 8.868546e-09     lm  40409   1069
12 9.204793e-09     lm 172879   1070
13 2.580068e-08     lm  50070   1092
14 4.719332e-08     lm  28630   1101
15 7.795850e-07     lm  28631   1157
16 9.448597e-07     lm     88   1164
17 5.663411e-06     lm 234846   1230
18 1.027275e-05     lm  38837   1251
19 1.087123e-05     lm  13423   1254
20 3.572210e-05     lm 276792   1304
21 3.764200e-05     lm  61280   1309
22 3.824733e-05     lm 116598   1311
23 8.590132e-05     lm 116599   1352
24 1.169511e-04     lm 113029   1377
25 1.310568e-04     lm 109444   1391
26 1.603605e-04     lm 116602   1420
27 2.343013e-04     lm   2620   1472
28 2.478641e-04     lm 250870   1480
29 3.166738e-04     lm   5864   1526
30 3.948011e-04     lm 221199   1571
31 4.083755e-04     lm  99224   1577
32 5.365683e-04     lm 197911   1634
33 6.644093e-04     lm  16326   1695
34 6.681579e-04     lm 209311   1700
35 9.062050e-04     lm 109441   1778
36 2.307384e-03     lm 122882   2332
37 3.385705e-03     lm  86896   2730
38 3.954167e-03     lm 147434   2915
39 6.610409e-03     lm    813   3725
40 8.923028e-03     lm 245524   4425
41 1.486567e-02     lm  39545   6149
42 1.732572e-02     lm 275804   6854
43 2.007250e-02     lm 147445   7668
44 3.810430e-02     lm  14037  12800
45 9.152812e-02     lm 162427  27547
46 2.558236e-01     lm  14048  72673
47 4.059647e-01     lm 269927 114363
48 6.504444e-01     lm 112718 182731
49 7.456977e-01     lm 218005 209276
#+end_example
On observe bien que lm à moins de puissance. 
**** CANCELLED sva 
CLOSED: [2017-06-01 jeu. 18:21]
:LOGBOOK:
- State "CANCELLED"  from "TODO"       [2017-06-01 jeu. 18:21]
- State "TODO"       from              [2017-05-23 mar. 15:33]
:END:
#+begin_src R :results output :exports both
## sva
method.batch$m.sva <- finalSVAMethod(K = 9)
#+end_src
**** CANCELLED famt
CLOSED: [2017-06-01 jeu. 18:21]
:LOGBOOK:
- State "CANCELLED"  from "TODO"       [2017-06-01 jeu. 18:21]
- State "TODO"       from              [2017-05-23 mar. 15:33]
:END:
#+begin_src R :results output :exports both
## famt
method.batch$m.famt <- finalFamtMethod(K = 9)
#+end_src
**** DONE cate
CLOSED: [2017-06-01 jeu. 17:20]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-06-01 jeu. 17:20]
- State "STARTED"    from "WAITING"    [2017-06-01 jeu. 17:04]
- State "WAITING"    from "RUNNING"    [2017-05-31 mer. 08:53]
- State "RUNNING"    from "TODO"       [2017-05-31 mer. 08:36]
- State "TODO"       from              [2017-05-23 mar. 15:34]
:END:

***** DONE run
CLOSED: [2017-06-01 jeu. 17:18]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-06-01 jeu. 17:18]
- State "RUNNING"    from              [2017-06-01 jeu. 17:04]
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## we retrieve fitted method
  expr <- retrieveExperiment(136)
  m <- expr$method.batch[[1]]
  rm(expr)
  m$epsilon <- NULL
  m$C <- NULL
  m$P <- NULL
  gc()
  object.size(m)

  m$nickname
  dim(m$U)
  ## run lm
  expr <- MethodBatchExperiment("Celiac lm whole dataset with U",
                                s = Article3_Celiac_fake_sampler(), 
                                method.batch = list(m = m),
                                func = Article3_Celiac_lm)
  expr <- runExperiment(expr, save = TRUE)

#+end_src

#+RESULTS:
#+begin_example
>   m$nickname
[1] "cate"
>   dim(m$U)
[1] 15155     9

#+end_example

***** plot
:PROPERTIES:
:header-args: :cache no :session *ssh krakenator* :eval no-export
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  expr <- retrieveExperiment(137)
  expr$description
  expr <- MethodBatchExperiment_calibrate(expr)
#+end_src

#+RESULTS:
#+begin_example
>   expr$description
[1] "Run on Celiac lm whole dataset with U with cate|func=Article3_Celiac_lm"
>   expr <- MethodBatchExperiment_calibrate(expr)
[1] "cate"
[1] "== calibrate: median"
[1] 0.0118414
[1] "== calibrate: mad"
[1] 1.052495
#+end_example

****** Candidates
#+begin_src R :results output :exports both
  cat("============= candidates with fdr < 0.05  \n")
  res <- MethodBatchExperiment_candidates(expr, fdr.threshold = 0.05, print = TRUE)
  cat('============= all candidates \n')
  pl <- MethodBatchExperiment_qqplot(expr)
#+end_src

#+RESULTS:
#+begin_example
  ============= candidates with fdr < 0.05  
    method   nb observed.fdr observed.puissance
  1   cate 1492    0.9745308          0.7755102
  ============= all candidates 
          pvalue1 method     id   rank
  1  0.000000e+00   cate 103828    104
  2  1.933307e-23   cate  63274    782
  3  1.384456e-16   cate  60508    902
  4  7.824784e-15   cate  75334    929
  5  6.306602e-13   cate  31804    972
  6  7.332164e-13   cate 203233    974
  7  6.916363e-12   cate 114103    995
  8  1.190883e-11   cate  31789   1003
  9  1.117737e-10   cate  15649   1031
  10 1.179775e-10   cate  50070   1032
  11 6.883056e-09   cate  50080   1080
  12 2.822458e-08   cate 116598   1099
  13 1.188332e-07   cate  40409   1117
  14 2.089014e-07   cate 172879   1129
  15 2.265089e-07   cate  28630   1133
  16 2.904890e-07   cate 116599   1137
  17 5.828200e-07   cate  38837   1148
  18 7.273079e-07   cate  13423   1151
  19 9.524053e-07   cate 276792   1162
  20 1.049396e-06   cate  28631   1166
  21 1.231041e-06   cate 113029   1172
  22 1.500158e-06   cate 116602   1177
  23 1.830223e-06   cate 250870   1179
  24 3.895536e-06   cate     88   1204
  25 8.426060e-06   cate  61280   1230
  26 1.176549e-05   cate   5864   1243
  27 1.494987e-05   cate 209311   1253
  28 1.852909e-05   cate  99224   1258
  29 2.440185e-05   cate 109444   1275
  30 3.222632e-05   cate   2620   1289
  31 4.231491e-05   cate 234846   1303
  32 4.588758e-05   cate    813   1312
  33 4.645923e-05   cate 245524   1313
  34 5.305677e-05   cate 147434   1323
  35 5.619108e-05   cate 122882   1327
  36 8.642969e-05   cate  16326   1362
  37 1.232841e-04   cate 275804   1398
  38 1.857824e-04   cate 147445   1445
  39 3.633833e-04   cate 221199   1545
  40 3.941267e-04   cate  86896   1560
  41 4.228748e-04   cate 109441   1578
  42 4.460965e-04   cate  14037   1590
  43 1.912542e-03   cate 197911   2142
  44 6.282883e-03   cate  39545   3563
  45 1.846550e-02   cate 162427   7205
  46 9.926091e-02   cate  14048  30002
  47 2.596580e-01   cate 112718  74206
  48 4.672110e-01   cate 269927 131496
  49 5.511297e-01   cate 218005 154761
#+end_example

Quand on regarde le ranking, cate, lfmm et pca+lm recupere tous dans leur top
1500 les outlier qui ont été trouvé.
**** TODO Comparaison des méthodes
:LOGBOOK:
- State "TODO"       from              [2017-06-01 jeu. 17:49]
:END:

On va comparer les méthodes entre elles !! Ce qui est interessant c'est que tous
le monde ne trouve pas les même listes. C'est normal que l'acp soit bonne pour
trouver la liste du GWAScatalogue, la plupart on surment été trouvé comme ca !!
De toute facon je pense que ma methode est bonne quand il y a beaucoups
d'outlier !!

Il faudrait faire un coup de clamping netoyer et fournir une liste de candidat non corrélé.

** DONE LEA lfmm tuto                                             :3Article:
CLOSED: [2017-05-23 mar. 11:11]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-23 mar. 11:11]
- State "STARTED"    from "TODO"       [2017-05-23 mar. 11:10]
- State "TODO"       from              [2017-05-23 mar. 09:44]
:END:
#+begin_src R :results output :exports both :session *ssh krakenator*
  library(LEA)
  library(ThesisRpackage)

  ## sampler
  data("tutorial")
  G <- scale(tutorial.R)
  X <- scale(tutorial.C)
  s <- TrueSampler(G.file = G,
                   X.file = X,
                   outlier.file = 350:400)

  ## run batch
  method.batch <- list()
  method.batch$lea <- finalLEAMethod(4)
  method.batch$lfmm.ridge <- finalLfmmRdigeMethod(4, 1e-5)
  method.batch$lfmm.lasso <- finalLfmmLassoMethod(4, 0.01)
  method.batch$lm.pca <- finalPcaLm(4)
  method.batch$lm <- finalLm()
  method.batch$cate <- finalcateMethod(4)
  expr <- MethodBatchExperiment("LEA tuto", s,
                                method.batch)
  expr <- runExperiment(expr)

  ## plot
  pl <- MethodBatchExperiment_count_intersect(expr, top = 50, plot = "tile")
  save_plot_timc_bcm_15(pl, "lea_tuto_top05.png")

  ## fdr
  pl <- MethodBatchExperiment_count_intersect(expr, fdr.threshold = 0.05, plot = "tile")
  save_plot_timc_bcm_15(pl, "lea_tuto_fdr05.png")

  ## calibrate
  expr.calibrate <- MethodBatchExperiment_calibrate(expr)
  pl <- MethodBatchExperiment_count_intersect(expr.calibrate, fdr.threshold = 0.05, plot = "tile")
  save_plot_timc_bcm_15(pl, "lea_tuto_calibraed_fdr05.png")

#+end_src

#+RESULTS:
[[./Rplots/lea_tuto_top05.png]]
[[./Rplots/lea_tuto_fdr05.png]]
#+begin_example
     method nb observed.fdr observed.puissance
1      cate 50         0.24          0.7450980
2 LassoLfmm 50         0.28          0.7058824
3       LEA 50         0.10          0.8823529
4        lm 50         0.12          0.8627451
5     PcaLm 50         0.86          0.1372549
6 RidgeLfmm 50         0.28          0.7058824
     method  nb observed.fdr observed.puissance
1      cate 109    0.5412844          0.9803922
2 LassoLfmm  98    0.5000000          0.9607843
3        lm 125    0.6000000          0.9803922
4 RidgeLfmm 102    0.5196078          0.9607843
[1] "LEA"
[1] "== calibrate: median"
   run 1 
0.435759 
[1] "== calibrate: mad"
   run 1 
1.017892 
[1] "RidgeLfmm"
[1] "== calibrate: median"
[1] 0.6040863
[1] "== calibrate: mad"
[1] 1.639835
[1] "LassoLfmm"
[1] "== calibrate: median"
[1] 0.6677491
[1] "== calibrate: mad"
[1] 1.655878
[1] "PcaLm"
[1] "== calibrate: median"
[1] 0.05019761
[1] "== calibrate: mad"
[1] 0.9895817
[1] "lm"
[1] "== calibrate: median"
[1] 0.7437392
[1] "== calibrate: mad"
[1] 1.912658
[1] "cate"
[1] "== calibrate: median"
[1] 0.6620739
[1] "== calibrate: mad"
[1] 1.636655
     method  nb observed.fdr observed.puissance
1      cate 109    0.5412844          0.9803922
2 LassoLfmm  98    0.5000000          0.9607843
3        lm 125    0.6000000          0.9803922
4 RidgeLfmm 102    0.5196078          0.9607843
#+end_example

Le jeux de donnée à 12.5 % d'outlier. Ca ne peut pas être considéré comme des
outliers. C'est pour ca que la calibration par maf et mad echoue.

#+begin_src R :results output :exports both :session *ssh krakenator*
  pl <- MethodBatchExperiment_plot(expr, "pvalue") +
    geom_point(aes(x = index, y = -log10(stat), color = outlier))
  pl
  save_plot_timc_bcm_15(pl, "LEA_tuto_manhattanplot.png")

#+end_src

#+RESULTS:
[[./Rplots/LEA_tuto_manhattanplot.png]]

#+begin_src R :results output :exports both :session *ssh krakenator*
  pl <- MethodBatchExperiment_plot(expr, "pvalue") +
    geom_histogram(aes(stat, fill = outlier))
  save_plot_timc_bcm_15(pl, "LEA_tuto_hist.png")
#+end_src

#+RESULTS:
[[./Rplots/LEA_tuto_hist.png]]

C'est juste que l'on ne peut pas recalibré car il y a 12.5 % d'outlier mais
sinon tout le monde a les mêmes resultats y compris lm.

** Epigenome challenge
*** Mike data
ddl data
#+begin_src R :results output :exports both
  mike_data <- function() {
    data1 <- data.table::fread("~/Projects/BcmPowerRangers/challenge1.txt")
    dat <- list()
    dat$G <- as.matrix(data1[,-c("exposure", "phenotype")])
    dat$X.droite <- as.matrix(data1[,c("phenotype")])
    dat$X.gauche <- as.matrix(data1[,c("exposure")])
    dat$G <- scale(dat$G)
    dat$X.gauche <- scale(dat$X.gauche)
    dat$X.droite <- scale(dat$X.droite)
    dat
  }

#+end_src

#+RESULTS:
*** With lfmm
***** sandbox
with lfmm
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  m <- finalLfmmRdigeMethod(3, 1e-5)

  ## gauche
  dat$X <- dat$X_gauche 
  m.gauche <- run(m, dat)
  hist(m.gauche$pvalue)

  ## droite
  dat$X <- dat$X_droite
  m.droite <- run(m, dat)
  hist(m.droite$pvalue)

  ## plot
  library(tidyverse)
  library(ggplot2)
  toplot <- tibble::tibble(pvalue.gauche = m.gauche$pvalue[1,],
                           pvalue.droite = m.droite$pvalue[1,]) %>%
    dplyr::mutate(index = row_number()) %>%
    dplyr::mutate(name = colnames(dat$G))

  head(toplot)
  ggplot2::ggplot(toplot, ggplot2::aes(x = index, y = -log10(pvalue.droite))) +
    ggplot2::geom_point()



#+end_src

#+RESULTS:
: # A tibble: 6 x 4
:   pvalue.gauche pvalue.droite index  name
:           <dbl>         <dbl> <int> <chr>
: 1     0.3746316     0.3779603     1    M1
: 2     0.1911586     0.5554809     2    M2
: 3     0.2622793     0.5594943     3    M3
: 4     0.9848397     0.7843780     4    M4
: 5     0.2721801     0.2103095     5    M5
: 6     0.3915787     0.3336072     6    M6


top list de la reg de droite
#+begin_src R :results output :exports both
  toplot %>% arrange(pvalue.droite) %>%
    filter(row_number() < 20) %>%
    print.data.frame()

  sub3 <- read_delim(file = "~/Projects/BcmPowerRangers/submit3.txt", delim = " ", col_names = FALSE)

  toplot %>%
    filter(name %in% sub3$X1) %>%
    print.data.frame()
#+end_src

#+RESULTS:
#+begin_example
   pvalue.gauche pvalue.droite index  name
1   1.708482e-16  5.303736e-13   308  M308
2   6.219487e-51  5.869345e-12  2850 M2850
3  6.138023e-120  7.625876e-11   492  M492
4   6.701728e-06  1.069232e-10  5000 M5000
5   8.433646e-18  5.347791e-10  3891 M3891
6   1.244780e-25  9.870141e-08  4879 M4879
7   4.409917e-02  4.566478e-07  1873 M1873
8   1.340024e-10  4.936565e-07   196  M196
9   8.275175e-01  1.384457e-06  3130 M3130
10  3.599609e-08  4.162804e-06  2086 M2086
11  1.851784e-68  4.348085e-06  3126 M3126
12 1.309825e-151  1.553832e-05  1824 M1824
13  1.291742e-32  2.812437e-05   280  M280
14  1.148795e-53  1.924092e-04  3648 M3648
15  5.639290e-01  2.365867e-04  2218 M2218
16  8.030217e-82  3.027279e-04  1094 M1094
17  5.179647e-01  3.351219e-04   947  M947
18  9.444986e-02  3.617969e-04  4801 M4801
19  2.829809e-02  8.049950e-04   718  M718
Parsed with column specification:
cols(
  X1 = col_character()
)
   pvalue.gauche pvalue.droite index  name
1   1.340024e-10  4.936565e-07   196  M196
2   1.291742e-32  2.812437e-05   280  M280
3   1.708482e-16  5.303736e-13   308  M308
4  6.138023e-120  7.625876e-11   492  M492
5   3.673059e-22  1.221691e-03   575  M575
6   6.043301e-01  6.050826e-03   577  M577
7   1.109586e-15  4.338240e-03   596  M596
8   4.041645e-02  1.283414e-02   693  M693
9   3.111263e-01  4.730869e-03   791  M791
10  2.272248e-57  1.051997e-02   816  M816
11  1.612240e-55  6.468961e-01   900  M900
12  1.350387e-07  4.003050e-03   996  M996
13  8.030217e-82  3.027279e-04  1094 M1094
14  6.657324e-51  4.179041e-02  1308 M1308
15  2.007427e-04  1.192193e-03  1353 M1353
16  2.771511e-59  6.249105e-01  1391 M1391
17  2.630007e-55  3.022709e-03  1397 M1397
18 1.309825e-151  1.553832e-05  1824 M1824
19  4.409917e-02  4.566478e-07  1873 M1873
20  8.649048e-82  6.425090e-01  1960 M1960
21  1.423150e-08  5.937961e-01  1963 M1963
22  3.599609e-08  4.162804e-06  2086 M2086
23  3.513083e-04  1.936482e-02  2136 M2136
24  5.295119e-06  3.617421e-03  2422 M2422
25  6.219487e-51  5.869345e-12  2850 M2850
26  1.851784e-68  4.348085e-06  3126 M3126
27  8.275175e-01  1.384457e-06  3130 M3130
28  7.013637e-54  3.514398e-02  3256 M3256
29  9.202064e-10  7.924074e-01  3424 M3424
30  1.148795e-53  1.924092e-04  3648 M3648
31 1.448659e-128  3.963830e-01  3798 M3798
32  8.433646e-18  5.347791e-10  3891 M3891
33  2.493073e-23  8.541290e-01  3934 M3934
34  6.411171e-50  1.536778e-03  3951 M3951
35  1.442523e-39  1.092356e-01  4089 M4089
36  1.244780e-25  9.870141e-08  4879 M4879
37  6.701728e-06  1.069232e-10  5000 M5000
#+end_example


controle du fdr et intersection
#+begin_src R :results output :exports both
  library(qvalue)
  result <- toplot %>%
    mutate(candidate.gauche = qvalue(toplot$pvalue.gauche, fdr.level = 0.05)$significant) %>%
    mutate(candidate.droite = qvalue(toplot$pvalue.droite, fdr.level = 0.05)$significant) %>%
    mutate(candidate = candidate.gauche * candidate.droite)

  result <- result %>%
    filter(candidate == 1)

  result %>%
    print.data.frame()

  mean(sub3$X1 %in% result$name) %>% print()
  mean(result$name %in% sub3$X1) %>% print()


  ## not in sub3
  result %>%
    filter(!(result$name %in% sub3$X1))
#+end_src

#+RESULTS:
#+begin_example
   pvalue.gauche pvalue.droite index  name candidate.gauche candidate.droite
1   1.340024e-10  4.936565e-07   196  M196             TRUE             TRUE
2   1.291742e-32  2.812437e-05   280  M280             TRUE             TRUE
3   1.708482e-16  5.303736e-13   308  M308             TRUE             TRUE
4  6.138023e-120  7.625876e-11   492  M492             TRUE             TRUE
5  1.309825e-151  1.553832e-05  1824 M1824             TRUE             TRUE
6   3.599609e-08  4.162804e-06  2086 M2086             TRUE             TRUE
7   6.219487e-51  5.869345e-12  2850 M2850             TRUE             TRUE
8   1.851784e-68  4.348085e-06  3126 M3126             TRUE             TRUE
9   8.433646e-18  5.347791e-10  3891 M3891             TRUE             TRUE
10  1.244780e-25  9.870141e-08  4879 M4879             TRUE             TRUE
11  6.701728e-06  1.069232e-10  5000 M5000             TRUE             TRUE
   candidate
1          1
2          1
3          1
4          1
5          1
6          1
7          1
8          1
9          1
10         1
11         1
[1] 0.2972973
[1] 1
# A tibble: 0 x 7
# ... with 7 variables: pvalue.gauche <dbl>, pvalue.droite <dbl>, index <int>,
#   name <chr>, candidate.gauche <lgl>, candidate.droite <lgl>, candidate <int>
#+end_example

***** a function
#+begin_src R :results output :exports both
  fit_lfmm <- function(K, X, G, X.gauche, X.droite, fdr.threshold) {

    library(ThesisRpackage)

    m <- finalLfmmRdigeMethod(3, 1e-5)

    ## gauche
    dat <- list()
    dat$X <- cbind(X.gauche, X)
    dat$G <- G
    m.gauche <- run(m, dat)

    ## gauche
    dat <- list()
    dat$X <- cbind(X.droite, X)
    dat$G <- G
    m.droite <- run(m, dat)


    res.df<- tibble::tibble(pvalue.gauche = m.gauche$pvalue[1,],
                             pvalue.droite = m.droite$pvalue[1,]) %>%
      dplyr::mutate(index = row_number()) %>%
      dplyr::mutate(name = colnames(G))

    ## fdr control
    res.df <- res.df %>%
      mutate(candidate.gauche = qvalue(res.df$pvalue.gauche, fdr.level = fdr.threshold)$significant) %>%
      mutate(candidate.droite = qvalue(res.df$pvalue.droite, fdr.level = fdr.threshold)$significant) %>%
      mutate(candidate = candidate.gauche * candidate.droite)

  }

#+end_src

#+RESULTS:

lets try the function
#+begin_src R :results output :exports both
  library(tidyverse)
  library(qvalue)
  sub3 <- read_delim(file = "~/Projects/BcmPowerRangers/submit3.txt", delim = " ", col_names = FALSE)
  library(data.table)
  data1 <- fread("~/Projects/BcmPowerRangers/challenge1.txt")
  G <- as.matrix(data1[,-c("exposure", "phenotype")]) %>% scale()
  X.droite <- as.matrix(data1[,c("phenotype")]) %>% scale()
  X.gauche <- as.matrix(data1[,c("exposure")]) %>% scale()
  X <- G[, colnames(G) %in% sub3$X1] 
  dim(X)

  res.df <- fit_lfmm(K = 5,
                     X = X, G = G, X.gauche = X.gauche, X.droite = X.droite,
                     fdr.threshold = 0.05)

  candidates <- res.df %>%
    filter(candidate == 1)
  candidates

  mean(candidates$name %in% sub3$X1)
#+end_src

Correct for outlier
#+begin_src R :results output :exports both
  sub3 <- read_delim(file = "~/Projects/BcmPowerRangers/submit3.txt", delim = " ", col_names = FALSE)
  library(data.table)
  data1 <- fread("~/Projects/BcmPowerRangers/challenge1.txt")
  G <- as.matrix(data1[,-c("exposure", "phenotype")]) %>% scale()
  X.droite <- as.matrix(data1[,c("phenotype")]) %>% scale()
  X.gauche <- as.matrix(data1[,c("exposure")]) %>% scale()
  X <- G[, colnames(G) %in% sub3$X1] 
  dim(X)

  ## correction for X
  dat <- list()
  dat$G <- G
  dat$X <- X
  m.lm <- finalLm() %>%
    run(dat)
  hist(m.lm$pvalue)


  res.df <- fit_lfmm(K = 1,
                     X = NULL,
                     G = m.lm$epsilon,
                     X.gauche = X.gauche, X.droite = X.droite,
                     fdr.threshold = 0.1)

  candidates <- res.df %>%
    filter(candidate == 1)

  candidates

  mean(candidates$name %in% sub3$X1)
#+end_src
*** With xgboost
**** sandbox
#+begin_src R :results output :exports both
  library(xgboost)
  library(tidyverse)
  dat <- mike_data()

  feature.name <- colnames(dat$G)
  xg.gauche <- xgboost(data = dat$G, label = dat$X.gauche, objective = 'reg:linear',
                       max.depth = 1, eta = 0.05, nthread = 4, nround = 100)


  ## importance
  importance_matrix <- xgb.importance(model = xg.gauche, feature_names = feature.name)
  print(importance_matrix)
  xgb.plot.importance(importance_matrix = importance_matrix)

  importance.gauche.df <- importance_matrix %>%
    as_tibble()
  importance.gauche.df
  hist(importance.gauche.df$Importance)

  ## th.gauche <- 0.0000001
  ## importance.gauche.df <- importance_matrix %>%
  ##   as_tibble() %>%
  ##   filter(Importance > th.gauche)
  ## importance.gauche.df


  ## droite
  xg.droite <- xgboost(data = dat$G,
                       label = dat$X.droite, objective = 'reg:linear',
                       max.depth = 1, eta = 0.001, nthread = 4, nround = 5000)



  ## importance
  importance_matrix <- xgb.importance(model = xg.droite,
                                      feature_names=feature.name)
  print(importance_matrix)
  xgb.plot.importance(importance_matrix = importance_matrix)

  importance.droite.df <- importance_matrix %>%
    as_tibble()
  importance.droite.df
  hist(importance.droite.df$Importance)

  ## th.droite <- 0.01
  ## importance.droite.df <- importance_matrix %>%
  ##   as_tibble() %>%
  ##   filter(Importance > th.droite)
  ## importance.droite.df

  ## mult
  importance.mult <- importance.gauche.df %>%
    inner_join(importance.droite.df, by = "Feature", suffix = c(".gauche", ".droite")) %>%
    mutate(importance.mult = Importance.gauche *
             Importance.droite) %>%
    arrange(-importance.mult)


  ## plot
  importance.mult$Feature

  ## sub3
  sub3 <- read_delim(file = "~/Projects/BcmPowerRangers/submit3.txt", delim = " ", col_names = FALSE)


  sum(sub3$X1 %in% importance.mult$Feature)
  sum(sub3$X1 %in% importance.droite.df$Feature)
  sum(sub3$X1 %in% importance.gauche.df$Feature)


  importance.mult %>%
    select(Feature,
           importance.mult)
  hist(importance.mult$importance.mult)
#+end_src
*** Second dataset
ddl data
#+begin_src R :results output :exports both
  of_data <- function() {
    data1 <- read.table("~/Projects/BcmPowerRangers/challenge2.txt")
    dat <- list()
    dat$G <- as.matrix(data1[,-(1497:1501)])
    dat$X.droite <- as.matrix(data1[,c("phenotype")])
    dat$X.gauche <- as.matrix(as.numeric(data1[,c("exposure")]))
    dat$age <- as.numeric(data1[,c("age")]) %>% scale
    dat$gender <- as.numeric(data1[,c("gender")]) %>% scale
    dat$tissue <- as.numeric(data1[,c("tissue")]) %>% scale
    dat$G <- scale(dat$G)
    dat$X.gauche <- scale(dat$X.gauche)
    dat$X.droite <- scale(dat$X.droite)
    ## dat$X.co <- scale(dat$X.co)
    dat
  }
#+end_src

#+RESULTS:

**** sandbox
#+begin_src R :results output :exports both
  library(tidyverse)
  library(ThesisRpackage)
  library(qvalue)

  ## run of lfmm
  dat <- of_data()
  m.lfmm <- finalLfmmRdigeMethod(K = 5, 1e-5)
  dat$X <- dat$X.gauche
  m.lfmm <- run( m.lfmm, dat)


  res <- tibble(pvalue.exposure = m.lfmm$pvalue[1,],
                feature = colnames(dat$G)) %>%
    mutate(qvalue.exposure = qvalue(pvalue.exposure)$qvalues)

  hist(res$pvalue.exposure)
  step1.filter <- res$qvalue.exposure < 0.000001
  sum(step1.filter)

  seq(11, 1496, 80) %in% which(step1.filter)

  ## write(colnames(dat$G)[which(step1.filter)],file = "~/Projects/BcmPowerRangers/data2_gauche.txt")

  ####################
  ## hima
  data.of <- read.table("~/Projects/BcmPowerRangers/challenge2.txt")
  ## devtools::install_github("privefl/HIMA")
  require(HIMA)
  exp <- 1 - (data.of[, "exposure"] %>% as.integer() - 1)
  exp
  cov <- data.frame(gender = as.integer(data.of$gender),
                    age = as.integer(data.of$age),
                    tissue = as.integer(data.of$tissue))
  hima.res <- hima(X = exp,
                   Y = data.of$phenotype,
                   M = dat$G[,step1.filter],
                   COV = cov,
                   family = "binomial",
                   lambda.min = 0.000000000001)
  hima.res
  ####################
  ## 
  install.packages("RcppNumerical")


  ## run of glmnet with selected outlier
  library(glmnet)

  x = dat$G[, step1.filter] %>%
    cbind(dat$age, dat$gender, dat$tissue)
  glmnet.res <- glmnet(x = x,
                       y = as.factor(dat$X.droite), family = "binomial")
  glmnet.res
  rownames(glmnet.res$beta)[glmnet.res$beta[,100] != 0]

#+end_src

**** a lfmm function
#+begin_src R :results output :exports both

  lfmm.func <- function(K = 5, lambda = 1e-5, X, G) {
    require(ThesisRpackage)
    require(qvalue)

    m.lfmm <- finalLfmmRdigeMethod(K = K, lambda = lambda)
    dat <- list()
    dat$X <- X
    dat$G <- G
    m.lfmm <- run(m.lfmm, dat)

    res <- tibble(pvalue = m.lfmm$pvalue[1,],
                  feature = colnames(dat$G),
                  beta = m.lfmm$B[1,]) %>%
      mutate(qvalue = qvalue(pvalue)$qvalues)
  res

  }

  dat <- of_data()
  res <- lfmm.func(K = 5,
                   lambda = 1e-5,
                   X = dat$X.gauche,
                   G = dat$G)
  hist(res$pvalue)
  hist(res$beta)
#+end_src

**** lfmm a gauche et a droite
#+begin_src R :results output :exports both
  dat <- of_data()
  true.cand <- seq(11, 1496, 80)
  true.cand


  ## gauche
  res.gauche <- lfmm.func(K = 5, lambda = 1e-5,
                          X = dat$X.gauche,
                          G = dat$G)

  res.gauche %>%
    filter(qvalue < 0.000001)
  candidate.gauche <- which(res.gauche$qvalue < 0.000001)
  candidate.gauche

  toplot <- res.gauche %>%
    mutate(id = row_number()) %>%
    mutate(col = id %in% true.cand)
  ggplot(toplot, aes(x = id, y = -log10(pvalue), col = col)) +
    geom_point()

  ## lfmm droite
  res.droite <- lfmm.func(K = 1, lambda = 1e-5,
                          X = dat$X.droite,
                          G = dat$G)

  toplot <- res.droite %>%
    mutate(id = row_number()) %>%
    mutate(col = id %in% true.cand)
  ggplot(toplot, aes(x = id, y = -log10(pvalue), col = col)) +
    geom_point()


  ## mult
  res.mult <- res.gauche %>%
    inner_join(res.droite, by = "feature", suffix = c(".gauche",
                                                    ".droite")) %>%
    mutate(beta.sobel = beta.gauche * beta.droite) %>%
    mutate(sd.gauche = mad(beta.gauche),
           sd.droite = mad(beta.droite),
           t.test.sobel = beta.gauche * beta.droite /
             (sqrt(beta.gauche ^ 2 * sd.droite ^ 2 +
                   beta.droite ^ 2 * sd.gauche ^ 2))) %>%
    mutate(pvalue = 2 * pnorm(abs(t.test.sobel), lower.tail = FALSE))

  toplot <- res.mult %>%
    mutate(id = row_number()) %>%
    mutate(col = id %in% true.cand)
  ggplot(toplot, aes(x = id, y = -log10(pvalue), col = col)) +
    geom_point()

  res.mult <- res.mult %>%
    mutate(qvalue = qvalue(res.mult$pvalue)$qvalues)

  candidate <- which(res.mult$pvalue < 0.02)
  length(candidate)
  f.score <- function(candidate, sol) {
    pwr <- mean(sol %in% candidate)
    cat("P", pwr)
    fdr <- 1 -  mean(candidate %in% sol)
    cat("FDR", fdr)
    2 * pwr * (1 - fdr) / (pwr + (1 - fdr))
  }
  f.score(candidate, true.cand)

  write(colnames(dat$G)[candidate], file = "~/Projects/BcmPowerRangers/data2_submit.txt")
#+end_src

** Cate SVA et lfmm sur des simu générative

*** =NormalSampler2=
On simule des données avec le modèle génératif de lfmm
#+begin_src R :results output :exports both
  K <- 5
  s <- NormalSampler2(n = 500,
                      L = 2000,
                      K = K,
                      prop.outlier = 0.1,
                      cs = c(0.6, 0.5, 0.0, 0.0, 0.0))

  dat <- sampl(s)

  methods <- finalBench(K = K, lambda = 1e-5, sparse.prop = 0.1, fast.only = TRUE, calibrate = FALSE)
  methods$sva <- NULL

  expr <- do.call(FDRControlExperiment, c(list(nb.rep = 3, sampler = s), methods))

  expr <- runExperiment(expr)
#+end_src


#+begin_src R :results output graphics :file Rplots/cate_comp_pvalue.png :exports both :width 600 :height 400 
  plot(expr, plot.type = "pvalue.grid")
#+end_src

#+RESULTS:
[[file:Rplots/cate_comp_pvalue.png]]

#+begin_src R :results output graphics :file Rplots/cate_comp_precision.png :exports both :width 600 :height 400 
plot(expr, plot.type = "precision.recall", summary_bin = TRUE, geom = "line")
#+end_src

#+RESULTS:
[[file:Rplots/cate_comp_precision.png]]

Il y a vraissemblablement un problème avec Cate. Dans ce cas le modèle utilisé
est différent de celui de cate. On va essayer avec NormalSampler

*** =NormalSampler=
On simule des données avec le modèle génératif de lfmm
#+begin_src R :results output :exports both
  K <- 5
  s <- NormalSampler(n = 500,
                     L = 2000,
                     K = K,
                     prop.outlier = 0.05,
                     c = 0.2)

  dat <- sampl(s)

  methods <- finalBench(K = 5, lambda = 1e-5, sparse.prop = 0.1, fast.only = TRUE, calibrate = FALSE)
  methods$sva <- NULL
  ## methods$lfmmRidge <- NULL
  methods$pcaLm <- NULL

  expr <- do.call(FDRControlExperiment, c(list(nb.rep = 3, sampler = s), methods))

  expr <- runExperiment(expr)
#+end_src

#+RESULTS:
#+begin_example
DEBUG [2017-06-12 13:28:34] runExperiment.FDRControlExperiment: We set the seed
DEBUG [2017-06-12 13:28:41] run.Method: running  lm+zscore|calibrate=FALSE
TRACE [2017-06-12 13:28:41] attaching impute
DEBUG [2017-06-12 13:28:41] FAMT::as.FAMTdata said:
--------------------------------
$`Rows with missing values`
integer(0)

$`Columns with missing values`
integer(0)

--------------------------------
DEBUG [2017-06-12 13:28:43] FAMT::modelFAMT said:
--------------------------------
[1] "Fitting Factor Analysis Model with 5 factors"
[1] "Fitting Factor Analysis Model with 5 factors"
--------------------------------
DEBUG [2017-06-12 13:28:44] run.Method: running  Zscore
DEBUG [2017-06-12 13:28:44] run.Method: running  lm+zscore|calibrate=FALSE
DEBUG [2017-06-12 13:28:44] run.Method: running  lm+zscore|calibrate=FALSE
DEBUG [2017-06-12 13:28:45] run.Method: running  lm+zscore|calibrate=FALSE
TRACE [2017-06-12 13:28:45] attaching impute
DEBUG [2017-06-12 13:28:45] FAMT::as.FAMTdata said:
--------------------------------
$`Rows with missing values`
integer(0)

$`Columns with missing values`
integer(0)

--------------------------------
DEBUG [2017-06-12 13:28:48] FAMT::modelFAMT said:
--------------------------------
[1] "Fitting Factor Analysis Model with 5 factors"
[1] "Fitting Factor Analysis Model with 5 factors"
--------------------------------
DEBUG [2017-06-12 13:28:49] run.Method: running  Zscore
DEBUG [2017-06-12 13:28:49] run.Method: running  lm+zscore|calibrate=FALSE
DEBUG [2017-06-12 13:28:49] run.Method: running  lm+zscore|calibrate=FALSE
DEBUG [2017-06-12 13:28:49] run.Method: running  lm+zscore|calibrate=FALSE
TRACE [2017-06-12 13:28:49] attaching impute
DEBUG [2017-06-12 13:28:49] FAMT::as.FAMTdata said:
--------------------------------
$`Rows with missing values`
integer(0)

$`Columns with missing values`
integer(0)

--------------------------------
DEBUG [2017-06-12 13:28:52] FAMT::modelFAMT said:
--------------------------------
[1] "Fitting Factor Analysis Model with 5 factors"
[1] "Fitting Factor Analysis Model with 5 factors"
--------------------------------
DEBUG [2017-06-12 13:28:53] run.Method: running  Zscore
DEBUG [2017-06-12 13:28:54] run.Method: running  lm+zscore|calibrate=FALSE
DEBUG [2017-06-12 13:28:54] run.Method: running  lm+zscore|calibrate=FALSE
#+end_example

#+begin_src R :results output graphics :file Rplots/cate_comp_normalsampler_pvalue.png :exports both :width 600 :height 400 
  plot(expr, plot.type = "pvalue.grid")
#+end_src

#+RESULTS:
[[file:Rplots/cate_comp_normalsampler_pvalue.png]]



#+begin_src R :results output graphics :file Rplots/cate_comp_normalsampler_precision.png :exports both :width 600 :height 400 
plot(expr, plot.type = "precision.recall", summary_bin = FALSE, geom = "point")
#+end_src

#+RESULTS:
[[file:Rplots/cate_comp_normalsampler_precision.png]]

C'est vraiment bizare si c est trop grand cate fait n'imp. Pk j'ai pas les mêmes
résultats avec les vrais dataset ?

*** DONE Sur des vrais données
CLOSED: [2017-06-13 mar. 10:53]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-06-13 mar. 10:53]
- Note taken on [2017-06-12 lun. 14:39] \\
  On verra ca plus tard...
- State "TODO"       from              [2017-06-12 lun. 14:39]
:END:

#+begin_src R :results output :exports both
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000.rds"
  pca.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000_PCA.rds"

  K <- 5
  cs <- cs_sampler(K)
  cs
  s <- FromTrueSampler2(G.file = G.file,
                        K = K,
                        prop.outlier = 0.1,
                        cs = cs,
                        pca.file = pca.file,
                        rho.B = 2.8,
                        L = 1000)
  ## dat <- sampl(s)

  methods <- finalBench(K = K, lambda = 1e-5, sparse.prop = 0.15, fast.only = FALSE, calibrate = FALSE)
  methods$sva <- NULL
  methods$famt <- NULL
  ## methods$lfmmRidge <- NULL
  ## methods$pcaLm <- NULL

  expr <- do.call(FDRControlExperiment, c(list(nb.rep = 3, sampler = s), methods))

  expr <- runExperiment(expr)

#+end_src


#+begin_src R :results output graphics :file Rplots/cate_comp_fromtruesampler2_pvalue.png :exports both :width 600 :height 400 
  plot(expr, plot.type = "pvalue.grid")
#+end_src

#+RESULTS:
[[file:Rplots/cate_comp_fromtruesampler2_pvalue.png]]


#+begin_src R :results output graphics :file Rplots/cate_comp_fromtruesampler2_precision.png :exports both :width 600 :height 400 
plot(expr, plot.type = "precision.recall", summary_bin = TRUE, geom = "point")
#+end_src

#+RESULTS:
[[file:Rplots/cate_comp_fromtruesampler2_precision.png]]


Avec ce simlateur on arrive a simuler plus de situation j'ai l'impression !! On
va lancer tout ca sur krakenator !!!
* Sandbox
** Test of bigsnpr
#+begin_src R :results output :exports both
  library(bigsnpr)
  big_univLogReg
  snp_clumping
#+end_src

** Test of R5 object in R
#+begin_src R :results output :exports both
  Person <- setRefClass("Person", fields = c("a"))
  p <- Person$new(a = 1)

  hello  <- function(p){
    UseMethod("hello")
  }

  hello.Person <- function(p) {
    print("hello")
    print(p$a)
  }

  hello(p)
  str(p)

  p.bis <- list(a = 2)
  class(p.bis) <- "Person"
  hello(p.bis)
  str(p.bis)
#+end_src

** Plink
*** Extract a sample
See [[http://zzz.bwh.harvard.edu/plink/dataman.shtml#extract][doc]]

#+begin_src shell :results output :exports both 
  cd ~/Projects/Thesis/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300 --chr 1 --from-kb 1 --to-kb 10000 --make-bed --out FinnuncorrNLITUK1UK3hap300_sample
#+end_src

#+RESULTS:
#+begin_example
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to FinnuncorrNLITUK1UK3hap300_sample.log.
Options in effect:
  --bfile FinnuncorrNLITUK1UK3hap300
  --chr 1
  --from-kb 1
  --make-bed
  --out FinnuncorrNLITUK1UK3hap300_sample
  --to-kb 10000

7761 MB RAM detected; reserving 3880 MB for main workspace.
1024 out of 295453 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Total genotyping rate is 0.999556.
1024 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--make-bed to FinnuncorrNLITUK1UK3hap300_sample.bed +
FinnuncorrNLITUK1UK3hap300_sample.bim + FinnuncorrNLITUK1UK3hap300_sample.fam
#+end_example

#+begin_src shell :results output :exports both 
  cd ~/Projects/Thesis/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300 --thin 0.1 --make-bed --out FinnuncorrNLITUK1UK3hap300_sample
#+end_src

#+RESULTS:
#+begin_example
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to FinnuncorrNLITUK1UK3hap300_sample.log.
Options in effect:
  --bfile FinnuncorrNLITUK1UK3hap300
  --make-bed
  --out FinnuncorrNLITUK1UK3hap300_sample
  --thin 0.1

7761 MB RAM detected; reserving 3880 MB for main workspace.
295453 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
--thin: 265860 variants removed (29593 remaining).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Total genotyping rate is 0.999583.
29593 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--make-bed to FinnuncorrNLITUK1UK3hap300_sample.bed +
FinnuncorrNLITUK1UK3hap300_sample.bim + FinnuncorrNLITUK1UK3hap300_sample.fam
#+end_example

** rsnps
[[https://cran.r-project.org/web/packages/rsnps/rsnps.pdf][Doc]]
#+begin_src R :results output :exports both
  library(rsnps)
  ld_search('rs2836443')
  ncbi_snp_query("rs420358")
  ncbi_snp_query2("rs420358")
#+end_src
Ca sert a rien il y a pas les genes.

** biomaRt
#+begin_src R :results output :exports both
  library(biomaRt) # biomaRt_2.30.0, R version 3.3.2 (2016-10-31)

  ## list db
  listMarts()

  ## test on a celiac snps
  snp.db <- useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")


  listFilters(snp.db)
  att <- listAttributes(snp.db)
  att

  the.snps <- c("rs13010713")

  nt.biomart <- getBM(c("refsnp_id",
                        "refsnp_source",
                        "chr_name",
                        "chrom_start",
                        'phenotype_name',
                        "phenotype_description"),
                      filters="snp_filter",
                      values=the.snps,
                      mart=snp.db)
  nt.biomart
#+end_src

Ce que je comprends c'est que le top pour faire des annotation de SNP c'est
[[http://www.ensembl.org/index.html][ensembl]] (voir ce [[https://www.biostars.org/p/1332/][topic]]). Ensembl lui prend les info de dbSNP. MAIS je ne sais
pas si les rs sont les même d'une release a l'autre... [2017-05-23 mar.] on est
a la release 88.

D'après Thomas d'un release a l'autre les rs sont les mêmes ! Il y a de forte
chance de celiac soit en GRCh37. Faudrait aller voir ca

* Articles
** 2014 - Advantages and Pitfalls in the Application of Mixed-Model  Association Methods :LFMM:
:PROPERTIES:
:Custom_ID: yang14_advan_pitfal_applic_mixed_model_assoc_method
:AUTHOR:   Jian Yang, Noah A Zaitlen, Michael E Goddard, Peter M, Visscher \& Alkes L Price
:JOURNAL:  Nature Genetics
:YEAR:     2014
:VOLUME:   46
:PAGES:    100-106
:DOI:      10.1038/ng.2876
:URL:      https://doi.org/10.1038/ng.2876
:END:

cite:yang14_advan_pitfal_applic_mixed_model_assoc_method
*** Abstract
C'est un article sur les mixed-linear model pour les associations, en
particulier il s'interesse au GWAS (donc plutot phénotype ~ génotype). Ils
vont donner des recommendation sur l'utilisation des MLMA methods.

*** Mixed-model association methods prevent false positive associations and increase power
ok classic quand il y a de la structure d'échatillonage (structure de pop,
parenté etc) elle est capté par la partie aléatoire le reste est
incomprehenssible ....

*** Reducing the computational cost of mixed-model association analysis
il y a des améliorations computationnelles qui ont été faite et qui permette de passer a l'echelle.

*** Pitfall: loss in power when the candidate marker is included in the GRM (genetic relationship matrix)
C'est ce qui avait été constaté dans l'article de LFMM. La puissance diminue
quand les merker candidats sont expliqué à la fois par les effets fixes et les
effets aléatoires Après je crois qu'ils font des simultations numérique pour
montrer ca.
   
*** Pitfall: using a small subset of markers in the GRM can compromise correction for stratification
Tout est dans le titre... rien de nouveau.

*** Pitfall: loss of power in ascertained case-control studies
Les phénotype ne sont pas observé au hasard! surtout dans les cas controles, on
a pas pris des gens au hasard, il y a surepresentation des malades evidament !!
Mais ca fait quoi ? OK, ok, en fait c'est dans les étude ascertained qu'il y a
un problème, il y a une perte de puissance. Ca me parait logique puisque on a
des echantillion petit de malade par exemple. Apparament il y a des méthode qui
corrige ca. Mais si on en detecte moins c'est par ce que a un taux d'erreur fixe
la méthode ne peut rien dire !! mais c'est normal, il y a moins d'info. On va
voir les simulations.
**** Tableau 3: file:./org-ref-pdfs/yang14_advan_pitfal_applic_mixed_model_assoc_method.pdf::4
Ok il report les pvalues des des marker outlier... 
***** Rmk: 
On parle de pvaleur mais on enonce jamais les hypothèses. C'est implicite que
$H0_j$ : le marker j est neutre $H1_j$ : le marker j est associé au phénotype
Biensur la modélisation n'est pas la même dans le modèle linéaire et MLMe. Mais
le raisonnement marche quand même c'est deux modèle sont vu comme des boites et
la pvalues c'est la probabilité que sous H0 on observe un truc plus atypique,
donc pvalue plus faible veux dire moins de puissance. Mais bon je suis pret a
parier que les pvaleur de tous le monde sont plus faible dans le cas de MLMe et
que le problème c'est juste l'application des teste d'hypothèse classic !! Je
suis persuader qu'il faut quelqueshose de plus robuste pour les test
d'hypothèse, avec moins de modèle et plus de logique ;)...
     

** 2015 - A Practical Guide To Environmental Association Analysis in  Landscape Genomics :LFMM:EAAReviewAndComparison:
:PROPERTIES:
:Custom_ID: rellstab15_pract_guide_to_envir_assoc
:AUTHOR:   Christian Rellstab, Felix Gugerli, Andrew Eckert, , Angela Hancock \& Rolf Holderegger
:JOURNAL:  Molecular Ecology
:YEAR:     2015
:VOLUME:   24
:PAGES:    4348-4370
:DOI:      10.1111/mec.13322
:URL:      https://doi.org/10.1111/mec.13322
:END:

cite:rellstab15_pract_guide_to_envir_assoc
*** Abstract
bon il propose de faire un tableaux des méthodess d'association env, c'est parfait 
pour lister les concurents à LFMM et voir ou sont les manques :D 
*** The emergence of landscape genomics
Il distbigue deux approches pour identifier les genes codant pour des phénotypes
héritables : 
- top-down: GWAS and QTL (quantitative trait locus: https://en.wikipedia.org/wiki/Quantitative_trait_locus) mapping. 
  On mesure un phénotype et on le relie à un QTL ou un locus.
- bottom-up: population and landscape genomics. On utilise l'information génétique
  pour detecter les gènes sous selection (donc codant pour un phénotype impliqué dans un 
  prcessus de selection)
***** selective sweep                                            :definition:

https://en.wikipedia.org/wiki/Selective_sweep
Bon deja sweep ca veux dire balayage. C'est l'idée d'une propagation dans la population 
d'un allele. Et dans ce cas c'est a cause d'une selection
- hard selective sweep: dés que l'allele adaptatif arrive dans la généalogie il se 
  propage très vite
- soft selective sweep: la mutation neutre était déja présente dans la populations et 
  elle devient adaptative a cause d'un changement de l'environnement.

***** Box 1 file:./LFMM/Method/Bio/article_Rellstab_2015.pdf::2
<<EAA_schemas>>
[[./biblioImages/box1.jpg]]
 
***** what is next
Notations in the pdf.
Il y a un tableau de méthodes pour l'EAA
C'est pas un article de comparaison du coup il n'y a pas de dataset ni
d'experiences. On va aller voir les autre article qu'il cite.

** 2016 - Methods to study local adaptation and application to the context of high elevation in the Alpine plant Arabis alpina :LFMM:
:PROPERTIES:
:Custom_ID: thesis_Devillemereuil_2016
:AUTHOR:   Villemereuil
:JOURNAL:
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:
:URL:      https://tel.archives-ouvertes.fr/tel-01322336
:END:

cite:thesis_Devillemereuil_2016
This the thesis of piere devillemereuil.

*** Introduction Generale
**** 2.3 Méthodologie statistique - paragraphe 1 file:./Thesis/thesis_Devillemereuil_2016.pdf::24
Il fait la distinction entre deux types de scan genomique, le premier on ne sait pas si c'est adaptatif
le deuxieme on le sais.
Mais je suis pas sur de comprendre, ma disctinction: Genome = X (comme dans lfmm)
ou X = G (comme dans les GWAS). 
     
*** Chapitre 1 : Étude et comparaison des méthodes de scan génomique pour détecter la sélection file:./Thesis/thesis_Devillemereuil_2016.pdf::29
**** 1 Le problème des scan génomique file:./Thesis/thesis_Devillemereuil_2016.pdf::30
Il discute du proèblème de définition de l'hypothèse nulle. Et du fait qu'il
faut prendre en compte la structure de pop !! Interessant, derniere ligne,
o, est passé a la problèmatique des tests multiples ! avant on ne testait
que 1 seul locus, maintenant on en a la pelle.
***** Remark pour ma thèse                                          :MaThese:
mettre l'accent sur cette transition, on a de plus en plus de données =>
test multiples. Eric n'a pas l'air dans parler.
**** 2.3 Le point commun entre ces nouvelles méthodes file:./Thesis/thesis_Devillemereuil_2016.pdf::32
Il identifie es hypothèses générales des méthodes de detection de la
selection du type de LFMM cad 
- beacoups de locus neutre
- un modèle neutre souple pour s'adapter a toutes les situations
  Sont premier papier va consister a comparer les méthodes sur des simultations.
*** Article 1: Genome scan methods against more complex models: when and how much should we trust them?
C'est l'article que j'ai déja parcouru... avec les resultats qui plantent
tous le mondes ...
**** Fig A16 file:./Thesis/thesis_Devillemereuil_2016.pdf::46
Une reg avec une fausse variable, je comprends son histoire de spurious
power... Par contre on pourrait faire ca pour tester le FDR observé quand X
est faux (on en simule un ou on permute les X existants)
**** Tab A1.2 file:./Thesis/thesis_Devillemereuil_2016.pdf::47      
c'est une blague ce genre de tableau !! On ne peut pas comparer la
puissance entre deux méthodes a un seuil fixe (ici 0.05) alors que le FDR
n'est pas controlé ... La méthode qui renvoie tous le monde aurait le
meilleur power et la pire puissance ! 
    
*** 5 Conclusions principales de l’article file:./Thesis/thesis_Devillemereuil_2016.pdf::51
Il conclue que le taux de faux positif est non controlé
Il aborde la combinaison de méthodes pour réduire 
Il minimise en disant que c'est parce que le gradient env est dans le même
sens que la structure de population...
Je comprends pas son mot sur la simultation
**** Remark perso sur les data de cette article  
On ne va pas récuperer ces données surtout qu'il ne les utilise même dans
l'article 2!! En faite si je vais les récuperer par ce que ca ne me coute
rien mais bon je vais pas trop y croire !!
*** Article 2 : A new FST-based method to uncover local adaptation using environmental variables file:./Thesis/thesis_Devillemereuil_2016.pdf::57 :BayeScEnv:
github: http://github.com/devillemereuil/bayescenv
**** Abstract: 
Il fait la difference entre les méthodes Fst et avec variable environmental
Sa methode distinque 2 cause de différenciation dans les disctribution alélique: 
-divergent selection: cad une différenciation causée par la selection
-le reste .... cad l'hystoire démographique, la selection de fond 
(https://en.wikipedia.org/wiki/Background_selection c'est la selection qui reduit 
la divesité à cause de l'environnement), c'est un des facteur confondants.
    
**** Model: 
- il calcule Fst_ij dans le F model, c'est une Fst local qui décrit la structure 
  de population. Ca mesure la différenciation génétique entre chaque sous population
  et le pool de migrant. (voir Fig7: file:./Thesis/thesis_Devillemereuil_2016.pdf::54)
- et en gros ce que je comprend c'est que après il cherche les locales fst qui sont corrélées
  avec une mesure de la différenciation environementale.
- c'est bayesien, il a 3 modèles et une probabilité $P(M2|ai,E)$ ou en gros $a_i$ et $E$ 
  sont les mesures de la structure de pop et de l'environnement (voir file:./Thesis/thesis_Devillemereuil_2016.pdf::162) et il en déduit une propba d'erreur.
***** Rmk   
Ca fait un peu naif comme modèle, on dirrait que les grands concepts on tous été appliqués
a la lettre (c'est une belle modélisation bayesienne en esperant qu ca va marcher a la fin) 
mais en fait ca donne un modèle qui a l'arrivé est dure a fitter et qui a surement des problèmes
mathématiques ...
*** Pourquoi cette profusion de méthodes ? file:./Thesis/thesis_Devillemereuil_2016.pdf::73
"course a la méthode idéale ..." 
on peut justifier ca par le No Free Lunch theorem (https://en.wikipedia.org/wiki/No_free_lunch_theorem) 
Ca dit que si un algo perform bien sur une classe de problème alors il ne sera pas le
meilleur sur tous les autres problèmes.
   

   
** 2014 - Accounting for Cellular Heterogeneity Is Critical in  Epigenome-Wide Association Studies :EWAS:
:PROPERTIES:
:Custom_ID: jaffe14_accoun_cellul_heter_is_critic
:AUTHOR:   Andrew E Jaffe \& Rafael A Irizarry
:JOURNAL:  Genome Biology
:YEAR:     2014
:VOLUME:   15
:PAGES:    R31
:DOI:      10.1186/gb-2014-15-2-r31
:URL:      https://doi.org/10.1186/gb-2014-15-2-r31
:END:

cite:jaffe14_accoun_cellul_heter_is_critic
EWAS data used in this article can be ddl here https://www.ncbi.nlm.nih.gov/gds/?term=GSE20242
d'après O.F. la méthode est du même genre que dans lfmm. (la strucutre de pop est la composition cellulaire)
*** Abstract
Il propose une méthode qui prend en compte la composition cellulaire dans les etudes d'associations entre EWAS et des phénotypes ici l'age.

** 2016 - Epigenome-Wide Association Study of Body Mass Index, and the  Adverse Outcomes of Adiposity :EWAS:
:PROPERTIES:
:Custom_ID: wahl16_epigen_wide_assoc_study_body
:AUTHOR:   Simone Wahl {\it et al.}
:JOURNAL:  Nature
:YEAR:     2016
:VOLUME:   541
:PAGES:    81-86
:DOI:      10.1038/nature20784
:URL:      https://doi.org/10.1038/nature20784
:END:

cite:wahl16_epigen_wide_assoc_study_body
 
C'est une EWAS avec l'indice de masse corporelle.


** 2009 - Regression-based latent factor models               :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: agarwal09_regres
:AUTHOR:   Deepak Agarwal \& Bee-Chung Chen
:JOURNAL:
:YEAR:     2009
:VOLUME:
:PAGES:    nil
:DOI:      10.1145/1557019.1557029
:URL:      https://doi.org/10.1145/1557019.1557029
:END:

cite:agarwal09_regres
*** Domaine d'application
Système de recommandation.
data: 
- MovieLens 943*1M
*** Modèle 
[[./biblioImages/2017_01_04_001_2017-01-04_14-21-14.png]]
*** Algorithme
Je comprend que c'est un Monte Carlo EM (a voir ce que c'est).
*** Slides
[[file:./Biblio/org-ref-pdfs/slides_agarwal09_regres.pdf]]
** 2008 - High-Dimensional Sparse Factor Modeling: Applications in Gene  Epression Genomics :LFMMLike:
:PROPERTIES:
:Custom_ID: carvalho08_high_dimen_spars_factor_model
:AUTHOR:   Carlos Carvalho, Jeffrey Chang, Joseph Lucas, , Joseph Nevins, Quanli Wang \& Mike West
:JOURNAL:  Journal of the American Statistical Association
:YEAR:     2008
:VOLUME:   103
:PAGES:    1438-1456
:DOI:      10.1198/016214508000000869
:URL:      https://doi.org/10.1198/016214508000000869
:END:

cite:carvalho08_high_dimen_spars_factor_model


** 2013 - A Latent Factor Linear Mixed Model for High-Dimensional  Longitudinal Data Analysis :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: an13_laten_factor_linear_mixed_model
:AUTHOR:   Xinming An, Qing Yang \& Peter Bentler
:JOURNAL:  Statistics in Medicine
:YEAR:     2013
:VOLUME:   32
:PAGES:    4229-4239
:DOI:      10.1002/sim.5825
:URL:      https://doi.org/10.1002/sim.5825
:END:

cite:an13_laten_factor_linear_mixed_model
Le nom de la méthode c'est LFLMM ^^
*** Application Domain
High-dimensional longitudinal data analysis. Si je comprends bien c'est pour
des etudes en médecine. SOn exemple sur des vrais données est la
décroissance des capacité cognitif avec l'age.
*** Model
C'est quand même un peut différent que LFMM, il y un mixed model sur les
facteurs lattents dans l'acp en gros...
*** Algorithm
EM
*** Remarques
Je n'arrive pas a bien comprendre l'interet d'un tel modèle dans son cas.

** 2016 - Sparse Multivariate Factor Analysis Regression Models and Its  Applications To Integrative Genomics Analysis :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: zhou16_spars_multiv_factor_analy_regres
:AUTHOR:   Yan Zhou, Pei Wang, Xianlong Wang, Ji Zhu, Peter \& Song
:JOURNAL:  Genetic Epidemiology
:YEAR:     2016
:VOLUME:   41
:PAGES:    70-80
:DOI:      10.1002/gepi.22018
:URL:      https://doi.org/10.1002/gepi.22018
:END:

cite:zhou16_spars_multiv_factor_analy_regres 

C'est le même modèle que lfmm sauf que leur algo est un EM et il on une
regularisation sparse. Par contre je n'ai pas trouvé de code. Mais ca peut
valoir le coup d'implementer leur méthode.

*Le modèle est très bien décrit dans ce papier !!* 
*** TODO Remarques
J'ai pas l'impression qu'ils fasse de test d'hyporhèse par contre.
Leur B est le V de lfmm
 
 
** 2010 - An accelerated proximal gradient algorithm for nuclear norm regularized linear least squares problems :LFMM:NuclearNorm:
:PROPERTIES:
:Custom_ID: article_Toh_Yun_2010
:AUTHOR:   Kim-Chuan Toh \& Sangwoon Yun
:JOURNAL:  Pacific Journal of Optimization
:YEAR:     2010
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:article_Toh_Yun_2010
C'est article est interessant pour file:./Biblio/org-ref-pdfs/article_Toh_Yun_2010.pdf::9 
Il donne le lien entre SVD et nuclear norm : 
#+DOWNLOADED: /tmp/screenshot.png @ 2017-01-06 13:28:59
[[file:./Biblio/org-download/Articles/screenshot_2017-01-06_13-28-59.png]]  
   

** 2004 - Generalized Multilevel Structural Equation Modeling :LFMM:LFMMLike:GLLAMM:
:PROPERTIES:
:Custom_ID: rabe-hesketh04_gener_multil_struc_equat_model
:AUTHOR:   Sophia Rabe-Hesketh, Anders Skrondal \& Andrew Pickles
:JOURNAL:  Psychometrika
:YEAR:     2004
:VOLUME:   69
:PAGES:    167-190
:DOI:      10.1007/bf02295939
:URL:      https://doi.org/10.1007/bf02295939
:END:

cite:rabe-hesketh04_gener_multil_struc_equat_model

** 2010 - A Singular Value Thresholding Algorithm for Matrix Completion :LFMM:NuclearNorm:
:PROPERTIES:
:Custom_ID: cai10_singul_value_thres_algor_matrix_compl
:AUTHOR:   Jian-Feng Cai, Emmanuel Cand\`es \& Zuowei Shen
:JOURNAL:  SIAM Journal on Optimization
:YEAR:     2010
:VOLUME:   20
:PAGES:    1956-1982
:DOI:      10.1137/080738970
:URL:      https://doi.org/10.1137/080738970
:END:

cite:cai10_singul_value_thres_algor_matrix_compl
Démo de
#+DOWNLOADED: /tmp/screenshot.png @ 2017-01-06 14:49:43
[[file:./Biblio/org-download/Articles/screenshot_2017-01-06_14-49-43.png]]
Du coup c'est un example de preuve avec la norme nucléaire (donc calcul de subgradient).
Rmk: dans la preuve il font pas l'analyse, il font que la synthèse. De toute facon ils ont 
l'unicité car c'est strictement convexe !!!

** 2016 - False Discovery Rates: a New Deal
:PROPERTIES:
:Custom_ID: stephens16_false_discov_rates
:AUTHOR:   Matthew Stephens
:JOURNAL:  Biostatistics
:YEAR:     2016
:VOLUME:   nil
:PAGES:    kxw041
:DOI:      10.1093/biostatistics/kxw041
:URL:      https://doi.org/10.1093/biostatistics/kxw041
:END:

cite:stephens16_false_discov_rates
Commentaries in the pdf.

** 2007 - Capturing Heterogeneity in Gene Expression Studies by  Surrogate Variable Analysis :LFMMLike:
:PROPERTIES:
:Custom_ID: article_Leek_Storey_2007
:AUTHOR:   Leek \& Storey
:JOURNAL:  PLoS Genetics
:YEAR:     2007
:VOLUME:   3
:PAGES:    e161
:DOI:      10.1371/journal.pgen.0030161
:URL:      http://dx.doi.org/10.1371/journal.pgen.0030161
:END:

cite:article_Leek_Storey_2007
remark as okular commentary !! Supporting information and figure [[http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0030161#s5][here]].
 

*** Gene ranking more accurate and stable
Le fait de prendre en compte la structure lattente donne un ranking des
gênes plus stable. Ca pourait être un critere pour le choix de model :D
*** The R package                                                  :Rpackage:
http://www.genomine.org/sva/
[[./Biblio/org-ref-pdfs/Rpackage_sva.pdf][The SVA manual]]
**** Overview
- "Surrogate variables are covariates constructed directly
  from high-dimensional data (like gene expression/RNA sequencing/
  *methylation* /brain imaging data" : il propose de l'utiliser sur des
  données de méthylation !!
*** Simulations
Ils en dit plus dans [[ref:article_Leek_Storey_2008][cette article]]
** 2012 - Cross-Dimensional Inference of Dependent High-Dimensional  Data :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: article_Desai_Storey_2012
:AUTHOR:   Desai \& Storey
:JOURNAL:  Journal of the American Statistical Association
:YEAR:     2012
:VOLUME:   107
:PAGES:    135–151
:DOI:      10.1080/01621459.2011.645777
:URL:      http://dx.doi.org/10.1080/01621459.2011.645777
:END:

cite:article_Desai_Storey_2012
Rmk : notes in the pdf with okular

*** 5.4 Multiple Testing
Il compare 4 méthodes pour 
- MLE
- CDI
- SVA
- FAMT
Je comprends que c'est sur des données simulé de son modèle : 

#+DOWNLOADED: /tmp/screenshot.png @ 2017-01-10 15:04:44
[[file:org-download/Articles/screenshot_2017-01-10_15-04-44.png]]

avec E une structure de variance particulière, je pense que ca revient au même que mes simulation
générative de lfmm.

*/Mais quelle sva il utilise ? il y en a plein dans la doc/*
Il cite cite:article_Leek_Storey_2007 and cite:article_Leek_Storey_2008 c'est les deux papiers
a citer quand on utilise le package SVA pour enlever les batch effect et autre variation 
non voulue d'apres file:./org-ref-pdfs/Rpackage_sva.pdf::11 

*** Implementation
Il n'y a pas de package R mais ils parlent de plusieurs pacakge pour l'implémentation
    
** 2008 - A general framework for multiple testing dependence :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: article_Leek_Storey_2008
:AUTHOR:   Leek \& Storey
:JOURNAL:  Proceedings of the National Academy of Sciences
:YEAR:     2008
:VOLUME:   105
:PAGES:    18718–18723
:DOI:      10.1073/pnas.0808709105
:URL:      http://dx.doi.org/10.1073/pnas.0808709105
:END:

cite:article_Leek_Storey_2008
Rmk : note in the pdf with okular
*** Method
C'est l'article qui vent le concepte de LFMM, c'est a dire la correction pour
les fateurs de confusions

#+DOWNLOADED: /tmp/screenshot.png @ 2017-01-10 09:34:10
[[file:org-download/Articles/screenshot_2017-01-10_09-34-10.png]] 

C'est pas nouveau comme concepte !!

*** Remarques
Ce qu'il appel G c'est U dans Lfmm et il est éstimé ! Le test est fait
sashant cette estimation, quel est l'influence sur le tst d'hypothèse ??
*** Apendix file:./org-ref-pdfs/SI_Leek_Storey_2008.pdf 
remark in the pdf with okular Il dit que tout a été fait en language R mais
ou est le code ????
*** Comment calculer sont G (le V de lfmm)
Il propose l'algo iteratively re- weighted surrogate variable analysis
(IRW-SVA) : voir [[file:org-ref-pdfs/Rpackage_sva.pdf][ce R package]]. 

Comme il décrit l'algo dans le [[file:LFMM/Method/StoreyStuff/SI_Leek_Storey_2008.pdf][sup info]] c'est exactement le principe de ce
que on veut faire dans lfmm. Cad calculer G sans capter la variation causé
par S : 
#+BEGIN_QUOTE
The basic idea when estimating G in this scenario is to identify a subset of
tests whose data show a strong association with G, but not a strong
association with S. The estimate of G can then be formed based on the
right singular vectors of this subset. This approach accomplishes two
things. -- cite:article_Leek_Storey_2008 
#+END_QUOTE
*** Simulations
Voir le [[file:Biblio/org-ref-pdfs/SI_Leek_Storey_2008.pdf][SI]]. Ca pourrait valoir le coup de faire ce genre de simulation. En
tout les simulations son avantagueuse par rapport a l'algo SVA.


** 2009 - A Factor Model Approach To Multiple Testing Under Dependence :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: friguet09_factor_model_approac_to_multip
:AUTHOR:   Chlo\'e Friguet, Maela Kloareg \& David Causeur
:JOURNAL:  Journal of the American Statistical Association
:YEAR:     2009
:VOLUME:   104
:PAGES:    1406-1415
:DOI:      10.1198/jasa.2009.tm08332
:URL:      https://doi.org/10.1198/jasa.2009.tm08332
:END:

cite:friguet09_factor_model_approac_to_multip
*** Poster
file:./org-ref-pdfs/poster_friguet09_factor_model_approac_to_multip.pdf
On retrouve les même chose que dans tous les papier LFMMLike
*** R package                                                      :Rpackage:
http://famt.free.fr/
   
** 2010 - Regularization Paths for Generalized Linear Models Via  Coordinate Descent :algorithm:Rpackage:
:PROPERTIES:
:Custom_ID: friedman10_regul_paths_gener_linear_model
:AUTHOR:   Jerome Friedman, Trevor Hastie \& Robert Tibshirani
:JOURNAL:  Journal of Statistical Software
:YEAR:     2010
:VOLUME:   33
:PAGES:    nil
:DOI:      10.18637/jss.v033.i01
:URL:      https://doi.org/10.18637/jss.v033.i01
:END:

cite:friedman10_regul_paths_gener_linear_model
C'est l'article vendu dans la doc de [[https://cran.r-project.org/web/packages/glmnet/glmnet.pdf][glmnet]]
*** 2.5. Pathwise coordinate descent file:./org-ref-pdfs/friedman10_regul_paths_gener_linear_model.pdf:7
On part du plus grand $\lambda$ et on decroit (en suivant une courbe logistique)
pour atteindre un $\lambda_{min}$.
On doit pouvoir faire ca avec les regularisations en nuclear norm.
*** 3. Regularized logistic regression file:./org-ref-pdfs/friedman10_regul_paths_gener_linear_model.pdf:8
Il decrit un peut plus l'algo. Avec la perte logistique on a plus la solution
analytique du pb d'optim, c'est pour ca qu'il y a 3 boucles: 
#+DOWNLOADED: /tmp/screenshot.png @ 2017-01-11 09:52:54
[[file:org-download/Articles/screenshot_2017-01-11_09-52-54.png]] 
**** Idée pour lfmm                                                 :MaThese:
On n'a pas l'étape d'approximation quadratique (puisque ca l'ai déja). Mais 
on fait une descente par bloc de coordonnées !! 
Je pense même que l'on pourrait changer la fonction de perte en la mettant logistique
et faire cette approximation quadratique. Ca peut faire une bonne ouverture pour la thèse.
     
     

** 2015 - Binary Factorization Models for Statistical Relational Learning :LFMM:MaThese:
:PROPERTIES:
:Custom_ID: slides_Bouchard_WinterSchool2015
:AUTHOR:   Guillaume Bouchard
:JOURNAL:
:YEAR:     2015
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:slides_Bouchard_WinterSchool2015 Slides présenté par Guillaume Bouchard à
la winter school à Villard que j'ai fait en 2015 au début de ma thèse. Ce qui
m'interesse est sur le slide 21. Il parle facteur analysis sur des données
binaires. Je pense que faire de même avec lfmm est une bonne idée, ca peut
faire des pistes pour des ouvertures.

** 2016 - Reference-free deconvolution of DNA methylation data and  mediation by cell composition effects :LFMM:EWAS:
:PROPERTIES:
:Custom_ID: article_Houseman_2016
:AUTHOR:   Houseman, Kile, Christiani, , Ince, Kelsey \& Marsit
:JOURNAL:  BMC Bioinformatics
:YEAR:     2016
:VOLUME:   17
:PAGES:
:DOI:      10.1186/s12859-016-1140-4
:URL:      http://dx.doi.org/10.1186/s12859-016-1140-4
:END:

cite:article_Houseman_2016
C'est une méthode pour faire des de l'association avec des données de méthylation de l'adn 
et d'autre facteurs (je comprends que le but des d'identifier les zones du génome exprimé en 
association avec des co variables).
La méthode est comme LFMM
*** Background
DNA methylation : $Y$  (rmk transposer du sens de LFMM) valeur dans $[0,1]$, c'est la proportion 
de methylated cytosine molecules à ce locus...
$Y = M \Hommega^T$ ou $M$ est l'état de méthylation et $\Hommega$ le type des cellules.
Donc $M$ c'est la base et $\Hommega$ les quantité de chaque echantillon dans cette base.
Il parle apres d'une méthode que resemble à LFMM. Du coup sa méthode est différente ?
**** Le méthode    
Il fait un NMF avec des contrainte en plus sur $\Hommega$ et $M$ ... comme sNMF. Jusque ici c'est classique. Je comprends pas ou intervient $X$ les co-variable??
*** Methods                                                       :mediation:
C'est plus detaillé dans le supplementary material S1, c'était un .docx mdrrrrr
file:./org-ref-pdfs/S1_Houseman_2016.pdf
Je comprends qu'il fait deux type d'association 
- dans S4 c'est $\Hommega$ ~ $X$ 
- et dans S5 c'est Y ~ X + \Hommega
  Du coup c'est pas du lfmm, dans le sens ou il fait pas tout en une fois, c'est comme faire l'acp 
  et après le mettre dans lm.
  Ce que je comprend pas c'est pour il fait les deux associations ? C'est ca la [[https://en.wikipedia.org/wiki/Mediation_(statistics)][mediation]] ? 
  Dans ce cas : 
  #+DOWNLOADED: file:///home/cayek/Téléchargements/screenshot_001.jpg @ 2017-01-12 11:03:43
  [[file:org-download/Articles/screenshot_001_2017-01-12_11-03-43.jpg]]

  Finnalement LFMM est un modèle qui permet de faire de la médiation ...
*** Implementation
Dans la doc de [[https://cran.r-project.org/web/packages/RefFreeEWAS/index.html][RefFreeEWAS]] il dit que Houseman 2016 est implementé dans ce package.

** 2014 - Reference-Free Cell Mixture Adjustments in Analysis of Dna  Methylation Data :LFMM:LFMMLike:Rpackage:EWAS:
:PROPERTIES:
:Custom_ID: houseman14_refer_free_cell_mixtur_adjus
:AUTHOR:   Houseman, Molitor \& Marsit
:JOURNAL:  Bioinformatics
:YEAR:     2014
:VOLUME:   30
:PAGES:    1431-1439
:DOI:      10.1093/bioinformatics/btu029
:URL:      https://doi.org/10.1093/bioinformatics/btu029
:END:

cite:houseman14_refer_free_cell_mixtur_adjus
Celui la c'est un lfmm like !!
*** TODO Method
Il dit que c'est similaire à SVA
Il y a des notations partout... on va voir le package R [[https://cran.r-project.org/web/packages/RefFreeEWAS/RefFreeEWAS.pdf][RefFreeEWAS]] (il y a pas de vignette...)
Ok j'y comprend rien...

** TODO - 2015 Testing Mediation with Regression Analysis         :mediation:
:PROPERTIES:
:Custom_ID: tuto_mediation_2015
:AUTHOR:
:JOURNAL:
:YEAR:     2015
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:tuto_mediation_2015
C'est un tuto pour faire des test sur la médiation. 
Ce que je comprends est que le but est d'identifier le role joué par M dans un lien de 
causalité. 
 

** TODO 2001 - Direct and indirect effects                  :CausalInference:
:PROPERTIES:
:Custom_ID: pearl2001direct
:AUTHOR:   Pearl
:JOURNAL:
:YEAR:     2001
:VOLUME:
:PAGES:    411--420
:DOI:
:URL:
:END:

cite:pearl2001direct
D'après of c'est un des papes de l'inference causal

** TODO 2012 - Dna Methylation Arrays As Surrogate Measures of Cell Mixture  Distribution :LFMM:EWAS:
:PROPERTIES:
:Custom_ID: houseman12_dna_methy_array_as_surrog
:AUTHOR:   Eugene Houseman {\it et al.}
:JOURNAL:  BMC Bioinformatics
:YEAR:     2012
:VOLUME:   13
:PAGES:    86
:DOI:      10.1186/1471-2105-13-86
:URL:      https://doi.org/10.1186/1471-2105-13-86
:END:

cite:houseman12_dna_methy_array_as_surrog
 
** 2013 - Testing for Associations Between Loci and Environmental  Gradients Using Latent Factor Mixed Models :LFMM:
:PROPERTIES:
:Custom_ID: frichot13_testin_assoc_between_loci_envir
:AUTHOR:   Frichot, Schoville, Bouchard, \& Francois
:JOURNAL:  Molecular Biology and Evolution
:YEAR:     2013
:VOLUME:   30
:PAGES:    1687-1699
:DOI:      10.1093/molbev/mst063
:URL:      https://doi.org/10.1093/molbev/mst063
:END:

cite:frichot13_testin_assoc_between_loci_envir
C'est l'article d'LFMM

*** Simulations
Il fait des simulations avec que des H0, il utilise le model de stepping
stone pour ca. *MAIS* je ne comprend pas comment il fait ses simulations
avec la seletion. 

** TODO 2008 - Bolasso
:PROPERTIES:
:END:
:PROPERTIES:
:Custom_ID: Bach_2008
:AUTHOR: Bach
:JOURNAL: Proceedings of the 25th international conference on Machine
learning - ICML ’08
:YEAR: 2008
:VOLUME: 
:PAGES: 
:DOI: 10.1145/1390156.1390161
:URL: http://dx.doi.org/10.1145/1390156.1390161
:END:

cite:Bach_2008 
Je suis tombé sur ce papier en cherchant sur google [[https://www.google.fr/webhp?sourceid=chrome-instant&ion=1&espv=2&ie=UTF-8#q=bootstrap%20lasso][bootstrap lasso]]
Comme c'est un papier de ce bon vieux Bach

** TODO 2013 - Low-Rank Optimization with Trace Norm Penalty
:PROPERTIES:
:Custom_ID: article_Mishra_Meyer_Bach_Sepulchre_2011
:AUTHOR:   Mishra, Meyer, Bach \& Sepulchre
:JOURNAL:  SIAM Journal on Optimization
:YEAR:     2013
:VOLUME:   23
:PAGES:    2124–2149
:DOI:      10.1137/110859646
:URL:      http://dx.doi.org/10.1137/110859646
:END:

cite:article_Mishra_Meyer_Bach_Sepulchre_2011

** TODO 2007 - Size, Power and False Discovery Rates                    :FDR:
:PROPERTIES:
:Custom_ID: efron07_size_power_false_discov_rates
:AUTHOR:   Bradley Efron
:JOURNAL:  The Annals of Statistics
:YEAR:     2007
:VOLUME:   35
:PAGES:    1351-1377
:DOI:      10.1214/009053606000001460
:URL:      https://doi.org/10.1214/009053606000001460
:END:

cite:efron07_size_power_false_discov_rates
Un article d'efrond un peu meta je pense.. A LIRE pour la parti sur le FDR pour ma thèse.
 

** 2016 - Panning for Gold: Model-free Knockoffs for High-dimensional Controlled Variable Selection :FDR:
:PROPERTIES:
:Custom_ID: candes2016panning
:AUTHOR:   Candes, Fan, Janson \& Lv
:JOURNAL:  arXiv preprint arXiv:1610.02351
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:candes2016panning 
 
C'est le papier qui devellope la théorie des knockoff en détail, il y a aussi
une revu des méthodes classiques des tests d'hypothèses. 
 

** 2015 - Controlling the false discovery rate via knockoffs :HypothesisTesting:MultipleTesting:
:PROPERTIES:
:Custom_ID: Barber_2015
:AUTHOR:   Barber \& Candès
:JOURNAL:  The Annals of Statistics
:YEAR:     2015
:VOLUME:   43
:PAGES:    2055–2085
:DOI:      10.1214/15-aos1337
:URL:      http://dx.doi.org/10.1214/15-aos1337
:END:

cite:Barber_2015 C'est le premier papier sur les knockoffs. Il décrit la
méthode et la compare. 

*** TODO Implementation                                            :Rpackage:
Il y a un pacakge :
https://cran.r-project.org/web/packages/knockoff/knockoff.pdf

** 2010 - Rank Constrained Matrix Optimization Problems                :LFMM:
:PROPERTIES:
:Custom_ID: slides_Rk_Const_Matrix_Optim_2015
:AUTHOR:   Defeng Sun
:JOURNAL:
:YEAR:     2010
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:slides_Rk_Const_Matrix_Optim_2015
C'est pour le slides 2 ils y a les référence pour montrer que min avec
contraintes du rank à une solution analytique qui est la svd de rank K.

** TODO 2000 - On the Convergence of the Block Nonlinear Gauss-Seidel Method  Under Convex Constraints :Optimisation:
:PROPERTIES:
:Custom_ID: grippo00_conver_block_nonlin_gauss_seidel
:AUTHOR:   Grippo \& Sciandrone
:JOURNAL:  Operations Research Letters
:YEAR:     2000
:VOLUME:   26
:PAGES:    127-136
:DOI:      10.1016/s0167-6377(99)00074-7
:URL:      https://doi.org/10.1016/s0167-6377(99)00074-7
:END:

cite:grippo00_conver_block_nonlin_gauss_seidel
C'est le papier que j'ai cité dans TESS3 article 2 pour justifier la
convergeance du mon algo.
 
 
** 2009 - Genome-wide association analysis by lasso penalized logistic  regression :GWAS:Lasso:
:PROPERTIES:
:Custom_ID: Wu_2009
:AUTHOR:   Wu, Chen, Hastie, Sobel, \& Lange
:JOURNAL:  Bioinformatics
:YEAR:     2009
:VOLUME:   25
:PAGES:    714–721
:DOI:      10.1093/bioinformatics/btp041
:URL:      http://dx.doi.org/10.1093/bioinformatics/btp041
:END:

cite:Wu_2009
La partie test d'hypothèse est vraiment mal détaillé !! J'ai l'impression qu'il
estime des variables avec le lasso et après sur les selectionnés éstime la
vraisemblance en mettant de coté a chaque fois chacune des vars mais sans lasso.
Il dit pas comment il obtiend ses pvalue.....
 
** TODO 2014 - A significance test for the lasso                      :Lasso:
:PROPERTIES:
:Custom_ID: Lockhart_2014
:AUTHOR:   Lockhart, Taylor, Tibshirani, \& Tibshirani
:JOURNAL:  The Annals of Statistics
:YEAR:     2014
:VOLUME:   42
:PAGES:    413–468
:DOI:      10.1214/13-aos1175
:URL:      http://dx.doi.org/10.1214/13-aos1175
:END:

cite:Lockhart_2014
C'est papier du test stat pour les modèle linéaire avec regularisation lasso. 
 
Voici un présentation qui va avec [[file:MultipleTesting/pres_Tibshirani_2013.pdf]]

** TODO 2016 - Ten Simple Rules for Structuring Papers
:PROPERTIES:
:Custom_ID: kording16_ten_simpl_rules_struc_paper
:AUTHOR:   Kording \& Mensh
:JOURNAL:
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:      10.1101/088278
:URL:      https://doi.org/10.1101/088278
:END:

cite:kording16_ten_simpl_rules_struc_paper
I printed it !!!

** 2016 - Fast Inference of Individual Admixture Coefficients Using  Geographic Data :TESS3_article2:
:PROPERTIES:
:Custom_ID: Caye_2016
:AUTHOR:   Caye, Jay, Michel, Francois \& Olivier
:JOURNAL:
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:      10.1101/080291
:URL:      http://dx.doi.org/10.1101/080291
:END:

cite:Caye_2016
 

** 2000 - On the convergence of the block nonlinear Gauss–Seidel method  under convex constraints :Optimisation:TESS3_article2:
:PROPERTIES:
:Custom_ID: Grippo_2000
:AUTHOR:   Grippo \& Sciandrone
:JOURNAL:  Operations Research Letters
:YEAR:     2000
:VOLUME:   26
:PAGES:    127–136
:DOI:      10.1016/s0167-6377(99)00074-7
:URL:      http://dx.doi.org/10.1016/s0167-6377(99)00074-7
:END:

cite:Grippo_2000 C'est le papier por justifier la convergence de l'algo 1 dans
le papier TESS3_article2.

** 1997 - Nonlinear Programming                 :Optimisation:TESS3_article2:
:PROPERTIES:
:Custom_ID: Bertsekas_1997
:AUTHOR:   Bertsekas
:JOURNAL:  Journal of the Operational Research Society
:YEAR:     1997
:VOLUME:   48
:PAGES:    334–334
:DOI:      10.1057/palgrave.jors.2600425
:URL:      http://dx.doi.org/10.1057/palgrave.jors.2600425
:END:

cite:Bertsekas_1997 C'est le papier toujours cité pour les [[file:./org-ref-pdfs/bertsekas_1997.pdf:135][block coordinate
descent]] (voir a la page 135). Le resultat de congergence s'applique sur des
ensembles convexes fermés.

** 2016 - Recovery guarantee of weighted low-rank approximation via  alternating minimization :Optimisation:
:PROPERTIES:
:Custom_ID: li16_recov
:AUTHOR:   Yuanzhi Li, Yingyu Liang \& Andrej Risteski
:JOURNAL:
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:li16_recov
Article proposé par flora dans un mail : 
---
Pour info
Un chercheur de mon équipe m'a parlé de whitening pour améliorer l'alternating LS (et surtout pour avoir un résultat théorique  pour avoir des résultats théoriques à propos de la convergence). C'était très rapide donc j'ai pas eu plus d'explications mais un papier : https://arxiv.org/pdf/1602.02262v1.pdf
---
 
C'est un papier pas mal si je veux faire de la biblio sur les aproximations de
matrice de rank faible par de l'optimization.

** 2010 - Spectral Regularization Algorithms for Learning Large  Incomplete Matrices :LFMM:Rpackage:
:PROPERTIES:
:Custom_ID: mazumder10_spect_regul_algor_learn_large_incom_matric
:AUTHOR:   Mazumder, Hastie \& Tibshirani
:JOURNAL:  Journal of machine learning research
:YEAR:     2010
:VOLUME:   11
:PAGES:    2287--2322
:DOI:
:URL:
:END:

cite:mazumder10_spect_regul_algor_learn_large_incom_matric C'est l'article du
Rpackage SOFT-IMPUTE: [[./LFMM/NuclearNorm/RpackageSoftImpute_Hastie_2015.pdf][doc]] Il propose un algo dit EM pour faire de l'imputation,
ca m'interesse car ca peut etre un moyen de faire le fit de lfmm sans avoir a
imputer au préalable !!


** 2015 - The Relative Power of Genome Scans To Detect Local Adaptation  Depends on Sampling Design and Statistical Method :LFMM:EAAReviewAndComparison:
:PROPERTIES:
:Custom_ID: lotterhos15_relat_power_genom_scans_to
:AUTHOR:   Katie Lotterhos \& Michael Whitlock
:JOURNAL:  Molecular Ecology
:YEAR:     2015
:VOLUME:   24
:PAGES:    1031-1046
:DOI:      10.1111/mec.13100
:URL:      https://doi.org/10.1111/mec.13100
:END:

cite:lotterhos15_relat_power_genom_scans_to
Mdr les graphes de ce papier... ils sont gros et ne disent pas grands choses
... Mais j'ai du choper une version pas review, il y a plien de trucs qui sont
pas acceptable (surtout en matiere de graphe je trouve !)
Bon en tout cas on peut peut ètre choper ses simulations.

** 2011 - Significance testing in ridge regression for genetic data
:PROPERTIES:
:Custom_ID: Cule_2011
:AUTHOR:   Cule, Vineis \& De Iorio
:JOURNAL:  BMC Bioinformatics
:YEAR:     2011
:VOLUME:   12
:PAGES:    372
:DOI:      10.1186/1471-2105-12-372
:URL:      http://dx.doi.org/10.1186/1471-2105-12-372
:END:

cite:Cule_2011
Papier dans lequel il developpe le modèle ridge linéaire et logistique. Il font
des tests d'hypothèse en calculant la variance de B.

** 2016 - Sparse PCA corrects for cell type heterogeneity in  epigenome-wide association studies :LFMM:EWAS:
:PROPERTIES:
:Custom_ID: Rahmani_2016
:AUTHOR:   Rahmani {\it et al.}
:JOURNAL:  Nature Methods
:YEAR:     2016
:VOLUME:   13
:PAGES:    443–445
:DOI:      10.1038/nmeth.3809
:URL:      http://dx.doi.org/10.1038/nmeth.3809
:END:

cite:Rahmani_2016

C'est la papier qui présente ReFACTor. [[http://www.cs.tau.ac.il/~heran/cozygene/software/refactor.html][Le sowftware ici]]. L'idée est que l'on
corrige sans connaitre la composition cellulaire à priorie donc on l'apprend
dans les data. Eux avec l'acp sparse. Comme je le comprend il prenne un sous
ensemblde de snps pour estimer la structure cellulaire... Ou plutot tous les
sites de méthylation ne sont pas considérer egualement informatif, c'est pour
ca qu'il y a une liste rangé de site de méthylation en sorti de leur
algorithme. 
 
*** Suplementary Information: 
Un regal :D
- file:./Biblio/org-ref-pdfs/ST_Rahmani_2016.pdf
- file:./Biblio/org-ref-pdfs/SF_Rahmani_2016.pdf
*** Software
C'est un script R... (super TP les gars !!13/20)
- README: file:./org-ref-pdfs/README_Rahmani_2016.pdf 

*** Rmk perso et comparaison avec lfmm
En faite c'est juste l'acp fait sur les t (dans le code t = 500 par defaut)
site les plus proche de la low rank structure... ^_^'
    
Du coup ca marche très bien sur mes simulations dites lfmm normales. Normal
il fait une acp mais pas sur tout le monde. Du coup c'est très simple pour
moi de le planter, il suffit qu'il y ai beaucoups d'outlier ( 60 % dans mes
tests ^^). Après je suis pas sur que ca arrive en pratique.

L'idée est pas mauvaise finalement et très simple, et je suis que en
fouillant je tomberais sur la même idée pour les GWAS. 

** 2014 - Epigenome-wide association studies without the need for  cell-type composition :EWAS:
:PROPERTIES:
:Custom_ID: Zou_2014
:AUTHOR:   Zou, Lippert, Heckerman, , Aryee \& Listgarten
:JOURNAL:  Nature Methods
:YEAR:     2014
:VOLUME:   11
:PAGES:    309–311
:DOI:      10.1038/nmeth.2815
:URL:      http://dx.doi.org/10.1038/nmeth.2815
:END:

cite:Zou_2014
Un autre papier qui fait l'étude du dataset ewas RA ([[https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE42861][GSE42861]]).

Suplementary materials: file:./Biblio/org-ref-pdfs/SM_Zou_2016.pdf

*** Datasets and data processing
C'est bien mieux détaillé que quand l'article cite:Rahmani_2016 !! On va
faire le preprocessing de cette aritcle. De toute facon l'objectif est de se
comparer au papier cite:Zou_2014 avec la méthode qui connait la composition
cellulaire ! 

*** Simulations
Ils ont simulé des données a partir du dataset RA cf page 5.

** TODO 2011 - Epigenome-wide association studies for common human diseases :EWAS:
:PROPERTIES:
:Custom_ID: Rakyan_2011
:AUTHOR:   Rakyan, Down, Balding, \& Beck
:JOURNAL:  Nature Reviews Genetics
:YEAR:     2011
:VOLUME:   12
:PAGES:    529–541
:DOI:      10.1038/nrg3000
:URL:      http://dx.doi.org/10.1038/nrg3000
:END:

cite:Rakyan_2011

C'est article pour présenter le problème des EWAS par rapport au GWAS dans les
études d'association avec des maladies. Il parle des facteurs de confusions
dans les données EWAS. Je pense que c'est l'article a citer pour justifier
l'utilisation de LFMM dans les EWAS. Il a été cité plus de 600 fois.

** 2015 - Testing for genetic associations in arbitrarily structured  populations :GWAS:
:PROPERTIES:
:Custom_ID: Song_2015
:AUTHOR:   Song, Hao \& Storey
:JOURNAL:  Nature Genetics
:YEAR:     2015
:VOLUME:   47
:PAGES:    550–554
:DOI:      10.1038/ng.3244
:URL:      http://dx.doi.org/10.1038/ng.3244
:END:

cite:Song_2015 C'est la papier qui m'a inspiré les plots de comparaisons. Il y
a un gros [[file:Biblio/org-ref-pdfs/SI_Song_2015.pdf][Sup Info]].
 
*** Preprint
[[file:org-ref-pdfs/preprint_Song_2015.pdf]] Papier trouvé dans la biblio que OF
m'a donnée en début de thèse.

** 2013 - Epigenome-wide association data implicate DNA methylation as  an intermediary of genetic risk in rheumatoid arthritis :EWAS:
:PROPERTIES:
:Custom_ID: Liu_2013
:AUTHOR:   Liu {\it et al.}
:JOURNAL:  Nature Biotechnology
:YEAR:     2013
:VOLUME:   31
:PAGES:    142–147
:DOI:      10.1038/nbt.2487
:URL:      http://dx.doi.org/10.1038/nbt.2487
:END:

cite:Liu_2013
C'est le papier pour présenté les données RA GSE42861 des articles
cite:Zou_2014,Rahmani_2016.
 

** 2008 - Worldwide Human Relationships Inferred from Genome-Wide  Patterns of Variation
:PROPERTIES:
:Custom_ID: Li_2008
:AUTHOR:   Li {\it et al.}
:JOURNAL:  Science
:YEAR:     2008
:VOLUME:   319
:PAGES:    1100–1104
:DOI:      10.1126/science.1153717
:URL:      http://dx.doi.org/10.1126/science.1153717
:END:

cite:Li_2008
C'est l'article du dataset HGDP utilisé dans cite:frichot13_testin_assoc_between_loci_envir. 

** 2009 - Gestion des donn{\'e}es manquantes en analyse en composantes principales :LFMM:PCA:
:PROPERTIES:
:Custom_ID: josse2009gestion
:AUTHOR:   Josse, Pages \& Husson
:JOURNAL:  Journal de la Soci{\'e}t{\'e} Fran{\c{c}}aise de Statistique
:YEAR:     2009
:VOLUME:   150
:PAGES:    28--51
:DOI:
:URL:
:END:

cite:josse2009gestion
Un article en francais sur les méthodes d'ACP quand il y a des missing value.
Ca m'interesse parce que pour lfmm avec des missing value je vais alterner ma
procedure jusqu'a convergeance. Elle a l'aire de dire que ca converge.

** 2015 - Visualizing spatial population structure with estimated  effective migration surfaces :TESS3:MaThese:
:PROPERTIES:
:Custom_ID: Petkova_2015
:AUTHOR:   Petkova, Novembre \& Stephens
:JOURNAL:  Nature Genetics
:YEAR:     2015
:VOLUME:   48
:PAGES:    94–100
:DOI:      10.1038/ng.3464
:URL:      http://dx.doi.org/10.1038/ng.3464
:END:
 
cite:Petkova_2015
 
Article important pour ma thèse, c'est une méthode qui permet de visualiser une
stat qu'ils appellent le coefficient de migration sur une carte donc c'est la
même idée que TESS3. Ca montre que maper les populations sur une carte est
important ! C'est interessant pour l'intro aussi, pour s'inspirer pour la thèse
:D

** TODO 2014 - Efficient multivariate linear mixed model algorithms for  genome-wide association studies
:PROPERTIES:
:Custom_ID: Zhou_2014
:AUTHOR:   Zhou \& Stephens
:JOURNAL:  Nature Methods
:YEAR:     2014
:VOLUME:   11
:PAGES:    407–409
:DOI:      10.1038/nmeth.2848
:URL:      http://dx.doi.org/10.1038/nmeth.2848
:END:

cite:Zhou_2014
Cette version du papier est très complete et m'a beaucoup inspiré ! 

** 2013 - Polygenic Modeling with Bayesian Sparse Linear Mixed Models :LFMM:GWAS:
:PROPERTIES:
:Custom_ID: Zhou_2013
:AUTHOR:   Zhou, Carbonetto \& Stephens
:JOURNAL:  PLoS Genetics
:YEAR:     2013
:VOLUME:   9
:PAGES:    e1003264
:DOI:      10.1371/journal.pgen.1003264
:URL:      http://dx.doi.org/10.1371/journal.pgen.1003264
:END:
 
cite:Zhou_2013 C'est la méthode implémenté dans GEMMA pour les GWAS polygenic.
Se je comprends bien il dit que on sait pas trop quoi choisir entre le linear
mixed model et la regression sparse => il fait un modèle bayesien qui est
melange des deux et du coup c'est senser apprendre le meilleur vu que c'est
bayesien :D comme ca pas d'hypothèse.

*** TODO Pour ma thèse                                              :MaThese:
Faudrait que je lise l'intro de ce papier, en général les papier avec
stephens son bien écrit. Le résumé est pas mal ! 

** 1982 - Conflict Among the Criteria Revisited; The W, LR and LM Tests :LFMM:HypothesisTesting:
:PROPERTIES:
:Custom_ID: Evans_1982
:AUTHOR:   Evans \& Savin
:JOURNAL:  Econometrica
:YEAR:     1982
:VOLUME:   50
:PAGES:    737
:DOI:      10.2307/1912611
:URL:      http://dx.doi.org/10.2307/1912611
:END:

cite:Evans_1982
Article cité dans [[ref:Zhou_2014][cet article]] pour justifier la calibration des pvalues.

** 1984 - Hypothesis Testing in Linear Models when the Error Covariance  Matrix is Nonscalar :LFMM:HypothesisTesting:
:PROPERTIES:
:Custom_ID: Rothenberg_1984
:AUTHOR:   Rothenberg
:JOURNAL:  Econometrica
:YEAR:     1984
:VOLUME:   52
:PAGES:    827
:DOI:      10.2307/1911186
:URL:      http://dx.doi.org/10.2307/1911186
:END:

cite:Rothenberg_1984
Article cité dans [[ref:Zhou_2014][cet article]] pour justifier la calibration des pvalues. La
matrice de covariance est uen fonction d'un parametre theta. C'est pas tout a
fait mon problème ! 
 

** TODO 2000 - Tests of regression coefficients under ridge regression  models :HypothesisTesting:
:PROPERTIES:
:Custom_ID: Halawa_2000
:AUTHOR:   Halawa \& El Bassiouni
:JOURNAL:  Journal of Statistical Computation and Simulation
:YEAR:     2000
:VOLUME:   65
:PAGES:    341–356
:DOI:      10.1080/00949650008812006
:URL:      http://dx.doi.org/10.1080/00949650008812006
:END:

cite:Halawa_2000
Cité dans [[ref:Cule_2011]] pour justifier le test d'hypothèse. 

** 2016 - Controlling false discoveries in genome scans for selection :HypothesisTesting:MaThese:
:PROPERTIES:
:Custom_ID: Fran_ois_2016
:AUTHOR:   François, Martins, Caye, \& Schoville
:JOURNAL:  Molecular Ecology
:YEAR:     2016
:VOLUME:   25
:PAGES:    454–469
:DOI:      10.1111/mec.13513
:URL:      http://dx.doi.org/10.1111/mec.13513
:END:
 
cite:Fran_ois_2016
Il faudrat que je comprenne bien cette article pour ma thèse !! 

** 2011 - Parameter estimation and inference in the linear mixed model :LFMM:HypothesisTesting:
:PROPERTIES:
:Custom_ID: Gumedze_2011
:AUTHOR:   Gumedze \& Dunne
:JOURNAL:  Linear Algebra and its Applications
:YEAR:     2011
:VOLUME:   435
:PAGES:    1920–1944
:DOI:      10.1016/j.laa.2011.04.015
:URL:      http://dx.doi.org/10.1016/j.laa.2011.04.015
:END:

cite:Gumedze_2011
Un article de théorie sur les modèles mixes linéaire, trouvé dans [[ref:Zhou_2014][cette article]]. 

** TODO 2013 - A Sparse-Group Lasso
:PROPERTIES:
:Custom_ID: Simon_2013
:AUTHOR:   Simon, Friedman, Hastie, \& Tibshirani
:JOURNAL:  Journal of Computational and Graphical Statistics
:YEAR:     2013
:VOLUME:   22
:PAGES:    231–245
:DOI:      10.1080/10618600.2012.681250
:URL:      http://dx.doi.org/10.1080/10618600.2012.681250
:END:

cite:Simon_2013
Papier cité dans cite:zhou16_spars_multiv_factor_analy_regres pour l'algo.

** TODO 2004 - Generalized latent variable modeling: Multilevel, longitudinal, and structural equation models :LFMM:LFMMLike:GLLAMM:
:PROPERTIES:
:Custom_ID: skrondal2004generalized
:AUTHOR:   Skrondal \& Rabe-Hesketh
:JOURNAL:
:YEAR:     2004
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:
 
cite:skrondal2004generalized

** 2001 - Factor analysis with (mixed) observed and latent variables in  the exponential family :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: Wedel_2001
:AUTHOR:   Wedel \& Kamakura
:JOURNAL:  Psychometrika
:YEAR:     2001
:VOLUME:   66
:PAGES:    515–530
:DOI:      10.1007/bf02296193
:URL:      http://dx.doi.org/10.1007/bf02296193
:END:

cite:Wedel_2001
 
*Remark:* ce pdf était dans un dossier SML, mais je ne me rappel plus pk ? Ok
c'est pour Simulated Maximum Likelyhood. C'est truc qui a l'aire utilisé en
econometrie...
 
Contrairement à lfmm il n'y a pas de co-variable, il n'y a que les variables
latentes. C'est pas vraiment un LFMMLike.

C'est papier super dur a comprendre pour moi, en gros je comprend que c'est un
GLM avec les facteurs latents. Il propose une méthode de SML pour estimer les
loadings de son modèle a fateur latents. Ces résultats portent sur des simu de
son modèle et une étude de cas.
 
Pourtant dans le titre il parle de observed data... je pense que c'est les
données en sortie du model.

** TODO - How to perform leave-one-out cross-validation for PCA to  determine the number of principal components?
:PROPERTIES:
:Custom_ID: crossValidated_PCACrossValidation_2017
:AUTHOR:   amoeba
:JOURNAL:
:YEAR:
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:crossValidated_PCACrossValidation_2017
Une super reponse trouvée sur Cross Validated quand je cherchais un moyen de
cross valider une lfmm (j'ai chercher comment cross valider l'acp)
 

** 2011 - Finding Structure with Randomness: Probabilistic Algorithms  for Constructing Approximate Matrix Decompositions :LFMM:
:PROPERTIES:
:Custom_ID: Halko_2011
:AUTHOR:   Halko, Martinsson \& Tropp
:JOURNAL:  SIAM Review
:YEAR:     2011
:VOLUME:   53
:PAGES:    217–288
:DOI:      10.1137/090771806
:URL:      http://dx.doi.org/10.1137/090771806
:END:

cite:Halko_2011
C'est un papier qui était dans la biblio que OF m'avait envoyé en début de
thèse. C'est sur les méthode de randomization pour les approximation de rang
faible. 

Je pense que l'idée c'est de faire des projections aléatoires et trouver a
décomposition. C'est peut être interessant pour améloirer les perfs de lfmm.

** 2010 - Correction for hidden confounders in the genetic analysis of  gene expression :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: Listgarten_2010
:AUTHOR:   Listgarten, Kadie, Schadt, Heckerman \&
:JOURNAL:  Proceedings of the National Academy of Sciences
:YEAR:     2010
:VOLUME:   107
:PAGES:    16465–16470
:DOI:      10.1073/pnas.1002425107
:URL:      http://dx.doi.org/10.1073/pnas.1002425107
:END:

cite:Listgarten_2010
On est en plein dans la correction de s facteurs de confusion pour l'analyse
de l'expression des gènes (population structure, batch effects). 
Il y a un [[file:org-ref-pdfs/SI_Listgarten_2010.pdf][SI Apprendix]].
Ils vendent une méthode qui prend en compte a la fois la sutructure de pop(PS) et
Expression Heterogeneity (EH).
*** Application
C'est pour des eQTL scan. C'est a dire qu'on cherche les liens entre
polymophisme et expression des gènes. D'après Magalie, les jeux de données
sont plus petit dans les eQTLs scan, on fait des croisements d'indiv, c'est
plus de l'experience a petite echelle. 

Pourtant les application son sur des gros jeux de données !!
*** Method
Un mixed model ou la sortie est les gene probes (une mesure de l'expression)
et la co-variable le SNP. L'hypothèse H0 est il n'y a pas corrélation entre
SNP et expression du gène, pour la bio ce n'est pas un eQTL. Si on rejète H0
c'est un eQTL
*** Experiments
**** Synthetic dataset
Il fit leur modèle et utilise le modèle génératif pour simuler des gene
probe (la sortie du modèle), pour 5% il multiplie les B trouvé par un
facteur. Ca leur génère 5% loci sous H1.
*** Remarques
Leur méthode à le même objectif que lfmm, c'est a dire association avec
variable lattente. Mais il on une application cible les eQTL scan. Pour moi
c'est les test d'asssociations plymorphism-var ecologique. Et je veux
montrer qu'on peut faire des EWAS aussi... enfin si ca marche :D
*** TODO Aller plus loin
Le papier est complet, faudrait que je vois leur test d'hypothèse.
** TODO 2004 - Mixed Models                                            :LFMM:
:PROPERTIES:
:Custom_ID: Demidenko_2004
:AUTHOR:   Demidenko
:JOURNAL:  Wiley Series in Probability and Statistics
:YEAR:     2004
:VOLUME:
:PAGES:
:DOI:      10.1002/0471728438
:URL:      http://dx.doi.org/10.1002/0471728438
:END:

cite:Demidenko_2004
C'est le livre qui est cité dans cite:Listgarten_2010 pour citer les Mixed
Models.

** TODO - Generalized Linear Mixed Model                               :LFMM:
:PROPERTIES:
:Custom_ID: GLMM
:AUTHOR:
:JOURNAL:
:YEAR:
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

J'ai trouvé ca dans la bib d'of pour lfmm. cite:GLMM.

C'est un cours sur les modèle mixte généralisé, c'est a dire avec d'autre distribution
que la loi normale.

** 1996 - Latent Variable Models with Fixed Effects           :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: Sammel_1996
:AUTHOR:   Sammel \& Ryan
:JOURNAL:  Biometrics
:YEAR:     1996
:VOLUME:   52
:PAGES:    650
:DOI:      10.2307/2532903
:URL:      http://dx.doi.org/10.2307/2532903
:END:

cite:Sammel_1996 Papier trouvé dans la biblio que OF m'a donnée en début de thèse.
*** Model 
Le modèle est comme LFMM avec en plus des co-variable pour modéliser les
facteurs lattents. Il y a un test d'hypothèse pour test l'effet des covariables
avec les facteurs lattents.
*** Experiments
Sur des données réelles dirrecte

** TODO 2003 - Some applications of generalized linear latent and mixed models in epidemiology: repeated measures, measurement error and multilevel modeling :LFMM:GLLAMM:
:PROPERTIES:
:Custom_ID: skrondal2003some
:AUTHOR:   Skrondal \& Rabe-Hesketh
:JOURNAL:  Norsk epidemiologi
:YEAR:     2003
:VOLUME:   13
:PAGES:    265--278
:DOI:
:URL:
:END:

cite:skrondal2003some Papier trouvé dans la biblio que OF m'a donnée en début
de thèse.

** TODO 1981 - The bayesian bootstrap                                  :LFMM:
:PROPERTIES:
:Custom_ID: rubin1981bayesian
:AUTHOR:   Rubin \& others
:JOURNAL:  The annals of statistics
:YEAR:     1981
:VOLUME:   9
:PAGES:    130--134
:DOI:
:URL:
:END:

cite:rubin1981bayesian Papier trouvé dans la biblio que OF m'a donnée en début
de thèse.

 

** TODO 2005 - Structural equation models: a review with applications to environmental epidemiology :LFMM:
:PROPERTIES:
:Custom_ID: sanchez2005structural
:AUTHOR:   Sanchez, Budtz-J\orgensen, Ryan \& Hu
:JOURNAL:  Journal of the American Statistical Association
:YEAR:     2005
:VOLUME:   100
:PAGES:    1443--1455
:DOI:
:URL:
:END:
 
cite:sanchez2005structural Papier trouvé dans la biblio que OF m'a donnée en
début de thèse.

** TODO 2007 - Latent Variable Modelling: A Survey*                    :LFMM:
:PROPERTIES:
:Custom_ID: SKRONDAL_2007
:AUTHOR:   SKRONDAL \& RABE-SKETH
:JOURNAL:  Scandinavian Journal of Statistics
:YEAR:     2007
:VOLUME:   34
:PAGES:    712–745
:DOI:      10.1111/j.1467-9469.2007.00573.x
:URL:      http://dx.doi.org/10.1111/j.1467-9469.2007.00573.x
:END:

cite:SKRONDAL_2007 Papier trouvé dans la biblio que OF m'a donnée en début de
thèse.

** TODO 2010 - Conditions Under Which Genome-Wide Association Studies Will be  Positively Misleading :LFMM:
:PROPERTIES:
:Custom_ID: Platt_2010
:AUTHOR:   Platt, Vilhjalmsson \& Nordborg
:JOURNAL:  Genetics
:YEAR:     2010
:VOLUME:   186
:PAGES:    1045–1052
:DOI:      10.1534/genetics.110.121665
:URL:      http://dx.doi.org/10.1534/genetics.110.121665
:END:

cite:Platt_2010 Papier trouvé dans la biblio que OF m'a donnée en début de
thèse.

** TODO 2007 - Classical latent variable models for medical research   :LFMM:
:PROPERTIES:
:Custom_ID: Rabe_Hesketh_2007
:AUTHOR:   Rabe-Hesketh \& Skrondal
:JOURNAL:  Statistical Methods in Medical Research
:YEAR:     2007
:VOLUME:   17
:PAGES:    5–32
:DOI:      10.1177/0962280207081236
:URL:      http://dx.doi.org/10.1177/0962280207081236
:END:

cite:Rabe_Hesketh_2007 Papier trouvé dans la biblio que OF m'a donnée en début
de thèse.

** TODO 2013 - Latent factor regression models for grouped outcomes    :LFMM:
:PROPERTIES:
:Custom_ID: Woodard_2013
:AUTHOR:   Woodard, Love, Thurston, , Ruppert, Sathyanarayana \& Swan
:JOURNAL:  Biometrics
:YEAR:     2013
:VOLUME:   69
:PAGES:    785–794
:DOI:      10.1111/biom.12037
:URL:      http://dx.doi.org/10.1111/biom.12037
:END:

cite:Woodard_2013 Papier trouvé dans la biblio que OF m'a donnée en début de
thèse.

** TODO 2004 - GLLAMM manual                                    :LFMM:GLLAMM:
:PROPERTIES:
:Custom_ID: rabe2004gllamm
:AUTHOR:   Rabe-Hesketh, Skrondal \& Pickles
:JOURNAL:
:YEAR:     2004
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:rabe2004gllamm Papier trouvé dans la biblio que OF m'a donnée en début de
thèse.

** 2004 - Convex Optimization                                          :Book:
:PROPERTIES:
:Custom_ID: Boyd_2004
:AUTHOR:   Boyd \& Vandenberghe
:JOURNAL:
:YEAR:     2004
:VOLUME:
:PAGES:
:DOI:      10.1017/cbo9780511804441
:URL:      http://dx.doi.org/10.1017/cbo9780511804441
:END:

cite:Boyd_2004

** 2009 - Large-Scale Inference                                        :Book:
:PROPERTIES:
:Custom_ID: Efron_2009
:AUTHOR:   Efron
:JOURNAL:
:YEAR:     2009
:VOLUME:
:PAGES:
:DOI:      10.1017/cbo9780511761362
:URL:      http://dx.doi.org/10.1017/cbo9780511761362
:END:

cite:Efron_2009
 
*** Empirical Null Estimation 
C'est quand on change l'hypothèse null en fonction de ce qu'on a observé.
 
** 2016 - Computer Age Statistical Inference                           :Book:
:PROPERTIES:
:Custom_ID: Efron_2016
:AUTHOR:   Efron \& Hastie
:JOURNAL:
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:      10.1017/cbo9781316576533
:URL:      http://dx.doi.org/10.1017/cbo9781316576533
:END:

cite:Efron_2016

** 1993 - An Introduction to the Bootstrap                             :Book:
:PROPERTIES:
:Custom_ID: Efron_1993
:AUTHOR:   Efron \& Tibshirani
:JOURNAL:
:YEAR:     1993
:VOLUME:
:PAGES:
:DOI:      10.1007/978-1-4899-4541-9
:URL:      http://dx.doi.org/10.1007/978-1-4899-4541-9
:END:
 
cite:Efron_1993

** 2013 - Genome-Wide Association Studies and Genomic Prediction       :Book:
:PROPERTIES:
:Custom_ID: Gondro_2013
:AUTHOR:
:JOURNAL:  Methods in Molecular Biology
:YEAR:     2013
:VOLUME:
:PAGES:
:DOI:      10.1007/978-1-62703-447-0
:URL:      http://dx.doi.org/10.1007/978-1-62703-447-0
:END:

cite:Gondro_2013

** 2009 - The Elements of Statistical Learning                         :Book:
:PROPERTIES:
:Custom_ID: Hastie_2009
:AUTHOR:   Hastie, Tibshirani \& Friedman
:JOURNAL:  Springer Series in Statistics
:YEAR:     2009
:VOLUME:
:PAGES:
:DOI:      10.1007/978-0-387-84858-7
:URL:      http://dx.doi.org/10.1007/978-0-387-84858-7
:END:

cite:Hastie_2009

** 2012 - Machine learning: a probabilistic perspective                :Book:
:PROPERTIES:
:Custom_ID: murphy2012machine
:AUTHOR:   Murphy
:JOURNAL:
:YEAR:     2012
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:murphy2012machine

** 2012 - Analysis of Genetic Association Studies                      :Book:
:PROPERTIES:
:Custom_ID: Zheng_2012
:AUTHOR:   Zheng, Yang, Zhu, Elston \& Robert
:JOURNAL:  Statistics for Biology and Health
:YEAR:     2012
:VOLUME:
:PAGES:
:DOI:      10.1007/978-1-4614-2245-7
:URL:      http://dx.doi.org/10.1007/978-1-4614-2245-7
:END:

cite:Zheng_2012

** TODO 2016 - Controlling the Rate of GWAS False Discoveries :HypothesisTesting:MultipleTesting:
:PROPERTIES:
:Custom_ID: Brzyski_2016
:AUTHOR:   Brzyski, Peterson, Sobczyk, , Candès, Bogdan, Sabatti \& Chiara
:JOURNAL:  Genetics
:YEAR:     2016
:VOLUME:   205
:PAGES:    61–75
:DOI:      10.1534/genetics.116.193987
:URL:      http://dx.doi.org/10.1534/genetics.116.193987
:END:

cite:Brzyski_2016

** TODO 2016 - Orthogonal Tensor Decompositions Via Two-Mode Higher-Order Svd  (hosvd)
:PROPERTIES:
:Custom_ID: wang16_orthog_tensor_decom_via_two
:AUTHOR:   Wang \& Song
:JOURNAL:
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:
:URL:      http://arxiv.org/abs/1612.03839v1
:END:

cite:wang16_orthog_tensor_decom_via_two. Envoyé par OF "ca peut t'interessé".
C'est papier théorique sur la décomposition matricielle...

** TODO 2015 - The role of regulatory variation in complex traits and  disease
:PROPERTIES:
:Custom_ID: Albert_2015
:AUTHOR:   Albert \& Kruglyak
:JOURNAL:  Nature Reviews Genetics
:YEAR:     2015
:VOLUME:   16
:PAGES:    197–212
:DOI:      10.1038/nrg3891
:URL:      http://dx.doi.org/10.1038/nrg3891
:END:

cite:Albert_2015. Papier que Magalie m'a envoyé pour comprendre le eQTL stidies.

** TODO 2006 - Principal components analysis corrects for stratification in  genome-wide association studies :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: Price_2006
:AUTHOR:   Price, Patterson, Plenge, , Weinblatt, Shadick \& Reich
:JOURNAL:  Nature Genetics
:YEAR:     2006
:VOLUME:   38
:PAGES:    904–909
:DOI:      10.1038/ng1847
:URL:      http://dx.doi.org/10.1038/ng1847
:END:

cite:Price_2006. C'est le papier EIGENSTRAT, c'est l'acp et une stat Armitage.
 

** 2012 - The sva package for removing batch effects and other unwanted  variation in high-throughput experiments :LFMM:LFMMLike:Rpackage:
:PROPERTIES:
:Custom_ID: Leek_2012
:AUTHOR:   Leek, Johnson, Parker, Jaffe, \& Storey
:JOURNAL:  Bioinformatics
:YEAR:     2012
:VOLUME:   28
:PAGES:    882–883
:DOI:      10.1093/bioinformatics/bts034
:URL:      http://dx.doi.org/10.1093/bioinformatics/bts034
:END:
 
cite:Leek_2012 C'est l'article de pacakge sva. La vignette : [[./Biblio/org-ref-pdfs/Rpackage_sva.pdf][The SVA manual]].
 

** TODO 1995 - Controlling the false discovery rate: a practical and powerful approach to multiple testing
:PROPERTIES:
:Custom_ID: benjamini1995controlling
:AUTHOR:   Benjamini \& Hochberg
:JOURNAL:  Journal of the royal statistical society. Series B (Methodological)
:YEAR:     1995
:VOLUME:
:PAGES:    289--300
:DOI:
:URL:
:END:

cite:benjamini1995controlling Article classic a citer pour the Benjamini-Hochberg procedure

** TODO 2012 - Multiple hypothesis testing adjusted for latent variables,  with an application to the AGEMAP gene expression data :LFMM:LFMMLike:Rpackage:
:PROPERTIES:
:Custom_ID: Sun_2012
:AUTHOR:   Sun, Zhang \& Owen
:JOURNAL:  The Annals of Applied Statistics
:YEAR:     2012
:VOLUME:   6
:PAGES:    1664–1688
:DOI:      10.1214/12-aoas561
:URL:      http://dx.doi.org/10.1214/12-aoas561
:END:

cite:Sun_2012 C'est très très proche de LFMM encore une fois et il y a un
[[https://cran.r-project.org/web/packages/leapp/][package R LEAPP]]. Il faut que je lise ca plus en détail. 

** TODO 2015 - Confounder Adjustment in Multiple Hypothesis Testing :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: wang2015confounder
:AUTHOR:   Wang, Zhao, Hastie \& Owen
:JOURNAL:  arXiv preprint arXiv:1508.04178
:YEAR:     2015
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:wang2015confounder Ok la c'est vraiment du lourd ! C'est de la théorie sur
LFMM en gros, faut que je le lise ! C'est vraiment sans fin cette biblio...
Mais c'est rassurant de voir des gens qui travail sur les même chose ! 

*** CRAN R package
[[https://cran.r-project.org/web/packages/cate/index.html][cate]]
** TODO 2007 - Correlation and Large-Scale Simultaneous Significance Testing
:PROPERTIES:
:Custom_ID: Efron_2007
:AUTHOR:   Efron
:JOURNAL:  Journal of the American Statistical Association
:YEAR:     2007
:VOLUME:   102
:PAGES:    93–103
:DOI:      10.1198/016214506000001211
:URL:      http://dx.doi.org/10.1198/016214506000001211
:END:

cite:Efron_2007 Un papier qui justifie que quand on a des hypothèse corrélées,
la fonction de répartition H0 n'est plus $N(0,1)$

** 2005 - Local False Discovery Rates
:PROPERTIES:
:Custom_ID: cours_Efron_2005
:AUTHOR:   Bradley Efron
:JOURNAL:
:YEAR:     2005
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:
 
cite:cours_Efron_2005 Un pdf pour expliquer le fdr local. Très bien fait ! 

** TODO 2004 - Large-Scale Simultaneous Hypothesis Testing
:PROPERTIES:
:Custom_ID: Efron_2004
:AUTHOR:   Efron
:JOURNAL:  Journal of the American Statistical Association
:YEAR:     2004
:VOLUME:   99
:PAGES:    96–104
:DOI:      10.1198/016214504000000089
:URL:      http://dx.doi.org/10.1198/016214504000000089
:END:

cite:Efron_2004

*** Introduction
Il y phrase interessante dans l'intro, en gros: le but des test d'hypothèse
multiple c'est trouver une liste de candidat qui merite qu'on s'y attarde.
Moi je comprend que une fois qu'on a creer des zscore (il faut des score car
les test doivent etre comprable, donc on les normalise) on peut faire
estimer l'hypothese null sur les données, ca va lisser les erreur, regler
les problème d'autocorélation, enlever les petits effets sans interet et
mettre le test au bonne endroit (si la moyenne est non nul par exemple)!

*** Rmks
C'est aussi dans cette article qu'il liste les possibilité pour expliquer que
les pvalue ne sont pas uniforme sous H0.
Il parple aussi des diff philosophique entre test simple et multiple !! Bon pour la thèse.
** TODO 1999 - Genomic Control for Association Studies
:PROPERTIES:
:Custom_ID: Devlin_1999
:AUTHOR:   Devlin \& Roeder
:JOURNAL:  Biometrics
:YEAR:     1999
:VOLUME:   55
:PAGES:    997–1004
:DOI:      10.1111/j.0006-341x.1999.00997.x
:URL:      http://dx.doi.org/10.1111/j.0006-341x.1999.00997.x
:END:
:LOGBOOK:
- State "TODO"       from "TODO"       [2017-04-11 mar. 17:51]
:END:

cite:Devlin_1999 C'est le papier du genomic inflation factor (le gif)

** 2015 - A global reference for human genetic variation
:PROPERTIES:
:Custom_ID: 1000Genome_2015
:AUTHOR:   The 1000 Genomes Project Consortium
:JOURNAL:  Nature
:YEAR:     2015
:VOLUME:   526
:PAGES:    68--74
:DOI:      10.1038/nature1539cite:Auton_20153
:URL:      https://doi.org/10.1038~/Projects/Biblio/org-ref-pdfs/Auton_2015.pdfnature15393
:END:

cite:Auton_2015 To cite the 1000genomes (found [[http://www.internationalgenome.org/faq/how-do-i-cite-1000-genomes-project/][here]])

** TODO 2008 - Cross-validation of component models: A critical look at  current methods
:PROPERTIES:
:Custom_ID: Bro_2008
:AUTHOR:   Bro, Kjeldahl, Smilde, Kiers \&
:JOURNAL:  Analytical and Bioanalytical Chemistry
:YEAR:     2008
:VOLUME:   390
:PAGES:    1241–1251
:DOI:      10.1007/s00216-007-1790-1
:URL:      http://dx.doi.org/10.1007/s00216-007-1790-1
:END:

cite:Bro_2008 Plein de méthodes pour la cross validation de l'acp. C'est
généralisable au méthode non supervisé ! 
 
 
** TODO 2016 - The Simons Genome Diversity Project: 300 genomes from 142 diverse populations
:PROPERTIES:
:Custom_ID: mallick2016simons
:AUTHOR:   Mallick {\it et al.}
:JOURNAL:  Nature
:YEAR:     2016
:VOLUME:   538
:PAGES:    201--206
:DOI:
:URL:
:END:

cite:mallick2016simons Papier du [[https://www.simonsfoundation.org/life-sciences/simons-genome-diversity-project-dataset/][simons diversity project]].
 

** TODO 2011 - Detecting Novel Associations in Large Data Sets
:PROPERTIES:
:Custom_ID: Reshef_2011
:AUTHOR:   Reshef {\it et al.}
:JOURNAL:  Science
:YEAR:     2011
:VOLUME:   334
:PAGES:    1518–1524
:DOI:      10.1126/science.1205438
:URL:      http://dx.doi.org/10.1126/science.1205438
:END:

cite:Reshef_2011
Pk le R^2 de pearson c'est pas bien ... A lIRE

** TODO 2015 - Seven common mistakes in population genetics and how to avoid  them
:PROPERTIES:
:Custom_ID: Meirmans_2015
:AUTHOR:   Meirmans
:JOURNAL:  Molecular Ecology
:YEAR:     2015
:VOLUME:   24
:PAGES:    3223–3231
:DOI:      10.1111/mec.13243
:URL:      http://dx.doi.org/10.1111/mec.13243
:END:

cite:Meirmans_2015 Le nombre d'outlier attendu est petit :D. Pourtant dans
cite:Abraham_2014 il trouve de l'ordre de 1000 locus pour expliquer la maladie celiac.

** TODO - Imputation de données manquantes
:PROPERTIES:
:Custom_ID: imp_don_manquante
:AUTHOR:
:JOURNAL:
:YEAR:
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:imp_don_manquante

Un cours simple en francais sur les données manquantes. Il liste plien d'algo
pour l'imputation.

** DONE 2017 - Using genotype-environment associations to identify multilocus  local adaptation :GEA:LFMM:
CLOSED: [2017-05-02 mar. 16:07]
:PROPERTIES:
:Custom_ID: Forester_2017
:AUTHOR: Forester, Lasky, Wagner, \& Urban
:JOURNAL: 
:YEAR: 2017
:VOLUME: 
:PAGES: 
:DOI: 10.1101/129460
:URL: http://dx.doi.org/10.1101/129460
:END:
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-02 mar. 16:07]
:END:

cite:Forester_2017 

- Une comparaison des méthodes stat et machine learning pour l'association. Il
parle de la méthode redundancy analysis (RDA).
- Dans cette article il parle Genotype-environment association (GEA).
- Le papier est interessant dans la demarche (comparaison  de méthodes sur des
  simulations). A voir les plots et les simu ! 


** DONE 2015 - Detecting spatial genetic signatures of local adaptation in  heterogeneous landscapes :GEA:LFMM:
CLOSED: [2017-05-02 mar. 14:09]
:PROPERTIES:
:Custom_ID: Forester_2015
:AUTHOR: Forester, Jones, Joost, , Landguth \& Lasky
:JOURNAL: Molecular Ecology
:YEAR: 2015
:VOLUME: 25
:PAGES: 104–120
:DOI: 10.1111/mec.13476
:URL: http://dx.doi.org/10.1111/mec.13476
:END:
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-02 mar. 14:09]
:END:

cite:Forester_2015

- Un autre papier ou ils utilisent RDA pour les GEA
*** Ordination methods
Je comprends que c'est comme du clustering mais le long d'un gradient !! ([[http://ordination.okstate.edu/overview.htm][see this page]])
*** RDA
En faite cette méthodes ne donnent pas de pvalue.
Ils trouvent des outlier a partir de leur projection et calcule des pvalue après
, avec un modèle linéaire.

Mais il n'y a pas de correction pour des quelconce variable lattente ! 

** TODO 1921 - Correlation and causation              :CausalInference:LFMM:
 :PROPERTIES:
  :Custom_ID: wright1921correlation
  :AUTHOR: Wright
  :JOURNAL: Journal of agricultural research
  :YEAR: 1921
  :VOLUME: 20
  :PAGES: 557--585
  :DOI: 
  :URL: 
 :END:

cite:wright1921correlation

Un papier de 1921 qui evoque la diference entre les corrélations et les cause.
Je n'ai pas l'impression qui parle de variable lattente mais plutot de
l'influence de lajout de variable au model quand on calcule des correlations. Ca
fait penser a ce que je connais de l'inference causal ! 

** TODO 2014 - Accurate and Robust Genomic Prediction of Celiac Disease Using  Statistical Learning :LFMM:GWAS:
 :PROPERTIES:
  :Custom_ID: Abraham_2014
  :AUTHOR: Abraham, Tye-Din, Bhalala, , Kowalczyk, Zobel \& Inouye
  :JOURNAL: PLoS Genetics
  :YEAR: 2014
  :VOLUME: 10
  :PAGES: e1004137
  :DOI: 10.1371/journal.pgen.1004137
  :URL: http://dx.doi.org/10.1371/journal.pgen.1004137
 :END:
 
cite:Abraham_2014 

Ils font un modèle de prédiction pour la malidie celiac (pour estimer un facteur
de risque). Dans ce modèle il y a de l'orde du millier de SNIPs causaux !

** TODO 2010 - Multiple common variants for celiac disease influencing immune gene expression
 :PROPERTIES:
  :Custom_ID: dubois2010multiple
  :AUTHOR: Dubois {\it et al.}
  :JOURNAL: Nature genetics
  :YEAR: 2010
  :VOLUME: 42
  :PAGES: 295--302
  :DOI: 
  :URL: 
 :END:

cite:dubois2010multiple C'est l'article du dataset Celiac

** TODO 2017 - Unifying and Generalizing Methods for Removing Unwanted Variation Based on Negative Controls :LFMMLike:LFMM:3Article:
 :PROPERTIES:
  :Custom_ID: gerard2017unifying
  :AUTHOR: Gerard \& Stephens
  :JOURNAL: arXiv preprint arXiv:1705.08393
  :YEAR: 2017
  :VOLUME: 
  :PAGES: 
  :DOI: 
  :URL: 
 :END:
 
 cite:gerard2017unifying Un papier qui veut faire comme lfmm, cad identifier la
 vairance indesirable pour faire une association. 
 
 Papier bien ecrit et très proche de lfmm, j'ai l'impression qu'il font des
 simulation avec 50 % d'outlier dans ce cas LassoLFMM est bien :D. Mais dans quel
 cas c'est interessant autant d'outlier ?


** TODO 2007 - PLINK: A Tool Set for Whole-Genome Association and  Population-Based Linkage Analyses
 :PROPERTIES:
  :Custom_ID: Purcell_2007
  :AUTHOR: Purcell {\it et al.}
  :JOURNAL: The American Journal of Human Genetics
  :YEAR: 2007
  :VOLUME: 81
  :PAGES: 559–575
  :DOI: 10.1086/519795
  :URL: http://dx.doi.org/10.1086/519795
 :END:

  cite:Purcell_2007 C'est la papier a cité pour citer plink (voir [[http://zzz.bwh.harvard.edu/plink/contact.shtml][le site
  deplink]]). Ils faut aussi citer le logiciel...

** TODO 2016 - Genotype Imputation with Millions of Reference Samples
 :PROPERTIES:
  :Custom_ID: Browning_2016
  :AUTHOR: Browning \& Browning
  :JOURNAL: The American Journal of Human Genetics
  :YEAR: 2016
  :VOLUME: 98
  :PAGES: 116–126
  :DOI: 10.1016/j.ajhg.2015.11.020
  :URL: http://dx.doi.org/10.1016/j.ajhg.2015.11.020
 :END:

cite:Browning_2016 C'est l'article a citer  Beagle's genotype imputation algorithm.
Voir le [[https://faculty.washington.edu/browning/beagle/beagle.html][site]].


** TODO 2009 - Cross-Validation for Unsupervised Learning
 :PROPERTIES:
  :Custom_ID: perry09_cross_valid_unsup_learn
  :AUTHOR: Perry
  :JOURNAL: 
  :YEAR: 2009
  :VOLUME: 
  :PAGES: 
  :DOI: 
  :URL: http://arxiv.org/abs/0909.3052v1
 :END:

cite:perry09_cross_valid_unsup_learn Tout est dit dans le titre !! Ca peut être
interessant de cross valider proprement mes deux algos :D A voir

** TODO 2009 - Bi-cross-validation of the SVD and the nonnegative matrix  factorization
 :PROPERTIES:
  :Custom_ID: Owen_2009
  :AUTHOR: Owen \& Perry
  :JOURNAL: The Annals of Applied Statistics
  :YEAR: 2009
  :VOLUME: 3
  :PAGES: 564–594
  :DOI: 10.1214/08-aoas227
  :URL: http://dx.doi.org/10.1214/08-aoas227
 :END:

cite:Owen_2009. Parfait si je veux faire le cross validation de lfmm et TESS3

** TODO 2017 - Controlling bias and inflation in epigenome- and transcriptome-wide association studies using the empirical null distribution :LFMM:
 :PROPERTIES:
  :Custom_ID: vanIterson2017
  :AUTHOR: van Iterson, , van Zwet, \& Heijmans
  :JOURNAL: Genome Biology
  :YEAR: 2017
  :VOLUME: 18
  :PAGES: 19
  :DOI: 10.1186/s13059-016-1131-9
  :URL: http://dx.doi.org/10.1186/s13059-016-1131-9
 :END:

cite:vanIterson2017 Encore un papier qui se compare a cate et ruv ! a voir pour
la biblio.

** TODO 2007 - Méthodes Statistiques pour l'Analyse des Données Génétiques  d'Association à Grande Échelle
 :PROPERTIES:
  :Custom_ID: phdGuedj
  :AUTHOR: Mickaël Guedj
  :JOURNAL: 
  :YEAR: 2007
  :VOLUME: 
  :PAGES: 
  :DOI: 
  :URL: 
 :END:

cite:phdGuedj Une thèse sur les thèse d'association mais en 2007, ca date. A voir.

** TODO 2016 - TOPICS IN CAUSAL AND HIGH DIMENSIONAL INFERENCE      :Thesis:
 :PROPERTIES:
  :Custom_ID: ZhaoThesis2016
  :AUTHOR: Qingyuan Zhao
  :JOURNAL: 
  :YEAR: 2016
  :VOLUME: 
  :PAGES: 
  :DOI: 
  :URL: 
 :END:

cite:ZhaoThesis2016 C'est une thèse sur le développement théorique des modèle a
facteur latents pour les test d'association et de la confusion. Il y a un
résultat théorique que je comprends pas mais qui d'après OF a un grand interet.
Les apporteurs c'est du lourd :D

Pour la thèse voir son developpement sur la causalité. 



** TODO 1999 - Probabilistic principal component analysis
 :PROPERTIES:
  :Custom_ID: tipping1999probabilistic
  :AUTHOR: Tipping \& Bishop
  :JOURNAL: Journal of the Royal Statistical Society: Series B (Statistical Methodology)
  :YEAR: 1999
  :VOLUME: 61
  :PAGES: 611--622
  :DOI: 
  :URL: 
 :END:

cite:tipping1999probabilistic c'est le papier de bishop sur un modèle probabilistic de l'acp.

** TODO - Quelle statistique pour les Big Data?
 :PROPERTIES:
  :Custom_ID: slides_sfds2015_saporta
  :AUTHOR: Gilbert Saporta
  :JOURNAL: 
  :YEAR: 
  :VOLUME: 
  :PAGES: 
  :DOI: 
  :URL: 
 :END:

cite:slides_sfds2015_saporta Slide présenté par un grand stateux francais sur
quelles stat pour le big data. Il y a plein de considération méta interessantes !!

** TODO - Introductory Genetics for Statisticians
 :PROPERTIES:
  :Custom_ID: url_slides_genet_stat
  :AUTHOR: Ken Rice
  :JOURNAL: 
  :YEAR: 
  :VOLUME: 
  :PAGES: 
  :DOI: 
  :URL: Introductory Genetics for Statisticians
 :END:

cite:url_slides_genet_stat une page avec des slides sur la genet pour les
stateux. Ca peut etre interessant a lire pour la these.

** TODO 2014 - A Brief Survey of Modern Optimization for Statisticians
 :PROPERTIES:
  :Custom_ID: Lange_2014
  :AUTHOR: Lange, Chi \& Zhou
  :JOURNAL: International Statistical Review
  :YEAR: 2014
  :VOLUME: 82
  :PAGES: 46–70
  :DOI: 10.1111/insr.12022
  :URL: http://dx.doi.org/10.1111/insr.12022
 :END:

cite:Lange_2014 Je vais le citer dans l'intro de ma thèse, il parle des algo
que j'ai utilisé (block descent etc).

** TODO 2014 - Next-Generation Statistical Genetics: Modeling, Penalization,  and Optimization in High-Dimensional Data
 :PROPERTIES:
  :Custom_ID: Lange_2014_2
  :AUTHOR: Lange, Papp, Sinsheimer, \& Sobel
  :JOURNAL: Annual Review of Statistics and Its Application
  :YEAR: 2014
  :VOLUME: 1
  :PAGES: 279–300
  :DOI: 10.1146/annurev-statistics-022513-115638
  :URL: http://dx.doi.org/10.1146/annurev-statistics-022513-115638
 :END:

cite:Lange_2014_2 C'est le meme papier que cite:Lange_2014 mais dans une autre
revue... L'autre est pas publié je crois.

** TODO 2008 - THE END OF THEORY: THE DATA DELUGE MAKES THE SCIENTIFIC METHOD  OBSOLETE
 :PROPERTIES:
  :Custom_ID: endOfTheory
  :AUTHOR: CHRIS ANDERSON
  :JOURNAL: The Wire
  :YEAR: 2008
  :VOLUME: 
  :PAGES: 
  :DOI: 
  :URL: https://www.wired.com/2008/06/pb-theory/
 :END:

cite:endOfTheory Un article provocateur sur le big data

Ma review de cette article. En faite il confont tout dans cette article le fait
d'avoir plus de données et de ne plus faire d'hypothèse n'a rien a voir. Dans
l'exemple qu'il donne sur la decouverte d'espece est typique, le scientific fait
l'hypothèse quand il rencontre une sequence qu'il la connait, cette hypothèse
est rejeté... Il y a des hypothèses !!!! On rejetes des hypothèse ce n'est pas
simplement des données. La comparaison avec google et internet est très mal
honnete car nous avons construit internet, c'est une système simple a coté du
vivant !! Encore une fois il y a des modèle et des hypothèses chez google !!

Enfin, je ne connais pas l'étude bio dont il parle dans l'article mais devant
une nouvelle séquence adn qui nous dit que ce n'ai pas le produit d'espece connu
?? Il y a un enorme risque à laisser parler les données !! Si on ne comprend pas
se qu'on observe (pas de modèle) on peut dire n'importe quoi ! 


** TODO 2006 - Probabilit{\'e}s, analyse des donn{\'e}es et statistique
 :PROPERTIES:
  :Custom_ID: saporta2006probabilites
  :AUTHOR: Saporta
  :JOURNAL: 
  :YEAR: 2006
  :VOLUME: 
  :PAGES: 
  :DOI: 
  :URL: 
 :END:

cite:saporta2006probabilites un super livre en francais sur les stat.

** TODO 2017 - Genome-wide association meta-analysis of 78,308 individuals identifies  new loci and genes influencing human intelligence
 :PROPERTIES:
  :Custom_ID: sniekers2017genome
  :AUTHOR: Sniekers {\it et al.}
  :JOURNAL: Nature Genetics
  :YEAR: 2017
  :VOLUME: 
  :PAGES: 
  :DOI: 
  :URL: 
 :END:

cite:sniekers2017genome Un GWAS avec l'inteligence, une grosse GWAS.

** TODO 2017 - An Expanded View of Complex Traits: From Polygenic to Omnigenic
 :PROPERTIES:
  :Custom_ID: boyle2017expanded
  :AUTHOR: Boyle, Li \& Pritchard
  :JOURNAL: Cell
  :YEAR: 2017
  :VOLUME: 169
  :PAGES: 1177--1186
  :DOI: 
  :URL: 
 :END:

cite:boyle2017expanded Omnigenic, c'est a dire sur tout le génome, on se
raproche du modèle a infinité d'allele de fisher.

Un blog qui parle qui critique les controls des erreurs trop conservatif :
[[file:Biblio/org-ref-pdfs/irizarry_2017.pdf][Lowering the GWAS threshold would save millions of dollars]].

** TODO - Régression pénalisée : le Lasso
 :PROPERTIES:
  :Custom_ID: coursLasso
  :AUTHOR: VIALLON
  :JOURNAL: 
  :YEAR: 
  :VOLUME: 
  :PAGES: 
  :DOI: 
  :URL: 
 :END:

cite:coursLasso Un cours sur le lasso avec des formules pour choisir le lambda.

** TODO 2012 - Matrix analysis
 :PROPERTIES:
  :Custom_ID: johnson2012matrix
  :AUTHOR: Johnson \& Horn
  :JOURNAL: 
  :YEAR: 2012
  :VOLUME: 
  :PAGES: 
  :DOI: 
  :URL: 
 :END:

cite:johnson2012matrix Un classic de l'analyse matricielle.

** TODO 2008 - Genome-wide association studies for complex traits: consensus,  uncertainty and challenges
 :PROPERTIES:
  :Custom_ID: McCarthy_2008
  :AUTHOR: McCarthy, Abecasis, Cardon, , Goldstein, Little, Ioannidis, \& Hirschhorn
  :JOURNAL: Nature Reviews Genetics
  :YEAR: 2008
  :VOLUME: 9
  :PAGES: 356–369
  :DOI: 10.1038/nrg2344
  :URL: http://dx.doi.org/10.1038/nrg2344
 :END:

 cite:McCarthy_2008 Sur l'utilisation des GWASs ! a quoi ca sert !  
