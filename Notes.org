# -*- mode: org -*-
# -*- coding: utf-8 -*-
#+STARTUP: overview indent inlineimages logdrawer
#+TITLE:       Thesis Lab Notebook
#+AUTHOR:      Kevin Caye
#+LANGUAGE:    en
#+TAGS: noexport(n)
#+TAGS: 1Article(1) 2Article(2) 3Article(3) Thesis(T)
#+EXPORT_SELECT_TAGS: Blog
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) RUNNING(r!) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

* Notebooks
:PROPERTIES:
:header-args: :cache no :session *R* :dir ./ :eval no-export
:END:
Les autres notebooks de ma thèse sont un peu partout... :D
** DONE Premier org notebook
CLOSED: [2017-04-04 mar. 11:05]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-04-04 mar. 11:05]
- State "STARTED"    from "TODO"       [2017-04-04 mar. 10:28]
- State "TODO"       from              [2017-04-04 mar. 10:27]
:END:
#+begin_src R :results output graphics :file Rplots/first_plot.png :exports both :width 600 :height 400 
plot(1)
#+end_src

#+RESULTS:
[[file:Rplots/first_plot.png]]

** DONE Comparison of methods on generative simu cor(U1,X)=c      :3Article:
CLOSED: [2017-04-13 jeu. 09:02]
:LOGBOOK:
- Note taken on [2017-04-13 jeu. 09:02] \\
  On a pas lancé sur toutes les méthodes (cate et lea) mais on passe sur des
  simulation plus dure !!
- State "DONE"       from "STARTED"    [2017-04-13 jeu. 09:02]
- Note taken on [2017-04-12 mer. 16:38] \\
  Il faut vraiment que je trouve des simulation plus facile, peut etre en
  augmentant la variance de B. Faut que j'essaie avec d'autre axe corrélé avec X
  peut être qu'on y verra plus clair !!
- Note taken on [2017-04-12 mer. 16:33] \\
  Les resultats avec K over estimated sont pas mal. Au final tout le lfmmLasso est
  bien robuste ! L'oracle fait comme PCAlm ... il faut que je modifie ca ! Je vais
  faire un vrai oracle !!
- Note taken on [2017-04-12 mer. 10:22] \\
  Je pense que ces simulation sont un peut trop dure, mais on voit quand même que
  mes lfmmRidge et lfmmLasso sont pas mal !
- Note taken on [2017-04-11 mar. 17:18] \\
  On a fait les courbe d'auc, ca rend pas mal. Ce qu'on voit c'est que FAMT et
  lassoLFMM font les meilleurs résultats. L'avantave de ma méthode est sur le
  control du FDR.
- Note taken on [2017-04-07 ven. 10:30] \\
  Courbe d'AUC ?
- Note taken on [2017-04-07 ven. 10:27] \\
  Les resultats sont pas clairs => mettre d'autre param (comme avant c(0.6,0.3)?)
- State "STARTED"    from "RUNNING"    [2017-04-05 mer. 16:33]
- State "RUNNING"    from "STARTED"    [2017-04-05 mer. 16:33]
- State "STARTED"    from "WAITING"    [2017-04-04 mar. 16:55]
- State "WAITING"    from "STARTED"    [2017-04-04 mar. 15:58]
- State "STARTED"    from "TODO"       [2017-04-04 mar. 13:01]
- State "TODO"       from              [2017-04-04 mar. 11:06]
:END:
*** With the same 10000 loci for every body 
**** Run on krak
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 10,
                                   fast.only = FALSE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)
#+end_src
**** Plots
:PROPERTIES:
:header-args: :cache no :session *R* :dir ./ :eval no-export :width 1000 :height 800
:END:

We retrieve the experiment
#+begin_src R :results output :exports both
  exp <- retrieveExperiment(96)
  exp$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/European_Chrm22.maf.05.sample.10000.rds K=4 n= L=10000 cs=0.2|0.4|0.6|0.8 outlier.props=0.01|0.05|0.1 nb.rep=10 "

***** C = 0.2
#+begin_src R :results output graphics :file Rplots/1000_loci_c02.png :exports both
  Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.2)
#+end_src

#+RESULTS:
[[file:Rplots/1000_loci_c02.png]]

***** C = 0.6
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.6)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-4989Cvd.png]]
***** precision-recall
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_precisionRecall(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-15107ugK.png]]

On y voit pas grand chose. Faire des courbes d'AUC comme dans 2Article ? Je vais
lancer sur tous le data set pour voir si c'est pas ces 10000 loci qui sont bizare.
***** AUC
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071UEP.png]]
***** Inflation factor
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071VFW.png]]

*** By sampling loci every time
**** DONE Run on krakenator or patator
CLOSED: [2017-04-07 ven. 08:32]
:LOGBOOK:
- Note taken on [2017-04-07 ven. 08:33] \\
  exp id = 100
- State "DONE"       from "RUNNING"    [2017-04-07 ven. 08:32]
- State "RUNNING"    from "WAITING"    [2017-04-06 jeu. 11:53]
- Note taken on [2017-04-05 mer. 09:03] \\
  Bug when running on krakenator
- State "WAITING"    from "RUNNING"    [2017-04-05 mer. 09:01]
- State "RUNNING"    from              [2017-04-04 mar. 16:56]
:END:
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 10,
                                   fast.only = FALSE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)
#+end_src
**** Plots
We retrieve exp results
#+begin_src R :results output :session *R* :exports both
library(ThesisRpackage)
exp <- retrieveExperiment(100)
#+end_src

#+RESULTS:

***** C = 0.2
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.2)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-5560Z9V.png]]

***** C = 0.6
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.6)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-5560Aco.png]]

***** C = 0.8
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_pvalueGrid(exp, c = 0.8)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-5560aw0.png]]

***** precision-recall
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
  Article3_MethodComparison_plot_precisionRecall(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-5560ZEK.png]]

***** AUC
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071hOV.png]]

***** Inflation factor
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071vZi.png]]

*** We over estimate K (K+1)
**** DONE Run on krakenator
CLOSED: [2017-04-12 mer. 16:32]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-12 mer. 16:32]
- State "RUNNING"    from              [2017-04-12 mer. 10:56]
:END:
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   K.method = 5,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 5,
                                   fast.only = TRUE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)


#+end_src
**** plots
#+begin_src R :results output :session *R* :exports both
exp <- retrieveExperiment(103)
exp$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds K=4 K.method=5 fast.only=TRUE n= L=10000 cs=0.2|0.4|0.6|0.8 outlier.props=0.01|0.05|0.1 nb.rep=5 "
***** AUC
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-27994ouK.png]]

***** Inflation factor
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-2799414Q.png]]


*** We over estimate K (K+3)
**** DONE On krakenator
CLOSED: [2017-04-12 mer. 16:32]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-12 mer. 16:32]
- State "RUNNING"    from              [2017-04-12 mer. 10:57]
:END:
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   K.method = 7,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 5,
                                   fast.only = TRUE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)


#+end_src
**** plots
#+begin_src R :results output :session *R* :exports both
exp <- retrieveExperiment(104)
exp$description
#+end_src

#+RESULTS:
: [1] "Article3_MethodComparison with G.file=~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds K=4 K.method=7 fast.only=TRUE n= L=10000 cs=0.2|0.4|0.6|0.8 outlier.props=0.01|0.05|0.1 nb.rep=5 "
***** AUC
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-27994PNd.png]]
***** Inflation factor
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 1000 :height 800 :session *R* 
  Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-27994php.png]]




** CANCELLED EWAS for LFMM article                                :3Article:
CLOSED: [2017-05-10 mer. 11:05]
:LOGBOOK:
- State "CANCELLED"  from "STARTED"    [2017-05-10 mer. 11:05]
- Note taken on [2017-05-10 mer. 11:04] \\
  On va reprendre cette analyse depuis le debut, au propre !
- Note taken on [2017-04-13 jeu. 18:00] \\
  Ok c'est on va retrouver les même resultats par contre lasso donne pas les même
  reultats... A voir.
- Note taken on [2017-04-13 jeu. 17:25] \\
  Je vais essayer de reproduire les resultats que j'avais trouvé pour la pres
  [[file:3Article/Slides/BCMSeminar/experiments.nb.html][seminarBCM]].
- Note taken on [2017-04-11 mar. 12:39] \\
  Il y a quelque chose qui ne va pas avec ces données je n'arrive même pas a
  reproduire les resultats des papiers cite:Rahmani_2016 etc... Je voulais
  retrouver les loci connu sans correction mais ca n'a pas l'aire de marcher.
  Affaire a suivre !!
- Note taken on [2017-04-10 lun. 17:43] \\
  Il faut que je recalibre les tests. Pk. Je vais faire de la biblio la dessus et
  identifier les causes du fdr pas controlé !!!! 
  Debug ca aussi [[file:ThesisRpackage/tests/testthat/test_3Article_runExp.R::test_that("Article3_runExp_calibrate",%20{][Article3_runExp_calibrate]]
- State "STARTED"    from "TODO"       [2017-04-04 mar. 16:19]
- State "TODO"       from              [2017-04-04 mar. 12:06]
:END:
*** PCA on betanormalized_metylationlvl.filtered.rds
**** on krakenator
#+begin_src R :results output :session *R* :exports both
library(ThesisRpackage)
s <- TrueSampler(G.file = "../Data/GSE42861/betanormalized_metylationlvl.filtered.rds",
                 X.file = "../Data/GSE42861/X.rds",
                 outlier.file = NULL,
                 n = NULL,
                 L = NULL)
exp <- Article3_pcaExp(s = s,
                       s.name = "GSE42861 filtered",
                       cluster.nb = NULL,
                       save = TRUE, bypass = FALSE)
#+end_src
**** Plots
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  exp <- retrieveExperiment(40)
  plot(exp)
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-28683uFt.png]]
*** <<CV_GSE42861_not_corrected>> LFMM ridge crossvalidation on betanormalized_metylationlvl.filtered.rds
**** On krakenator
#+begin_src R :results output :session *R* :exports both
library(ThesisRpackage)
s <- TrueSampler(G.file = "../Data/GSE42861/betanormalized_metylationlvl.filtered.rds",
                 X.file = "../Data/GSE42861/X.rds",
                 outlier.file = NULL,
                 n = NULL,
                 L = NULL)
dat <- sampl(s)
exp <- Article3_cvExp(s = s,
                      s.name = "GSE42861 filtered",
                      Ks = c(1,2,3, 4, 5, 6, 7, 8, 10,15),
                      lambdas = c(1e-10, 1e0, 1e10, 1e20),
                      row.left.out.func = left.out.kfold(5),
                      col.left.out.func = left.out.sample(5, 0.2),
                      cluster.nb = 2,
                      save = TRUE, bypass = FALSE)
#+end_src
**** Plots
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
exp <- retrieveExperiment(41)
plot(exp$cv, color = "K")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-28683tZC.png]]
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
plot(exp$cv, color = "lambda")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-286836jI.png]]

*** LFMM ridge crossvalidation on betanormalized_metylationlvl.filtered.LMresidu.rds
**** DONE On krakenator
CLOSED: [2017-04-05 mer. 08:47]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-05 mer. 08:47]
- State "RUNNING"    from              [2017-04-04 mar. 16:56]
:END:
#+begin_src R :results output :session *R* :exports both
library(ThesisRpackage)
  s <- TrueSampler(G.file = "../Data/GSE42861/betanormalized_metylationlvl.filtered.LMresidu.rds",
                   X.file = "../Data/GSE42861/X.rds",
                   outlier.file = NULL,
                   n = NULL,
                   L = NULL)
  dat <- sampl(s)
  exp <- Article3_cvExp(dat = dat,
                        dat.name = "GSE42861 filtered and LM residual",
                        Ks = c(1,2,3, 4, 5, 6, 7, 8, 10,15),
                        lambdas = c(1e-10, 1e0, 1e10, 1e20),
                        row.left.out.func = left.out.kfold(5),
                        col.left.out.func = left.out.sample(5, 0.2),
                        cluster.nb = 2,
                        save = TRUE, bypass = FALSE)
#+end_src

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
exp <- retrieveExperiment(97)
plot(exp$cv, color = 'K')
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-15107iJj.png]]

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 800 :height 800 :session *R* 
plot(exp$cv, color = "lambda")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-151077xE.png]]

La cross validation donne plutot K = 2 et pas d'importance pour le choix de
lambda. Ce qui est interessant c'est que la [[CV_GSE42861_not_corrected][CV]] sur les données avec variables
lattente donne plutot K = 4 et lambda petit.
*** Run on betanormalized_metylationlvl.filtered.rds
**** DONE on krakenator
CLOSED: [2017-04-10 lun. 14:39]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-10 lun. 14:39]
- State "RUNNING"    from "DONE"       [2017-04-07 ven. 13:56]
- Note taken on [2017-04-07 ven. 13:17] \\
  exp id = 99
- State "DONE"       from "RUNNING"    [2017-04-07 ven. 13:17]
- State "RUNNING"    from "WAITING"    [2017-04-06 jeu. 09:15]
- State "WAITING"    from "RUNNING"    [2017-04-06 jeu. 08:35]
- State "RUNNING"    from "WAITING"    [2017-04-05 mer. 16:34]
- Note taken on [2017-04-05 mer. 16:22] \\
  krakenator va etre mis a jour, on relance après !
- State "WAITING"    from "RUNNING"    [2017-04-05 mer. 16:22]
- State "RUNNING"    from "TODO"       [2017-04-05 mer. 12:33]
- State "TODO"       from              [2017-04-05 mer. 08:58]
:END:
#+begin_src R :results output :session *R* :exports both
  library(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/GSE42861/betanormalized_metylationlvl.filtered.rds"
  X.file <- "~/Projects/Thesis/Data/GSE42861/X.rds"


  s <- TrueSampler(G.file = G.file,
                   X.file = X.file,
                   outlier.file = NULL)
  dat <- sampl(s)
  dat$X <- dat$X[,1,drop=FALSE] ## keep only first covariate
  exp <- Article3_GSE42861(dat = dat,
                           dat.name = "betanormalized_metylationlvl.filtered.rds",
                           cluster.nb = 4,
                           Ks = c(2,3,4),
                           lambdas = c(1e-4, 1e0, 1e10),
                           sparse.prop = c(0.1),
                           save = TRUE,
                           bypass = FALSE)

#+end_src
**** plots
#+begin_src R :results output :session *R* :exports both
  exp <- retrieveExperiment(101)
  exp$description
#+end_src

#+RESULTS:
: [1] "Article3_runExp with methods=lfmmRidge|glm|refactor|lfmmLasso lambdas=1e-04|1|1e+10|NA|0.0152324128831718|0.0120402443893896|0.00992138012483149 Ks=2|3|4|NA sparse.prop=NA|0.1 dat.name=betanormalized_metylationlvl.filtered.rds "

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
Article3_runExp_manhattan(exp, 0.05,'refactor')
#+end_src


*** Run on betanormalized_metylationlvl.filtered.LMresidu.rds
**** DONE on krakenator
CLOSED: [2017-04-10 lun. 14:39]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-10 lun. 14:39]
- State "RUNNING"    from "WAITING"    [2017-04-06 jeu. 09:16]
- State "WAITING"    from "RUNNING"    [2017-04-06 jeu. 08:35]
- State "RUNNING"    from "WAITING"    [2017-04-05 mer. 16:34]
- Note taken on [2017-04-05 mer. 16:23] \\
  krakenator va etre mis a jour...
- State "WAITING"    from "RUNNING"    [2017-04-05 mer. 16:23]
- State "RUNNING"    from "TODO"       [2017-04-05 mer. 12:33]
- State "TODO"       from              [2017-04-05 mer. 08:59]
:END:
#+begin_src R :results output :session *R* :exports both
  library(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/GSE42861/betanormalized_metylationlvl.filtered.LMresidu.rds"
  X.file <- "~/Projects/Thesis/Data/GSE42861/X.rds"


  s <- TrueSampler(G.file = G.file,
                   X.file = X.file,
                   outlier.file = NULL)
  dat <- sampl(s)
  dat$X <- dat$X[,1,drop=FALSE] ## keep only first covariate
  exp <- Article3_GSE42861(dat = dat,
                           dat.name = "betanormalized_metylationlvl.filtered.LMresidu.rds",
                           cluster.nb = 4,
                           Ks = c(2,3,4),
                           lambdas = c(1e-4, 1e0, 1e10),
                           sparse.prop = c(0.1),
                           save = TRUE,
                           bypass = FALSE)

#+end_src
**** plots
#+begin_src R :results output :session *R* :exports both
exp.LMresidu <- retrieveExperiment(102)
exp.LMresidu$description
#+end_src

#+RESULTS:
: [1] "Article3_runExp with methods=lfmmRidge|glm|refactor|lfmmLasso lambdas=1e-04|1|1e+10|NA|0.0118857550712915|0.00966331357938067|0.00901972710130546 Ks=2|3|4|NA sparse.prop=NA|0.1 dat.name=betanormalized_metylationlvl.filtered.LMresidu.rds "

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
Article3_runExp_manhattan(exp.LMresidu, 0.05,'refactor')
#+end_src

*** Interesting loci
List discuted in cite:Rahmani_2016 
#+begin_src R :results output :session *R* :exports both
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  exp.LMresidu$df.res %>%
    dplyr::filter(col.name %in% rahmani.outlier,
                  method == "refactor")
  exp$df.res %>%
    dplyr::filter(col.name %in% rahmani.outlier,
                  method == "refactor")

  exp$df.res %>%
    dplyr::filter(col.name %in% rahmani.outlier,
                  method == "glm")
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 9 × 10
   index   col.name       pvalue     score     B       qvalue   method lambda
   <int>      <chr>        <dbl>     <dbl> <dbl>        <dbl>    <chr>  <dbl>
1  36714 cg05428452 9.339330e-16 -8.035243    NA 2.081697e-13 refactor     NA
2  51546 cg07839457 1.286740e-10 -6.428731    NA 3.125326e-09 refactor     NA
3 101455 cg16411857 4.428888e-12 -6.922772    NA 2.005025e-10 refactor     NA
4  36714 cg05428452 4.787580e-13 -7.231196    NA 2.189824e-10 refactor     NA
5  51546 cg07839457 4.877471e-09 -5.851299    NA 2.533710e-07 refactor     NA
6 101455 cg16411857 5.670667e-11 -6.552171    NA 7.623022e-09 refactor     NA
7  36714 cg05428452 3.221914e-12 -6.967688    NA 9.739772e-08 refactor     NA
8  51546 cg07839457 2.888125e-09 -5.937834    NA 5.020182e-06 refactor     NA
9 101455 cg16411857 5.414775e-10 -6.206587    NA 2.104871e-06 refactor     NA
# ... with 2 more variables: K <dbl>, sparse.prop <dbl>
# A tibble: 9 × 10
   index   col.name       pvalue     score     B       qvalue   method lambda
   <int>      <chr>        <dbl>     <dbl> <dbl>        <dbl>    <chr>  <dbl>
1  36714 cg05428452 4.245903e-16 -8.131334    NA 1.108760e-13 refactor     NA
2  51546 cg07839457 6.395240e-11 -6.534195    NA 1.771405e-09 refactor     NA
3 101455 cg16411857 2.174284e-12 -7.022824    NA 1.117797e-10 refactor     NA
4  36714 cg05428452 1.466297e-13 -7.390180    NA 1.000277e-10 refactor     NA
5  51546 cg07839457 8.570508e-09 -5.756836    NA 4.075391e-07 refactor     NA
6 101455 cg16411857 1.028115e-10 -6.462758    NA 1.311893e-08 refactor     NA
7  36714 cg05428452 3.653304e-14 -7.572777    NA 6.668225e-12 refactor     NA
8  51546 cg07839457 4.747825e-09 -5.855778    NA 9.198646e-08 refactor     NA
9 101455 cg16411857 6.215250e-10 -6.184873    NA 1.747915e-08 refactor     NA
# ... with 2 more variables: K <dbl>, sparse.prop <dbl>
# A tibble: 3 × 10
   index   col.name       pvalue      score            B       qvalue method
   <int>      <chr>        <dbl>      <dbl>        <dbl>        <dbl>  <chr>
1  36714 cg05428452 6.772196e-20 -9.1312355 -0.045467876 2.888329e-19    glm
2  51546 cg07839457 5.077905e-01 -0.6622819 -0.002318433 1.710891e-01    glm
3 101455 cg16411857 1.138380e-02 -2.5306913 -0.004700647 6.103030e-03    glm
# ... with 3 more variables: lambda <dbl>, K <dbl>, sparse.prop <dbl>
#+end_example

**** Do we find these loci with lfmmLasso and lfmmRidge on betanormalized_metylationlvl.filtered.rds
#+begin_src R :results output :session *R* :exports both
exp <- retrieveExperiment(101)
#+end_src
***** Compute of the gif

#+begin_src R :results output :session *R* :exports both
  gif.func <- function(score) {
    score2 <- score ^ 2
    median(score2) / qchisq(0.5, df = 1)
  }

  exp$df.res %>%
    group_by(K, lambda, sparse.prop, method) %>%
    summarise(gif = gif.func(score))
#+end_src

#+RESULTS:
#+begin_example
Source: local data frame [16 x 5]
Groups: K, lambda, sparse.prop [?]

       K       lambda sparse.prop    method       gif
   <dbl>        <dbl>       <dbl>     <chr>     <dbl>
1      2 1.000000e-04          NA lfmmRidge 11.584908
2      2 1.523241e-02         0.1 lfmmLasso 10.000808
3      2 1.000000e+00          NA lfmmRidge 11.572514
4      2 1.000000e+10          NA lfmmRidge  8.064392
5      2           NA          NA  refactor  7.096974
6      3 1.000000e-04          NA lfmmRidge  6.222251
7      3 1.204024e-02         0.1 lfmmLasso  5.435089
8      3 1.000000e+00          NA lfmmRidge  6.220483
9      3 1.000000e+10          NA lfmmRidge  5.609513
10     3           NA          NA  refactor  4.795921
11     4 1.000000e-04          NA lfmmRidge  6.088887
12     4 9.921380e-03         0.1 lfmmLasso  5.697559
13     4 1.000000e+00          NA lfmmRidge  6.088300
14     4 1.000000e+10          NA lfmmRidge  5.371812
15     4           NA          NA  refactor  6.914059
16    NA           NA          NA       glm 17.280261
#+end_example
***** Test calibration

#+begin_src R :results output :session *R* :exports both
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  ## lfmm lasso with K = 4

  lasso.df <- exp$df.res %>% dplyr::filter(method == "lfmmLasso", K == 4)
  lasso.df %>% dplyr::filter(col.name %in% rahmani.outlier)

  Article3_runExp_hist(exp, 0.05, "lfmmLasso")

  lcfdr <- locfdr::locfdr(lasso.df$score, df = 9)

  ggplot(lasso.df, aes(x = index, -log10(pvalue), color = col.name %in% rahmani.outlier)) +
    geom_point()
#+end_src

#+RESULTS:
: # A tibble: 3 × 10
:    index   col.name       pvalue     score           B       qvalue    method
:    <int>      <chr>        <dbl>     <dbl>       <dbl>        <dbl>     <chr>
: 1  36714 cg05428452 1.841763e-17 -8.503363 -0.03504021 8.391866e-16 lfmmLasso
: 2  51546 cg07839457 4.022940e-10 -6.253135  0.00000000 4.573476e-09 lfmmLasso
: 3 101455 cg16411857 1.751052e-10 -6.381724  0.00000000 2.154437e-09 lfmmLasso

Ca va jusqu'a $10^{-30}$ ... on ne les a pas detecté.

**** Do we find these loci with lfmmLasso and lfmmRidge on betanormalized_metylationlvl.filtered.LMresidu.rds
#+begin_src R :results output :exports both
exp <- retrieveExperiment(102)
exp$description
#+end_src

#+RESULTS:
: [1] "Article3_runExp with methods=lfmmRidge|glm|refactor|lfmmLasso lambdas=1e-04|1|1e+10|NA|0.0118857550712915|0.00966331357938067|0.00901972710130546 Ks=2|3|4|NA sparse.prop=NA|0.1 dat.name=betanormalized_metylationlvl.filtered.LMresidu.rds "

***** Compute of the gif

#+begin_src R :results output :exports both
  gif.func <- function(score) {
    score2 <- score ^ 2
    median(score2) / qchisq(0.5, df = 1)
  }

  exp$df.res %>%
    group_by(K, lambda, sparse.prop, method) %>%
    summarise(gif = gif.func(score))

#+end_src

#+RESULTS:
#+begin_example
Source: local data frame [16 x 5]
Groups: K, lambda, sparse.prop [?]

       K       lambda sparse.prop    method       gif
   <dbl>        <dbl>       <dbl>     <chr>     <dbl>
1      2 1.000000e-04          NA lfmmRidge  6.231422
2      2 1.188576e-02         0.1 lfmmLasso  5.530324
3      2 1.000000e+00          NA lfmmRidge  6.229777
4      2 1.000000e+10          NA lfmmRidge  5.689075
5      2           NA          NA  refactor  7.618795
6      3 1.000000e-04          NA lfmmRidge  6.383900
7      3 9.663314e-03         0.1 lfmmLasso  5.923144
8      3 1.000000e+00          NA lfmmRidge  6.383613
9      3 1.000000e+10          NA lfmmRidge  5.690365
10     3           NA          NA  refactor  4.968611
11     4 1.000000e-04          NA lfmmRidge  2.432270
12     4 9.019727e-03         0.1 lfmmLasso  2.286301
13     4 1.000000e+00          NA lfmmRidge  2.431269
14     4 1.000000e+10          NA lfmmRidge  2.057842
15     4           NA          NA  refactor  2.409529
16    NA           NA          NA       glm 17.286869
#+end_example

***** Methods comparison

****** Ridge LFMM
#+begin_src R :results output graphics :file Rplots/GSE42861_LMResidu_rahmani_ridge.png :exports both :width 600 :height 400 
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  ## lfmm lasso with K = 4

  ridge.df <- exp$df.res %>% dplyr::filter(method == "lfmmRidge", K == 4, lambda == 1e-4)

  ggplot(ridge.df, aes(x = index, -log10(pvalue), color = col.name %in% rahmani.outlier)) +
    geom_point()

#+end_src

#+RESULTS:
[[file:Rplots/GSE42861_LMResidu_rahmani.png]]

Il sortent presque. Dans [[file:3Article/Slides/BCMSeminar/experiments.nb.html][la pres BCM]] on les retrouvait carément bien. Mais je
pense que avec K = 6 c'est on trouvera comme refactor !!

****** Refactor
#+begin_src R :results output graphics :file Rplots/GSE42861_LMResidu_rahmani_refactor.png :exports both :width 600 :height 400 
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  ## lfmm lasso with K = 4

  df <- exp$df.res %>% dplyr::filter(method == "refactor", K == 4)

  ggplot(df, aes(x = index, -log10(pvalue), color = col.name %in% rahmani.outlier)) +
    geom_point()

#+end_src

#+RESULTS:
[[file:Rplots/GSE42861_LMResidu_rahmani_refactor.png]]

On ne retrouve pas comme dans cite:Rahmani_2016 ca doit être a cause des batch
effect que l'on a pas !!

****** Lasso LFMM
#+begin_src R :results output graphics :file Rplots/GSE42861_LMResidu_rahmani_lasso.png :exports both :width 600 :height 400 
  rahmani.outlier <- c("cg05428452", "cg07839457", "cg16411857")
  ## lfmm lasso with K = 4

  df <- exp$df.res %>% dplyr::filter(method == "lfmmLasso", K == 4)

  ggplot(df, aes(x = index, -log10(pvalue), color = col.name %in% rahmani.outlier)) +
    geom_point()

#+end_src

#+RESULTS:
[[file:Rplots/GSE42861_LMResidu_rahmani_lasso.png]]

Lasso ne trouve vraiment pas comme les autres ... bizare bizare. Il faudrait
voir la vrai valeur de K après convergeance.
** TODO GWAS for LFMM article                                     :3Article:
:LOGBOOK:
- State "TODO"       from              [2017-04-04 mar. 12:07]
:END:
** TODO EAS for LFMM article                                      :3Article:
:LOGBOOK:
- State "TODO"       from              [2017-04-04 mar. 12:09]
:END:
** STARTED Run of methods on OF GWAS simulation                   :3Article:
:LOGBOOK:
- Note taken on [2017-05-03 mer. 09:03] \\
  Je m'occupe des résultats de l'article 3, on reviendra la dessus après !
- Note taken on [2017-04-11 mar. 10:37] \\
  Il faut que je vois la litérature sur les methodes GWAS, comment il font pour
  simuler ? see [[file:Notes.org::*Mais%20avec%20un%20seul%20outlier][here]]
- Note taken on [2017-04-11 mar. 09:48] \\
  Ok c'est bon c'est bien les facteurs lattents qui expliquent que le test n'est
  pas calibré (mettre J = 0 et K = 40 pour les methods). see [[*Calibration du test quand il n'y a pas d'outlier][here]]
- Note taken on [2017-04-10 lun. 17:40] \\
  Il faut debuguer la simu : une methode oracle qui doit faire le top (ou alors je
  ne mets pas de var environmental) et fdr controlé !!
- Note taken on [2017-04-10 lun. 14:15] \\
  J'ai debuguer phenotypeWayReg_lm et ajouter les modifs de OF dans le sampler. Et
  maintenant ?
- Note taken on [2017-04-07 ven. 18:23] \\
  il faut debug + integrer les modif dans le sampler et après on pourra voir ce
  que ca fait
- Note taken on [2017-04-06 jeu. 11:28] \\
  C'est très long la boucle des glm !!
- Note taken on [2017-04-05 mer. 17:57] \\
  to be continued: finir le [[file:ThesisRpackage/R/Sampler/Sampler_PhenotypeFromTrueData.R][cette fonction]]
- Note taken on [2017-04-05 mer. 15:55] \\
  Premiere etape: faire le sampler
- State "STARTED"    from "TODO"       [2017-04-05 mer. 15:55]
- State "TODO"       from              [2017-04-04 mar. 13:07]
:END:
- [ ] pca
- [ ] run all methods
- [ ] Eigenstrat
- [ ] mesure de la précision ??
- [ ] Gemma

*** RMKs
**** Calibration du test quand il n'y a pas d'outlier
:LOGBOOK:
- State "DONE"       from              [2017-04-11 mar. 10:24]
:END:

#+begin_src R :results output :session *R* :exports both
## library
library(ThesisRpackage)

## sample
G.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.rds"
env.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.env.rds"
## pca.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.pca.rds"
pca.file <- NULL
coord.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.coord.rds"
chrm.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.chrm.rds"
K <- 5
s <- PhenotypeFromTrueSampler(G.file,
                              coord.file,
                              env.file,
                              pca.file,
                              n = NULL,
                              L = 3000,
                              K = K,
                              J = 0,
                              beta = 6,
                              delta = 0.0,
                              chrm.file = chrm.file,
                              chrm.window = 20)

dat <- sampl(s)

## methods
methods <- list()
K <- 50
hypothesis.testing.func <- phenotypeWayReg_lm_score(calibrate = FALSE)

## lm
methods$lm <- ClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                  nickname="lm")
## lm + PCA
methods$lmPCA <- PCAClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                        K = K, 
                                        nickname="lm+PCA")


## lfmm ridge
methods$ridgeLFMM <- RidgeLFMMMethod(K = K,
                                     lambda = 1e0,
                                     hypothesis.testing.method = hypothesis.testing.func,
                                     nickname = "ridgeLFMM")

## lfmm lasso
methods$lassoLFMM <- LassoLFMMMethod(K = K,
                                     lambda = NULL,
                                     sparse.prop = 0.01,
                                     hypothesis.testing.method = hypothesis.testing.func,
                                     nickname = "lassoLFMM")



exp <- do.call(FDRControlExperiment, c(list(nb.rep = 5,
                                            sampler = s), methods))
exp <- runExperiment(exp)


#+end_src

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  plot(exp, plot.type = "pvalue.grid")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-60712Bu.png]]

Le test est bien calibré.

**** Mais avec un seul outlier
#+begin_src R :results output :session *R* :exports both
  ## library
  library(ThesisRpackage)

  ## sample
  G.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.rds"
  env.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.env.rds"
  ## pca.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.pca.rds"
  pca.file <- NULL
  coord.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.coord.rds"
  chrm.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.chrm.rds"
  K <- 5
  s <- PhenotypeFromTrueSampler(G.file,
                                coord.file,
                                env.file,
                                pca.file,
                                n = NULL,
                                L = 3000,
                                K = K,
                                J = 1,
                                beta = 6,
                                delta = 0.0,
                                chrm.file = chrm.file,
                                chrm.window = 20)

  dat <- sampl(s)

  ## methods
  methods <- list()
  K <- 50
  hypothesis.testing.func <- phenotypeWayReg_lm_score(calibrate = FALSE)

  ## lm
  methods$lm <- ClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                    nickname="lm")
  ## lm + PCA
  methods$lmPCA <- PCAClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                          K = K, 
                                          nickname="lm+PCA")


  ## lfmm ridge
  methods$ridgeLFMM <- RidgeLFMMMethod(K = K,
                                       lambda = 1e0,
                                       hypothesis.testing.method = hypothesis.testing.func,
                                       nickname = "ridgeLFMM")

  ## lfmm lasso
  methods$lassoLFMM <- LassoLFMMMethod(K = K,
                                       lambda = NULL,
                                       sparse.prop = 0.01,
                                       hypothesis.testing.method = hypothesis.testing.func,
                                       nickname = "lassoLFMM")



  exp <- do.call(FDRControlExperiment, c(list(nb.rep = 5,
                                              sampler = s), methods))
  exp <- runExperiment(exp)


#+end_src

#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  plot(exp, plot.type = "pvalue.grid")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-6071PqP.png]]

C'est plus calibré, en faite c'est logique a cause la structure ils sont tous
corélé à $G_j$. A voir comment il font dans les GWAS...
*** Install of ThesisRpackage
#+BEGIN_SRC bash
cd /home/cayek/Projects/Thesis
make Rpackage_install
#+END_SRC
*** Run of methods
#+begin_src R :results output :session *R* :exports both

  ## library
  library(ThesisRpackage)

  ## sample
  G.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.rds"
  env.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.env.rds"
  ## pca.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.pca.rds"
  pca.file <- NULL
  coord.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.coord.rds"
  chrm.file <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/G_OF_filtered.sample.chrm.rds"
  K <- 5
  s <- PhenotypeFromTrueSampler(G.file,
                                coord.file,
                                env.file,
                                pca.file,
                                n = NULL,
                                L = 3000,
                                K = K,
                                J = 0,
                                beta = 6,
                                delta = 0.0,
                                chrm.file = chrm.file,
                                chrm.window = 20)

  dat <- sampl(s)

  ## methods
  methods <- list()
  K <- 50
  hypothesis.testing.func <- phenotypeWayReg_lm_score(calibrate = FALSE)

  ## lm
  methods$lm <- ClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                    nickname="lm")
  ## lm + PCA
  methods$lmPCA <- PCAClassicLinearMethod(hypothesis.testing.method = hypothesis.testing.func,
                                          K = K, 
                                          nickname="lm+PCA")


  ## lfmm ridge
  methods$ridgeLFMM <- RidgeLFMMMethod(K = K,
                                       lambda = 1e0,
                                       hypothesis.testing.method = hypothesis.testing.func,
                                       nickname = "ridgeLFMM")

  ## lfmm lasso
  methods$lassoLFMM <- LassoLFMMMethod(K = K,
                                       lambda = NULL,
                                       sparse.prop = 0.01,
                                       hypothesis.testing.method = hypothesis.testing.func,
                                       nickname = "lassoLFMM")

  ## sva
  methods$sva <- SVAMethod(K = K,
                           hypothesis.testing.method = hypothesis.testing.func,
                           nickname = "sva")

  ## experiment
  exp <- do.call(FDRControlExperiment, c(list(nb.rep = 5,
                                              sampler = s), methods))
  exp <- runExperiment(exp)

  ## plot
  # plot(exp, plot.type = "pvalue.grid")
#+end_src
*** FDR control
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  plot(exp, plot.type = "pvalue.grid")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-4925ulr.png]]

*** Precision recall
#+begin_src R :results output graphics :file  (org-babel-temp-file (concat (file-name-directory (or load-file-name buffer-file-name)) "Rfigures/figure-") ".png") :exports both :width 600 :height 400 :session *R* 
  plot(exp, plot.type = "precision.recall")
#+end_src

#+RESULTS:
[[file:/home/cayek/Projects/Thesis/Rfigures/figure-49257vx.png]]

** DONE LEA lfmm debug                                            :3Article:
CLOSED: [2017-05-03 mer. 08:57]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-05-03 mer. 08:57]
- Note taken on [2017-05-03 mer. 08:57] \\
  Il faut combiner des run et recalibrer ! De toute facon je ne vais pas utiliser
  LEA pour les resultat de l'article.
- Note taken on [2017-04-12 mer. 09:01] \\
  IL faut que je vois avec OF pourquoi ca ne marche pas.
- Note taken on [2017-04-11 mar. 14:42] \\
  L'objectif est de comprendre pourquoi ca donne d'aussi mauvais résultat sur mes
  simu de [[file:Notes.org::*Comparaison%20of%20methods%20for%203Article][Comparaison of methods for 3Article]]
- State "STARTED"    from              [2017-04-11 mar. 14:42]
:END:

#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)

  ## sample data
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  K <- 4
  s <- FromTrueSampler(G.file = G.file,
                       n = NULL,
                       L = 1000,
                       K = K,
                       prop.outlier = 0.05,
                       rho = NULL,
                       cs = 0.4,
                       round = FALSE)
  dat <- sampl(s)

  ## run LEA
  m <- LeaLFMMMethod(K = K,
                     iterations = 20000,
                     CPU = 16)
  m <- run(m, dat)

  ## plot
  gplot_stat(m$pvalue[1,],
             outlier = dat$outlier) +
    geom_histogram(aes(stat, fill = outlier, y = ..density..))

  gplot_stat(m$pvalue[1,],
             outlier = dat$outlier) +
    geom_point(aes(x = index, color = outlier, y = -log10(stat)))

#+end_src

*** LEA::lfmm
:PROPERTIES:
:header-args: :cache no :session *notebookR* :dir ./ :eval no-export
:END:
On krakenator
**** Install of ThesisRpackage on krakenator
#+BEGIN_SRC bash :dir /cayek@krakenator.imag.fr:~/Projects/Thesis/
cd /home/cayek/Projects/Thesis
make Rpackage_install
#+END_SRC

**** Simulate data with 0.05 % of outlier
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## sample data
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.rds"
  K <- 4
  s <- FromTrueSampler(G.file = G.file,
                       n = NULL,
                       L = 1000,
                       K = K,
                       prop.outlier = 0.05,
                       rho = NULL,
                       cs = 0.4,
                       round = FALSE)

  dat <- sampl(s)
  names(dat)
  saveRDS(dat, "./Data/NotebookTMP/Simulation_outlier05_cor04.rds")
#+end_src

#+RESULTS:
: [1] "G"       "X"       "U"       "V"       "B"       "epsilon" "outlier"
: [8] "mu"

**** Run LEA::lfmm
#+begin_src R :results output :exports both
  library(LEA)

  ## read data
  dat <- readRDS("./Data/NotebookTMP/Simulation_outlier05_cor04.rds")

  ## write to lfmm format
  write.lfmm(dat$G, "./Simulation_outlier05_cor04.lfmm")
  write.env(dat$X, "./Simulation_outlier05_cor04.env")

  ## run lfmm
  lfmm.res <- lfmm(input.file="./Simulation_outlier05_cor04.lfmm",
                   environment.file="./Simulation_outlier05_cor04.env",
                   K = 4,
                   project="new",
                   CPU = 4)


#+end_src

#+RESULTS:
#+begin_example
[1] "./Simulation_outlier05_cor04.lfmm"
[1] "./Simulation_outlier05_cor04.env"
The project is saved into :
 Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject 

To load the project, use:
 project = load.lfmmProject("Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject")

To remove the project, use:
 remove.lfmmProject("Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject")

[1] "********************************"
[1] "* K = 4  repetition 1  d = 1   *"
[1] "********************************"
Summary of the options:

        -n (number of individuals)      503
        -L (number of loci)             1000
        -K (number of latent factors)   4
        -o (output file)                Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmm/K4/run1/Simulation_outlier05_cor04_r1
        -i (number of iterations)       10000
        -b (burnin)                     5000
        -s (seed random init)           61801602730908
        -p (number of processes (CPU))  4
        -x (genotype file)              Simulation_outlier05_cor04.lfmm
        -v (variable file)              Simulation_outlier05_cor04.env
        -D (number of covariables)      1
        -d (the dth covariable)         1

Read variable file:
 	Simulation_outlier05_cor04.env		OK.

Read genotype file:
 	Simulation_outlier05_cor04.lfmm		OK.

<<<<
	 Analyse for variable 1

		Start of the Gibbs Sampler algorithm.

	[                                                                           ]
	[===========================================================================]

		End of the Gibbs Sampler algorithm.

	ED:503000.1531	 DIC: 503001.0074 

	The statistics for the run are registered in:
 		Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmm/K4/run1/Simulation_outlier05_cor04_r1_s1.4.dic.

	The zscores for variable 1 are registered in:
 		Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmm/K4/run1/Simulation_outlier05_cor04_r1_s1.4.zscore.
	The columns are: zscores, -log10(p-values), p-values.

	-------------------------
	The execution for variable 1 worked without error.
>>>>

The project is saved into :
 Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject 

To load the project, use:
 project = load.lfmmProject("Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject")

To remove the project, use:
 remove.lfmmProject("Simulation_outlier05_cor04_Simulation_outlier05_cor04.lfmmProject")
#+end_example

Histogram
#+begin_src R :results output graphics :file Rplots/LEA/lea_histo.png :exports both :width 600 :height 400 
## plot
pvalue <- LEA::p.values(lfmm.res, K = 4)
hist(pvalue)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lea_histo.png]]

Manhattan plot
#+begin_src R :results output graphics :file Rplots/LEA/lea_man.png :exports both :width 600 :height 400 
library(ggplot2)
index <- seq_along(pvalue)
qplot(index, -log10(pvalue), color = index %in% dat$outlier)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lea_man.png]]

**** Run of LassoLFMM
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## read data
  dat <- readRDS("./Data/NotebookTMP/Simulation_outlier05_cor04.rds")

  ## run of lfmmLasso 
  m <- finalLfmmLassoMethod(K = 4,
                            sparse.prop = 0.05)
  m <- run(m, dat)
#+end_src


Histogram
#+begin_src R :results output graphics :file Rplots/LEA/lasso_hist.png :exports both :width 600 :height 400 
  hist(m$pvalue)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lasso_hist.png]]

Manhattan plot
#+begin_src R :results output graphics :file Rplots/LEA/lasso_man.png :exports both :width 600 :height 400 
  library(ggplot2)
  pvalue <- as.numeric(m$pvalue)
  index <- seq_along(pvalue)

  qplot(x = index, y = -log10(pvalue), color = index %in% dat$outlier)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lasso_man.png]]

**** Run of lm 
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## read data
  dat <- readRDS("./Data/NotebookTMP/Simulation_outlier05_cor04.rds")

  ## run of lfmmLasso 
  m <- finalLm()
  m <- run(m, dat)
#+end_src


Histogram:
#+begin_src R :results output graphics :file Rplots/LEA/lm_histo.png :exports both :width 600 :height 400 
hist(m$pvalue)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lm_histo.png]]

C'est mal calibré.

Manhattan plot:
#+begin_src R :results output graphics :file Rplots/LEA/lm_man.png :exports both :width 600 :height 400 
  library(ggplot2)
  pvalue <- as.numeric(m$pvalue)
  index <- seq_along(pvalue)

  qplot(x = index, y = -log10(pvalue), color = index %in% dat$outlier)
#+end_src

#+RESULTS:
[[file:Rplots/LEA/lm_man.png]]

**** export notebook                                            :noexport:
:PROPERTIES:
:header-args: :cache no :session *bash* :dir ./ :eval no-export
:END:
#+BEGIN_SRC bash 
  mkdir NOTEBOOK/
  mkdir NOTEBOOK/Data
  mkdir NOTEBOOK/Rplots
  cp Notes.html NOTEBOOK/
  cp -r Data/NotebookTMP/ NOTEBOOK/Data/
  cp -r Rplots/LEA/ NOTEBOOK/Rplots/
  tar -czvf NOTEBOOK.tar.gz NOTEBOOK
  rm -rf NOTEBOOK
  scp NOTEBOOK.tar.gz cayek@krakenator.imag.fr:~/Notebook_LEAdebug.tar.gz
#+END_SRC




** DONE Test of [[https://cran.r-project.org/web/packages/cate/index.html][cate]] CRAN package                                 :3Article:
CLOSED: [2017-04-12 mer. 16:17]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-04-12 mer. 16:17]
- Note taken on [2017-04-12 mer. 16:17] \\
  Je vais l'ajouter au methodes !!
- State "STARTED"    from              [2017-04-12 mer. 15:45]
:END:
La [[file:Biblio/org-ref-pdfs/cate_vignette.pdf][vignette]]
#+begin_src R :results output :session *R* :exports both
  install.packages("cate")
  library(cate)

  data(gender.sm)
  names(gender.sm)

  ## compute t test
  t.stats <- apply(gender.sm$Y, 2, function(y, x) t.test(y~x)$statistic, gender.sm$X)
  hist(t.stats)

  ## estimation of the number of lattent factor
  n <- nrow(gender.sm$Y) # number of samples
  gender.data <- data.frame(gender = gender.sm$X, gender.sm$Z)
  factor.num <- est.confounder.num(~ gender | . - gender + 0,
                                   gender.data, gender.sm$Y,
                                   method = "bcv", bcv.plot = FALSE,
                                   rmax = 30, nRepeat = 20)
  factor.num$r

  cate.results <- cate(~ gender | . - gender + 0,
                       gender.data, gender.sm$Y, r = factor.num$r)
  names(cate.results)

  ## ....

  ## factor analysis
  mle <- factor.analysis(gender.sm$Y, r = 5) 
  names(mle)
#+end_src

** CANCELLED Comparison of methods on generative simu cor(U1/2,X)=c :3Article:
CLOSED: [2017-04-13 jeu. 18:16]
:LOGBOOK:
- Note taken on [2017-04-13 jeu. 18:16] \\
  On va faire l'experience final pour le papier dirrect !!
- State "CANCELLED"  from "STARTED"    [2017-04-13 jeu. 18:16]
- State "STARTED"    from              [2017-04-13 jeu. 09:02]
:END:
**** Run on krak
#+begin_src R :results output :session *R* :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05, 0.1),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   cs = c(0.2, 0.4, 0.6, 0.8),
                                   nb.rep = 10,
                                   fast.only = FALSE,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)
#+end_src

** DONE Correction $G - U V^T$ on generative simulations          :3Article:
CLOSED: [2017-04-14 ven. 14:56]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-04-14 ven. 14:56]
- State "STARTED"    from "TODO"       [2017-04-14 ven. 10:03]
- State "TODO"       from              [2017-04-14 ven. 10:01]
:END:

*** DONE On krakenator
CLOSED: [2017-04-14 ven. 14:49]
:PROPERTIES:
:CUSTOM_ID: simu with NA
:END:
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-04-14 ven. 14:49]
- State "RUNNING"    from              [2017-04-14 ven. 10:08]
:END:
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000.rds"
  ## run all simulation on the same 10000 loci sample
  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = c(0.01, 0.05),
                                   n = NULL, L = 10000,
                                   K = 4,
                                   cs = c(0.4, 0.6),
                                   nb.rep = 5,
                                   cluster.nb = 16,
                                   save = TRUE, bypass = FALSE)
#+end_src

*** plots
:PROPERTIES:
:header-args: :cache no :session *R* :dir ./ :eval no-export :width 800 :height 600
:END:

We retrieve the experiment
#+begin_src R :results output :exports both
  exp <- retrieveExperiment(106)
  exp$description
#+end_src

***** AUC
#+begin_src R :results output graphics :file Rplots/G_UV.auc.png :exports both 
Article3_MethodComparison_plot_AUC(exp)
#+end_src

#+RESULTS:
[[file:Rplots/G_UV.auc.png]]

***** gif
#+begin_src R :results output graphics :file Rplots/G_UV.gif.png :exports both 
Article3_MethodComparison_plot_GIF(exp)
#+end_src

#+RESULTS:
[[file:Rplots/G_UV.gif.png]]

** DONE Check NA in results                                       :3Article:
CLOSED: [2017-05-03 mer. 08:56]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-03 mer. 08:56]
- Note taken on [2017-04-14 ven. 14:57] \\
  Tout est dans le titre, je veux m'assurer que les NA qu'on a en sorti parfois ne
  sont pas des outlier !! J'en ai observé sur [[#simu with NA][cette simu]].
- State "TODO"       from              [2017-04-14 ven. 14:57]
:END:
#+begin_src R :results output :exports both
  ## sample data
  s <- FromTrueSampler(G.file = "~/Projects/Thesis/Data/1000Genomes/Phase3/European_Chrm22.maf.05.sample.10000.rds",
                       n = NULL,
                       L = 10000,
                       K = 4,
                       cs = 0.4,
                       rho = NULL,
                       prop.outlier = 0.01,
                       round = FALSE)
  dat <- sampl(s)

  ## var of loci
  sum( apply(dat$G, 2, var) == 0)

  ## run of a method
  m <- finalLfmmRdigeMethod(K = 4, lambda = 1e-3)
  m <- run(m, dat)

  ## NA ?
  sum(is.na(m$score))

  ## NA and var = 0 ?
  m$score[1, apply(dat$G, 2, var) == 0]
#+end_src

#+RESULTS:
: [1] 1
: DEBUG [2017-05-03 08:54:26] run.Method: running  lm+zscore|calibrate=FALSE
: [1] 1
: rs1747928 
:       NaN

Il y a un locus sans variance .... De toute facon je vais regénérer des dataset
pour les resultats ! 

** DONE Redundancy Analysis (RDA)                                 :3Article:
CLOSED: [2017-05-02 mar. 15:40]
:LOGBOOK:
- Note taken on [2017-05-02 mar. 16:07] \\
  On laisse ca de coté les papiers de Forester sont trop légé sur les méthodes...
- State "DONE"       from "TODO"       [2017-05-02 mar. 15:40]
- Note taken on [2017-05-02 mar. 15:32] \\
  Il y a tout une litérature des ordination methods... J'ai l'impression que rda
  est bien une méthode pour faire des association. Mais ca ne prend pas en compte
  une structure lattente. Ou alors il faut la calculer avec une autre méthode et
  l'ajouté en covariable dans rda ([[cite:Forester_2017][see page 6]])
- Note taken on [2017-05-02 mar. 12:00] \\
  Faut que je comprenne le principe de cette methode ! A table.
- Note taken on [2017-05-02 mar. 10:20] \\
  Comment ca réagis sur mes simulations genérative. On l'ajoute dans les méthodes
  du papier ?
- State "TODO"       from              [2017-05-02 mar. 09:22]
:END:

Dans cite:Forester_2015 ils utilisent RDA pour trouver des locus outlier en
passant par un PCA de XB (dans le modèle G = XB + E). Après ils calculent des
pvaleur en ces locus plus précisement (avec un lm).

Je comprends que : 
- il n'y aura pas de correction pour la structure de populations
- c'est juste un moyen de ne pas passer par le controle du FDR
*** Sur une simulations

#+begin_src R :results output :exports both
  ## sampler data with lfmm generative model
  library(ThesisRpackage)
  s <- NormalSampler2(n = 100,
                      L = 1000,
                      K = 3,
                      prop.outlier = 0.02,
                      cs = c(0.6, 0.0, 0.0))
  dat <- sampl(s)

  ## run rda
  library(vegan)

  rda.res <- rda(dat$G ~ dat$X)
  names(rda.res)

#+end_src

#+RESULTS:
:  [1] "call"        "grand.total" "rowsum"      "colsum"      "tot.chi"    
:  [6] "pCCA"        "CCA"         "CA"          "method"      "inertia"    
: [11] "terms"       "terminfo"

#+begin_src R :results output graphics :file Rplots/RDA_1.png :exports both :width 600 :height 400
  plot(rda.res)
#+end_src

#+RESULTS:
[[file:Rplots/RDA_1.png]]

A quoi correspond les rouges et les autres ? C'est les indiv et les locus...

#+begin_src R :results output graphics :file Rplots/RDA_2.png :exports both :width 600 :height 400 
  library(tidyverse)

  toplot <- cbind(as.data.frame(rda.res$CA$v),
                  as.data.frame(rda.res$CCA$v))
  toplot <- toplot %>%
    mutate(index = 1:nrow(toplot),
           outlier = index %in% dat$outlier)

  ggplot(toplot, aes(x = RDA1, y = PC1, color = outlier)) +
    geom_point()
#+end_src

#+RESULTS:
[[file:Rplots/RDA_2.png]]

Je n'arrive pas a reproduire le graphe précédent.

MAIS on voit que RDA1 ne permet capte la variable lattente.

**** Si on utilise lfmm 

#+begin_src R :results output graphics :file Rplots/RDA_3.png :exports both :width 600 :height 400 
  ## run of lfmm ridge
  lfmm.ridge <- finalLfmmRdigeMethod(K = 3,lambda = 1e-1)
  lfmm.ridge <- run(lfmm.ridge, dat)

  gplot_stat(B = lfmm.ridge$B[1,], outlier = dat$outlier) +
    geom_point(aes(x = index, y = stat, color = outlier))
#+end_src

#+RESULTS:
[[file:Rplots/RDA_3.png]]

On arrive bien a avoir ceux qui sont vraiment associé a X et pas avec la
variable lattentes.

**** Si on utilise lm
#+begin_src R :results output graphics :file Rplots/RDA_4.png :exports both :width 600 :height 400 
  ## run of lfmm ridge
  lm.res <- finalLm()
  lm.res <- run(lm.res, dat)

  gplot_stat(B = lm.res$B[1,], outlier = dat$outlier) +
    geom_point(aes(x = index, y = stat, color = outlier))
#+end_src

#+RESULTS:
[[file:Rplots/RDA_4.png]]

C'est comparable a les loadings RDA1

** STARTED Validation numérique pour l'article "LFMM"             :3Article:
:LOGBOOK:
- Note taken on [2017-05-10 mer. 10:55] \\
  J'ai joué avec les datasets ([[file:ThesisRpackage/tests/testthat/test_3Article_ValidationNumerique.R::test_that("Play%20with%20experiment",%20{][ici]]), avec si outlier.prop < 0.05 on ne voit pas
  l'avantage de lfmm sur PCA+lm. alors que avec 0.05 c'est bien clair ! Je me
  demande si avec vraiment beaucoup d'indiv (donc beucoup de puissance) 0.05 c'est
  si aberrant ? Il faut que j'en parle avec OF. 
  
  Aussi, avec ce dataset il y a vraiment paut de structure (1 %), du coup si je
  baisse pas l'erreur la variance des estimateurs des effets sont du meme ordre
  que les B. Je peut prendre un dataset avec plus de structure. Ou plus d'indiv
  
  To be continued.
- Note taken on [2017-05-10 mer. 08:55] \\
  Si l'oracle n'a pas de bonne performance, on trouve n'imp ! C'est des simu trop
  dure pour dire quoi que ce soit !
CLOCK: [2017-05-05 ven. 13:03]--[2017-05-05 ven. 13:29] =>  0:26
- Note taken on [2017-05-05 ven. 10:56] \\
  Je vais travailler sur un dataset centré et normalisé !
CLOCK: [2017-05-05 ven. 10:48]--[2017-05-05 ven. 11:13] =>  0:25
CLOCK: [2017-05-05 ven. 09:47]--[2017-05-05 ven. 10:12] =>  0:25
- Note taken on [2017-05-03 mer. 18:10] \\
  J'en suis a sample les dataset et faire la svd sur la matrice STANDARDISED !!!!
- State "STARTED"    from "TODO"       [2017-05-03 mer. 09:49]
- State "TODO"       from              [2017-05-03 mer. 09:05]
:END:
*** Sample dataset
**** structure de population faible
On sample sur tout le 1000Genome et que les européens.
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  file.res <- Article3_ValidationNumerique_Sample(L = 5e5, only.EUR = TRUE,
                                                  dat.file = "~/Projects/Thesis/Data/1000Genomes/Phase3/Eu_Af_Afam.maf.05.rds")

#+end_src

#+begin_src R :results output graphics :file Rplots/faible_struct_pop_vps.png :exports both :width 600 :height 400 
  ## test and PCA
  file.res <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/ValidationNumerique_EU_L5e+05.G.rds"
  G <- readRDS(file.res)
  dim(G)
  anyNA(G)

  ## PCA
  svd.res <- svd(G, nu = 0, nv = 0)
  variances <- svd.res$d / sum(svd.res$d)
  ## plot
  pl <- qplot(x = seq_along(variances), y = variances, geom='line') +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  pl
#+end_src

#+RESULTS:
[[file:Rplots/faible_struct_pop_vps.png]]

On va prendre $K = 2$ variables latentes.

Var explained with 2 variables:
#+begin_src R :results output :exports both
  print(sum(variances[1:2]))
#+end_src

#+RESULTS:
: [1] 0.01235195


***** Choix de K pour les méthodes
Pour le moment on va prendre le K de la simulation.
***** Run on krak 
#+begin_src R :results output :exports both
  require(ThesisRpackage)
  G.file <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/ValidationNumerique_EU_L5e+05.G.rds"

  exp <- Article3_MethodComparison(G.file,
                                   outlier.props = 0.0005,
                                   n = NULL, L = 10000,
                                   K = 2,
                                   K.method = 2,
                                   cs = c(0.1, 0.2, 0.6, 0.8, 1.0),
                                   cs.sum = TRUE,
                                   sd.V.rho = 2, 
                                   nb.rep = 5,
                                   fast.only = TRUE,
                                   cluster.nb = 20,
                                   save = TRUE, bypass = FALSE)

  Article3_MethodComparison_plot_relative_diff_AUC(exp)
#+end_src
**** structure de population forte
On sample sur tout le 1000Genome et que les européens.
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  file.res <- Article3_ValidationNumerique_Sample(L = 5e5, only.EUR = FALSE,
                                                  dat.file = "~/Projects/Thesis/Data/1000Genomes/Phase3/Eu_Af_Afam.maf.05.rds")

#+end_src

On va pendre $K = 4$.
#+begin_src R :results output graphics :file Rplots/forte_struct_pop_vps.png :exports both :width 600 :height 400 
  ## test and PCA
  file.res <- "~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/ValidationNumerique_ALL_L5e+05.G.rds"
  G <- readRDS(file.res)
  dim(G)
  anyNA(G)

  ## PCA
  svd.res <- svd(G, nu = 0, nv = 0)
  variances <- svd.res$d / sum(svd.res$d)
  ## plot
  pl <- qplot(x = seq_along(variances), y = variances, geom='line') +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  pl
#+end_src

#+RESULTS:
[[file:Rplots/forte_struct_pop_vps.png]]

Var explained with 4 variables:
#+begin_src R :results output :exports both
  print(sum(variances[1:2]))
  print(sum(variances[1:4]))
#+end_src

#+RESULTS:
: [1] 0.02006896
: [1] 0.02561421



** Dataset
How dataset in ./Data/ was generated. Some script and urls...
*** ./Data/SSMPG2015/ 
Dataset simulated by Katie Lotterhos for the school SSMPG2015
*** ./Data/MathieuGautier/
Dataset used in *Genome scan methods against more complex models: when and how much should we trust them?* of piere de villemereuil et al.
**** TODO Convert 
.csv into .RData
**** =mec12705-sup-0002-Pythonscripts/=
Python script that generated dataset 
**** Monogenic
I find this in an older .Rmd in my first LFMM project of 2016
#+BEGIN_SRC R
 outlier = c(546) # for monogenic
#+END_SRC

**** Polygenic
I find this in an older .Rmd in my first LFMM project of 2016
#+BEGIN_SRC R 
 outlier = c(2793,1850,583,4083,3349,860,4785,706,947,939,1819,925,403,2867,2897,97,3102,2618,708,1190,2471,1533,3924,2395,2690,2926,1511,668,4826,4755,638,4148,1777,1869,2252,4326,397,3416,3171,2451,1233,2055,3013,3202,1055,3484,2984,2145,4547,4831) + 1
#+END_SRC
*** ./Data/AthalianaGegMapLines/
- Data download from: http://bergelson.uchicago.edu/?page_id=790
- [[http://bergelson.uchicago.edu/wp-content/uploads/2015/04/call_method_75.tar.gz][download the data]]
  There are data I used in TESS3 second article
  
*** ./Data/1000Genomes/
**** ./Data/1000Genomes/Phase3Chrm22/
Phase 3 version of the 1000 genome, only the chromosom 22. I ddl the vcf
file [[ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/][here]]
- ddl file: 
  #+BEGIN_SRC bash
     curl -O ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
     curl -O ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel
  #+END_SRC
    
  - ddl all chromosom:
    #+BEGIN_SRC R
      ids <- 1:22
      for (i in ids) {
        url <- paste0("ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr", i, ".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz")
        system(paste("curl -O",url))
      }
    #+END_SRC

  - zip and unzip
    #+BEGIN_SRC bash
    gzip ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
    gzip ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf     
    #+END_SRC
***** Eu_Af_Afam.maf.05.rds

A dataset with only European, African and Aro-american population. We also fiter
maf at 5%.

#+begin_src R :results output :exports both
  ## data set with African European and AfroAmerican

  ## libs
  library(ThesisRpackage)
  library(tidyverse)
  library(crayon)
  options(ThesisRpackage.debug = "TRUE")

  ## read indiv informations
  indiv <- read_delim("./integrated_call_samples_v3.20130502.ALL.panel",
                      delim = "\t",
                      skip = 1,
                      col_names = FALSE)
  names(indiv) <- c("sample", "pop", "super_pop","gender")

  unique(indiv %>% select(super_pop))

  Eu <- c("TSI", "GBR")
  Af <- c("ASW")
  Afam <- c("YRI", "LWK")

  ## indiv
  indiv.index <- which(indiv$pop %in% c(Eu, Af, Afam))


  ## read data
  maf.threshold <- 0.05
  ploidy <- 2
  ### list files
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.maf.05.rds$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)


  dat <- list()
  for (f in files) {
    cat(green(paste0("== reading ",f,"\n")))

    ## read file
    dat.aux <- readRDS(f)

    ## filter indiv
    dat.aux$G <- dat.aux$G[indiv.index,]

    ## filter maf
    maf <- apply(dat.aux$G, 2, function(locus) {p <- mean(locus, na.rm = TRUE) / ploidy; min(p, 1 - p)})
    cat(green(paste0("Removing ", mean(maf <= maf.threshold),"% loci\n")))
    dat.aux$G <- dat.aux$G[,maf > maf.threshold, drop = FALSE]
    dat.aux$snps.info <- dat.aux$snps.info[maf > maf.threshold,]


    ## bind
    dat$G <- cbind(dat$G, dat.aux$G)
    dat$snps.info <- rbind(dat$snps.info, dat.aux$snps.info)

    cat(green(paste0("== ncol ",ncol(dat$G),"\n")))
  }

  ## subsample ?

  ## coord of indiv
  dat$indiv <- indiv[indiv.index,]
  dat$coord <- matrix(NA, nrow = nrow(dat$indiv), ncol = 2)

  ## map: https://www.coordonnees-gps.fr/
  ## pops: http://www.internationalgenome.org/category/population/
  aux <- function(dat, pop, coord) {
    aux.indiv <- dat$indiv$pop == pop
    dat$coord[aux.indiv,] <- matrix(coord,sum(aux.indiv),2, byrow = TRUE)
    dat
  }
  ## Toscani in Italia
  dat <- aux(dat, "TSI", c(11.25581360000001, 43.7695604)) ## florance
  ## British in England and Scotland
  dat <- aux(dat, "GBR", c(-2.2426305000000184, 53.4807593)) ## manchester
  ## Americans of African Ancestry in SW USA
  dat <- aux(dat, "ASW", c(-122.41941550000001, 37.7749295)) ## san francisco
  ## Yoruba in Ibadan, Nigeria
  dat <- aux(dat, "YRI", c(3.947039600000039,7.377535500000001)) ## Idaban
  ## Luhya in Webuye, Kenya
  dat <- aux(dat, "LWK", c(34.77960299999995, 0.5992059)) ## Webuye

  ## check
  assertthat::assert_that(mean(rownames(dat$G) == dat$indiv$sample) == 1)

  ## compute a W matrix
  dat$dist.matrix <- geosphere::distm(dat$coord) ## geodesic on hearth
  sigma <- mean(dat$dist.matrix) * 0.05 ## tess3 default param
  dat$W <- exp( -dat$dist.matrix ^ 2 / sigma / sigma)

  saveRDS(dat, "Eu_Af_Afam.maf.05.rds")

#+end_src
***** FromVcfToRds

Conversion of =.vcf= into R data format =.R=.

#+begin_src R :results output :exports both
  # libs
  library(ThesisRpackage)
  library(tidyverse)
  library(crayon)
  options(ThesisRpackage.debug = "TRUE")

  ## We filter maf to 0.05%
  maf.threshold <- 0.05

  ### list files
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)


  for (f in files) {
    cat(green(paste0("== reading ",f,"\n")))

    ## read file
    dat.aux <- read_vcf(f = f, maf.threshold = maf.threshold, block.size = 1e5)

    ### save in rds format
    saveRDS(dat.aux, sub("\\.vcf$", ".maf.05.rds", f))
    rm(dat.aux)
    gc()
  }
#+end_src
***** Eu_Af_Afam_to_geno

Create a =.geno= format file.

#+begin_src R :results output :exports both
  dat <- readRDS("~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.maf.05.rds")
  X <- t(dat$G)
  rm(dat)
  gc()
  file.remove("~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.maf.05.geno")
  chunks <- split(1:nrow(X), ceiling(1:nrow(X) / 5e5))
  for (c in chunks) {
    write.table(X[c,], file = "~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.maf.05.geno",
                sep = "",
                row.names = FALSE,
                col.names = FALSE, append = TRUE)
  }

  ## write G.geno
  dat <- readRDS("~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.maf.05.rds")
  dat$G.geno <- "~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.maf.05.geno"
  saveRDS(dat, "~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.maf.05.rds")
#+end_src
***** European_Chrm22

A dataset with only European and chromosome 22, maf filter to 5%.

#+begin_src R :results output :exports both
  # We want to extract a snips matrix with only european

  # libs
  library(tidyverse)

  # read indiv informations
  indiv <- read_delim("./integrated_call_samples_v3.20130502.ALL.panel",
                      delim = "\t",
                      skip = 1,
                      col_names = FALSE)

  names(indiv) <- c("sample", "pop", "super_pop","gender")

  unique(indiv %>% select(super_pop))
  unique(indiv[indiv$super_pop == "EUR","pop"])
  EUR.index <- which(indiv$super_pop == "EUR")
  length(EUR.index)


  ## read dataset
  dat <- readRDS("ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.maf.05.rds")

  # keep only europe
  # geno.EUR <- matrix(as.raw(geno[EUR.index,]),
  #                    nrow = length(EUR.index),
  #                    ncol = ncol(geno))
  G.EUR <- dat$G[EUR.index,]

  # Filter
  ## maf > 0.05 %
  maf <- apply(G.EUR, 2, function(locus) {p <- mean(locus) / 2; min(p, 1 - p)})
  maf.threshold <- 0.05
  mean(maf <= maf.threshold)
  filtered.index <- (maf > maf.threshold)
  G.EUR.filtered <- G.EUR[,filtered.index]

  # names con and row
  ## already set
  #rownames(G.EUR.filtered) <- indiv$sample[EUR.index]
  #colnames(G.EUR.filtered) <- snps.info$X3[filtered.index]

  # save
  saveRDS(G.EUR.filtered, file = "European_Chrm22.maf.05.rds")
#+end_src
*** ./Data/GSE42861/
Données trouvé ici:
https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE42861
Utilisé dans ce papier cite:Rahmani_2016.
**** Retrieve dataset
C'est le fichier qu'olivier a utilisé pour pour ddl les données. Ca marche
pas chez moi...
#+BEGIN_SRC R
       ## try http:// if https:// URLs are not supported
       source("https://bioconductor.org/biocLite.R")
       biocLite("Biobase")

       ## try http:// if https:// URLs are not supported
       source("https://bioconductor.org/biocLite.R")
       biocLite("GEOquery")


       require(Biobase)
       require(GEOquery)

       ## get le jeu de données dans le format biobase
       obj861 <- getGEO("GSE42861",GSEMatrix = T)

       ## extrait les phenotypes (factors)
       disease.state <- pData(phenoData(obj861[[1]]))[,11]

       ## extrait les covariables (subject, age, gender, smocking.status)
       ## age est converti en numeric

       subject <- pData(phenoData(obj861[[1]]))[,12]

       age.f <- pData(phenoData(obj861[[1]]))[,13]
       write.table(file = "age.txt", as.character(age.f))
       age <- as.numeric(read.table(file = "age.txt")[,1])


       gender <- pData(phenoData(obj861[[1]]))[,14]

       smocking.status <- pData(phenoData(obj861[[1]]))[,15]

       ## download la matrice d'expression. Attention elle est transposée (individus en colonnes)
       expmat861 <- exprs(obj861[[1]])
#+END_SRC
    
**** ./GSE42861/exp861.RData
C'est les variables defs dans file:./GSE42861/script_methylome.R. Output par
olivier.
**** Format data
    
#+BEGIN_SRC R
       ## load data send by OF
       load("exp861.RData")
       ls()

       ## save G and X
       G <- t(expmat861)
       ### G
       rm(expmat861)
       dim(G)
       saveRDS(G, "betanormalized_metylationlvl.rds")

       ## we scale and center data
       X <- data.frame(disease.state = as.numeric(disease.state),
                       age = as.numeric(age),
                       gender = as.numeric(gender),
                       smocking.status = as.numeric(smocking.status))
       X <- scale(X)
       X <- as.matrix(X)
       rownames(X) <- rownames(G)
       saveRDS(X, "X.rds")

       ## downsample for test
       sample.row <- sample.int(nrow(G), size = 100)
       sample.col <- sample.int(ncol(G), size = 2000)
       saveRDS(G[sample.row, sample.col], "betanormalized_metylationlvl.sample.rds")
       saveRDS(X[sample.row,], "X.sample.rds")

#+END_SRC

**** Data pre-processing
CLOSED: [2017-02-22 mer. 10:54]
Goal: repruduce data processing of paper cite:Zou_2014 
    
#+BEGIN_SRC R
       setwd("~/Projects/Thesis/Data/GSE42861/")
       X <- readRDS("X.rds")
       G <- readRDS("betanormalized_metylationlvl.rds")

       ## filter maf !
       maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
       out.index <- which(maf <= 0.2)

       G.filtered <- G[,-out.index]
       dim(G.filtered)

       saveRDS(G.filtered, "betanormalized_metylationlvl.filtered.rds")

       ## linear reg res
       library(ThesisRpackage)
       ## G.filtered <- readRDS("betanormalized_metylationlvl.filtered.rds")
       lm.method <- ClassicLinearMethod()
       dat <- list(G = G.filtered, X = X[,-1])

       lm.method <- fit(lm.method, dat)
       saveRDS(lm.method$epsilon, "betanormalized_metylationlvl.filtered.LMresidu.rds")

       ## subsample
       ## G <- readRDS("betanormalized_metylationlvl.filtered.LMresidu.rds")
       G <- lm.method$epsilon
       row.sample <- sample.int(nrow(G), 100)
       col.sample <- sample.int(ncol(G), 1000)
       X.sample <- X[row.sample,,drop = FALSE]
       G.sample <- G[row.sample,col.sample]
       sds <- apply(G.sample, 2, sd)
       mean(sds == 0)
       saveRDS(G.sample, "betanormalized_metylationlvl.filtered.LMresidu.sample.rds")
       saveRDS(X.sample, "X.sample.rds")
#+END_SRC

*** ./Data/refractorDemo/
data found here: https://github.com/cozygene/refactor. There are data used in
the demo of refractor method.
*** ./Data/Hgdp_Li/
Hgdp data used in cite:frichot13_testin_assoc_between_loci_envir anylisis. I
I found this dataset on patator.imag.fr.
*** [[file:Data/gwas_riz][Gwas_Riz]]
Données de riz.
*** [[file:Data/Simons][Simons]]
- [[https://www.simonsfoundation.org/life-sciences/simons-genome-diversity-project-dataset/][website]]
***** to donwload the dataset
I copy the docx file found [[http://simonsfoundation.s3.amazonaws.com/share/SCDA/datasets/2014_11_12/StepstodownloadtheSGDPdataset_v4.docx][here]]:
****** Steps to download the SGDP dataset:	
Get a personal grid x509 certificate to download data using GridFTP from
Fermi Lab. To get a personal certificate follow the instructions from this
link: https://fermi.service-now.com/kb_view.do?sysparm_article=KB0010815
and use the VO as: SCDA Alternatively if you are from an institute
included in cilogon (other than google) you can use https://cilogon.org
      
Once you get your certificate follow the instructions in the email and
upload it to your browser, and send the subject (which will look something
like /DC=org/DC=cilogon/C=US/O=Google/CN=User Name A16321) and mail it to
ifisk@simonsfoundation.org

      
Follow instructions from the below link if you will be using Globus tools
for submitting grid jobs from Linux/UNIX:
https://fermi.service-now.com/kb_view.do?sysparm_article=KB0010815. Make
sure you do this step as soon as you get your certificate and use the same
browser window. Note: If you wait too long the certificate is no longer in
the PKCS#12 format that you need for this step.

Install osg-ca-certs and osg-client on your machine; will probably need
help from the Systems group to do this. The instructions for this are at:
https://twiki.grid.iu.edu/bin/view/Documentation/Release3/InstallOSGClient#6_2_Stopping_and_Disabling_Servi
Note for regular users without root access there is an OSG tarball option:
https://twiki.grid.iu.edu/bin/view/Documentation/Release3/InstallOSGClientTarball

Send the certificate to Yujun Wu (yujun@fnal.gov) or Dmitry O Litvintsev
(litvinse@fnal.gov) to ensure that things are set up properly.
 
Run the following command: . /opt/globus-5.2.5/etc/globus-user-env.sh, to
ensure you are running the correct version of globus

Run the command grid-proxy-init -valid 168:0 (This will allow keep the
proxy active for a week; after which you will need to renew it again)

Test if the download is working using the following command:
“globus-url-copy -vb  -dbg –nodcau
gsiftp://fndca1.fnal.gov:2811//temp/testfnal.txt  file:////tmp/testfile”


Copy a file called COMPLETE_FILE_LISTING in your folder using the below
command: globus-url-copy gsiftp://fndca1.fnal.gov/COMPLETE_FILE_LISTING
file:////`pwd`/COMPLETE_FILE_LISTING

Copy the script complete.sh (see below) in the same folder as where you
have the COMPLETE_FILE_LISTING file; and run ./complete.sh to copy all the
files. Script: complete.sh: #!/bin/bash


cat COMPLETE_FILE_LISTING | grep SGDP | while read path size cksum do
#  echo "globus-url-copy -c gsiftp://fndca1.fnal.gov${path} file:////`pwd`/${path}"
globus-url-copy -c -vb -nodcau -cd -bs 2000000 -sync
gsiftp://fndca1.fnal.gov${path} file:////`pwd`/${path} done
 

Once you have succeeded, you will find the transfers are much faster if
parallel streams are enabled. You may need to speak with the local network
administrator to open ports in the firewall

Two environment variables need to be set export
GLOBUS_TCP_PORT_RANGE=50000,50100 export
GLOBUS_HOSTNAME=Name_of_the_external_IP


And ports 50000-50100 need to be open in the firewall

Then add “-p 10” to the list of options in the globus-url-copy command
above
*** [[file:Data/1001Genomes][1001Genomes]]
- [[http://1001genomes.org/index.html][Website]]
- ddl data: 
  #+BEGIN_SRC bash
  curl -O http://1001genomes.org/data/GMI-MPI/releases/v3.1/SNP_matrix_imputed_hdf5/1001_SNP_MATRIX.tar.gz
  #+END_SRC
**** From h5f to rds
Very long script....
#+begin_src python :results output :exports both
       # from http://stackoverflow.com/questions/28170623/how-to-read-hdf5-files-in-python
       import h5py
       import numpy as np

       filename = "./imputed_snps_binary.hdf5"
       f = h5py.File(filename, 'r')

       # List all groups
       print("Keys: %s" % f.keys())
    
       # Get the data
       acc = f['accessions'][()]
       positions = f['positions'][()]
       # snps = f['snps'][()] ## dangerous

       ## filter maf
       maf_threshold = 0.05
       snps = f['snps']
       L = snps.shape[0]
       maf = np.zeros(L)
       snps_matrix = snps[:,:]
       for i in range(L):
           p = np.mean(snps_matrix[i,:])
           maf[i] = min(p, 1-p)

       np.mean(maf > maf_threshold)
       np.sum(maf > maf_threshold)

       ## max and min ?
       snps.min() ## 0
       snps.max() ## 1


       ## write the whole dataset

       np.savetxt("sample.txt",snps_matrix[1:10,1:10], "%u")
       np.savetxt("snps_matrix.txt",snps_matrix, "%u")

       np.savetxt("snps_matrix.maf05.txt",snps_matrix[maf > maf_threshold,:], "%u")

#+end_src
    

#+begin_src R :results output :session *R* :exports both
       ## reading snps matrix

       library(tidyverse)
       snps.matrix <- read_delim("~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/sample.txt",
                                 delim = " ", col_types = cols(.default = col_logical()),
                                 col_names = FALSE)
       data.matrix(snps.matrix)

       dat <- list()
       ## read by chunck... ugly
       L = 10709949
       # L = 9
       n = 1135
       # n = 9
       step = seq.int(1, L, by = 500000)[-1]
       dat$snps.matrix = NULL ##
       skip = 0
       for (s in step) {
         print(s)
         n_max <- s - skip
         aux <- data.matrix(read_delim("~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/snps_matrix.txt",
                           delim = " ", col_types = cols(.default = col_integer()),
                           col_names = FALSE, skip = skip, n_max = n_max))
         dat$snps.matrix <- rbind(dat$snps.matrix, matrix(as.raw(aux), nrow(aux), ncol(aux)))
         skip <- skip + n_max
       }
       ## I miss the end...
       n_max <- L - skip
       aux <- data.matrix(read_delim("~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/snps_matrix.txt",
                                     delim = " ", col_types = cols(.default = col_integer()),
                                     col_names = FALSE, skip = skip, n_max = n_max))
       dat$snps.matrix <- rbind(dat$snps.matrix, matrix(as.raw(aux), nrow(aux), ncol(aux)))


       assertthat::assert_that(nrow(dat$snps.matrix) == L)
       assertthat::assert_that(ncol(dat$snps.matrix) == n)

       library(rhdf5)
       file.h5 <- "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/imputed_snps_binary.hdf5"
       h5ls(file.h5)

       ## col.names
       acc <- h5read(file.h5,"accessions")
       colnames(dat$snps.matrix) <- acc

       ## row.names
       pos <- h5read(file.h5,"positions")
       rownames(dat$snps.matrix) <- pos

       ## retrieve coord
       dat$accessions <- read_delim("~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/accessions.txt", delim = "\t")



       ## Save
       saveRDS(dat, "snps_matrix.rds")

       ## filter maf
       library(crayon)
       maf.threshold <- 0.05
       maf <- apply(dat$snps.matrix, 1, function(r) {p <- mean(as.integer(r)); min(p, 1 - p)})
       cat(green(paste0("Removing ", mean(maf <= maf.threshold),"% loci\n")))
       dat.maf <- list()
       dat.maf$accessions <- dat$accessions
       dat.maf$maf.threshold <- maf.threshold
       dat.maf$G <- t(dat$snps.matrix[maf > maf.threshold,])
       rm(dat)
       gc()
       rnames <- rownames(dat.maf$G)
       cnames <- colnames(dat.maf$G)
       dat.maf$G <- matrix(as.integer(dat.maf$G), nrow(dat.maf$G), ncol(dat.maf$G))
       colnames(dat.maf$G) <- cnames
       rownames(dat.maf$G) <- rnames

       assertthat::assert_that(nrow(dat.maf$G) == n)
       assertthat::assert_that(ncol(dat.maf$G) == 1783980)
       assertthat::assert_that(nrow(dat.maf$accession) == nrow(dat.maf$G))

       saveRDS(dat.maf, "snps_matrix_maf05.rds")


#+end_src
**** Subsample
#+begin_src R :results output :session *R* :exports both
       dat <- readRDS("~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/snps_matrix_maf05.rds")
       n <- nrow(dat$G)
       L <- ncol(dat$G)
       G.sample <- dat$G[,sample.int(L,100000)]
       saveRDS(G.sample, "~/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/snps_matrix_maf05.sample.rds")
#+end_src
**** OF GWAS simulations
#+begin_src R :results output :session *R* :exports both
       setwd("/home/cayek/Projects/Thesis/Data/1001Genomes/1001_SNP_MATRIX/")
       library(raster)
       library(LEA)

       load("/home/francois/Athaliana_1001G/athaliana.Rdata")
       attach(athaliana)

       climate = getData('worldclim', var='bio', res = 2.5)
       bio = extract(climate, y = as.matrix(metadata[,6:5]))
       pc.bio = prcomp(bio,scale = T)
       env = pc.bio$x[,1]

       write.geno(R = G, output = "G_OF_filtered.geno")
       pc = pca("G_OF_filtered.geno", K = 995)
       plot(pc, lwd=5, col="red",xlab=("PCs"),ylab="eigen")

       K = 40
       sigma = sqrt( sum(pc$sdev^2) - sum(pc$sdev[1:K]^2) )
       base.effect = sqrt( sum(pc$sdev^2) )

       ##parametres de la simu:
       J = 10
       beta = 6*base.effect
       delta = 0.3*base.effect ##G X E

       ## definition des SNPs ref
       window = 201

       lch = 0

       ref.set = NULL

       for (i in 1:5){
         chromosome = which(chr == i)
         set = seq(lch + 1+(window-1)/2, lch + length(chromosome) , by = window )
         ref.set = c(ref.set, set)
         lch = lch + length(chromosome)
       }
       loc.J = sort(sample(ref.set, J))
       table(chr[loc.J])

       ##simu du phenotype
       x = beta*rowSums(G[,loc.J]) +
         delta*rowSums(G[,loc.J])*env +
         rowSums(pc$projections[,1:K]) + rnorm(995, sd = sigma)

       cor(x, G[,loc.J])

       ##associations:
       r = as.numeric( cor(x, G) )
       sum( loc.J %in% which(r > 0.3) )

       ## save into RDS
       saveRDS(G,"G_OF_filtered.rds")
       sample.loci <- sample.int(ncol(G), 50000)
       saveRDS(G[,sample.loci],"G_OF_filtered.sample.rds")


       ## save chrm
       saveRDS(chr, "G_OF_filtered.chrm.rds")
       saveRDS(chr[sample.loci], "G_OF_filtered.sample.chrm.rds")



       ## save coord
       coord <- as.matrix(metadata[,c(6,5)])
       saveRDS(coord, "G_OF_filtered.coord.rds")

       detach(athaliana)
#+end_src

** STARTED Étude de [[#Liu_2013][GSE42861]]                                      :3Article:
:LOGBOOK:
- Note taken on [2017-05-10 mer. 16:58] \\
  Il faut que je trouve les locus interessant indentifié dans les papiers qui ont
  bosser sur GSE42861 et les mettre dans les outlier.
- State "STARTED"    from "TODO"       [2017-05-10 mer. 16:58]
- State "TODO"       from              [2017-05-10 mer. 16:58]
:END:
*** Data pre-processing
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  X <- readRDS("~/Projects/Thesis/Data/GSE42861/X.rds")
  G <- readRDS("~/Projects/Thesis/Data/GSE42861/betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G <- G[,-out.index]
  dim(G)

  ## check variable without variance
  G <- Preprocessing_filter_sd(G)
  dim(G)

  ## scale and center
  G <- scale(G)

  ## save
  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/G.rds")
  saveRDS(X, "~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/X.rds")
#+end_src
*** TODO Interesting loci 
:LOGBOOK:
- Note taken on [2017-05-11 jeu. 11:20] \\
  Il me manque 1 cadidat dans G, pk ?
- State "TODO"       from              [2017-05-11 jeu. 11:20]
:END:
Les loci relevé par cite:Rahmani_2016
#+begin_src R :results output :exports both
  rahmani.loci <- c("cg05428452",
                     "cg07839457",
                     "cg16411857")
#+end_src
Ceux de cite:Zou_2014
#+begin_src R :results output :exports both
  Zou.loci <- c("cg05428452",
                "g07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
#+end_src

On retrouve les 3 mêmes. On va prend cela  
#+begin_src R :results output :exports both
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/G.rds")
  Zou.loci <- c("cg05428452",
                  "g07839457",
                  "cg16411857",
                  "cg25372449",
                  "cg20821042")
  candidates <- which(colnames(dat$G) %in% Zou.loci)
  saveRDS(candidates, "~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+end_src

*** Choix des parametres
**** PCA
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## we keep only disease.state
  X <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/X.rds")
  X <- X[,1]
  head(X)

  s <- TrueSampler(G.file = "~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/G.rds",
                   X.file = X,
                   outlier.file = NULL,
                   n = NULL,
                   L = NULL)
  expr <- PCAExperiment(s = s,
                        description = "GSE42861 PCA")
  expr <- runExperiment(expr)
  dumpExperiment(expr)
#+end_src

#+begin_src R :results output graphics :file Rplots/GSE42861_pca.png :exports both :width 600 :height 400 
  expr <- retrieveExperiment(109)
  variances <- expr$res.df$sdev / sum(expr$res.df$sdev)
  ## plot
  pl <- qplot(x = seq_along(variances), y = variances, geom='line') +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  pl
#+end_src

#+RESULTS:
[[file:Rplots/GSE42861_pca.png]]

**** lfmm ridge
*** Run des méthodes
**** lm
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  m <- finalLm()
  expr <- Article3_GSE42861_run_method(m)

#+end_src

#+RESULTS:
[[./Rplots/GSE42861_qqplot_lm.png]]
**** PCA
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  s <- Article3_GSE42861_sampler()
  dat <- sampl(s)
  m <- finalPcaLm(K = 50)
  m <- run(m, dat)

  outlier <- which(colnames(dat$G) %in% rahmani.loci)

  pl <- qqplott(m, outlier)
  pl


  m.cal <- calibrate(m)
  x11()
  pl <- qqplott(m.cal, outlier)
  pl

  save_plot_timc_bcm_15(pl, "GSE42861_qqplot_PcaLm.png")
#+end_src

#+RESULTS:
[[./Rplots/GSE42861_qqplot_PcaLm.png]]
**** lfmm lasso
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  s <- Article3_GSE42861_sampler()
  dat <- sampl(s)
  m <- finalLfmmLassoMethod(K = 30, sparse.prop = 0.01)
  m <- run(m, dat)

  outlier <- which(colnames(dat$G) %in% rahmani.loci)

  pl <- qqplott(m, outlier)
  pl


  m <- calibrate(m)
  pl <- qqplott(m, outlier)
  pl

  save_plot_timc_bcm_15(pl, "GSE42861_qqplot_PcaLm.png")
#+end_src

#+RESULTS:
**** lfmm ridge
#+begin_src R :results output :exports both

#+end_src
* Articles
** 2014 - Advantages and Pitfalls in the Application of Mixed-Model  Association Methods :LFMM:
:PROPERTIES:
:Custom_ID: yang14_advan_pitfal_applic_mixed_model_assoc_method
:AUTHOR:   Jian Yang, Noah A Zaitlen, Michael E Goddard, Peter M, Visscher \& Alkes L Price
:JOURNAL:  Nature Genetics
:YEAR:     2014
:VOLUME:   46
:PAGES:    100-106
:DOI:      10.1038/ng.2876
:URL:      https://doi.org/10.1038/ng.2876
:END:

cite:yang14_advan_pitfal_applic_mixed_model_assoc_method
*** Abstract
C'est un article sur les mixed-linear model pour les associations, en
particulier il s'interesse au GWAS (donc plutot phénotype ~ génotype). Ils
vont donner des recommendation sur l'utilisation des MLMA methods.

*** Mixed-model association methods prevent false positive associations and increase power
ok classic quand il y a de la structure d'échatillonage (structure de pop,
parenté etc) elle est capté par la partie aléatoire le reste est
incomprehenssible ....

*** Reducing the computational cost of mixed-model association analysis
il y a des améliorations computationnelles qui ont été faite et qui permette de passer a l'echelle.

*** Pitfall: loss in power when the candidate marker is included in the GRM (genetic relationship matrix)
C'est ce qui avait été constaté dans l'article de LFMM. La puissance diminue
quand les merker candidats sont expliqué à la fois par les effets fixes et les
effets aléatoires Après je crois qu'ils font des simultations numérique pour
montrer ca.
   
*** Pitfall: using a small subset of markers in the GRM can compromise correction for stratification
Tout est dans le titre... rien de nouveau.

*** Pitfall: loss of power in ascertained case-control studies
Les phénotype ne sont pas observé au hasard! surtout dans les cas controles, on
a pas pris des gens au hasard, il y a surepresentation des malades evidament !!
Mais ca fait quoi ? OK, ok, en fait c'est dans les étude ascertained qu'il y a
un problème, il y a une perte de puissance. Ca me parait logique puisque on a
des echantillion petit de malade par exemple. Apparament il y a des méthode qui
corrige ca. Mais si on en detecte moins c'est par ce que a un taux d'erreur fixe
la méthode ne peut rien dire !! mais c'est normal, il y a moins d'info. On va
voir les simulations.
**** Tableau 3: file:./org-ref-pdfs/yang14_advan_pitfal_applic_mixed_model_assoc_method.pdf::4
Ok il report les pvalues des des marker outlier... 
***** Rmk: 
On parle de pvaleur mais on enonce jamais les hypothèses. C'est implicite que
$H0_j$ : le marker j est neutre $H1_j$ : le marker j est associé au phénotype
Biensur la modélisation n'est pas la même dans le modèle linéaire et MLMe. Mais
le raisonnement marche quand même c'est deux modèle sont vu comme des boites et
la pvalues c'est la probabilité que sous H0 on observe un truc plus atypique,
donc pvalue plus faible veux dire moins de puissance. Mais bon je suis pret a
parier que les pvaleur de tous le monde sont plus faible dans le cas de MLMe et
que le problème c'est juste l'application des teste d'hypothèse classic !! Je
suis persuader qu'il faut quelqueshose de plus robuste pour les test
d'hypothèse, avec moins de modèle et plus de logique ;)...
     

** 2015 - A Practical Guide To Environmental Association Analysis in  Landscape Genomics :LFMM:EAAReviewAndComparison:
:PROPERTIES:
:Custom_ID: rellstab15_pract_guide_to_envir_assoc
:AUTHOR:   Christian Rellstab, Felix Gugerli, Andrew Eckert, , Angela Hancock \& Rolf Holderegger
:JOURNAL:  Molecular Ecology
:YEAR:     2015
:VOLUME:   24
:PAGES:    4348-4370
:DOI:      10.1111/mec.13322
:URL:      https://doi.org/10.1111/mec.13322
:END:

cite:rellstab15_pract_guide_to_envir_assoc
*** Abstract
bon il propose de faire un tableaux des méthodess d'association env, c'est parfait 
pour lister les concurents à LFMM et voir ou sont les manques :D 
*** The emergence of landscape genomics
Il distbigue deux approches pour identifier les genes codant pour des phénotypes
héritables : 
- top-down: GWAS and QTL (quantitative trait locus: https://en.wikipedia.org/wiki/Quantitative_trait_locus) mapping. 
  On mesure un phénotype et on le relie à un QTL ou un locus.
- bottom-up: population and landscape genomics. On utilise l'information génétique
  pour detecter les gènes sous selection (donc codant pour un phénotype impliqué dans un 
  prcessus de selection)
***** selective sweep                                            :definition:

https://en.wikipedia.org/wiki/Selective_sweep
Bon deja sweep ca veux dire balayage. C'est l'idée d'une propagation dans la population 
d'un allele. Et dans ce cas c'est a cause d'une selection
- hard selective sweep: dés que l'allele adaptatif arrive dans la généalogie il se 
  propage très vite
- soft selective sweep: la mutation neutre était déja présente dans la populations et 
  elle devient adaptative a cause d'un changement de l'environnement.

***** Box 1 file:./LFMM/Method/Bio/article_Rellstab_2015.pdf::2
<<EAA_schemas>>
[[./biblioImages/box1.jpg]]
 
***** what is next
Notations in the pdf.
Il y a un tableau de méthodes pour l'EAA
C'est pas un article de comparaison du coup il n'y a pas de dataset ni
d'experiences. On va aller voir les autre article qu'il cite.

** 2016 - Methods to study local adaptation and application to the context of high elevation in the Alpine plant Arabis alpina :LFMM:
:PROPERTIES:
:Custom_ID: thesis_Devillemereuil_2016
:AUTHOR:   Villemereuil
:JOURNAL:
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:
:URL:      https://tel.archives-ouvertes.fr/tel-01322336
:END:

cite:thesis_Devillemereuil_2016
This the thesis of piere devillemereuil.

*** Introduction Generale
**** 2.3 Méthodologie statistique - paragraphe 1 file:./Thesis/thesis_Devillemereuil_2016.pdf::24
Il fait la distinction entre deux types de scan genomique, le premier on ne sait pas si c'est adaptatif
le deuxieme on le sais.
Mais je suis pas sur de comprendre, ma disctinction: Genome = X (comme dans lfmm)
ou X = G (comme dans les GWAS). 
     
*** Chapitre 1 : Étude et comparaison des méthodes de scan génomique pour détecter la sélection file:./Thesis/thesis_Devillemereuil_2016.pdf::29
**** 1 Le problème des scan génomique file:./Thesis/thesis_Devillemereuil_2016.pdf::30
Il discute du proèblème de définition de l'hypothèse nulle. Et du fait qu'il
faut prendre en compte la structure de pop !! Interessant, derniere ligne,
o, est passé a la problèmatique des tests multiples ! avant on ne testait
que 1 seul locus, maintenant on en a la pelle.
***** Remark pour ma thèse                                          :MaThese:
mettre l'accent sur cette transition, on a de plus en plus de données =>
test multiples. Eric n'a pas l'air dans parler.
**** 2.3 Le point commun entre ces nouvelles méthodes file:./Thesis/thesis_Devillemereuil_2016.pdf::32
Il identifie es hypothèses générales des méthodes de detection de la
selection du type de LFMM cad 
- beacoups de locus neutre
- un modèle neutre souple pour s'adapter a toutes les situations
  Sont premier papier va consister a comparer les méthodes sur des simultations.
*** Article 1: Genome scan methods against more complex models: when and how much should we trust them?
C'est l'article que j'ai déja parcouru... avec les resultats qui plantent
tous le mondes ...
**** Fig A16 file:./Thesis/thesis_Devillemereuil_2016.pdf::46
Une reg avec une fausse variable, je comprends son histoire de spurious
power... Par contre on pourrait faire ca pour tester le FDR observé quand X
est faux (on en simule un ou on permute les X existants)
**** Tab A1.2 file:./Thesis/thesis_Devillemereuil_2016.pdf::47      
c'est une blague ce genre de tableau !! On ne peut pas comparer la
puissance entre deux méthodes a un seuil fixe (ici 0.05) alors que le FDR
n'est pas controlé ... La méthode qui renvoie tous le monde aurait le
meilleur power et la pire puissance ! 
    
*** 5 Conclusions principales de l’article file:./Thesis/thesis_Devillemereuil_2016.pdf::51
Il conclue que le taux de faux positif est non controlé
Il aborde la combinaison de méthodes pour réduire 
Il minimise en disant que c'est parce que le gradient env est dans le même
sens que la structure de population...
Je comprends pas son mot sur la simultation
**** Remark perso sur les data de cette article  
On ne va pas récuperer ces données surtout qu'il ne les utilise même dans
l'article 2!! En faite si je vais les récuperer par ce que ca ne me coute
rien mais bon je vais pas trop y croire !!
*** Article 2 : A new FST-based method to uncover local adaptation using environmental variables file:./Thesis/thesis_Devillemereuil_2016.pdf::57 :BayeScEnv:
github: http://github.com/devillemereuil/bayescenv
**** Abstract: 
Il fait la difference entre les méthodes Fst et avec variable environmental
Sa methode distinque 2 cause de différenciation dans les disctribution alélique: 
-divergent selection: cad une différenciation causée par la selection
-le reste .... cad l'hystoire démographique, la selection de fond 
(https://en.wikipedia.org/wiki/Background_selection c'est la selection qui reduit 
la divesité à cause de l'environnement), c'est un des facteur confondants.
    
**** Model: 
- il calcule Fst_ij dans le F model, c'est une Fst local qui décrit la structure 
  de population. Ca mesure la différenciation génétique entre chaque sous population
  et le pool de migrant. (voir Fig7: file:./Thesis/thesis_Devillemereuil_2016.pdf::54)
- et en gros ce que je comprend c'est que après il cherche les locales fst qui sont corrélées
  avec une mesure de la différenciation environementale.
- c'est bayesien, il a 3 modèles et une probabilité $P(M2|ai,E)$ ou en gros $a_i$ et $E$ 
  sont les mesures de la structure de pop et de l'environnement (voir file:./Thesis/thesis_Devillemereuil_2016.pdf::162) et il en déduit une propba d'erreur.
***** Rmk   
Ca fait un peu naif comme modèle, on dirrait que les grands concepts on tous été appliqués
a la lettre (c'est une belle modélisation bayesienne en esperant qu ca va marcher a la fin) 
mais en fait ca donne un modèle qui a l'arrivé est dure a fitter et qui a surement des problèmes
mathématiques ...
*** Pourquoi cette profusion de méthodes ? file:./Thesis/thesis_Devillemereuil_2016.pdf::73
"course a la méthode idéale ..." 
on peut justifier ca par le No Free Lunch theorem (https://en.wikipedia.org/wiki/No_free_lunch_theorem) 
Ca dit que si un algo perform bien sur une classe de problème alors il ne sera pas le
meilleur sur tous les autres problèmes.
   

   
** 2014 - Accounting for Cellular Heterogeneity Is Critical in  Epigenome-Wide Association Studies :EWAS:
:PROPERTIES:
:Custom_ID: jaffe14_accoun_cellul_heter_is_critic
:AUTHOR:   Andrew E Jaffe \& Rafael A Irizarry
:JOURNAL:  Genome Biology
:YEAR:     2014
:VOLUME:   15
:PAGES:    R31
:DOI:      10.1186/gb-2014-15-2-r31
:URL:      https://doi.org/10.1186/gb-2014-15-2-r31
:END:

cite:jaffe14_accoun_cellul_heter_is_critic
EWAS data used in this article can be ddl here https://www.ncbi.nlm.nih.gov/gds/?term=GSE20242
d'après O.F. la méthode est du même genre que dans lfmm. (la strucutre de pop est la composition cellulaire)
*** Abstract
Il propose une méthode qui prend en compte la composition cellulaire dans les etudes d'associations entre EWAS et des phénotypes ici l'age.

** 2016 - Epigenome-Wide Association Study of Body Mass Index, and the  Adverse Outcomes of Adiposity :EWAS:
:PROPERTIES:
:Custom_ID: wahl16_epigen_wide_assoc_study_body
:AUTHOR:   Simone Wahl {\it et al.}
:JOURNAL:  Nature
:YEAR:     2016
:VOLUME:   541
:PAGES:    81-86
:DOI:      10.1038/nature20784
:URL:      https://doi.org/10.1038/nature20784
:END:

cite:wahl16_epigen_wide_assoc_study_body
 
C'est une EWAS avec l'indice de masse corporelle.


** 2009 - Regression-based latent factor models               :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: agarwal09_regres
:AUTHOR:   Deepak Agarwal \& Bee-Chung Chen
:JOURNAL:
:YEAR:     2009
:VOLUME:
:PAGES:    nil
:DOI:      10.1145/1557019.1557029
:URL:      https://doi.org/10.1145/1557019.1557029
:END:

cite:agarwal09_regres
*** Domaine d'application
Système de recommandation.
data: 
- MovieLens 943*1M
*** Modèle 
[[./biblioImages/2017_01_04_001_2017-01-04_14-21-14.png]]
*** Algorithme
Je comprend que c'est un Monte Carlo EM (a voir ce que c'est).
*** Slides
[[file:org-ref-pdfs/slides_agarwal09_regres.pdf]]
** 2008 - High-Dimensional Sparse Factor Modeling: Applications in Gene  Epression Genomics :LFMMLike:
:PROPERTIES:
:Custom_ID: carvalho08_high_dimen_spars_factor_model
:AUTHOR:   Carlos Carvalho, Jeffrey Chang, Joseph Lucas, , Joseph Nevins, Quanli Wang \& Mike West
:JOURNAL:  Journal of the American Statistical Association
:YEAR:     2008
:VOLUME:   103
:PAGES:    1438-1456
:DOI:      10.1198/016214508000000869
:URL:      https://doi.org/10.1198/016214508000000869
:END:

cite:carvalho08_high_dimen_spars_factor_model


** 2013 - A Latent Factor Linear Mixed Model for High-Dimensional  Longitudinal Data Analysis :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: an13_laten_factor_linear_mixed_model
:AUTHOR:   Xinming An, Qing Yang \& Peter Bentler
:JOURNAL:  Statistics in Medicine
:YEAR:     2013
:VOLUME:   32
:PAGES:    4229-4239
:DOI:      10.1002/sim.5825
:URL:      https://doi.org/10.1002/sim.5825
:END:

cite:an13_laten_factor_linear_mixed_model
Le nom de la méthode c'est LFLMM ^^
*** Application Domain
High-dimensional longitudinal data analysis. Si je comprends bien c'est pour
des etudes en médecine. SOn exemple sur des vrais données est la
décroissance des capacité cognitif avec l'age.
*** Model
C'est quand même un peut différent que LFMM, il y un mixed model sur les
facteurs lattents dans l'acp en gros...
*** Algorithm
EM
*** Remarques
Je n'arrive pas a bien comprendre l'interet d'un tel modèle dans son cas.

** 2016 - Sparse Multivariate Factor Analysis Regression Models and Its  Applications To Integrative Genomics Analysis :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: zhou16_spars_multiv_factor_analy_regres
:AUTHOR:   Yan Zhou, Pei Wang, Xianlong Wang, Ji Zhu, Peter \& Song
:JOURNAL:  Genetic Epidemiology
:YEAR:     2016
:VOLUME:   41
:PAGES:    70-80
:DOI:      10.1002/gepi.22018
:URL:      https://doi.org/10.1002/gepi.22018
:END:

cite:zhou16_spars_multiv_factor_analy_regres 

C'est le même modèle que lfmm sauf que leur algo est un EM et il on une
regularisation sparse. Par contre je n'ai pas trouvé de code. Mais ca peut
valoir le coup d'implementer leur méthode.

*Le modèle est très bien décrit dans ce papier !!* 
*** TODO Remarques
J'ai pas l'impression qu'ils fasse de test d'hyporhèse par contre.
Leur B est le V de lfmm
 
 
** 2010 - An accelerated proximal gradient algorithm for nuclear norm regularized linear least squares problems :LFMM:NuclearNorm:
:PROPERTIES:
:Custom_ID: article_Toh_Yun_2010
:AUTHOR:   Kim-Chuan Toh \& Sangwoon Yun
:JOURNAL:  Pacific Journal of Optimization
:YEAR:     2010
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:article_Toh_Yun_2010
C'est article est interessant pour file:./org-ref-pdfs/article_Toh_Yun_2010.pdf::9 
Il donne le lien entre SVD et nuclear norm : 
#+DOWNLOADED: /tmp/screenshot.png @ 2017-01-06 13:28:59
[[file:org-download/Articles/screenshot_2017-01-06_13-28-59.png]]  
   

** 2004 - Generalized Multilevel Structural Equation Modeling :LFMM:LFMMLike:GLLAMM:
:PROPERTIES:
:Custom_ID: rabe-hesketh04_gener_multil_struc_equat_model
:AUTHOR:   Sophia Rabe-Hesketh, Anders Skrondal \& Andrew Pickles
:JOURNAL:  Psychometrika
:YEAR:     2004
:VOLUME:   69
:PAGES:    167-190
:DOI:      10.1007/bf02295939
:URL:      https://doi.org/10.1007/bf02295939
:END:

cite:rabe-hesketh04_gener_multil_struc_equat_model

** 2010 - A Singular Value Thresholding Algorithm for Matrix Completion :LFMM:NuclearNorm:
:PROPERTIES:
:Custom_ID: cai10_singul_value_thres_algor_matrix_compl
:AUTHOR:   Jian-Feng Cai, Emmanuel Cand\`es \& Zuowei Shen
:JOURNAL:  SIAM Journal on Optimization
:YEAR:     2010
:VOLUME:   20
:PAGES:    1956-1982
:DOI:      10.1137/080738970
:URL:      https://doi.org/10.1137/080738970
:END:

cite:cai10_singul_value_thres_algor_matrix_compl
Démo de
#+DOWNLOADED: /tmp/screenshot.png @ 2017-01-06 14:49:43
[[file:org-download/Articles/screenshot_2017-01-06_14-49-43.png]]
Du coup c'est un example de preuve avec la norme nucléaire (donc calcul de subgradient).
Rmk: dans la preuve il font pas l'analyse, il font que la synthèse. De toute facon ils ont 
l'unicité car c'est strictement convexe !!!

** 2016 - False Discovery Rates: a New Deal
:PROPERTIES:
:Custom_ID: stephens16_false_discov_rates
:AUTHOR:   Matthew Stephens
:JOURNAL:  Biostatistics
:YEAR:     2016
:VOLUME:   nil
:PAGES:    kxw041
:DOI:      10.1093/biostatistics/kxw041
:URL:      https://doi.org/10.1093/biostatistics/kxw041
:END:

cite:stephens16_false_discov_rates
Commentaries in the pdf.

** 2007 - Capturing Heterogeneity in Gene Expression Studies by  Surrogate Variable Analysis :LFMMLike:
:PROPERTIES:
:Custom_ID: article_Leek_Storey_2007
:AUTHOR:   Leek \& Storey
:JOURNAL:  PLoS Genetics
:YEAR:     2007
:VOLUME:   3
:PAGES:    e161
:DOI:      10.1371/journal.pgen.0030161
:URL:      http://dx.doi.org/10.1371/journal.pgen.0030161
:END:

cite:article_Leek_Storey_2007
remark as okular commentary !! Supporting information and figure [[http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0030161#s5][here]].
 

*** Gene ranking more accurate and stable
Le fait de prendre en compte la structure lattente donne un ranking des
gênes plus stable. Ca pourait être un critere pour le choix de model :D
*** The R package                                                  :Rpackage:
http://www.genomine.org/sva/
[[./org-ref-pdfs/Rpackage_sva.pdf][The SVA manual]]
**** Overview
- "Surrogate variables are covariates constructed directly
  from high-dimensional data (like gene expression/RNA sequencing/
  *methylation* /brain imaging data" : il propose de l'utiliser sur des
  données de méthylation !!
*** Simulations
Ils en dit plus dans [[ref:article_Leek_Storey_2008][cette article]]
** 2012 - Cross-Dimensional Inference of Dependent High-Dimensional  Data :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: article_Desai_Storey_2012
:AUTHOR:   Desai \& Storey
:JOURNAL:  Journal of the American Statistical Association
:YEAR:     2012
:VOLUME:   107
:PAGES:    135–151
:DOI:      10.1080/01621459.2011.645777
:URL:      http://dx.doi.org/10.1080/01621459.2011.645777
:END:

cite:article_Desai_Storey_2012
Rmk : notes in the pdf with okular

*** 5.4 Multiple Testing
Il compare 4 méthodes pour 
- MLE
- CDI
- SVA
- FAMT
Je comprends que c'est sur des données simulé de son modèle : 

#+DOWNLOADED: /tmp/screenshot.png @ 2017-01-10 15:04:44
[[file:org-download/Articles/screenshot_2017-01-10_15-04-44.png]]

avec E une structure de variance particulière, je pense que ca revient au même que mes simulation
générative de lfmm.

*/Mais quelle sva il utilise ? il y en a plein dans la doc/*
Il cite cite:article_Leek_Storey_2007 and cite:article_Leek_Storey_2008 c'est les deux papiers
a citer quand on utilise le package SVA pour enlever les batch effect et autre variation 
non voulue d'apres file:./org-ref-pdfs/Rpackage_sva.pdf::11 

*** Implementation
Il n'y a pas de package R mais ils parlent de plusieurs pacakge pour l'implémentation
    
** 2008 - A general framework for multiple testing dependence :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: article_Leek_Storey_2008
:AUTHOR:   Leek \& Storey
:JOURNAL:  Proceedings of the National Academy of Sciences
:YEAR:     2008
:VOLUME:   105
:PAGES:    18718–18723
:DOI:      10.1073/pnas.0808709105
:URL:      http://dx.doi.org/10.1073/pnas.0808709105
:END:

cite:article_Leek_Storey_2008
Rmk : note in the pdf with okular
*** Method
C'est l'article qui vent le concepte de LFMM, c'est a dire la correction pour
les fateurs de confusions

#+DOWNLOADED: /tmp/screenshot.png @ 2017-01-10 09:34:10
[[file:org-download/Articles/screenshot_2017-01-10_09-34-10.png]] 

C'est pas nouveau comme concepte !!

*** Remarques
Ce qu'il appel G c'est U dans Lfmm et il est éstimé ! Le test est fait
sashant cette estimation, quel est l'influence sur le tst d'hypothèse ??
*** Apendix file:./org-ref-pdfs/SI_Leek_Storey_2008.pdf 
remark in the pdf with okular Il dit que tout a été fait en language R mais
ou est le code ????
*** Comment calculer sont G (le V de lfmm)
Il propose l'algo iteratively re- weighted surrogate variable analysis
(IRW-SVA) : voir [[file:org-ref-pdfs/Rpackage_sva.pdf][ce R package]]. 

Comme il décrit l'algo dans le [[file:LFMM/Method/StoreyStuff/SI_Leek_Storey_2008.pdf][sup info]] c'est exactement le principe de ce
que on veut faire dans lfmm. Cad calculer G sans capter la variation causé
par S : 
#+BEGIN_QUOTE
The basic idea when estimating G in this scenario is to identify a subset of
tests whose data show a strong association with G, but not a strong
association with S. The estimate of G can then be formed based on the
right singular vectors of this subset. This approach accomplishes two
things. -- cite:article_Leek_Storey_2008 
#+END_QUOTE
*** Simulations
Voir le [[file:Biblio/org-ref-pdfs/SI_Leek_Storey_2008.pdf][SI]]. Ca pourrait valoir le coup de faire ce genre de simulation. En
tout les simulations son avantagueuse par rapport a l'algo SVA.


** 2009 - A Factor Model Approach To Multiple Testing Under Dependence :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: friguet09_factor_model_approac_to_multip
:AUTHOR:   Chlo\'e Friguet, Maela Kloareg \& David Causeur
:JOURNAL:  Journal of the American Statistical Association
:YEAR:     2009
:VOLUME:   104
:PAGES:    1406-1415
:DOI:      10.1198/jasa.2009.tm08332
:URL:      https://doi.org/10.1198/jasa.2009.tm08332
:END:

cite:friguet09_factor_model_approac_to_multip
*** Poster
file:./org-ref-pdfs/poster_friguet09_factor_model_approac_to_multip.pdf
On retrouve les même chose que dans tous les papier LFMMLike
*** R package                                                      :Rpackage:
http://famt.free.fr/
   
** 2010 - Regularization Paths for Generalized Linear Models Via  Coordinate Descent :algorithm:Rpackage:
:PROPERTIES:
:Custom_ID: friedman10_regul_paths_gener_linear_model
:AUTHOR:   Jerome Friedman, Trevor Hastie \& Robert Tibshirani
:JOURNAL:  Journal of Statistical Software
:YEAR:     2010
:VOLUME:   33
:PAGES:    nil
:DOI:      10.18637/jss.v033.i01
:URL:      https://doi.org/10.18637/jss.v033.i01
:END:

cite:friedman10_regul_paths_gener_linear_model
C'est l'article vendu dans la doc de [[https://cran.r-project.org/web/packages/glmnet/glmnet.pdf][glmnet]]
*** 2.5. Pathwise coordinate descent file:./org-ref-pdfs/friedman10_regul_paths_gener_linear_model.pdf:7
On part du plus grand $\lambda$ et on decroit (en suivant une courbe logistique)
pour atteindre un $\lambda_{min}$.
On doit pouvoir faire ca avec les regularisations en nuclear norm.
*** 3. Regularized logistic regression file:./org-ref-pdfs/friedman10_regul_paths_gener_linear_model.pdf:8
Il decrit un peut plus l'algo. Avec la perte logistique on a plus la solution
analytique du pb d'optim, c'est pour ca qu'il y a 3 boucles: 
#+DOWNLOADED: /tmp/screenshot.png @ 2017-01-11 09:52:54
[[file:org-download/Articles/screenshot_2017-01-11_09-52-54.png]] 
**** Idée pour lfmm                                                 :MaThese:
On n'a pas l'étape d'approximation quadratique (puisque ca l'ai déja). Mais 
on fait une descente par bloc de coordonnées !! 
Je pense même que l'on pourrait changer la fonction de perte en la mettant logistique
et faire cette approximation quadratique. Ca peut faire une bonne ouverture pour la thèse.
     
     

** 2015 - Binary Factorization Models for Statistical Relational Learning :LFMM:MaThese:
:PROPERTIES:
:Custom_ID: slides_Bouchard_WinterSchool2015
:AUTHOR:   Guillaume Bouchard
:JOURNAL:
:YEAR:     2015
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:slides_Bouchard_WinterSchool2015 Slides présenté par Guillaume Bouchard à
la winter school à Villard que j'ai fait en 2015 au début de ma thèse. Ce qui
m'interesse est sur le slide 21. Il parle facteur analysis sur des données
binaires. Je pense que faire de même avec lfmm est une bonne idée, ca peut
faire des pistes pour des ouvertures.

** 2016 - Reference-free deconvolution of DNA methylation data and  mediation by cell composition effects :LFMM:EWAS:
:PROPERTIES:
:Custom_ID: article_Houseman_2016
:AUTHOR:   Houseman, Kile, Christiani, , Ince, Kelsey \& Marsit
:JOURNAL:  BMC Bioinformatics
:YEAR:     2016
:VOLUME:   17
:PAGES:
:DOI:      10.1186/s12859-016-1140-4
:URL:      http://dx.doi.org/10.1186/s12859-016-1140-4
:END:

cite:article_Houseman_2016
C'est une méthode pour faire des de l'association avec des données de méthylation de l'adn 
et d'autre facteurs (je comprends que le but des d'identifier les zones du génome exprimé en 
association avec des co variables).
La méthode est comme LFMM
*** Background
DNA methylation : $Y$  (rmk transposer du sens de LFMM) valeur dans $[0,1]$, c'est la proportion 
de methylated cytosine molecules à ce locus...
$Y = M \Hommega^T$ ou $M$ est l'état de méthylation et $\Hommega$ le type des cellules.
Donc $M$ c'est la base et $\Hommega$ les quantité de chaque echantillon dans cette base.
Il parle apres d'une méthode que resemble à LFMM. Du coup sa méthode est différente ?
**** Le méthode    
Il fait un NMF avec des contrainte en plus sur $\Hommega$ et $M$ ... comme sNMF. Jusque ici c'est classique. Je comprends pas ou intervient $X$ les co-variable??
*** Methods                                                       :mediation:
C'est plus detaillé dans le supplementary material S1, c'était un .docx mdrrrrr
file:./org-ref-pdfs/S1_Houseman_2016.pdf
Je comprends qu'il fait deux type d'association 
- dans S4 c'est $\Hommega$ ~ $X$ 
- et dans S5 c'est Y ~ X + \Hommega
  Du coup c'est pas du lfmm, dans le sens ou il fait pas tout en une fois, c'est comme faire l'acp 
  et après le mettre dans lm.
  Ce que je comprend pas c'est pour il fait les deux associations ? C'est ca la [[https://en.wikipedia.org/wiki/Mediation_(statistics)][mediation]] ? 
  Dans ce cas : 
  #+DOWNLOADED: file:///home/cayek/Téléchargements/screenshot_001.jpg @ 2017-01-12 11:03:43
  [[file:org-download/Articles/screenshot_001_2017-01-12_11-03-43.jpg]]

  Finnalement LFMM est un modèle qui permet de faire de la médiation ...
*** Implementation
Dans la doc de [[https://cran.r-project.org/web/packages/RefFreeEWAS/index.html][RefFreeEWAS]] il dit que Houseman 2016 est implementé dans ce package.

** 2014 - Reference-Free Cell Mixture Adjustments in Analysis of Dna  Methylation Data :LFMM:LFMMLike:Rpackage:EWAS:
:PROPERTIES:
:Custom_ID: houseman14_refer_free_cell_mixtur_adjus
:AUTHOR:   Houseman, Molitor \& Marsit
:JOURNAL:  Bioinformatics
:YEAR:     2014
:VOLUME:   30
:PAGES:    1431-1439
:DOI:      10.1093/bioinformatics/btu029
:URL:      https://doi.org/10.1093/bioinformatics/btu029
:END:

cite:houseman14_refer_free_cell_mixtur_adjus
Celui la c'est un lfmm like !!
*** TODO Method
Il dit que c'est similaire à SVA
Il y a des notations partout... on va voir le package R [[https://cran.r-project.org/web/packages/RefFreeEWAS/RefFreeEWAS.pdf][RefFreeEWAS]] (il y a pas de vignette...)
Ok j'y comprend rien...

** TODO - 2015 Testing Mediation with Regression Analysis         :mediation:
:PROPERTIES:
:Custom_ID: tuto_mediation_2015
:AUTHOR:
:JOURNAL:
:YEAR:     2015
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:tuto_mediation_2015
C'est un tuto pour faire des test sur la médiation. 
Ce que je comprends est que le but est d'identifier le role joué par M dans un lien de 
causalité. 
 

** TODO 2001 - Direct and indirect effects                  :CausalInference:
:PROPERTIES:
:Custom_ID: pearl2001direct
:AUTHOR:   Pearl
:JOURNAL:
:YEAR:     2001
:VOLUME:
:PAGES:    411--420
:DOI:
:URL:
:END:

cite:pearl2001direct
D'après of c'est un des papes de l'inference causal

** TODO 2012 - Dna Methylation Arrays As Surrogate Measures of Cell Mixture  Distribution :LFMM:EWAS:
:PROPERTIES:
:Custom_ID: houseman12_dna_methy_array_as_surrog
:AUTHOR:   Eugene Houseman {\it et al.}
:JOURNAL:  BMC Bioinformatics
:YEAR:     2012
:VOLUME:   13
:PAGES:    86
:DOI:      10.1186/1471-2105-13-86
:URL:      https://doi.org/10.1186/1471-2105-13-86
:END:

cite:houseman12_dna_methy_array_as_surrog
 
** 2013 - Testing for Associations Between Loci and Environmental  Gradients Using Latent Factor Mixed Models :LFMM:
:PROPERTIES:
:Custom_ID: frichot13_testin_assoc_between_loci_envir
:AUTHOR:   Frichot, Schoville, Bouchard, \& Francois
:JOURNAL:  Molecular Biology and Evolution
:YEAR:     2013
:VOLUME:   30
:PAGES:    1687-1699
:DOI:      10.1093/molbev/mst063
:URL:      https://doi.org/10.1093/molbev/mst063
:END:

cite:frichot13_testin_assoc_between_loci_envir
C'est l'article d'LFMM

*** Simulations
Il fait des simulations avec que des H0, il utilise le model de stepping
stone pour ca. *MAIS* je ne comprend pas comment il fait ses simulations
avec la seletion. 

** TODO 2008 - Bolasso
:PROPERTIES:
:END:
:PROPERTIES:
:Custom_ID: Bach_2008
:AUTHOR: Bach
:JOURNAL: Proceedings of the 25th international conference on Machine
learning - ICML ’08
:YEAR: 2008
:VOLUME: 
:PAGES: 
:DOI: 10.1145/1390156.1390161
:URL: http://dx.doi.org/10.1145/1390156.1390161
:END:

cite:Bach_2008 
Je suis tombé sur ce papier en cherchant sur google [[https://www.google.fr/webhp?sourceid=chrome-instant&ion=1&espv=2&ie=UTF-8#q=bootstrap%20lasso][bootstrap lasso]]
Comme c'est un papier de ce bon vieux Bach

** TODO 2013 - Low-Rank Optimization with Trace Norm Penalty
:PROPERTIES:
:Custom_ID: article_Mishra_Meyer_Bach_Sepulchre_2011
:AUTHOR:   Mishra, Meyer, Bach \& Sepulchre
:JOURNAL:  SIAM Journal on Optimization
:YEAR:     2013
:VOLUME:   23
:PAGES:    2124–2149
:DOI:      10.1137/110859646
:URL:      http://dx.doi.org/10.1137/110859646
:END:

cite:article_Mishra_Meyer_Bach_Sepulchre_2011

** TODO 2007 - Size, Power and False Discovery Rates                    :FDR:
:PROPERTIES:
:Custom_ID: efron07_size_power_false_discov_rates
:AUTHOR:   Bradley Efron
:JOURNAL:  The Annals of Statistics
:YEAR:     2007
:VOLUME:   35
:PAGES:    1351-1377
:DOI:      10.1214/009053606000001460
:URL:      https://doi.org/10.1214/009053606000001460
:END:

cite:efron07_size_power_false_discov_rates
Un article d'efrond un peu meta je pense.. A LIRE pour la parti sur le FDR pour ma thèse.
 

** 2016 - Panning for Gold: Model-free Knockoffs for High-dimensional Controlled Variable Selection :FDR:
:PROPERTIES:
:Custom_ID: candes2016panning
:AUTHOR:   Candes, Fan, Janson \& Lv
:JOURNAL:  arXiv preprint arXiv:1610.02351
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:candes2016panning 
 
C'est le papier qui devellope la théorie des knockoff en détail, il y a aussi
une revu des méthodes classiques des tests d'hypothèses. 
 

** 2015 - Controlling the false discovery rate via knockoffs :HypothesisTesting:MultipleTesting:
:PROPERTIES:
:Custom_ID: Barber_2015
:AUTHOR:   Barber \& Candès
:JOURNAL:  The Annals of Statistics
:YEAR:     2015
:VOLUME:   43
:PAGES:    2055–2085
:DOI:      10.1214/15-aos1337
:URL:      http://dx.doi.org/10.1214/15-aos1337
:END:

cite:Barber_2015 C'est le premier papier sur les knockoffs. Il décrit la
méthode et la compare. 

*** TODO Implementation                                            :Rpackage:
Il y a un pacakge :
https://cran.r-project.org/web/packages/knockoff/knockoff.pdf

** 2010 - Rank Constrained Matrix Optimization Problems                :LFMM:
:PROPERTIES:
:Custom_ID: slides_Rk_Const_Matrix_Optim_2015
:AUTHOR:   Defeng Sun
:JOURNAL:
:YEAR:     2010
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:slides_Rk_Const_Matrix_Optim_2015
C'est pour le slides 2 ils y a les référence pour montrer que min avec
contraintes du rank à une solution analytique qui est la svd de rank K.

** TODO 2000 - On the Convergence of the Block Nonlinear Gauss-Seidel Method  Under Convex Constraints :Optimisation:
:PROPERTIES:
:Custom_ID: grippo00_conver_block_nonlin_gauss_seidel
:AUTHOR:   Grippo \& Sciandrone
:JOURNAL:  Operations Research Letters
:YEAR:     2000
:VOLUME:   26
:PAGES:    127-136
:DOI:      10.1016/s0167-6377(99)00074-7
:URL:      https://doi.org/10.1016/s0167-6377(99)00074-7
:END:

cite:grippo00_conver_block_nonlin_gauss_seidel
C'est le papier que j'ai cité dans TESS3 article 2 pour justifier la
convergeance du mon algo.
 
 
** 2009 - Genome-wide association analysis by lasso penalized logistic  regression :GWAS:Lasso:
:PROPERTIES:
:Custom_ID: Wu_2009
:AUTHOR:   Wu, Chen, Hastie, Sobel, \& Lange
:JOURNAL:  Bioinformatics
:YEAR:     2009
:VOLUME:   25
:PAGES:    714–721
:DOI:      10.1093/bioinformatics/btp041
:URL:      http://dx.doi.org/10.1093/bioinformatics/btp041
:END:

cite:Wu_2009
La partie test d'hypothèse est vraiment mal détaillé !! J'ai l'impression qu'il
estime des variables avec le lasso et après sur les selectionnés éstime la
vraisemblance en mettant de coté a chaque fois chacune des vars mais sans lasso.
Il dit pas comment il obtiend ses pvalue.....
 
** TODO 2014 - A significance test for the lasso                      :Lasso:
:PROPERTIES:
:Custom_ID: Lockhart_2014
:AUTHOR:   Lockhart, Taylor, Tibshirani, \& Tibshirani
:JOURNAL:  The Annals of Statistics
:YEAR:     2014
:VOLUME:   42
:PAGES:    413–468
:DOI:      10.1214/13-aos1175
:URL:      http://dx.doi.org/10.1214/13-aos1175
:END:

cite:Lockhart_2014
C'est papier du test stat pour les modèle linéaire avec regularisation lasso. 
 
Voici un présentation qui va avec [[file:MultipleTesting/pres_Tibshirani_2013.pdf]]

** TODO 2016 - Ten Simple Rules for Structuring Papers
:PROPERTIES:
:Custom_ID: kording16_ten_simpl_rules_struc_paper
:AUTHOR:   Kording \& Mensh
:JOURNAL:
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:      10.1101/088278
:URL:      https://doi.org/10.1101/088278
:END:

cite:kording16_ten_simpl_rules_struc_paper
I printed it !!!

** 2016 - Fast Inference of Individual Admixture Coefficients Using  Geographic Data :TESS3_article2:
:PROPERTIES:
:Custom_ID: Caye_2016
:AUTHOR:   Caye, Jay, Michel, Francois \& Olivier
:JOURNAL:
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:      10.1101/080291
:URL:      http://dx.doi.org/10.1101/080291
:END:

cite:Caye_2016
 

** 2000 - On the convergence of the block nonlinear Gauss–Seidel method  under convex constraints :Optimisation:TESS3_article2:
:PROPERTIES:
:Custom_ID: Grippo_2000
:AUTHOR:   Grippo \& Sciandrone
:JOURNAL:  Operations Research Letters
:YEAR:     2000
:VOLUME:   26
:PAGES:    127–136
:DOI:      10.1016/s0167-6377(99)00074-7
:URL:      http://dx.doi.org/10.1016/s0167-6377(99)00074-7
:END:

cite:Grippo_2000 C'est le papier por justifier la convergence de l'algo 1 dans
le papier TESS3_article2.

** 1997 - Nonlinear Programming                 :Optimisation:TESS3_article2:
:PROPERTIES:
:Custom_ID: Bertsekas_1997
:AUTHOR:   Bertsekas
:JOURNAL:  Journal of the Operational Research Society
:YEAR:     1997
:VOLUME:   48
:PAGES:    334–334
:DOI:      10.1057/palgrave.jors.2600425
:URL:      http://dx.doi.org/10.1057/palgrave.jors.2600425
:END:

cite:Bertsekas_1997 C'est le papier toujours cité pour les [[file:./org-ref-pdfs/bertsekas_1997.pdf:135][block coordinate
descent]] (voir a la page 135). Le resultat de congergence s'applique sur des
ensembles convexes fermés.

** 2016 - Recovery guarantee of weighted low-rank approximation via  alternating minimization :Optimisation:
:PROPERTIES:
:Custom_ID: li16_recov
:AUTHOR:   Yuanzhi Li, Yingyu Liang \& Andrej Risteski
:JOURNAL:
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:li16_recov
Article proposé par flora dans un mail : 
---
Pour info
Un chercheur de mon équipe m'a parlé de whitening pour améliorer l'alternating LS (et surtout pour avoir un résultat théorique  pour avoir des résultats théoriques à propos de la convergence). C'était très rapide donc j'ai pas eu plus d'explications mais un papier : https://arxiv.org/pdf/1602.02262v1.pdf
---
 
C'est un papier pas mal si je veux faire de la biblio sur les aproximations de
matrice de rank faible par de l'optimization.

** 2010 - Spectral Regularization Algorithms for Learning Large  Incomplete Matrices :LFMM:Rpackage:
:PROPERTIES:
:Custom_ID: mazumder10_spect_regul_algor_learn_large_incom_matric
:AUTHOR:   Mazumder, Hastie \& Tibshirani
:JOURNAL:  Journal of machine learning research
:YEAR:     2010
:VOLUME:   11
:PAGES:    2287--2322
:DOI:
:URL:
:END:

cite:mazumder10_spect_regul_algor_learn_large_incom_matric C'est l'article du
Rpackage SOFT-IMPUTE: [[./LFMM/NuclearNorm/RpackageSoftImpute_Hastie_2015.pdf][doc]] Il propose un algo dit EM pour faire de l'imputation,
ca m'interesse car ca peut etre un moyen de faire le fit de lfmm sans avoir a
imputer au préalable !!


** 2015 - The Relative Power of Genome Scans To Detect Local Adaptation  Depends on Sampling Design and Statistical Method :LFMM:EAAReviewAndComparison:
:PROPERTIES:
:Custom_ID: lotterhos15_relat_power_genom_scans_to
:AUTHOR:   Katie Lotterhos \& Michael Whitlock
:JOURNAL:  Molecular Ecology
:YEAR:     2015
:VOLUME:   24
:PAGES:    1031-1046
:DOI:      10.1111/mec.13100
:URL:      https://doi.org/10.1111/mec.13100
:END:

cite:lotterhos15_relat_power_genom_scans_to
Mdr les graphes de ce papier... ils sont gros et ne disent pas grands choses
... Mais j'ai du choper une version pas review, il y a plien de trucs qui sont
pas acceptable (surtout en matiere de graphe je trouve !)
Bon en tout cas on peut peut ètre choper ses simulations.

** 2011 - Significance testing in ridge regression for genetic data
:PROPERTIES:
:Custom_ID: Cule_2011
:AUTHOR:   Cule, Vineis \& De Iorio
:JOURNAL:  BMC Bioinformatics
:YEAR:     2011
:VOLUME:   12
:PAGES:    372
:DOI:      10.1186/1471-2105-12-372
:URL:      http://dx.doi.org/10.1186/1471-2105-12-372
:END:

cite:Cule_2011
Papier dans lequel il developpe le modèle ridge linéaire et logistique. Il font
des tests d'hypothèse en calculant la variance de B.

** 2016 - Sparse PCA corrects for cell type heterogeneity in  epigenome-wide association studies :LFMM:EWAS:
:PROPERTIES:
:Custom_ID: Rahmani_2016
:AUTHOR:   Rahmani {\it et al.}
:JOURNAL:  Nature Methods
:YEAR:     2016
:VOLUME:   13
:PAGES:    443–445
:DOI:      10.1038/nmeth.3809
:URL:      http://dx.doi.org/10.1038/nmeth.3809
:END:

cite:Rahmani_2016

C'est la papier qui présente ReFACTor. [[http://www.cs.tau.ac.il/~heran/cozygene/software/refactor.html][Le sowftware ici]]. L'idée est que l'on
corrige sans connaitre la composition cellulaire à priorie donc on l'apprend
dans les data. Eux avec l'acp sparse. Comme je le comprend il prenne un sous
ensemblde de snps pour estimer la structure cellulaire... Ou plutot tous les
sites de méthylation ne sont pas considérer egualement informatif, c'est pour
ca qu'il y a une liste rangé de site de méthylation en sorti de leur
algorithme. 
 
*** Suplementary Information: 
Un regal :D
- file:./Biblio/org-ref-pdfs/ST_Rahmani_2016.pdf
- file:./Biblio/org-ref-pdfs/SF_Rahmani_2016.pdf
*** Software
C'est un script R... (super TP les gars !!13/20)
- README: file:./org-ref-pdfs/README_Rahmani_2016.pdf 

*** Rmk perso et comparaison avec lfmm
En faite c'est juste l'acp fait sur les t (dans le code t = 500 par defaut)
site les plus proche de la low rank structure... ^_^'
    
Du coup ca marche très bien sur mes simulations dites lfmm normales. Normal
il fait une acp mais pas sur tout le monde. Du coup c'est très simple pour
moi de le planter, il suffit qu'il y ai beaucoups d'outlier ( 60 % dans mes
tests ^^). Après je suis pas sur que ca arrive en pratique.

L'idée est pas mauvaise finalement et très simple, et je suis que en
fouillant je tomberais sur la même idée pour les GWAS. 

** 2014 - Epigenome-wide association studies without the need for  cell-type composition :EWAS:
:PROPERTIES:
:Custom_ID: Zou_2014
:AUTHOR:   Zou, Lippert, Heckerman, , Aryee \& Listgarten
:JOURNAL:  Nature Methods
:YEAR:     2014
:VOLUME:   11
:PAGES:    309–311
:DOI:      10.1038/nmeth.2815
:URL:      http://dx.doi.org/10.1038/nmeth.2815
:END:

cite:Zou_2014
Un autre papier qui fait l'étude du dataset ewas RA ([[https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE42861][GSE42861]]).

Suplementary materials: file:./Biblio/org-ref-pdfs/SM_Zou_2016.pdf

*** Datasets and data processing
C'est bien mieux détaillé que quand l'article cite:Rahmani_2016 !! On va
faire le preprocessing de cette aritcle. De toute facon l'objectif est de se
comparer au papier cite:Zou_2014 avec la méthode qui connait la composition
cellulaire ! 

*** Simulations
Ils ont simulé des données a partir du dataset RA cf page 5.

** TODO 2011 - Epigenome-wide association studies for common human diseases :EWAS:
:PROPERTIES:
:Custom_ID: Rakyan_2011
:AUTHOR:   Rakyan, Down, Balding, \& Beck
:JOURNAL:  Nature Reviews Genetics
:YEAR:     2011
:VOLUME:   12
:PAGES:    529–541
:DOI:      10.1038/nrg3000
:URL:      http://dx.doi.org/10.1038/nrg3000
:END:

cite:Rakyan_2011

C'est article pour présenter le problème des EWAS par rapport au GWAS dans les
études d'association avec des maladies. Il parle des facteurs de confusions
dans les données EWAS. Je pense que c'est l'article a citer pour justifier
l'utilisation de LFMM dans les EWAS. Il a été cité plus de 600 fois.

** 2015 - Testing for genetic associations in arbitrarily structured  populations :GWAS:
:PROPERTIES:
:Custom_ID: Song_2015
:AUTHOR:   Song, Hao \& Storey
:JOURNAL:  Nature Genetics
:YEAR:     2015
:VOLUME:   47
:PAGES:    550–554
:DOI:      10.1038/ng.3244
:URL:      http://dx.doi.org/10.1038/ng.3244
:END:

cite:Song_2015 C'est la papier qui m'a inspiré les plots de comparaisons. Il y
a un gros [[file:Biblio/org-ref-pdfs/SI_Song_2015.pdf][Sup Info]].
 
*** Preprint
[[file:org-ref-pdfs/preprint_Song_2015.pdf]] Papier trouvé dans la biblio que OF
m'a donnée en début de thèse.

** 2013 - Epigenome-wide association data implicate DNA methylation as  an intermediary of genetic risk in rheumatoid arthritis :EWAS:
:PROPERTIES:
:Custom_ID: Liu_2013
:AUTHOR:   Liu {\it et al.}
:JOURNAL:  Nature Biotechnology
:YEAR:     2013
:VOLUME:   31
:PAGES:    142–147
:DOI:      10.1038/nbt.2487
:URL:      http://dx.doi.org/10.1038/nbt.2487
:END:

cite:Liu_2013
C'est le papier pour présenté les données RA GSE42861 des articles
cite:Zou_2014,Rahmani_2016.
 

** 2008 - Worldwide Human Relationships Inferred from Genome-Wide  Patterns of Variation
:PROPERTIES:
:Custom_ID: Li_2008
:AUTHOR:   Li {\it et al.}
:JOURNAL:  Science
:YEAR:     2008
:VOLUME:   319
:PAGES:    1100–1104
:DOI:      10.1126/science.1153717
:URL:      http://dx.doi.org/10.1126/science.1153717
:END:

cite:Li_2008
C'est l'article du dataset HGDP utilisé dans cite:frichot13_testin_assoc_between_loci_envir. 

** 2009 - Gestion des donn{\'e}es manquantes en analyse en composantes principales :LFMM:PCA:
:PROPERTIES:
:Custom_ID: josse2009gestion
:AUTHOR:   Josse, Pages \& Husson
:JOURNAL:  Journal de la Soci{\'e}t{\'e} Fran{\c{c}}aise de Statistique
:YEAR:     2009
:VOLUME:   150
:PAGES:    28--51
:DOI:
:URL:
:END:

cite:josse2009gestion
Un article en francais sur les méthodes d'ACP quand il y a des missing value.
Ca m'interesse parce que pour lfmm avec des missing value je vais alterner ma
procedure jusqu'a convergeance. Elle a l'aire de dire que ca converge.

** 2015 - Visualizing spatial population structure with estimated  effective migration surfaces :TESS3:MaThese:
:PROPERTIES:
:Custom_ID: Petkova_2015
:AUTHOR:   Petkova, Novembre \& Stephens
:JOURNAL:  Nature Genetics
:YEAR:     2015
:VOLUME:   48
:PAGES:    94–100
:DOI:      10.1038/ng.3464
:URL:      http://dx.doi.org/10.1038/ng.3464
:END:
 
cite:Petkova_2015
 
Article important pour ma thèse, c'est une méthode qui permet de visualiser une
stat qu'ils appellent le coefficient de migration sur une carte donc c'est la
même idée que TESS3. Ca montre que maper les populations sur une carte est
important ! C'est interessant pour l'intro aussi, pour s'inspirer pour la thèse
:D

** TODO 2014 - Efficient multivariate linear mixed model algorithms for  genome-wide association studies
:PROPERTIES:
:Custom_ID: Zhou_2014
:AUTHOR:   Zhou \& Stephens
:JOURNAL:  Nature Methods
:YEAR:     2014
:VOLUME:   11
:PAGES:    407–409
:DOI:      10.1038/nmeth.2848
:URL:      http://dx.doi.org/10.1038/nmeth.2848
:END:

cite:Zhou_2014
Cette version du papier est très complete et m'a beaucoup inspiré ! 

** 2013 - Polygenic Modeling with Bayesian Sparse Linear Mixed Models :LFMM:GWAS:
:PROPERTIES:
:Custom_ID: Zhou_2013
:AUTHOR:   Zhou, Carbonetto \& Stephens
:JOURNAL:  PLoS Genetics
:YEAR:     2013
:VOLUME:   9
:PAGES:    e1003264
:DOI:      10.1371/journal.pgen.1003264
:URL:      http://dx.doi.org/10.1371/journal.pgen.1003264
:END:
 
cite:Zhou_2013 C'est la méthode implémenté dans GEMMA pour les GWAS polygenic.
Se je comprends bien il dit que on sait pas trop quoi choisir entre le linear
mixed model et la regression sparse => il fait un modèle bayesien qui est
melange des deux et du coup c'est senser apprendre le meilleur vu que c'est
bayesien :D comme ca pas d'hypothèse.

*** TODO Pour ma thèse                                              :MaThese:
Faudrait que je lise l'intro de ce papier, en général les papier avec
stephens son bien écrit. Le résumé est pas mal ! 

** 1982 - Conflict Among the Criteria Revisited; The W, LR and LM Tests :LFMM:HypothesisTesting:
:PROPERTIES:
:Custom_ID: Evans_1982
:AUTHOR:   Evans \& Savin
:JOURNAL:  Econometrica
:YEAR:     1982
:VOLUME:   50
:PAGES:    737
:DOI:      10.2307/1912611
:URL:      http://dx.doi.org/10.2307/1912611
:END:

cite:Evans_1982
Article cité dans [[ref:Zhou_2014][cet article]] pour justifier la calibration des pvalues.

** 1984 - Hypothesis Testing in Linear Models when the Error Covariance  Matrix is Nonscalar :LFMM:HypothesisTesting:
:PROPERTIES:
:Custom_ID: Rothenberg_1984
:AUTHOR:   Rothenberg
:JOURNAL:  Econometrica
:YEAR:     1984
:VOLUME:   52
:PAGES:    827
:DOI:      10.2307/1911186
:URL:      http://dx.doi.org/10.2307/1911186
:END:

cite:Rothenberg_1984
Article cité dans [[ref:Zhou_2014][cet article]] pour justifier la calibration des pvalues. La
matrice de covariance est uen fonction d'un parametre theta. C'est pas tout a
fait mon problème ! 
 

** TODO 2000 - Tests of regression coefficients under ridge regression  models :HypothesisTesting:
:PROPERTIES:
:Custom_ID: Halawa_2000
:AUTHOR:   Halawa \& El Bassiouni
:JOURNAL:  Journal of Statistical Computation and Simulation
:YEAR:     2000
:VOLUME:   65
:PAGES:    341–356
:DOI:      10.1080/00949650008812006
:URL:      http://dx.doi.org/10.1080/00949650008812006
:END:

cite:Halawa_2000
Cité dans [[ref:Cule_2011]] pour justifier le test d'hypothèse. 

** 2016 - Controlling false discoveries in genome scans for selection :HypothesisTesting:MaThese:
:PROPERTIES:
:Custom_ID: Fran_ois_2016
:AUTHOR:   François, Martins, Caye, \& Schoville
:JOURNAL:  Molecular Ecology
:YEAR:     2016
:VOLUME:   25
:PAGES:    454–469
:DOI:      10.1111/mec.13513
:URL:      http://dx.doi.org/10.1111/mec.13513
:END:
 
cite:Fran_ois_2016
Il faudrat que je comprenne bien cette article pour ma thèse !! 

** 2011 - Parameter estimation and inference in the linear mixed model :LFMM:HypothesisTesting:
:PROPERTIES:
:Custom_ID: Gumedze_2011
:AUTHOR:   Gumedze \& Dunne
:JOURNAL:  Linear Algebra and its Applications
:YEAR:     2011
:VOLUME:   435
:PAGES:    1920–1944
:DOI:      10.1016/j.laa.2011.04.015
:URL:      http://dx.doi.org/10.1016/j.laa.2011.04.015
:END:

cite:Gumedze_2011
Un article de théorie sur les modèles mixes linéaire, trouvé dans [[ref:Zhou_2014][cette article]]. 

** TODO 2013 - A Sparse-Group Lasso
:PROPERTIES:
:Custom_ID: Simon_2013
:AUTHOR:   Simon, Friedman, Hastie, \& Tibshirani
:JOURNAL:  Journal of Computational and Graphical Statistics
:YEAR:     2013
:VOLUME:   22
:PAGES:    231–245
:DOI:      10.1080/10618600.2012.681250
:URL:      http://dx.doi.org/10.1080/10618600.2012.681250
:END:

cite:Simon_2013
Papier cité dans cite:zhou16_spars_multiv_factor_analy_regres pour l'algo.

** TODO 2004 - Generalized latent variable modeling: Multilevel, longitudinal, and structural equation models :LFMM:LFMMLike:GLLAMM:
:PROPERTIES:
:Custom_ID: skrondal2004generalized
:AUTHOR:   Skrondal \& Rabe-Hesketh
:JOURNAL:
:YEAR:     2004
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:
 
cite:skrondal2004generalized

** 2001 - Factor analysis with (mixed) observed and latent variables in  the exponential family :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: Wedel_2001
:AUTHOR:   Wedel \& Kamakura
:JOURNAL:  Psychometrika
:YEAR:     2001
:VOLUME:   66
:PAGES:    515–530
:DOI:      10.1007/bf02296193
:URL:      http://dx.doi.org/10.1007/bf02296193
:END:

cite:Wedel_2001
 
*Remark:* ce pdf était dans un dossier SML, mais je ne me rappel plus pk ? Ok
c'est pour Simulated Maximum Likelyhood. C'est truc qui a l'aire utilisé en
econometrie...
 
Contrairement à lfmm il n'y a pas de co-variable, il n'y a que les variables
latentes. C'est pas vraiment un LFMMLike.

C'est papier super dur a comprendre pour moi, en gros je comprend que c'est un
GLM avec les facteurs latents. Il propose une méthode de SML pour estimer les
loadings de son modèle a fateur latents. Ces résultats portent sur des simu de
son modèle et une étude de cas.
 
Pourtant dans le titre il parle de observed data... je pense que c'est les
données en sortie du model.

** TODO - How to perform leave-one-out cross-validation for PCA to  determine the number of principal components?
:PROPERTIES:
:Custom_ID: crossValidated_PCACrossValidation_2017
:AUTHOR:   amoeba
:JOURNAL:
:YEAR:
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:crossValidated_PCACrossValidation_2017
Une super reponse trouvée sur Cross Validated quand je cherchais un moyen de
cross valider une lfmm (j'ai chercher comment cross valider l'acp)
 

** 2011 - Finding Structure with Randomness: Probabilistic Algorithms  for Constructing Approximate Matrix Decompositions :LFMM:
:PROPERTIES:
:Custom_ID: Halko_2011
:AUTHOR:   Halko, Martinsson \& Tropp
:JOURNAL:  SIAM Review
:YEAR:     2011
:VOLUME:   53
:PAGES:    217–288
:DOI:      10.1137/090771806
:URL:      http://dx.doi.org/10.1137/090771806
:END:

cite:Halko_2011
C'est un papier qui était dans la biblio que OF m'avait envoyé en début de
thèse. C'est sur les méthode de randomization pour les approximation de rang
faible. 

Je pense que l'idée c'est de faire des projections aléatoires et trouver a
décomposition. C'est peut être interessant pour améloirer les perfs de lfmm.

** 2010 - Correction for hidden confounders in the genetic analysis of  gene expression :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: Listgarten_2010
:AUTHOR:   Listgarten, Kadie, Schadt, Heckerman \&
:JOURNAL:  Proceedings of the National Academy of Sciences
:YEAR:     2010
:VOLUME:   107
:PAGES:    16465–16470
:DOI:      10.1073/pnas.1002425107
:URL:      http://dx.doi.org/10.1073/pnas.1002425107
:END:

cite:Listgarten_2010
On est en plein dans la correction de s facteurs de confusion pour l'analyse
de l'expression des gènes (population structure, batch effects). 
Il y a un [[file:org-ref-pdfs/SI_Listgarten_2010.pdf][SI Apprendix]].
Ils vendent une méthode qui prend en compte a la fois la sutructure de pop(PS) et
Expression Heterogeneity (EH).
*** Application
C'est pour des eQTL scan. C'est a dire qu'on cherche les liens entre
polymophisme et expression des gènes. D'après Magalie, les jeux de données
sont plus petit dans les eQTLs scan, on fait des croisements d'indiv, c'est
plus de l'experience a petite echelle. 

Pourtant les application son sur des gros jeux de données !!
*** Method
Un mixed model ou la sortie est les gene probes (une mesure de l'expression)
et la co-variable le SNP. L'hypothèse H0 est il n'y a pas corrélation entre
SNP et expression du gène, pour la bio ce n'est pas un eQTL. Si on rejète H0
c'est un eQTL
*** Experiments
**** Synthetic dataset
Il fit leur modèle et utilise le modèle génératif pour simuler des gene
probe (la sortie du modèle), pour 5% il multiplie les B trouvé par un
facteur. Ca leur génère 5% loci sous H1.
*** Remarques
Leur méthode à le même objectif que lfmm, c'est a dire association avec
variable lattente. Mais il on une application cible les eQTL scan. Pour moi
c'est les test d'asssociations plymorphism-var ecologique. Et je veux
montrer qu'on peut faire des EWAS aussi... enfin si ca marche :D
*** TODO Aller plus loin
Le papier est complet, faudrait que je vois leur test d'hypothèse.
** TODO 2004 - Mixed Models                                            :LFMM:
:PROPERTIES:
:Custom_ID: Demidenko_2004
:AUTHOR:   Demidenko
:JOURNAL:  Wiley Series in Probability and Statistics
:YEAR:     2004
:VOLUME:
:PAGES:
:DOI:      10.1002/0471728438
:URL:      http://dx.doi.org/10.1002/0471728438
:END:

cite:Demidenko_2004
C'est le livre qui est cité dans cite:Listgarten_2010 pour citer les Mixed
Models.

** TODO - Generalized Linear Mixed Model                               :LFMM:
:PROPERTIES:
:Custom_ID: GLMM
:AUTHOR:
:JOURNAL:
:YEAR:
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

J'ai trouvé ca dans la bib d'of pour lfmm. cite:GLMM.

C'est un cours sur les modèle mixte généralisé, c'est a dire avec d'autre distribution
que la loi normale.

** 1996 - Latent Variable Models with Fixed Effects           :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: Sammel_1996
:AUTHOR:   Sammel \& Ryan
:JOURNAL:  Biometrics
:YEAR:     1996
:VOLUME:   52
:PAGES:    650
:DOI:      10.2307/2532903
:URL:      http://dx.doi.org/10.2307/2532903
:END:

cite:Sammel_1996 Papier trouvé dans la biblio que OF m'a donnée en début de thèse.
*** Model 
Le modèle est comme LFMM avec en plus des co-variable pour modéliser les
facteurs lattents. Il y a un test d'hypothèse pour test l'effet des covariables
avec les facteurs lattents.
*** Experiments
Sur des données réelles dirrecte

** TODO 2003 - Some applications of generalized linear latent and mixed models in epidemiology: repeated measures, measurement error and multilevel modeling :LFMM:GLLAMM:
:PROPERTIES:
:Custom_ID: skrondal2003some
:AUTHOR:   Skrondal \& Rabe-Hesketh
:JOURNAL:  Norsk epidemiologi
:YEAR:     2003
:VOLUME:   13
:PAGES:    265--278
:DOI:
:URL:
:END:

cite:skrondal2003some Papier trouvé dans la biblio que OF m'a donnée en début
de thèse.

** TODO 1981 - The bayesian bootstrap                                  :LFMM:
:PROPERTIES:
:Custom_ID: rubin1981bayesian
:AUTHOR:   Rubin \& others
:JOURNAL:  The annals of statistics
:YEAR:     1981
:VOLUME:   9
:PAGES:    130--134
:DOI:
:URL:
:END:

cite:rubin1981bayesian Papier trouvé dans la biblio que OF m'a donnée en début
de thèse.

 

** TODO 2005 - Structural equation models: a review with applications to environmental epidemiology :LFMM:
:PROPERTIES:
:Custom_ID: sanchez2005structural
:AUTHOR:   Sanchez, Budtz-J\orgensen, Ryan \& Hu
:JOURNAL:  Journal of the American Statistical Association
:YEAR:     2005
:VOLUME:   100
:PAGES:    1443--1455
:DOI:
:URL:
:END:
 
cite:sanchez2005structural Papier trouvé dans la biblio que OF m'a donnée en
début de thèse.

** TODO 2007 - Latent Variable Modelling: A Survey*                    :LFMM:
:PROPERTIES:
:Custom_ID: SKRONDAL_2007
:AUTHOR:   SKRONDAL \& RABE-SKETH
:JOURNAL:  Scandinavian Journal of Statistics
:YEAR:     2007
:VOLUME:   34
:PAGES:    712–745
:DOI:      10.1111/j.1467-9469.2007.00573.x
:URL:      http://dx.doi.org/10.1111/j.1467-9469.2007.00573.x
:END:

cite:SKRONDAL_2007 Papier trouvé dans la biblio que OF m'a donnée en début de
thèse.

** TODO 2010 - Conditions Under Which Genome-Wide Association Studies Will be  Positively Misleading :LFMM:
:PROPERTIES:
:Custom_ID: Platt_2010
:AUTHOR:   Platt, Vilhjalmsson \& Nordborg
:JOURNAL:  Genetics
:YEAR:     2010
:VOLUME:   186
:PAGES:    1045–1052
:DOI:      10.1534/genetics.110.121665
:URL:      http://dx.doi.org/10.1534/genetics.110.121665
:END:

cite:Platt_2010 Papier trouvé dans la biblio que OF m'a donnée en début de
thèse.

** TODO 2007 - Classical latent variable models for medical research   :LFMM:
:PROPERTIES:
:Custom_ID: Rabe_Hesketh_2007
:AUTHOR:   Rabe-Hesketh \& Skrondal
:JOURNAL:  Statistical Methods in Medical Research
:YEAR:     2007
:VOLUME:   17
:PAGES:    5–32
:DOI:      10.1177/0962280207081236
:URL:      http://dx.doi.org/10.1177/0962280207081236
:END:

cite:Rabe_Hesketh_2007 Papier trouvé dans la biblio que OF m'a donnée en début
de thèse.

** TODO 2013 - Latent factor regression models for grouped outcomes    :LFMM:
:PROPERTIES:
:Custom_ID: Woodard_2013
:AUTHOR:   Woodard, Love, Thurston, , Ruppert, Sathyanarayana \& Swan
:JOURNAL:  Biometrics
:YEAR:     2013
:VOLUME:   69
:PAGES:    785–794
:DOI:      10.1111/biom.12037
:URL:      http://dx.doi.org/10.1111/biom.12037
:END:

cite:Woodard_2013 Papier trouvé dans la biblio que OF m'a donnée en début de
thèse.

** TODO 2004 - GLLAMM manual                                    :LFMM:GLLAMM:
:PROPERTIES:
:Custom_ID: rabe2004gllamm
:AUTHOR:   Rabe-Hesketh, Skrondal \& Pickles
:JOURNAL:
:YEAR:     2004
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:rabe2004gllamm Papier trouvé dans la biblio que OF m'a donnée en début de
thèse.

** 2004 - Convex Optimization                                          :Book:
:PROPERTIES:
:Custom_ID: Boyd_2004
:AUTHOR:   Boyd \& Vandenberghe
:JOURNAL:
:YEAR:     2004
:VOLUME:
:PAGES:
:DOI:      10.1017/cbo9780511804441
:URL:      http://dx.doi.org/10.1017/cbo9780511804441
:END:

cite:Boyd_2004

** 2009 - Large-Scale Inference                                        :Book:
:PROPERTIES:
:Custom_ID: Efron_2009
:AUTHOR:   Efron
:JOURNAL:
:YEAR:     2009
:VOLUME:
:PAGES:
:DOI:      10.1017/cbo9780511761362
:URL:      http://dx.doi.org/10.1017/cbo9780511761362
:END:

cite:Efron_2009
 
*** Empirical Null Estimation 
C'est quand on change l'hypothèse null en fonction de ce qu'on a observé.
 
** 2016 - Computer Age Statistical Inference                           :Book:
:PROPERTIES:
:Custom_ID: Efron_2016
:AUTHOR:   Efron \& Hastie
:JOURNAL:
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:      10.1017/cbo9781316576533
:URL:      http://dx.doi.org/10.1017/cbo9781316576533
:END:

cite:Efron_2016

** 1993 - An Introduction to the Bootstrap                             :Book:
:PROPERTIES:
:Custom_ID: Efron_1993
:AUTHOR:   Efron \& Tibshirani
:JOURNAL:
:YEAR:     1993
:VOLUME:
:PAGES:
:DOI:      10.1007/978-1-4899-4541-9
:URL:      http://dx.doi.org/10.1007/978-1-4899-4541-9
:END:
 
cite:Efron_1993

** 2013 - Genome-Wide Association Studies and Genomic Prediction       :Book:
:PROPERTIES:
:Custom_ID: Gondro_2013
:AUTHOR:
:JOURNAL:  Methods in Molecular Biology
:YEAR:     2013
:VOLUME:
:PAGES:
:DOI:      10.1007/978-1-62703-447-0
:URL:      http://dx.doi.org/10.1007/978-1-62703-447-0
:END:

cite:Gondro_2013

** 2009 - The Elements of Statistical Learning                         :Book:
:PROPERTIES:
:Custom_ID: Hastie_2009
:AUTHOR:   Hastie, Tibshirani \& Friedman
:JOURNAL:  Springer Series in Statistics
:YEAR:     2009
:VOLUME:
:PAGES:
:DOI:      10.1007/978-0-387-84858-7
:URL:      http://dx.doi.org/10.1007/978-0-387-84858-7
:END:

cite:Hastie_2009

** 2012 - Machine learning: a probabilistic perspective                :Book:
:PROPERTIES:
:Custom_ID: murphy2012machine
:AUTHOR:   Murphy
:JOURNAL:
:YEAR:     2012
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:murphy2012machine

** 2012 - Analysis of Genetic Association Studies                      :Book:
:PROPERTIES:
:Custom_ID: Zheng_2012
:AUTHOR:   Zheng, Yang, Zhu, Elston \& Robert
:JOURNAL:  Statistics for Biology and Health
:YEAR:     2012
:VOLUME:
:PAGES:
:DOI:      10.1007/978-1-4614-2245-7
:URL:      http://dx.doi.org/10.1007/978-1-4614-2245-7
:END:

cite:Zheng_2012

** TODO 2016 - Controlling the Rate of GWAS False Discoveries :HypothesisTesting:MultipleTesting:
:PROPERTIES:
:Custom_ID: Brzyski_2016
:AUTHOR:   Brzyski, Peterson, Sobczyk, , Candès, Bogdan, Sabatti \& Chiara
:JOURNAL:  Genetics
:YEAR:     2016
:VOLUME:   205
:PAGES:    61–75
:DOI:      10.1534/genetics.116.193987
:URL:      http://dx.doi.org/10.1534/genetics.116.193987
:END:

cite:Brzyski_2016

** TODO 2016 - Orthogonal Tensor Decompositions Via Two-Mode Higher-Order Svd  (hosvd)
:PROPERTIES:
:Custom_ID: wang16_orthog_tensor_decom_via_two
:AUTHOR:   Wang \& Song
:JOURNAL:
:YEAR:     2016
:VOLUME:
:PAGES:
:DOI:
:URL:      http://arxiv.org/abs/1612.03839v1
:END:

cite:wang16_orthog_tensor_decom_via_two. Envoyé par OF "ca peut t'interessé".
C'est papier théorique sur la décomposition matricielle...

** TODO 2015 - The role of regulatory variation in complex traits and  disease
:PROPERTIES:
:Custom_ID: Albert_2015
:AUTHOR:   Albert \& Kruglyak
:JOURNAL:  Nature Reviews Genetics
:YEAR:     2015
:VOLUME:   16
:PAGES:    197–212
:DOI:      10.1038/nrg3891
:URL:      http://dx.doi.org/10.1038/nrg3891
:END:

cite:Albert_2015. Papier que Magalie m'a envoyé pour comprendre le eQTL stidies.

** TODO 2006 - Principal components analysis corrects for stratification in  genome-wide association studies :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: Price_2006
:AUTHOR:   Price, Patterson, Plenge, , Weinblatt, Shadick \& Reich
:JOURNAL:  Nature Genetics
:YEAR:     2006
:VOLUME:   38
:PAGES:    904–909
:DOI:      10.1038/ng1847
:URL:      http://dx.doi.org/10.1038/ng1847
:END:

cite:Price_2006. C'est le papier EIGENSTRAT, c'est l'acp et une stat Armitage.
 

** 2012 - The sva package for removing batch effects and other unwanted  variation in high-throughput experiments :LFMM:LFMMLike:Rpackage:
:PROPERTIES:
:Custom_ID: Leek_2012
:AUTHOR:   Leek, Johnson, Parker, Jaffe, \& Storey
:JOURNAL:  Bioinformatics
:YEAR:     2012
:VOLUME:   28
:PAGES:    882–883
:DOI:      10.1093/bioinformatics/bts034
:URL:      http://dx.doi.org/10.1093/bioinformatics/bts034
:END:
 
cite:Leek_2012 C'est l'article de pacakge sva. La vignette : [[./org-ref-pdfs/Rpackage_sva.pdf][The SVA manual]].
 

** TODO 1995 - Controlling the false discovery rate: a practical and powerful approach to multiple testing
:PROPERTIES:
:Custom_ID: benjamini1995controlling
:AUTHOR:   Benjamini \& Hochberg
:JOURNAL:  Journal of the royal statistical society. Series B (Methodological)
:YEAR:     1995
:VOLUME:
:PAGES:    289--300
:DOI:
:URL:
:END:

cite:benjamini1995controlling Article classic a citer pour the Benjamini-Hochberg procedure

** TODO 2012 - Multiple hypothesis testing adjusted for latent variables,  with an application to the AGEMAP gene expression data :LFMM:LFMMLike:Rpackage:
:PROPERTIES:
:Custom_ID: Sun_2012
:AUTHOR:   Sun, Zhang \& Owen
:JOURNAL:  The Annals of Applied Statistics
:YEAR:     2012
:VOLUME:   6
:PAGES:    1664–1688
:DOI:      10.1214/12-aoas561
:URL:      http://dx.doi.org/10.1214/12-aoas561
:END:

cite:Sun_2012 C'est très très proche de LFMM encore une fois et il y a un
[[https://cran.r-project.org/web/packages/leapp/][package R LEAPP]]. Il faut que je lise ca plus en détail. 

** TODO 2015 - Confounder Adjustment in Multiple Hypothesis Testing :LFMM:LFMMLike:
:PROPERTIES:
:Custom_ID: wang2015confounder
:AUTHOR:   Wang, Zhao, Hastie \& Owen
:JOURNAL:  arXiv preprint arXiv:1508.04178
:YEAR:     2015
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:wang2015confounder Ok la c'est vraiment du lourd ! C'est de la théorie sur
LFMM en gros, faut que je le lise ! C'est vraiment sans fin cette biblio...
Mais c'est rassurant de voir des gens qui travail sur les même chose ! 

*** CRAN R package
[[https://cran.r-project.org/web/packages/cate/index.html][cate]]
** TODO 2007 - Correlation and Large-Scale Simultaneous Significance Testing
:PROPERTIES:
:Custom_ID: Efron_2007
:AUTHOR:   Efron
:JOURNAL:  Journal of the American Statistical Association
:YEAR:     2007
:VOLUME:   102
:PAGES:    93–103
:DOI:      10.1198/016214506000001211
:URL:      http://dx.doi.org/10.1198/016214506000001211
:END:

cite:Efron_2007 Un papier qui justifie que quand on a des hypothèse corrélées,
la fonction de répartition H0 n'est plus $N(0,1)$

** 2005 - Local False Discovery Rates
:PROPERTIES:
:Custom_ID: cours_Efron_2005
:AUTHOR:   Bradley Efron
:JOURNAL:
:YEAR:     2005
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:
 
cite:cours_Efron_2005 Un pdf pour expliquer le fdr local. Très bien fait ! 

** TODO 2004 - Large-Scale Simultaneous Hypothesis Testing
:PROPERTIES:
:Custom_ID: Efron_2004
:AUTHOR:   Efron
:JOURNAL:  Journal of the American Statistical Association
:YEAR:     2004
:VOLUME:   99
:PAGES:    96–104
:DOI:      10.1198/016214504000000089
:URL:      http://dx.doi.org/10.1198/016214504000000089
:END:

cite:Efron_2004

*** Introduction
Il y phrase interessante dans l'intro, en gros: le but des test d'hypothèse
multiple c'est trouver une liste de candidat qui merite qu'on s'y attarde.
Moi je comprend que une fois qu'on a creer des zscore (il faut des score car
les test doivent etre comprable, donc on les normalise) on peut faire
estimer l'hypothese null sur les données, ca va lisser les erreur, regler
les problème d'autocorélation, enlever les petits effets sans interet et
mettre le test au bonne endroit (si la moyenne est non nul par exemple)!

** TODO 1999 - Genomic Control for Association Studies
:PROPERTIES:
:Custom_ID: Devlin_1999
:AUTHOR:   Devlin \& Roeder
:JOURNAL:  Biometrics
:YEAR:     1999
:VOLUME:   55
:PAGES:    997–1004
:DOI:      10.1111/j.0006-341x.1999.00997.x
:URL:      http://dx.doi.org/10.1111/j.0006-341x.1999.00997.x
:END:
:LOGBOOK:
- State "TODO"       from "TODO"       [2017-04-11 mar. 17:51]
:END:

cite:Devlin_1999 C'est le papier du genomic inflation factor (le gif)

** 2015 - A global reference for human genetic variation
:PROPERTIES:
:Custom_ID: 1000Genome_2015
:AUTHOR:   The 1000 Genomes Project Consortium
:JOURNAL:  Nature
:YEAR:     2015
:VOLUME:   526
:PAGES:    68--74
:DOI:      10.1038/nature1539cite:Auton_20153
:URL:      https://doi.org/10.1038~/Projects/Biblio/org-ref-pdfs/Auton_2015.pdfnature15393
:END:

cite:Auton_2015 To cite the 1000genomes (found [[http://www.internationalgenome.org/faq/how-do-i-cite-1000-genomes-project/][here]])

** TODO 2008 - Cross-validation of component models: A critical look at  current methods
:PROPERTIES:
:Custom_ID: Bro_2008
:AUTHOR:   Bro, Kjeldahl, Smilde, Kiers \&
:JOURNAL:  Analytical and Bioanalytical Chemistry
:YEAR:     2008
:VOLUME:   390
:PAGES:    1241–1251
:DOI:      10.1007/s00216-007-1790-1
:URL:      http://dx.doi.org/10.1007/s00216-007-1790-1
:END:

cite:Bro_2008 Plein de méthodes pour la cross validation de l'acp. C'est
généralisable au méthode non supervisé ! 
 
 
** TODO 2016 - The Simons Genome Diversity Project: 300 genomes from 142 diverse populations
:PROPERTIES:
:Custom_ID: mallick2016simons
:AUTHOR:   Mallick {\it et al.}
:JOURNAL:  Nature
:YEAR:     2016
:VOLUME:   538
:PAGES:    201--206
:DOI:
:URL:
:END:

cite:mallick2016simons Papier du [[https://www.simonsfoundation.org/life-sciences/simons-genome-diversity-project-dataset/][simons diversity project]].
 

** TODO 2011 - Detecting Novel Associations in Large Data Sets
:PROPERTIES:
:Custom_ID: Reshef_2011
:AUTHOR:   Reshef {\it et al.}
:JOURNAL:  Science
:YEAR:     2011
:VOLUME:   334
:PAGES:    1518–1524
:DOI:      10.1126/science.1205438
:URL:      http://dx.doi.org/10.1126/science.1205438
:END:

cite:Reshef_2011
Pk le R^2 de pearson c'est pas bien ... A lIRE

** TODO 2015 - Seven common mistakes in population genetics and how to avoid  them
:PROPERTIES:
:Custom_ID: Meirmans_2015
:AUTHOR:   Meirmans
:JOURNAL:  Molecular Ecology
:YEAR:     2015
:VOLUME:   24
:PAGES:    3223–3231
:DOI:      10.1111/mec.13243
:URL:      http://dx.doi.org/10.1111/mec.13243
:END:

cite:Meirmans_2015 Le nombre d'outlier attendu est petit :D. Pourtant dans
cite:Abraham_2014 il trouve de l'ordre de 1000 locus pour expliquer la maladie celiac.

** TODO - Imputation de données manquantes
:PROPERTIES:
:Custom_ID: imp_don_manquante
:AUTHOR:
:JOURNAL:
:YEAR:
:VOLUME:
:PAGES:
:DOI:
:URL:
:END:

cite:imp_don_manquante

Un cours simple en francais sur les données manquantes. Il liste plien d'algo
pour l'imputation.

** DONE 2017 - Using genotype-environment associations to identify multilocus  local adaptation :GEA:LFMM:
CLOSED: [2017-05-02 mar. 16:07]
:PROPERTIES:
:Custom_ID: Forester_2017
:AUTHOR: Forester, Lasky, Wagner, \& Urban
:JOURNAL: 
:YEAR: 2017
:VOLUME: 
:PAGES: 
:DOI: 10.1101/129460
:URL: http://dx.doi.org/10.1101/129460
:END:
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-02 mar. 16:07]
:END:

cite:Forester_2017 

- Une comparaison des méthodes stat et machine learning pour l'association. Il
parle de la méthode redundancy analysis (RDA).
- Dans cette article il parle Genotype-environment association (GEA).
- Le papier est interessant dans la demarche (comparaison  de méthodes sur des
  simulations). A voir les plots et les simu ! 


** DONE 2015 - Detecting spatial genetic signatures of local adaptation in  heterogeneous landscapes :GEA:LFMM:
CLOSED: [2017-05-02 mar. 14:09]
:PROPERTIES:
:Custom_ID: Forester_2015
:AUTHOR: Forester, Jones, Joost, , Landguth \& Lasky
:JOURNAL: Molecular Ecology
:YEAR: 2015
:VOLUME: 25
:PAGES: 104–120
:DOI: 10.1111/mec.13476
:URL: http://dx.doi.org/10.1111/mec.13476
:END:
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-02 mar. 14:09]
:END:

cite:Forester_2015

- Un autre papier ou ils utilisent RDA pour les GEA
*** Ordination methods
Je comprends que c'est comme du clustering mais le long d'un gradient !! ([[http://ordination.okstate.edu/overview.htm][see this page]])
*** RDA
En faite cette méthodes ne donnent pas de pvalue.
Ils trouvent des outlier a partir de leur projection et calcule des pvalue après
, avec un modèle linéaire.

Mais il n'y a pas de correction pour des quelconce variable lattente ! 

** TODO 1921 - Correlation and causation              :CausalInference:LFMM:
 :PROPERTIES:
  :Custom_ID: wright1921correlation
  :AUTHOR: Wright
  :JOURNAL: Journal of agricultural research
  :YEAR: 1921
  :VOLUME: 20
  :PAGES: 557--585
  :DOI: 
  :URL: 
 :END:

cite:wright1921correlation

Un papier de 1921 qui evoque la diference entre les corrélations et les cause.
Je n'ai pas l'impression qui parle de variable lattente mais plutot de
l'influence de lajout de variable au model quand on calcule des correlations. Ca
fait penser a ce que je connais de l'inference causal ! 

** TODO 2014 - Accurate and Robust Genomic Prediction of Celiac Disease Using  Statistical Learning :LFMM:GWAS:
 :PROPERTIES:
  :Custom_ID: Abraham_2014
  :AUTHOR: Abraham, Tye-Din, Bhalala, , Kowalczyk, Zobel \& Inouye
  :JOURNAL: PLoS Genetics
  :YEAR: 2014
  :VOLUME: 10
  :PAGES: e1004137
  :DOI: 10.1371/journal.pgen.1004137
  :URL: http://dx.doi.org/10.1371/journal.pgen.1004137
 :END:
 
cite:Abraham_2014 

Ils font un modèle de prédiction pour la malidie celiac (pour estimer un facteur
de risque). Dans ce modèle il y a de l'orde du millier de SNIPs causaux ! 
